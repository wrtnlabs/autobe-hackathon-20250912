import { IConnection, HttpError } from "@nestia/fetcher";
import { PlainFetcher } from "@nestia/fetcher/lib/PlainFetcher";
import typia, { tags } from "typia";
import { NestiaSimulator } from "@nestia/fetcher/lib/NestiaSimulator";

import { IPoliticalNewsCrawlerCrawlSchedules } from "../../../../../structures/IPoliticalNewsCrawlerCrawlSchedules";
import { IPoliticalNewsCrawlerCrawlSchedule } from "../../../../../structures/IPoliticalNewsCrawlerCrawlSchedule";
import { IPageIPoliticalNewsCrawlerCrawlSchedule } from "../../../../../structures/IPageIPoliticalNewsCrawlerCrawlSchedule";

/**
 * Create a new political news crawler schedule.
 *
 * Create a new crawling schedule for political news crawling sources.
 *
 * This operation allows authorized systems or administrators to define when and
 * how often a crawl source should be crawled. The crawl schedule includes a
 * cron expression specifying the timing, links to the crawl source and crawl
 * policy to control crawl frequency and backoff strategies, and flags to enable
 * or disable the schedule.
 *
 * Security considerations restrict this operation to authorized roles managing
 * crawling infrastructure.
 *
 * The created schedule is registered in the
 * political_news_crawler_crawl_schedules table, with all required validations
 * for data integrity and foreign key constraints against crawl_sources and
 * crawl_policies.
 *
 * Expected behavior includes returning the newly created schedule with all
 * relevant metadata.
 *
 * Errors are raised for invalid references or conflicting schedules. The
 * operation never supports soft-deletion here, and data is persistently
 * stored.
 *
 * @param props.connection
 * @param props.body Creation info of the crawl schedules
 * @path /politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules
 * @accessor api.functional.politicalNewsCrawler.guest.politicalNewsCrawler.crawlSchedules.create
 * @autobe Generated by AutoBE - https://github.com/wrtnlabs/autobe
 */
export async function create(
  connection: IConnection,
  props: create.Props,
): Promise<create.Response> {
  return true === connection.simulate
    ? create.simulate(connection, props)
    : await PlainFetcher.fetch(
        {
          ...connection,
          headers: {
            ...connection.headers,
            "Content-Type": "application/json",
          },
        },
        {
          ...create.METADATA,
          path: create.path(),
          status: null,
        },
        props.body,
      );
}
export namespace create {
  export type Props = {
    /** Creation info of the crawl schedules */
    body: IPoliticalNewsCrawlerCrawlSchedules.ICreate;
  };
  export type Body = IPoliticalNewsCrawlerCrawlSchedules.ICreate;
  export type Response = IPoliticalNewsCrawlerCrawlSchedules;

  export const METADATA = {
    method: "POST",
    path: "/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules",
    request: {
      type: "application/json",
      encrypted: false,
    },
    response: {
      type: "application/json",
      encrypted: false,
    },
  } as const;

  export const path = () =>
    "/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules";
  export const random = (): IPoliticalNewsCrawlerCrawlSchedules =>
    typia.random<IPoliticalNewsCrawlerCrawlSchedules>();
  export const simulate = (
    connection: IConnection,
    props: create.Props,
  ): Response => {
    const assert = NestiaSimulator.assert({
      method: METADATA.method,
      host: connection.host,
      path: create.path(),
      contentType: "application/json",
    });
    try {
      assert.body(() => typia.assert(props.body));
    } catch (exp) {
      if (!typia.is<HttpError>(exp)) throw exp;
      return {
        success: false,
        status: exp.status,
        headers: exp.headers,
        data: exp.toJSON().message,
      } as any;
    }
    return random();
  };
}

/**
 * Search and list crawl schedules with filtering and pagination.
 *
 * This endpoint provides a paginated list of crawl schedules in the
 * politicalNewsCrawler system. Crawl schedules define when and how often
 * crawling occurs for each configured source, making this information critical
 * for managing crawl frequency and timing.
 *
 * Users can filter results by various criteria including source, policy, and
 * whether the schedule is enabled. Extensive pagination support allows clients
 * to manage large result sets efficiently.
 *
 * Security considerations: Access to crawl schedule listings might be
 * restricted to authorized personnel to prevent information disclosure about
 * crawling operations.
 *
 * The operation interfaces with the underlying
 * political_news_crawler_crawl_schedules table, projecting relevant fields for
 * API clients including schedule expression, last and next crawl timestamps,
 * and enablement status.
 *
 * Response contains a paginated array of crawl schedule summary information for
 * client consumption.
 *
 * @param props.connection
 * @param props.body Search and pagination filter criteria for crawl schedules
 * @path /politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules
 * @accessor api.functional.politicalNewsCrawler.guest.politicalNewsCrawler.crawlSchedules.searchCrawlSchedules
 * @autobe Generated by AutoBE - https://github.com/wrtnlabs/autobe
 */
export async function searchCrawlSchedules(
  connection: IConnection,
  props: searchCrawlSchedules.Props,
): Promise<searchCrawlSchedules.Response> {
  return true === connection.simulate
    ? searchCrawlSchedules.simulate(connection, props)
    : await PlainFetcher.fetch(
        {
          ...connection,
          headers: {
            ...connection.headers,
            "Content-Type": "application/json",
          },
        },
        {
          ...searchCrawlSchedules.METADATA,
          path: searchCrawlSchedules.path(),
          status: null,
        },
        props.body,
      );
}
export namespace searchCrawlSchedules {
  export type Props = {
    /** Search and pagination filter criteria for crawl schedules */
    body: IPoliticalNewsCrawlerCrawlSchedule.IRequest;
  };
  export type Body = IPoliticalNewsCrawlerCrawlSchedule.IRequest;
  export type Response = IPageIPoliticalNewsCrawlerCrawlSchedule.ISummary;

  export const METADATA = {
    method: "PATCH",
    path: "/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules",
    request: {
      type: "application/json",
      encrypted: false,
    },
    response: {
      type: "application/json",
      encrypted: false,
    },
  } as const;

  export const path = () =>
    "/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules";
  export const random = (): IPageIPoliticalNewsCrawlerCrawlSchedule.ISummary =>
    typia.random<IPageIPoliticalNewsCrawlerCrawlSchedule.ISummary>();
  export const simulate = (
    connection: IConnection,
    props: searchCrawlSchedules.Props,
  ): Response => {
    const assert = NestiaSimulator.assert({
      method: METADATA.method,
      host: connection.host,
      path: searchCrawlSchedules.path(),
      contentType: "application/json",
    });
    try {
      assert.body(() => typia.assert(props.body));
    } catch (exp) {
      if (!typia.is<HttpError>(exp)) throw exp;
      return {
        success: false,
        status: exp.status,
        headers: exp.headers,
        data: exp.toJSON().message,
      } as any;
    }
    return random();
  };
}

/**
 * Retrieve detailed crawl schedule by ID.
 *
 * This endpoint retrieves a detailed crawl schedule record identified by its
 * unique UUID from the politicalNewsCrawler system. Crawl schedules configure
 * how crawling jobs are scheduled for specific sources and policies.
 *
 * The operation returns full details of the schedule including its cron
 * expression, timestamps of last and next crawls, enablement state, creation
 * and update times, and links to the associated crawl source and crawl policy.
 *
 * Security considerations: Access may be limited to administrative users due to
 * operational sensitivity of crawl schedule data.
 *
 * Successful retrieval provides a comprehensive data structure representing the
 * specific crawl schedule for backend monitoring or management use cases.
 * Errors such as invalid IDs return appropriate HTTP status codes indicating
 * not found or unauthorized access.
 *
 * @param props.connection
 * @param props.id Unique identifier of the crawl schedule to retrieve
 * @path /politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules/:id
 * @accessor api.functional.politicalNewsCrawler.guest.politicalNewsCrawler.crawlSchedules.getCrawlSchedule
 * @autobe Generated by AutoBE - https://github.com/wrtnlabs/autobe
 */
export async function getCrawlSchedule(
  connection: IConnection,
  props: getCrawlSchedule.Props,
): Promise<getCrawlSchedule.Response> {
  return true === connection.simulate
    ? getCrawlSchedule.simulate(connection, props)
    : await PlainFetcher.fetch(
        {
          ...connection,
          headers: {
            ...connection.headers,
            "Content-Type": "application/json",
          },
        },
        {
          ...getCrawlSchedule.METADATA,
          path: getCrawlSchedule.path(props),
          status: null,
        },
      );
}
export namespace getCrawlSchedule {
  export type Props = {
    /** Unique identifier of the crawl schedule to retrieve */
    id: string & tags.Format<"uuid">;
  };
  export type Response = IPoliticalNewsCrawlerCrawlSchedule;

  export const METADATA = {
    method: "GET",
    path: "/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules/:id",
    request: null,
    response: {
      type: "application/json",
      encrypted: false,
    },
  } as const;

  export const path = (props: Props) =>
    `/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules/${encodeURIComponent(props.id ?? "null")}`;
  export const random = (): IPoliticalNewsCrawlerCrawlSchedule =>
    typia.random<IPoliticalNewsCrawlerCrawlSchedule>();
  export const simulate = (
    connection: IConnection,
    props: getCrawlSchedule.Props,
  ): Response => {
    const assert = NestiaSimulator.assert({
      method: METADATA.method,
      host: connection.host,
      path: getCrawlSchedule.path(props),
      contentType: "application/json",
    });
    try {
      assert.param("id")(() => typia.assert(props.id));
    } catch (exp) {
      if (!typia.is<HttpError>(exp)) throw exp;
      return {
        success: false,
        status: exp.status,
        headers: exp.headers,
        data: exp.toJSON().message,
      } as any;
    }
    return random();
  };
}

/**
 * Update specified political news crawler schedule.
 *
 * Update an existing crawling schedule identified by its ID.
 *
 * Allows modification of cron schedule expression, crawl source and policy
 * references, and enabled status.
 *
 * Only authorized roles can perform update operations.
 *
 * The operation updates the record in the
 * political_news_crawler_crawl_schedules table and returns the updated entity.
 *
 * Robust validation of the input is performed to prevent data inconsistencies.
 *
 * No soft delete behavior is relevant.
 *
 * Errors include not found schedule or invalid foreign keys.
 *
 * @param props.connection
 * @param props.id Target crawl schedule's ID
 * @param props.body Update info for crawl schedule
 * @path /politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules/:id
 * @accessor api.functional.politicalNewsCrawler.guest.politicalNewsCrawler.crawlSchedules.update
 * @autobe Generated by AutoBE - https://github.com/wrtnlabs/autobe
 */
export async function update(
  connection: IConnection,
  props: update.Props,
): Promise<update.Response> {
  return true === connection.simulate
    ? update.simulate(connection, props)
    : await PlainFetcher.fetch(
        {
          ...connection,
          headers: {
            ...connection.headers,
            "Content-Type": "application/json",
          },
        },
        {
          ...update.METADATA,
          path: update.path(props),
          status: null,
        },
        props.body,
      );
}
export namespace update {
  export type Props = {
    /** Target crawl schedule's ID */
    id: string & tags.Format<"uuid">;

    /** Update info for crawl schedule */
    body: IPoliticalNewsCrawlerCrawlSchedules.IUpdate;
  };
  export type Body = IPoliticalNewsCrawlerCrawlSchedules.IUpdate;
  export type Response = IPoliticalNewsCrawlerCrawlSchedules;

  export const METADATA = {
    method: "PUT",
    path: "/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules/:id",
    request: {
      type: "application/json",
      encrypted: false,
    },
    response: {
      type: "application/json",
      encrypted: false,
    },
  } as const;

  export const path = (props: Omit<Props, "body">) =>
    `/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules/${encodeURIComponent(props.id ?? "null")}`;
  export const random = (): IPoliticalNewsCrawlerCrawlSchedules =>
    typia.random<IPoliticalNewsCrawlerCrawlSchedules>();
  export const simulate = (
    connection: IConnection,
    props: update.Props,
  ): Response => {
    const assert = NestiaSimulator.assert({
      method: METADATA.method,
      host: connection.host,
      path: update.path(props),
      contentType: "application/json",
    });
    try {
      assert.param("id")(() => typia.assert(props.id));
      assert.body(() => typia.assert(props.body));
    } catch (exp) {
      if (!typia.is<HttpError>(exp)) throw exp;
      return {
        success: false,
        status: exp.status,
        headers: exp.headers,
        data: exp.toJSON().message,
      } as any;
    }
    return random();
  };
}

/**
 * Delete specified political news crawler schedule.
 *
 * Delete a crawling schedule by its ID.
 *
 * This operation permanently removes the schedule and disables associated crawl
 * jobs.
 *
 * Authorization is restricted to admin roles to ensure controlled operations.
 *
 * No response body is returned. Errors occur if the ID does not exist.
 *
 * This is a hard delete operation reflecting the physical removal of the
 * schedule record in the database.
 *
 * @param props.connection
 * @param props.id Target crawl schedule's ID
 * @path /politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules/:id
 * @accessor api.functional.politicalNewsCrawler.guest.politicalNewsCrawler.crawlSchedules.erase
 * @autobe Generated by AutoBE - https://github.com/wrtnlabs/autobe
 */
export async function erase(
  connection: IConnection,
  props: erase.Props,
): Promise<void> {
  return true === connection.simulate
    ? erase.simulate(connection, props)
    : await PlainFetcher.fetch(
        {
          ...connection,
          headers: {
            ...connection.headers,
            "Content-Type": "application/json",
          },
        },
        {
          ...erase.METADATA,
          path: erase.path(props),
          status: null,
        },
      );
}
export namespace erase {
  export type Props = {
    /** Target crawl schedule's ID */
    id: string & tags.Format<"uuid">;
  };

  export const METADATA = {
    method: "DELETE",
    path: "/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules/:id",
    request: null,
    response: {
      type: "application/json",
      encrypted: false,
    },
  } as const;

  export const path = (props: Props) =>
    `/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules/${encodeURIComponent(props.id ?? "null")}`;
  export const random = (): void => typia.random<void>();
  export const simulate = (
    connection: IConnection,
    props: erase.Props,
  ): void => {
    const assert = NestiaSimulator.assert({
      method: METADATA.method,
      host: connection.host,
      path: erase.path(props),
      contentType: "application/json",
    });
    try {
      assert.param("id")(() => typia.assert(props.id));
    } catch (exp) {
      if (!typia.is<HttpError>(exp)) throw exp;
      return {
        success: false,
        status: exp.status,
        headers: exp.headers,
        data: exp.toJSON().message,
      } as any;
    }
    return random();
  };
}

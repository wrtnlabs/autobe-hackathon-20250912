[{"id":"019946d3-76a0-77dc-9577-6631dfa4ae7c","type":"userMessage","contents":[{"type":"text","text":"begin"}],"created_at":"2025-09-14T06:04:47.648Z"},{"id":"019946d3-7922-7548-a4ea-d72e5e34ad67","type":"assistantMessage","text":"Hello! I'm here to help you plan and develop your backend server. To get started, could you please tell me about the main purpose or goal of the system you want to build? What key tasks or features do you want this backend to support? If you’re unsure, feel free to describe your ideas or the problems you want to solve.","created_at":"2025-09-14T06:04:48.290Z","completed_at":"2025-09-14T06:04:50.066Z"},{"id":"019946d5-49fb-707d-bb99-e1687d2391ef","type":"userMessage","contents":[{"type":"text","text":"I am trying to build a backend application that crawls a lot of information from multiple channels to collect news about politics.\n\nAfter crawling, we need to post-process it with llm for generating useful contents for audiences.\n\nThen, we will serve endpoints that return popular hot topics daily"}],"created_at":"2025-09-14T06:06:47.291Z"},{"id":"019946d5-4c38-712f-b35c-1bdb10116d53","type":"assistantMessage","text":"Thanks for sharing the core idea. Let me summarize what I understand so far:\n\n- The system will crawl news data about politics from multiple information channels.\n- Then it will process that raw data with a large language model (LLM) to generate useful content for audiences.\n- Finally, the system will provide API endpoints that serve hot popular political news topics daily.\n\nTo proceed, I’d like to get more details about each core part:\n\n1. Crawling:\n- What channels or sources do you want to crawl? (news websites, social media, RSS feeds, etc.)\n- How often should crawling run? (hourly, daily, etc.)\n- Do you have specific filtering rules for collecting relevant political news?  \n\n2. Post-processing with LLM:\n- What kind of content do you want to generate exactly? (summaries, analysis, highlights?)\n- Should the system store both raw and processed data?\n- Any preferences for which LLM or processing model to use?\n\n3. Serving endpoints:\n- What endpoints or features are required for hot topics? (top N topics, search, categories?)\n- Do you want any user roles or permissions to access the data?\n\nFeel free to provide as much detail as you can, and I can help break it down step-by-step!","created_at":"2025-09-14T06:06:47.864Z","completed_at":"2025-09-14T06:06:51.888Z"},{"id":"019946da-5860-775a-b3ae-c1fb209afbca","type":"userMessage","contents":[{"type":"text","text":"1. Crawling:\n- Channels and sources are unknown. we need to use all possible ways to collect data. Possibly, we can use tavily and other various known popular sources. Serp apis can be of choices too.\n- crawling schedule should be decided after how each crawling source behaves. Most of the time, it would be from 15~30 minutes, if I give a rough guess.\n- let's focus on South Korean Politics.\n\n2. Post-processing:\n- summaries/highlight would be one feature and analysis would be another feature. any additional features can be brainstormed and added. We should aim for a feature-rich system.\n- System should indeed keep the raw data somewhere in the database or a file storage.\n- we need to use cheap models and use prompt engineering to make them useful.\n\n3. Endpoints:\n- various types of endpoints would be preferred, as frontend can be flexible.\n- there are no permissions or roles."}],"created_at":"2025-09-14T06:12:18.656Z"},{"id":"019946da-5b0c-702a-8a29-8e1f9ad0f4e3","type":"assistantMessage","text":"Thank you for the detailed information. Here’s what I have captured as the core requirements:\n\n1. Crawling:\n- Data collection about South Korean politics from as many sources as possible, including services like Tavily, SERP APIs, and other popular channels.\n- Crawling frequency depends on each source’s behavior, roughly every 15 to 30 minutes.\n- Collect all relevant political news dynamically since exact sources are not fully known in advance.\n\n2. Post-processing with LLM:\n- Generate summaries and highlights as one set of features, and deeper analysis as another.\n- Keep raw crawled data stored in DB or file storage.\n- Use cost-effective LLMs combined with prompt engineering to generate enriched content.\n- System should be extendable to add more content generation features in the future.\n\n3. API Endpoints:\n- Provide various flexible endpoints to serve popular hot political topics daily.\n- No authentication or user roles needed.\n\nBefore I move forward to analyze and generate a structured specification, I want to clarify a few more things:\n\n- For crawling, do you envision the system managing the crawling schedules and coordinating different source crawlers? Or are you planning to plug in existing crawlers or third-party services for this?\n- For storing raw data, do you prefer a database solution, file storage, or a hybrid? Any preferences about data retention duration?\n- For the popular hot topics API, should the system automatically determine popularity (e.g., via views, reactions, or an algorithm), or will this be manually curated?\n- Do you want the system to support any real-time or near real-time updates on hot topics, or is daily update sufficient?\n\nPlease let me know your thoughts or anything else you want to add.","created_at":"2025-09-14T06:12:19.340Z","completed_at":"2025-09-14T06:12:23.849Z"},{"id":"019946e1-3954-741c-883b-4b5207b158c9","type":"userMessage","contents":[{"type":"text","text":"- For crawling, let's keep both options. For specific pages that we need to crawl, we crawl. For example, we could crawl new york times or some Korean magazine website. There shouldn't be one source to glean information, in diverse perspective: crawling within fixed website domain, using search engine apis, using news apis, etc. We should take in as much information as possible.\n- I think raw data should be stored in GCP/S3 along with duplication on local file storage. Local file storage should only guarantee TTL of 1 month.\n- we should invent our own algorithms for this. If you want we can brainstorm about this too. But if you are confident, you can proceed.\n- i highly prefer realtime. but there must be considerations with the crawlers since a lot of websites ban continuous crawling."}],"created_at":"2025-09-14T06:19:49.460Z"},{"id":"019946e1-3bcf-743c-b770-9a43eea8a0fd","type":"assistantMessage","text":"Thanks for the clarifications. Here's the refined understanding:\n\n1. Crawling:\n- Use diverse crawling methods all together: direct crawling of specific news websites (e.g., New York Times, Korean magazines), search engine APIs, news APIs, and possibly third-party services like Tavily.\n- Manage dynamic crawling schedules that adapt to each source's behavior.\n- Be mindful of crawling respectfully in real-time with intervals to avoid bans.\n\n2. Storage:\n- Raw crawled data will be stored primarily in cloud object storage (GCP or S3).\n- A local file storage will keep duplicates with a time-to-live (TTL) of 1 month as a fallback.\n\n3. Popularity Algorithm:\n- We will devise a custom algorithm to calculate real-time popularity of political news topics.\n- Real-time or near real-time data serving is preferred but needs to balance crawling constraints.\n\n4. API:\n- Flexible APIs to serve various types of popular hot topics daily or in real-time.\n- No user authentication needed.\n\nIf you agree, I can proceed to analyze this specification into a detailed requirements document that covers the system features, data models, and API needs. Or if you want, we can brainstorm the popularity algorithm approach first. What would you like to do next?","created_at":"2025-09-14T06:19:50.095Z","completed_at":"2025-09-14T06:19:53.160Z"},{"id":"019946e1-d5a2-729c-b994-e4157328fcd4","type":"userMessage","contents":[{"type":"text","text":"We can continue."}],"created_at":"2025-09-14T06:20:29.474Z"},{"type":"analyze","id":"019946ef-4643-72c9-a121-8c2db19fb575","reason":"Initial analysis for a backend system that crawls South Korean political news from multiple sources, stores raw data in cloud and local storage, processes data with cost-effective LLM for summaries, highlights and analysis, and serves real-time popular hot topics with flexible API endpoints and no user roles.","prefix":"politicalNewsCrawler","roles":[{"name":"guest","description":"Unauthenticated users who can access public endpoints to retrieve news and popular topics.","kind":"guest"}],"files":[{"reason":"To provide a comprehensive overview of the political news crawler service, its purpose, business model, and strategic goals.","filename":"01-service-overview.md","documentType":"service-overview","outline":["Introduction","Business Model","Service Vision","Core Features","Success Metrics"],"content":"# Functional Requirements Specification for Political News Crawler Backend\n\n## 1. Introduction\n\nThe politicalNewsCrawler backend service is designed to collect, process, and serve political news with a primary focus on South Korean politics. It aggregates news data from diverse sources such as fixed news websites, search engine APIs, and third-party news providers. The system processes collected data using large language models (LLMs) to generate enriched contents like summaries, highlights, and analyses to provide value to audiences. The service also computes real-time popularity metrics to present hot political topics.\n\nThis document specifies comprehensive business requirements for backend developers to implement the core functionalities required to meet user and business needs. It focuses on business rules, workflows, data management, processing, and API delivery without prescribing technical implementation details.\n\n## 2. Crawling Requirements\n\n### 2.1 Multi-Source Data Collection\n\n- THE system SHALL collect political news data primarily related to South Korean politics from diverse sources combining:\n  - Direct crawling within fixed website domains (e.g., New York Times, Korean magazine sites).\n  - Utilizing search engine APIs such as SERP to discover relevant news dynamically.\n  - Using third-party news APIs and aggregator services such as Tavily.\n\n### 2.2 Crawling Scheduling and Frequency\n\n- WHEN initiating crawling for a source, THE system SHALL determine crawling frequency based on source update behavior with typical intervals within 15 to 30 minutes.\n- THE system SHALL support adaptive scheduling to adjust frequency or temporarily suspend crawling based on source response or ban detection.\n- THE system SHALL coordinate crawling tasks to avoid making excessive or parallel requests that might trigger bans.\n\n### 2.3 Data Filtering and Relevance\n\n- THE system SHALL filter crawled data to retain only news relevant to South Korean political topics, using content filtering and source meta-information.\n\n### 2.4 Error and Ban Handling\n\n- IF crawler encounters failures such as HTTP errors, bans, or throttling,\n  THEN THE system SHALL log the event, notify monitoring services, and employ exponential backoff retry mechanisms.\n- IF a source issues bans or blocks persistently,\n  THEN THE system SHALL suspend crawling for the affected source temporarily and generate alerts.\n\n### 2.5 Real-Time Crawling Considerations\n\n- WHERE possible, THE system SHALL operate to keep data freshness high with near real-time crawling respecting crawling constraints.\n- THE system SHALL balance crawl frequency and source compliance to avoid IP bans or service denial.\n\n## 3. Data Storage Requirements\n\n### 3.1 Raw Data Storage\n\n- THE system SHALL store all raw crawled data persistently in cloud object storage (e.g., GCP, AWS S3).\n- A duplicate copy of raw data SHALL be maintained on local file storage to serve as a cache and backup.\n\n### 3.2 Local Storage TTL\n\n- THE system SHALL enforce a strict Time To Live (TTL) policy such that local storage copies older than one month are deleted automatically.\n\n### 3.3 Duplication and Consistency\n\n- THE system SHALL manage data duplication to prevent redundant storage and maintain consistency between cloud and local storage.\n- THE system SHALL implement synchronization and verification routines to ensure data integrity.\n\n## 4. LLM Post-Processing Requirements\n\n### 4.1 Cost-Effective LLM Usage\n\n- WHEN selecting LLM models, THE system SHALL prioritize low cost models supplemented by prompt engineering to maximize utility.\n\n### 4.2 Content Generation Feature Set\n\n- THE system SHALL generate at least two feature types from raw news data:\n  - Summaries and highlights that condense key points of the articles.\n  - Analytical content providing deeper contextual insights on political topics.\n- The system SHALL be designed to support additional features iteratively.\n\n### 4.3 Processing Pipeline\n\n- WHEN new raw data is available, THE system SHALL enqueue it for LLM post-processing promptly.\n- THE system SHALL meet processing latency targets to deliver content in near real-time.\n\n### 4.4 Data Retention for Processed Content\n\n- THE system SHALL store processed content alongside raw data with metadata including generation timestamp and source reference.\n\n### 4.5 Error Handling\n\n- IF LLM processing fails, THEN THE system SHALL implement retry mechanisms with exponential backoff and escalations if failures persist.\n\n## 5. Popularity Algorithm Requirements\n\n### 5.1 Popularity Metric Design\n\n- THE system SHALL calculate topic popularity considering metrics such as:\n  - Recency of news articles mentioning the topic.\n  - Frequency and volume of articles on the topic.\n  - Source diversity, favoring topics covered by multiple sources.\n  - Proxy user engagement signals derived from content volume or analysis features.\n  - Geographical relevance to South Korean politics.\n\n### 5.2 Algorithm Processing Steps\n\n- THE system SHALL aggregate articles by topic within a predefined window (e.g., last 24 hours).\n- Calculate normalized popularity scores using decay functions to prioritize recent and diverse coverage.\n\n### 5.3 Real-Time Computation\n\n- Popularity metrics SHALL be updated in near real-time with configurable intervals not exceeding 15 minutes where feasible.\n- THE system SHALL implement incremental update mechanisms for computational efficiency.\n\n### 5.4 Adaptive Scaling and Failure Handling\n\n- THE system SHALL adapt processing loads based on data volume and usage patterns.\n- If algorithms fail, THE system SHALL fallback to the last known stable state.\n\n## 6. API Endpoint Requirements\n\n### 6.1 Endpoint Types\n\n- THE system SHALL expose flexible API endpoints including:\n  - Retrieval of latest political news items with filtering (date, source, category).\n  - Retrieval of top popular hot topics with popularity scores.\n  - Access to generated content such as summaries and analyses.\n  - Real-time or near real-time update endpoints for hot topics.\n  - Health check and metadata endpoints.\n\n### 6.2 Access and Permissions\n\n- API endpoints SHALL be publicly accessible without authentication.\n\n### 6.3 Response Structure\n\n- Responses SHALL include metadata to justify topic rankings.\n- News items SHALL have identifiers, source info, crawling timestamp, raw content references, and processed content where available.\n\n### 6.4 Performance and Error Handling\n\n- API response times SHALL be under 2 seconds under normal load.\n- IF data is temporarily unavailable, THEN clear error messages SHALL be returned.\n- Invalid requests SHALL receive explicit error responses.\n\n## 7. Non-Functional Requirements\n\n### 7.1 Performance Metrics\n\n- The system SHALL deliver popular topics with less than 5 minutes latency from data ingestion.\n- Endpoint response times SHALL be 2 seconds or less typically; 5 seconds under high load.\n- Crawl concurrency SHALL support at least 10 parallel sources.\n\n### 7.2 Rate Limiting and Respectful Crawling\n\n- Crawling intervals SHALL respect source limits; minimum interval 15 minutes.\n- Back-off on HTTP 429 or 403 errors SHALL be implemented.\n\n### 7.3 Reliability and Scalability\n\n- System availability SHALL be 99.9% uptime.\n- Data storage shall be redundant with backups.\n- The system SHALL scale horizontally as demand grows.\n\n### 7.4 Compliance and Ethics\n\n- Respect robots.txt and source TOS for crawling.\n- Avoid sensitive data collection.\n- Comply with relevant data protection laws.\n\n## 8. Analytics and Reporting\n\n### 8.1 Crawling Monitoring\n\n- Track crawl success rates, failure reasons, and latency.\n- Alert on failure rates and bans.\n\n### 8.2 Processing Metrics\n\n- Monitor queue sizes, success/failure rates, and processing times for LLM tasks.\n- Trigger alerts on error thresholds.\n\n### 8.3 API Usage\n\n- Log and analyze call volumes, response times, and errors.\n- Alert on abnormal traffic or error increases.\n\n### 8.4 Popularity Trend Reporting\n\n- Generate daily topic popularity reports and trends over multiple time windows.\n\n## 9. Glossary\n\n- **Crawler**: Component fetching news data.\n- **LLM**: Large Language Model used for content processing.\n- **TTL**: Time To Live for cached data.\n- **Popularity Algorithm**: Business logic for trending topic identification.\n\n\n---\n\n```mermaid\ngraph LR\n  subgraph \"Crawling and Data Collection\"\n    A[\"Start Crawling\"] --> B{\"Fixed Domain?\"}\n    B -->|\"Yes\"| C[\"Direct Crawling\"]\n    B -->|\"No\"| D[\"API-Based Crawling\"]\n    C --> E[\"Filter for South Korean Politics\"]\n    D --> E\n    E --> F[\"Store Raw Data\"]\n  end\n\n  subgraph \"Post-Processing with LLM\"\n    F --> G[\"Enqueue Data for LLM Processing\"]\n    G --> H[\"Generate Summaries and Analysis\"]\n    H --> I[\"Store Processed Content\"]\n  end\n\n  subgraph \"Popularity Computation\"\n    I --> J[\"Compute Popularity Scores\"]\n    J --> K[\"Update Popular Topics\"]\n  end\n\n  subgraph \"API Serving\"\n    K --> L[\"Serve API Requests\"]\n  end\n\n  F -.->|\"Errors/Bans\"| M[\"Backoff and Alerts\"]\n```\n\nThis specification defines explicit, measurable, and testable business requirements. It provides clarity for backend developers to implement an efficient, compliant, and scalable political news crawler backend service. All technical design, API details, and storage implementation specifics are at the developers' discretion.\n"},{"reason":"To define the complete list of user roles and authentication specifications for the system, clarifying role permissions and access rules.","filename":"02-user-roles.md","documentType":"requirement","outline":["Overview of User Roles","Authentication Flow Requirements","Role Descriptions and Permissions","Token Management and Security","Permission Matrix"],"content":"# Political News Crawler - Analytics and Reporting Requirements\n\n## 1. Introduction\n\nThis document specifies the business requirements for the analytics and reporting components of the Political News Crawler backend system. The purpose is to ensure comprehensive monitoring of system health, detailed metrics on data processing pipelines, insightful API usage analytics, popularity trend reports, and timely alerts. These capabilities are critical to maintain operational excellence, understand user engagement, and guide ongoing improvements.\n\nThis document focuses exclusively on business-level analytics requirements, describing what data must be collected, tracked, and reported. It does not specify how these analytics should be implemented technically.\n\n---\n\n## 2. Crawler Monitoring Requirements\n\nThe system shall provide real-time and historical monitoring of the crawling subsystems, including diverse source management and scheduling efficiency.\n\n### 2.1 Metrics to Track\n- Number of successful crawls per source within configurable intervals\n- Number of failed crawl attempts per source and failure reasons\n- Crawling latency and duration statistics per source\n- Current crawl queue length and processing backlog\n- Number of ban detections or throttling events\n- Source-specific crawl frequency and any deviations\n\n### 2.2 Monitoring Features\n- WHEN the crawler is operational, THE system SHALL aggregate crawl success and failure data in real-time.\n- WHEN crawl errors or bans occur, THE system SHALL log these events with detailed metadata.\n- WHEN a source changes crawl behavior (e.g., slowing down), THE system SHALL flag this for review.\n- THE system SHALL maintain crawl history data for at least 30 days for trend analysis.\n\n### 2.3 Alerts\n- IF crawling failure rate per source exceeds 10% over a rolling 1 hour, THEN THE system SHALL generate an alert.\n- IF a source is detected as banning the crawler excessively, THEN THE system SHALL generate an alert and suggest schedule adjustment.\n\n---\n\n## 3. Processing Pipeline Metrics\n\nThis section covers the large language model post-processing analytics.\n\n### 3.1 Metrics to Track\n- Number of raw data items queued for processing\n- Processing throughput (items per minute/hour)\n- Success rate of processing tasks\n- Error rate and types in LLM processing\n- Average processing time per item\n\n### 3.2 Monitoring Features\n- THE system SHALL provide dashboards showing pipeline status, queue depths, and historical throughput.\n- WHEN an error in processing occurs, THE system SHALL log details for troubleshooting.\n- THE system SHALL store processing statistics with granularity sufficient to analyze hourly trends.\n\n### 3.3 Alerts\n- IF processing queue length exceeds configurable threshold for more than 15 minutes, THEN THE system SHALL generate a performance alert.\n- IF processing error rate exceeds 5%, THEN THE system SHALL generate an alert.\n\n---\n\n## 4. API Usage Analytics\n\n### 4.1 Metrics to Track\n- Number of API calls per endpoint, aggregated by minute/hour/day\n- Number of unique API consumers (e.g., unique IPs or API keys if any)\n- Most requested hot topic categories or query parameters\n- Average response times per endpoint\n- Number of API errors and error codes returned\n\n### 4.2 Monitoring Features\n- THE system SHALL track and store API usage metrics continuously.\n- THE system SHALL provide time-series reports for usage trends.\n- THE system SHALL segment data by endpoint and significant query parameters.\n\n### 4.3 Alerts\n- IF API error rate exceeds 3% over a 1-hour period, THEN THE system SHALL generate an operational alert.\n- IF API traffic spikes beyond historical averages by 2x, THEN THE system SHALL generate a traffic anomaly alert.\n\n---\n\n## 5. Popularity Trend Reports\n\n### 5.1 Reports\n- THE system SHALL generate daily summaries of the top popular political topics.\n- THE system SHALL provide trend analysis reports showing the rise or fall of topics over configurable time windows (e.g., 1 day, 3 days, 7 days).\n- THE system SHALL track source distribution contributing to popular topics.\n\n### 5.2 Data Retention and Access\n- THE system SHALL retain trend data for at least 90 days.\n- THE system SHALL allow export of popularity trends in common formats for offline analysis.\n\n---\n\n## 6. Alerts and Reporting\n\n### 6.1 Alerting Framework\n- THE system SHALL allow configuring alert thresholds for all key metrics.\n- THE system SHALL support real-time notifications via system logs or external notification services.\n\n### 6.2 Reporting Features\n- THE system SHALL provide scheduled reports (daily, weekly) of crawler and processing health.\n- THE system SHALL provide custom report generation on demand.\n- THE system SHALL allow export of reports in standard document formats.\n\n---\n\n## 7. Business Rules and Constraints\n- THE system SHALL ensure analytics data is collected in compliance with crawling rate limits to avoid source bans.\n- THE system SHALL guarantee data accuracy and freshness suitable for near real-time monitoring.\n- THE system SHALL maintain separation of raw data metrics and processed content metrics.\n- THE system SHALL provide API usage anonymization where applicable to protect consumer privacy.\n\n---\n\n## 8. Performance Requirements\n- Analytics dashboards and reports SHALL update within 1 minute of underlying data availability.\n- Alerts SHALL trigger within 5 minutes of threshold breaches.\n\n---\n\n## 9. Glossary\n- Crawl Source: Any external website, API, or service from which political news data is collected.\n- LLM Processing: Large Language Model based content post-processing like summarization or analysis.\n- API Endpoint: Exposed interface serving processed news data and trending topics.\n- Popularity Trend: Metrics defining which political topics are hot or rising in user interest.\n\n---\n\nThis document provides business requirements only. All technical implementation decisions belong to developers, who have full autonomy on backend architecture, data storage, analytics tooling, and reporting mechanisms. The document solely specifies WHAT the analytics and reporting system must achieve, not HOW it must be built.\n\n\n\n```mermaid\ngraph LR\n  subgraph \"Crawler Monitoring\"\n    A[\"Start Crawl Process\"] --> B{\"Crawl Success?\"}\n    B -->|\"Yes\"| C[\"Record Success Metrics\"]\n    B -->|\"No\"| D[\"Record Failure Metrics\"]\n    D --> E[\"Log Failure Reason\"]\n    E --> F[\"Check for Ban or Throttle\"]\n    F --> G{\"Ban Detected?\"}\n    G -->|\"Yes\"| H[\"Generate Alert for Ban\"]\n    G -->|\"No\"| I[\"Adjust Schedule if Needed\"]\n  end\n\n  subgraph \"Processing Pipeline Metrics\"\n    J[\"Start Processing Item\"] --> K{\"Processing Success?\"}\n    K -->|\"Yes\"| L[\"Record Processing Metrics\"]\n    K -->|\"No\"| M[\"Log Processing Error\"]\n    M --> N[\"Generate Error Alert if Needed\"]\n  end\n\n  subgraph \"API Usage Analytics\"\n    O[\"Receive API Call\"] --> P[\"Record API Call Data\"]\n    P --> Q{\"Error Rate High?\"}\n    Q -->|\"Yes\"| R[\"Generate API Error Alert\"]\n    Q -->|\"No\"| S[\"Continue Normal Operation\"]\n  end\n\n  subgraph \"Popularity Trend Reporting\"\n    T[\"Aggregate Popular Topic Data\"] --> U[\"Generate Daily Trend Reports\"]\n    U --> V[\"Store Trend Data 90 Days\"]\n  end\n\n  H --> W[\"Notify Operations Team\"]\n  N --> W\n  R --> W\n\n```"},{"reason":"To specify the detailed functional requirements of the system including crawling, processing, storing, and API services.","filename":"03-functional-requirements.md","documentType":"requirement","outline":["Crawling Requirements","Data Storage Requirements","LLM Post-Processing Requirements","Popularity Algorithm Requirements","API Endpoint Requirements"],"content":"# Functional Requirements Specification for Political News Crawler Backend\n\n## 1. Introduction\n\nThis document specifies the detailed functional business requirements for the \"politicalNewsCrawler\" backend system. Its purpose is to enable backend developers to build a robust, scalable service that crawls political news from diverse sources, processes this data using cost-effective large language models (LLMs), stores raw and processed data appropriately, computes real-time popularity of news topics, and exposes flexible API endpoints for frontend use. This document focuses exclusively on business requirements, not on technical implementation details.\n\nThe service primarily targets news on South Korean politics by aggregating information from multiple distinct channels including direct website crawling, search engine APIs, third-party news APIs, and public data aggregators.\n\n## 2. Crawling Requirements\n\n### 2.1 Overview\nThe system shall collect political news related to South Korean politics from as many diverse sources as possible to provide a wide, multiperspective view. This includes:\n- Direct crawling of news websites (e.g., New York Times, Korean magazines)\n- Using search engine APIs (e.g., SERP APIs)\n- Utilizing third-party news APIs (e.g., Tavily)\n\n### 2.2 Crawling Scheduling\n- WHEN the system initializes crawling for a given source, THE system SHALL determine and adapt crawling frequency based on the source's update patterns.\n- THE system SHALL attempt crawling intervals typically between 15 and 30 minutes per source unless adjusted for source limitations or bans.\n- The system SHALL comply with each source's crawling policies to avoid bans, including respecting rate limits and crawl delays.\n\n### 2.3 Crawling Modes\n- THE system SHALL support multiple crawling methods:\n  - Focused crawling within fixed website domains.\n  - Search queries through search engine APIs to discover news articles.\n  - Consuming news through official news APIs from various providers.\n- THE system SHALL allow configuration of specific website domains to crawl directly.\n\n### 2.4 Data Filtering\n- THE system SHALL only collect data relevant to South Korean politics based on source meta-information and text content filtering.\n\n### 2.5 Error and Ban Handling\n- IF crawling of a source is denied or results in errors due to bans or forbiddance,\n  THEN THE system SHALL back off and retry with exponential delay and notify system monitoring components.\n\n### 2.6 Real-Time Considerations\n- WHEN possible, THE system SHALL crawl frequently and process data for near real-time updates.\n- THE system SHALL limit crawling speed to avoid triggering source bans while maintaining freshness.\n\n## 3. Data Storage Requirements\n\n### 3.1 Raw Data Storage\n- THE system SHALL store all raw crawled data permanently in cloud object storage services such as Google Cloud Storage (GCP) or Amazon S3.\n- THE system SHALL maintain a duplicate copy of raw data in local file storage.\n\n### 3.2 Local Storage TTL\n- THE system SHALL enforce a Time To Live (TTL) policy on local file storage copies such that files older than one month are deleted.\n\n### 3.3 Data Integrity and Duplication\n- THE system SHALL manage and track duplication of data to prevent redundant storage.\n- THE system SHALL provide mechanisms to verify consistency between cloud and local storage.\n\n## 4. LLM Post-Processing Requirements\n\n### 4.1 Overview\n- THE system SHALL process raw news data using large language models (LLMs) to generate value-added content.\n- THE system SHALL use inexpensive LLM variants and optimize prompt engineering techniques to achieve cost efficiency.\n\n### 4.2 Content Generation Features\n- THE system SHALL generate at least two distinct content types:\n  - Summaries and Highlights: concise rendition of articles.\n  - Analysis: deeper, contextual insights on political news.\n- THE system SHALL be designed to support additional future content generation features as they are identified and prioritized.\n\n### 4.3 Data Retention\n- THE system SHALL store both raw data and generated processed content.\n- THE system SHALL maintain metadata tracking for each piece of content including generation time and source.\n\n### 4.4 Processing Pipeline\n- WHEN new raw news data is available,\n  THEN THE system SHALL enqueue it for LLM processing.\n- THE system SHALL prioritize timely processing to support near real-time availability of processed content.\n\n## 5. Popularity Algorithm Requirements\n\n### 5.1 Popularity Computation Goals\n- THE system SHALL compute popularity scores for political news topics based on custom, proprietary algorithms.\n\n### 5.2 Metrics Considered\n- THE system SHALL consider multiple signals such as article frequency, source authority, recency, user engagement metrics (if available), and content affinity.\n\n### 5.3 Real-Time Processing\n- The popularity algorithms SHALL operate in real-time or near real-time to enable up-to-date hot topic identification.\n- The system SHALL balance real-time responsiveness with crawling and processing constraints.\n\n### 5.4 Adaptive Scaling\n- THE system SHALL adjust algorithm parameters dynamically based on traffic loads and data volumes to maintain performance.\n\n## 6. API Endpoint Requirements\n\n### 6.1 Endpoint Flexibility\n- THE system SHALL provide a set of flexible API endpoints for frontend consumption.\n- THE endpoints SHALL include:\n  - Retrieval of top N popular political topics, refreshed daily or in near real-time.\n  - Query endpoints supporting filters such as category, time range, or keyword search.\n\n### 6.2 Access and Permissions\n- THE system SHALL expose all endpoints without user authentication or role-based access control.\n\n### 6.3 Response Requirements\n- THE API responses SHALL include metadata sufficient to justify popularity rankings.\n- THE responses SHALL provide both summary/highlight and analytical content where available.\n\n### 6.4 Performance Expectations\n- API responses SHALL be delivered within 2 seconds under typical loads to provide a responsive user experience.\n\n## 7. Glossary and Definitions\n\n- **Crawler**: Component responsible for fetching data from external sources.\n- **LLM (Large Language Model)**: AI models used for natural language processing tasks.\n- **TTL (Time To Live)**: Duration data is retained before being deleted.\n- **Popularity Algorithm**: Custom business logic calculating relevance and interest scores for news topics.\n\n---\n\nThis document provides business requirements only. All decisions regarding technical implementation, system architecture, database design, and API specification are fully within the developers' autonomy. This document describes WHAT the system should do, not HOW it should be built.\n\n---\n\n```mermaid\ngraph LR\n  subgraph \"Crawling Process\"\n    A[\"Start Crawling\"] --> B{\"Is Source Domain Fixed?\"}\n    B -->|\"Yes\"| C[\"Direct Domain Crawl\"]\n    B -->|\"No\"| D[\"Search API or News API Crawl\"]\n    C --> E[\"Filter South Korean Politics News\"]\n    D --> E\n    E --> F[\"Store Raw Data\"]\n    F --> G[\"Enqueue for LLM Processing\"]\n  end\n\n  subgraph \"LLM Processing\"\n    G --> H[\"Generate Summaries and Highlights\"]\n    G --> I[\"Generate Analysis Content\"]\n    H --> J[\"Store Processed Data\"]\n    I --> J\n  end\n\n  subgraph \"Popularity Computation\"\n    J --> K[\"Analyze Data\"]\n    K --> L[\"Calculate Popularity Scores\"]\n    L --> M[\"Prepare API Data\"]\n  end\n\n  subgraph \"API Serving\"\n    M --> N[\"Serve Popular Topics API\"]\n  end\n\n  F -.->|\"Ban/Error Handling\"| O[\"Backoff & Retry Mechanism\"]\n```\n\nThis diagram represents major data flow and business process interactions.\n\n---\n\nDetailed requirements ensure backend developers understand the scope, business logic, and expected system behavior fully and can proceed to design and implementation with clarity and confidence."},{"reason":"To describe user scenarios and workflows for the political news crawler service, including common and edge case interactions.","filename":"04-user-scenarios.md","documentType":"user-story","outline":["Primary User Scenarios","Secondary and Edge Cases","Error Handling"],"content":"# Political News Crawler Backend - Functional and Business Requirements\n\n## 1. Introduction\nThis document defines the complete functional and business requirements for the \"politicalNewsCrawler\" backend system. The system collects political news relevant to South Korean politics from multiple sources using diverse crawling methods and processes this data with cost-effective large language models (LLMs) to generate summaries, highlights, and analysis. It maintains raw and processed data storage, computes popularity scores algorithmically, and exposes flexible API endpoints serving popular hot topics.\n\nThis document focuses on business requirements only, providing backend developers with clear, testable, and implementation-ready specifications. It describes WHAT the system shall do, not HOW it should be built.\n\n## 2. Crawling Requirements\n\n### 2.1 Source Diversity\nTHE system SHALL collect political news by combining multiple crawling approaches, including:\n- Direct crawling of specific known news websites (e.g., New York Times, Korean political magazines).\n- Querying search engine APIs such as SERP APIs.\n- Integrating third-party news APIs and services like Tavily.\n\n### 2.2 Crawling Frequency and Scheduling\n- WHEN the system starts crawling a source, THE system SHALL adapt its crawling frequency based on the update pattern of that source.\n- THE system SHALL typically perform crawling of sources every 15 to 30 minutes, adjusting dynamically to avoid overloading or bans.\n- THE system SHALL comply with each source's crawling policies, respecting rate limits and robots.txt directives.\n\n### 2.3 Crawling Policies\n- THE system SHALL support crawling within fixed website domains where specified.\n- THE system SHALL support generic crawling via search engine or news APIs to maximize coverage.\n- THE system SHALL filter collected data to extract South Korean political news.\n\n### 2.4 Error and Ban Handling\n- WHEN crawling results in errors due to bans, network failures, or denied access, THEN THE system SHALL back off exponentially and notify monitoring systems.\n\n### 2.5 Real-Time Constraints\n- THE system SHALL balance crawling frequency to provide near-real-time updates without violating source restrictions.\n\n## 3. Data Storage Requirements\n\n### 3.1 Raw Data Storage\n- THE system SHALL store raw crawl data permanently in cloud object storage such as Google Cloud Storage or Amazon S3.\n- THE system SHALL maintain a duplicate cache copy in local file storage.\n\n### 3.2 Local Storage TTL\n- THE system SHALL delete local cached raw data older than one month automatically.\n\n### 3.3 Data Consistency\n- THE system SHALL detect and manage duplicate data.\n- THE system SHALL verify synchronization between cloud and local storages regularly.\n\n## 4. LLM Post-Processing Requirements\n\n### 4.1 Cost-Efficient Model Use\n- THE system SHALL use cost-effective LLMs optimized via prompt engineering.\n- THE system SHALL support integration of new LLM models without disruption.\n\n### 4.2 Content Generation\n- THE system SHALL generate multiple content types:\n  - Summaries and highlights of news articles.\n  - Analytical content for deeper political insights.\n- THE system SHALL store processed data along with raw data.\n\n### 4.3 Processing Pipeline\n- WHEN new raw data arrives, THE system SHALL enqueue it for prompt-engineered LLM processing prioritized for timely availability.\n\n### 4.4 Error Handling\n- IF LLM processing fails, THEN THE system SHALL retry with exponential backoff or flag for manual review.\n\n## 5. Popularity Algorithm Requirements\n\n### 5.1 Popularity Metrics\n- THE system SHALL compute popularity scores based on article frequency, recency, source diversity, and post-processed content measures.\n\n### 5.2 Processing\n- THE system SHALL provide near real-time popularity data updates at intervals no longer than 15 minutes.\n- THE system SHALL support incremental popularity updates for efficiency.\n\n### 5.3 Scaling and Resilience\n- THE system SHALL monitor processing load and adjust computations dynamically.\n\n## 6. API Endpoint Requirements\n\n### 6.1 Endpoint Variety\n- THE system SHALL provide flexible public API endpoints returning popular topics, news summaries, and analyses.\n- THE system SHALL support query parameters for filtering by topic, category, and time window.\n\n### 6.2 Access Control\n- THE system SHALL expose APIs with no authentication or user role restrictions.\n\n### 6.3 Response Performance\n- API responses SHALL be delivered within 2 seconds under normal loads.\n\n### 6.4 Error Management\n- On invalid requests, THE system SHALL return appropriate error statuses and messages.\n\n## 7. User Scenarios and Workflows\n\n### 7.1 Crawling Workflow\n- The system shall initiate and manage crawling schedules per source.\n- It shall store raw data in local and cloud storages.\n- It shall handle retries, errors, and bans gracefully.\n\n### 7.2 LLM Post-Processing Workflow\n- Raw data shall be processed into summaries and analysis.\n- Processed data shall be stored and made available for APIs.\n\n### 7.3 Popular Topics Computation and Serving\n- Popularity scores are computed as new data arrives.\n- The system serves hot topics via APIs in near-real-time.\n\n### 7.4 Error Handling\n- For failures in crawling or processing, the system shall retry or log and alert appropriately.\n- For API errors, meaningful messages and statuses shall be returned.\n\n## 8. Crawling System Specifications\n\n### 8.1 Multi-Method Crawling\n- Support fixed-domain crawling, search API crawling, and news API crawling.\n- Allow dynamic addition of new sources without downtime.\n\n### 8.2 Scheduling and Throttling\n- Implement adaptive crawling intervals per source, honoring rate limits and politeness.\n- Coordinate crawls to avoid flooding sources.\n\n### 8.3 Error Handling and Ban Recovery\n- Detect bans and throttling responses, back off, and alert operations.\n- Ensure redundancy in sources to mitigate failures.\n\n## 9. Storage Strategy\n\n- Use cloud object storage as primary repository for all raw data.\n- Duplicate data locally with a 1-month TTL.\n- Ensure consistency and automated deletion of expired local data.\n\n## 10. Non-Functional Requirements\n\n- Data freshness: Popular topics updated within 5 minutes of source data availability.\n- API latency: Responses within 2 seconds under typical load.\n- Crawlers operate concurrently up to 10 parallel jobs.\n- Handle errors and bans with backoff and alerting.\n- Ensure 99.9% system availability.\n- Compliance with source crawling policies and legal requirements.\n\n## 11. Analytics and Reporting\n\n- Monitor crawl success/failure rates.\n- Track LLM processing throughput and errors.\n- Record API usage metrics and error rates.\n- Generate daily trending reports.\n- Alert on error thresholds and anomalies.\n\n---\n\n## Mermaid Diagrams\n\n### System Overview\n```mermaid\ngraph LR\n    A[\"Start\"] --> B{\"Is source a fixed news website?\"}\n    B -->|\"Yes\"| C[\"Crawl specific website domain\"]\n    B -->|\"No\"| D[\"Use search engine APIs or news APIs\"]\n    C --> E[\"Store raw data in Cloud Storage and Local Cache\"]\n    D --> E\n    E --> F[\"Process raw data with LLM for summaries and analysis\"]\n    F --> G[\"Calculate popularity scores\"]\n    G --> H[\"Update API endpoints with hot topics\"]\n    H --> I[\"Serve API responses\"]\n    I --> J[\"End\"]\n```\n\n### Crawling and Processing Workflow\n```mermaid\ngraph LR\n  A[\"Start Crawling Schedule\"] --> B{\"Is Source Available?\"}\n  B --\"Yes\"--> C[\"Fetch News Data\"]\n  B --\"No\"--> D[\"Schedule Retry with Backoff\"]\n  C --> E[\"Store Raw Data in Cloud Storage\"]\n  E --> F[\"Duplicate Data in Local Storage (TTL 1 Month)\"]\n  F --> G[\"Initiate LLM Post-Processing\"]\n  G --> H[\"Generate Summaries, Highlights, Analysis\"]\n  H --> I[\"Store Processed Data\"]\n  I --> J[\"Update Popularity Metrics\"]\n  J --> K[\"Serve Data via API Endpoints\"]\n  D --> L[\"Log and Alert\" ]\n  L --> A\n```\n\n### LLM Post-Processing Workflow\n```mermaid\ngraph LR\n  A[\"Raw Data Ingestion\"] --> B[\"Cloud Storage of Raw Data\"]\n  A --> C[\"Local File Cache with TTL 1 month\"]\n  B --> D[\"LLM Post-Processing Service\"]\n  D --> E[\"Generate Summaries, Highlights, Analysis\"]\n  E --> F[\"Store Processed Data with Metadata\"]\n  F --> G[\"Serve API Endpoints\"]\n  D -.->|\"Error Handling & Retry\"| H[\"Monitoring and Alerts\"]\n```\n\n### API Endpoint Workflow\n```mermaid\ngraph LR\n    A[\"Client Requests Hot Topics\"] --> B[\"Backend Receives Request\"]\n    B --> C[\"Compute Current Hot Topics Using Algorithms\"]\n    C --> D[\"Retrieve Processed News Summaries and Raw Data\"]\n    D --> E[\"Format Response According to Schema\"]\n    E --> F[\"Send Response to Client\"]\n    F --> G[\"Client Displays Hot Topics\"]\n\n    subgraph \"Error Handling\"\n        H[\"If Data Unavailable or Error\"] --> I[\"Return Error Response with Message\"]\n    end\n\n    B --> H\n```\n\n### Popularity Algorithm Processing\n```mermaid\ngraph LR\n  subgraph \"Crawling Process\"\n    A[\"Start Crawling\"] --> B{\"Is Source Domain Fixed?\"}\n    B -->|\"Yes\"| C[\"Direct Domain Crawl\"]\n    B -->|\"No\"| D[\"Search API or News API Crawl\"]\n    C --> E[\"Filter South Korean Politics News\"]\n    D --> E\n    E --> F[\"Store Raw Data\"]\n    F --> G[\"Enqueue for LLM Processing\"]\n  end\n\n  subgraph \"LLM Processing\"\n    G --> H[\"Generate Summaries and Highlights\"]\n    G --> I[\"Generate Analysis Content\"]\n    H --> J[\"Store Processed Data\"]\n    I --> J\n  end\n\n  subgraph \"Popularity Computation\"\n    J --> K[\"Analyze Data\"]\n    K --> L[\"Calculate Popularity Scores\"]\n    L --> M[\"Prepare API Data\"]\n  end\n\n  subgraph \"API Serving\"\n    M --> N[\"Serve Popular Topics API\"]\n  end\n\n  F -.->|\"Ban/Error Handling\"| O[\"Backoff & Retry Mechanism\"]\n```\n\n---\n\nThis document contains business requirements only. All technical implementations including architecture, databases, APIs, and system infrastructure are the sole responsibility of the development team. This document defines WHAT the system MUST do, not HOW to implement it."},{"reason":"To document the crawling system components, integration points, scheduling considerations, and multi-source data collection strategies.","filename":"05-crawling-system.md","documentType":"requirement","outline":["Multiple Crawling Methods","Source Management","Scheduling and Throttling","Real-Time Constraints","Error and Ban Handling"],"content":"# Functional Requirements Specification for Political News Crawler Backend\n\n## 1. Introduction\n\nThis document specifies the detailed functional business requirements for the \"politicalNewsCrawler\" backend system. Its purpose is to enable backend developers to build a robust, scalable service that crawls political news from diverse sources, processes this data using cost-effective large language models (LLMs), stores raw and processed data appropriately, computes real-time popularity of news topics, and exposes flexible API endpoints for frontend use. This document focuses exclusively on business requirements, not on technical implementation details.\n\nThe service primarily targets news on South Korean politics by aggregating information from multiple distinct channels including direct website crawling, search engine APIs, third-party news APIs, and public data aggregators.\n\n## 2. Crawling Requirements\n\n### 2.1 Overview\nThe system shall collect political news related to South Korean politics from as many diverse sources as possible to provide a wide, multiperspective view. This includes:\n- Direct crawling of news websites (e.g., New York Times, Korean magazines)\n- Using search engine APIs (e.g., SERP APIs)\n- Utilizing third-party news APIs (e.g., Tavily)\n\n### 2.2 Crawling Scheduling\n- WHEN the system initializes crawling for a given source, THE system SHALL determine and adapt crawling frequency based on the source's update patterns.\n- THE system SHALL attempt crawling intervals typically between 15 and 30 minutes per source unless adjusted for source limitations or bans.\n- The system SHALL comply with each source's crawling policies to avoid bans, including respecting rate limits and crawl delays.\n\n### 2.3 Crawling Modes\n- THE system SHALL support multiple crawling methods:\n  - Focused crawling within fixed website domains.\n  - Search queries through search engine APIs to discover news articles.\n  - Consuming news through official news APIs from various providers.\n- THE system SHALL allow configuration of specific website domains to crawl directly.\n\n### 2.4 Data Filtering\n- THE system SHALL only collect data relevant to South Korean politics based on source meta-information and text content filtering.\n\n### 2.5 Error and Ban Handling\n- IF crawling of a source is denied or results in errors due to bans or forbiddance,\n  THEN THE system SHALL back off and retry with exponential delay and notify system monitoring components.\n\n### 2.6 Real-Time Considerations\n- WHEN possible, THE system SHALL crawl frequently and process data for near real-time updates.\n- THE system SHALL limit crawling speed to avoid triggering source bans while maintaining freshness.\n\n## 3. Data Storage Requirements\n\n### 3.1 Raw Data Storage\n- THE system SHALL store all raw crawled data permanently in cloud object storage services such as Google Cloud Storage (GCP) or Amazon S3.\n- THE system SHALL maintain a duplicate copy of raw data in local file storage.\n\n### 3.2 Local Storage TTL\n- THE system SHALL enforce a Time To Live (TTL) policy on local file storage copies such that files older than one month are deleted.\n\n### 3.3 Data Integrity and Duplication\n- THE system SHALL manage and track duplication of data to prevent redundant storage.\n- THE system SHALL provide mechanisms to verify consistency between cloud and local storage.\n\n## 4. LLM Post-Processing Requirements\n\n### 4.1 Overview\n- THE system SHALL process raw news data using large language models (LLMs) to generate value-added content.\n- THE system SHALL use inexpensive LLM variants and optimize prompt engineering techniques to achieve cost efficiency.\n\n### 4.2 Content Generation Features\n- THE system SHALL generate at least two distinct content types:\n  - Summaries and Highlights: concise rendition of articles.\n  - Analysis: deeper, contextual insights on political news.\n- THE system SHALL be designed to support additional future content generation features as they are identified and prioritized.\n\n### 4.3 Data Retention\n- THE system SHALL store both raw data and generated processed content.\n- THE system SHALL maintain metadata tracking for each piece of content including generation time and source.\n\n### 4.4 Processing Pipeline\n- WHEN new raw news data is available,\n  THEN THE system SHALL enqueue it for LLM processing.\n- THE system SHALL prioritize timely processing to support near real-time availability of processed content.\n\n## 5. Popularity Algorithm Requirements\n\n### 5.1 Popularity Computation Goals\n- THE system SHALL compute popularity scores for political news topics based on custom, proprietary algorithms.\n\n### 5.2 Metrics Considered\n- THE system SHALL consider multiple signals such as article frequency, source authority, recency, user engagement metrics (if available), and content affinity.\n\n### 5.3 Real-Time Processing\n- The popularity algorithms SHALL operate in real-time or near real-time to enable up-to-date hot topic identification.\n- The system SHALL balance real-time responsiveness with crawling and processing constraints.\n\n### 5.4 Adaptive Scaling\n- THE system SHALL adjust algorithm parameters dynamically based on traffic loads and data volumes to maintain performance.\n\n## 6. API Endpoint Requirements\n\n### 6.1 Endpoint Flexibility\n- THE system SHALL provide a set of flexible API endpoints for frontend consumption.\n- THE endpoints SHALL include:\n  - Retrieval of top N popular political topics, refreshed daily or in near real-time.\n  - Query endpoints supporting filters such as category, time range, or keyword search.\n\n### 6.2 Access and Permissions\n- THE system SHALL expose all endpoints without user authentication or role-based access control.\n\n### 6.3 Response Requirements\n- THE API responses SHALL include metadata sufficient to justify popularity rankings.\n- THE responses SHALL provide both summary/highlight and analytical content where available.\n\n### 6.4 Performance Expectations\n- API responses SHALL be delivered within 2 seconds under typical loads to provide a responsive user experience.\n\n## 7. Glossary and Definitions\n\n- **Crawler**: Component responsible for fetching data from external sources.\n- **LLM (Large Language Model)**: AI models used for natural language processing tasks.\n- **TTL (Time To Live)**: Duration data is retained before being deleted.\n- **Popularity Algorithm**: Custom business logic calculating relevance and interest scores for news topics.\n\n---\n\nThis document provides business requirements only. All decisions regarding technical implementation, system architecture, database design, and API specification are fully within the developers' autonomy. This document describes WHAT the system should do, not HOW it should be built.\n\n---\n\n```mermaid\ngraph LR\n  subgraph \"Crawling Process\"\n    A[\"Start Crawling\"] --> B{\"Is Source Domain Fixed?\"}\n    B -->|\"Yes\"| C[\"Direct Domain Crawl\"]\n    B -->|\"No\"| D[\"Search API or News API Crawl\"]\n    C --> E[\"Filter South Korean Politics News\"]\n    D --> E\n    E --> F[\"Store Raw Data\"]\n    F --> G[\"Enqueue for LLM Processing\"]\n  end\n\n  subgraph \"LLM Processing\"\n    G --> H[\"Generate Summaries and Highlights\"]\n    G --> I[\"Generate Analysis Content\"]\n    H --> J[\"Store Processed Data\"]\n    I --> J\n  end\n\n  subgraph \"Popularity Computation\"\n    J --> K[\"Analyze Data\"]\n    K --> L[\"Calculate Popularity Scores\"]\n    L --> M[\"Prepare API Data\"]\n  end\n\n  subgraph \"API Serving\"\n    M --> N[\"Serve Popular Topics API\"]\n  end\n\n  F -.->|\"Ban/Error Handling\"| O[\"Backoff & Retry Mechanism\"]\n```\n"},{"reason":"To detail the post-processing workflow with cost-efficient LLMs, content generation features, prompt engineering, and data retention policies.","filename":"06-llm-processing.md","documentType":"requirement","outline":["LLM Model Selection and Cost Strategies","Summary and Analysis Features","Prompt Engineering Techniques","Raw and Processed Data Storage","Extensibility"],"content":"# Functional Requirements Specification for Political News Crawler Backend\n\n## 1. Introduction\n\nThis document specifies the detailed functional business requirements for the \"politicalNewsCrawler\" backend system. Its purpose is to enable backend developers to build a robust, scalable service that crawls political news from diverse sources, processes this data using cost-effective large language models (LLMs), stores raw and processed data appropriately, computes real-time popularity of news topics, and exposes flexible API endpoints for frontend use. This document focuses exclusively on business requirements, not on technical implementation details.\n\nThe service primarily targets news on South Korean politics by aggregating information from multiple distinct channels including direct website crawling, search engine APIs, third-party news APIs, and public data aggregators.\n\n## 2. Crawling Requirements\n\n### 2.1 Overview\nThe system shall collect political news related to South Korean politics from as many diverse sources as possible to provide a wide, multiperspective view. This includes:\n- Direct crawling of news websites (e.g., New York Times, Korean magazines)\n- Using search engine APIs (e.g., SERP APIs)\n- Utilizing third-party news APIs (e.g., Tavily)\n\n### 2.2 Crawling Scheduling\n- WHEN the system initializes crawling for a given source, THE system SHALL determine and adapt crawling frequency based on the source's update patterns.\n- THE system SHALL attempt crawling intervals typically between 15 and 30 minutes per source unless adjusted for source limitations or bans.\n- The system SHALL comply with each source's crawling policies to avoid bans, including respecting rate limits and crawl delays.\n\n### 2.3 Crawling Modes\n- THE system SHALL support multiple crawling methods:\n  - Focused crawling within fixed website domains.\n  - Search queries through search engine APIs to discover news articles.\n  - Consuming news through official news APIs from various providers.\n- THE system SHALL allow configuration of specific website domains to crawl directly.\n\n### 2.4 Data Filtering\n- THE system SHALL only collect data relevant to South Korean politics based on source meta-information and text content filtering.\n\n### 2.5 Error and Ban Handling\n- IF crawling of a source is denied or results in errors due to bans or forbiddance,\n  THEN THE system SHALL back off and retry with exponential delay and notify system monitoring components.\n\n### 2.6 Real-Time Considerations\n- WHEN possible, THE system SHALL crawl frequently and process data for near real-time updates.\n- THE system SHALL limit crawling speed to avoid triggering source bans while maintaining freshness.\n\n## 3. Data Storage Requirements\n\n### 3.1 Raw Data Storage\n- THE system SHALL store all raw crawled data permanently in cloud object storage services such as Google Cloud Storage (GCP) or Amazon S3.\n- THE system SHALL maintain a duplicate copy of raw data in local file storage.\n\n### 3.2 Local Storage TTL\n- THE system SHALL enforce a Time To Live (TTL) policy on local file storage copies such that files older than one month are deleted.\n\n### 3.3 Data Integrity and Duplication\n- THE system SHALL manage and track duplication of data to prevent redundant storage.\n- THE system SHALL provide mechanisms to verify consistency between cloud and local storage.\n\n## 4. LLM Post-Processing Requirements\n\n### 4.1 Overview\n- THE system SHALL process raw news data using large language models (LLMs) to generate value-added content.\n- THE system SHALL use inexpensive LLM variants and optimize prompt engineering techniques to achieve cost efficiency.\n\n### 4.2 Content Generation Features\n- THE system SHALL generate at least two distinct content types:\n  - Summaries and Highlights: concise rendition of articles.\n  - Analysis: deeper, contextual insights on political news.\n- THE system SHALL be designed to support additional future content generation features as they are identified and prioritized.\n\n### 4.3 Data Retention\n- THE system SHALL store both raw data and generated processed content.\n- THE system SHALL maintain metadata tracking for each piece of content including generation time and source.\n\n### 4.4 Processing Pipeline\n- WHEN new raw news data is available,\n  THEN THE system SHALL enqueue it for LLM processing.\n- THE system SHALL prioritize timely processing to support near real-time availability of processed content.\n\n## 5. Popularity Algorithm Requirements\n\n### 5.1 Popularity Computation Goals\n- THE system SHALL compute popularity scores for political news topics based on custom, proprietary algorithms.\n\n### 5.2 Metrics Considered\n- THE system SHALL consider multiple signals such as article frequency, source authority, recency, user engagement metrics (if available), and content affinity.\n\n### 5.3 Real-Time Processing\n- The popularity algorithms SHALL operate in real-time or near real-time to enable up-to-date hot topic identification.\n- The system SHALL balance real-time responsiveness with crawling and processing constraints.\n\n### 5.4 Adaptive Scaling\n- THE system SHALL adjust algorithm parameters dynamically based on traffic loads and data volumes to maintain performance.\n\n## 6. API Endpoint Requirements\n\n### 6.1 Endpoint Flexibility\n- THE system SHALL provide a set of flexible API endpoints for frontend consumption.\n- THE endpoints SHALL include:\n  - Retrieval of top N popular political topics, refreshed daily or in near real-time.\n  - Query endpoints supporting filters such as category, time range, or keyword search.\n\n### 6.2 Access and Permissions\n- THE system SHALL expose all endpoints without user authentication or role-based access control.\n\n### 6.3 Response Requirements\n- THE API responses SHALL include metadata sufficient to justify popularity rankings.\n- THE responses SHALL provide both summary/highlight and analytical content where available.\n\n### 6.4 Performance Expectations\n- API responses SHALL be delivered within 2 seconds under typical loads to provide a responsive user experience.\n\n## 7. Glossary and Definitions\n\n- **Crawler**: Component responsible for fetching data from external sources.\n- **LLM (Large Language Model)**: AI models used for natural language processing tasks.\n- **TTL (Time To Live)**: Duration data is retained before being deleted.\n- **Popularity Algorithm**: Custom business logic calculating relevance and interest scores for news topics.\n\n---\n\nThis document provides business requirements only. All decisions regarding technical implementation, system architecture, database design, and API specification are fully within the developers' autonomy. This document describes WHAT the system should do, not HOW it should be built.\n\n---\n\n```mermaid\ngraph LR\n  subgraph \"Crawling Process\"\n    A[\"Start Crawling\"] --> B{\"Is Source Domain Fixed?\"}\n    B -->|\"Yes\"| C[\"Direct Domain Crawl\"]\n    B -->|\"No\"| D[\"Search API or News API Crawl\"]\n    C --> E[\"Filter South Korean Politics News\"]\n    D --> E\n    E --> F[\"Store Raw Data\"]\n    F --> G[\"Enqueue for LLM Processing\"]\n  end\n\n  subgraph \"LLM Processing\"\n    G --> H[\"Generate Summaries and Highlights\"]\n    G --> I[\"Generate Analysis Content\"]\n    H --> J[\"Store Processed Data\"]\n    I --> J\n  end\n\n  subgraph \"Popularity Computation\"\n    J --> K[\"Analyze Data\"]\n    K --> L[\"Calculate Popularity Scores\"]\n    L --> M[\"Prepare API Data\"]\n  end\n\n  subgraph \"API Serving\"\n    M --> N[\"Serve Popular Topics API\"]\n  end\n\n  F -.->|\"Ban/Error Handling\"| O[\"Backoff & Retry Mechanism\"]\n```\n\nThis diagram represents major data flow and business process interactions.\n\n---\n\nDetailed requirements ensure backend developers understand the scope, business logic, and expected system behavior fully and can proceed to design and implementation with clarity and confidence."},{"reason":"To outline the design and business logic of the backend API endpoints, response structures, and flexibility for frontend usage.","filename":"07-api-endpoints.md","documentType":"requirement","outline":["Endpoint Types and Functions","Response Data Structures","Real-Time Updates","Hot Topic Computation","No Authentication Requirements"],"content":"# Backend API Endpoints Design and Business Logic\n\n## 1. Introduction\n\nThe backend API endpoints serve as the primary interface through which processed political news and popular hot topics are delivered to client applications. This document specifies the comprehensive business requirements for these endpoints, ensuring a flexible, performant, and accessible API layer that meets the service's goals.\n\n## 2. Business Model Summary\n\nThe politicalNewsCrawler service aims to aggregate diverse political news sources focused on South Korean politics and provide enriched, analyzed content through public endpoints. This API supports a wide audience, offering real-time or near real-time updates of popular topics without requiring user authentication.\n\n## 3. User Roles and Access Rights\n\n### 3.1 Guest Role\n- THE system SHALL allow unauthenticated guest users to access all public API endpoints for political news and popular hot topics.\n- THE system SHALL NOT require any authentication or authorization mechanisms for these access points.\n- Guests SHALL NOT be able to perform any modification, write, or administrative operations.\n\n## 4. API Endpoint Types and Their Functions\n\n### 4.1 News Retrieval Endpoints\n- THE system SHALL provide endpoints to retrieve raw and processed political news data.\n- THE endpoints SHALL accept filters such as date ranges, source identifiers, categories, and keyword searches.\n\n### 4.2 Hot Topic Endpoints\n- THE system SHALL provide endpoints delivering ranked lists of popular political topics.\n- THE endpoints SHALL support querying by date ranges and sub-categories when applicable.\n\n### 4.3 Summary and Analysis Endpoints\n- THE system SHALL serve content generated from LLM post-processing, including summaries, highlights, and in-depth analyses.\n\n### 4.4 Real-Time Update Endpoints\n- THE system SHALL support endpoints enabling clients to receive or poll for near real-time updates about hot topics and breaking news.\n\n### 4.5 Metadata and Health Check Endpoints\n- THE system SHALL provide endpoints for basic system status, metadata exposure, and health checks for monitoring.\n\n## 5. Response Data Structures\n\n### 5.1 News Item Schema\n- Each news item SHALL include:\n  - Unique identifier\n  - Source metadata (name, URL, etc.)\n  - Crawling timestamp\n  - Reference or link to raw content storage\n  - Processed summary and highlights\n  - Language and regional tags relevant to South Korean politics\n\n### 5.2 Hot Topic Schema\n- Each hot topic entry SHALL include:\n  - Topic name and identifier\n  - Popularity score or ranking position\n  - Related news item references\n  - Time window for the popularity measurement\n\n### 5.3 Summary and Analysis Schema\n- Generated content entries SHALL include:\n  - Source news references\n  - Content type (summary, highlight, analysis)\n  - Textual content\n  - Generation timestamp\n\n## 6. Real-Time Updates and Performance Expectations\n\n- THE system SHALL provide fresh data with a latency not exceeding 30 seconds under normal conditions.\n- API response times SHALL be under 500 milliseconds for 95% of requests under typical load.\n- The system SHALL implement mechanisms to throttle updates per source to respect crawling and site restrictions.\n\n## 7. Hot Topic Computation and Popularity Algorithm Integration\n\n- Popular hot topics SHALL be computed based on internal algorithms that factor source diversity, recency, frequency, and engagement proxies.\n- THE system SHALL update hot topic information continuously and expose it via endpoints reflecting near real-time freshness within operational constraints.\n\n## 8. Error Handling and Recovery Processes\n\n- WHEN invalid or unsupported query parameters are received, THE system SHALL return meaningful error messages with appropriate status codes.\n- WHEN requested data is temporarily unavailable, THE system SHALL return clear status indications and fallback responses where possible.\n- THE system SHALL implement retry and backoff strategies in internal data fetching and crawling processes to minimize client-facing errors.\n\n## 9. Security and Access Control Requirements\n\n- All endpoints SHALL be publicly accessible without authentication.\n- THE system SHALL implement rate limiting to prevent abuse and ensure service stability.\n- Error responses due to rate limiting SHALL provide appropriate HTTP status codes and explanatory messages.\n\n## 10. Success Criteria and Performance Metrics\n\n- API endpoint availability SHALL exceed 99.9% uptime.\n- Real-time update latency SHALL be under 30 seconds.\n- API response times SHALL be under 500 milliseconds for 95% of calls.\n- Popular hot topics served SHALL reflect backend algorithm computations accurately.\n\n---\n\n## Mermaid Diagram: API Endpoint Flow\n\n```mermaid\ngraph LR\n    A[\"Client Requests Hot Topics\"] --> B[\"Backend Receives Request\"]\n    B --> C[\"Compute Current Hot Topics Using Algorithms\"]\n    C --> D[\"Retrieve Processed News Summaries and Raw Data\"]\n    D --> E[\"Format Response According to Schema\"]\n    E --> F[\"Send Response to Client\"]\n    F --> G[\"Client Displays Hot Topics\"]\n\n    subgraph \"Error Handling\"\n        H[\"If Data Unavailable or Error\"] --> I[\"Return Error Response with Message\"]\n    end\n\n    B --> H\n```\n\n```mermaid\nsequenceDiagram\n    participant Client\n    participant Backend\n    Client->>Backend: Request popular hot topics\n    Backend->>Backend: Validate request\n    Backend->>Algorithm: Compute hot topics\n    Algorithm-->>Backend: Hot topics list\n    Backend->>DB: Fetch news and summaries\n    DB-->>Backend: Return data\n    Backend->>Client: Send hot topics response\n    alt Error in data retrieval\n      Backend->>Client: Send error message\n    end\n```\n\n---\n\nThis document defines business requirements exclusively. All details about implementation, APIs, data storage, and system architecture are the sole responsibility of backend developers. The document's purpose is to specify WHAT the system should deliver, not HOW it must be built."},{"reason":"To define the custom algorithms for determining popular hot topics, metrics considered, and real-time computation challenges.","filename":"08-popularity-algorithms.md","documentType":"requirement","outline":["Popularity Metrics Design","Algorithm Logic","Real-Time Processing Considerations","Adaptive Scaling"],"content":"# Functional Requirements Specification for Political News Crawler Backend\n\n## 1. Introduction\nThis document specifies the detailed functional business requirements for the \"politicalNewsCrawler\" backend system. Its purpose is to enable backend developers to build a robust, scalable service that crawls political news from diverse sources, processes this data using cost-effective large language models (LLMs), stores raw and processed data appropriately, computes real-time popularity of news topics, and exposes flexible API endpoints for frontend use. This document focuses exclusively on business requirements, not on technical implementation details.\n\nThe service primarily targets news on South Korean politics by aggregating information from multiple distinct channels including direct website crawling, search engine APIs, third-party news APIs, and public data aggregators.\n\n## 2. Crawling Requirements\n\n### 2.1 Overview\nThe system shall collect political news related to South Korean politics from as many diverse sources as possible to provide a wide, multiperspective view. This includes:\n- Direct crawling of news websites (e.g., New York Times, Korean magazines)\n- Using search engine APIs (e.g., SERP APIs)\n- Utilizing third-party news APIs (e.g., Tavily)\n\n### 2.2 Crawling Scheduling\n- WHEN the system initializes crawling for a given source, THE system SHALL determine and adapt crawling frequency based on the source's update patterns.\n- THE system SHALL attempt crawling intervals typically between 15 and 30 minutes per source unless adjusted for source limitations or bans.\n- The system SHALL comply with each source's crawling policies to avoid bans, including respecting rate limits and crawl delays.\n\n### 2.3 Crawling Modes\n- THE system SHALL support multiple crawling methods:\n  - Focused crawling within fixed website domains.\n  - Search queries through search engine APIs to discover news articles.\n  - Consuming news through official news APIs from various providers.\n- THE system SHALL allow configuration of specific website domains to crawl directly.\n\n### 2.4 Data Filtering\n- THE system SHALL only collect data relevant to South Korean politics based on source meta-information and text content filtering.\n\n### 2.5 Error and Ban Handling\n- IF crawling of a source is denied or results in errors due to bans or forbiddance,\n  THEN THE system SHALL back off and retry with exponential delay and notify system monitoring components.\n\n### 2.6 Real-Time Considerations\n- WHEN possible, THE system SHALL crawl frequently and process data for near real-time updates.\n- THE system SHALL limit crawling speed to avoid triggering source bans while maintaining freshness.\n\n## 3. Data Storage Requirements\n\n### 3.1 Raw Data Storage\n- THE system SHALL store all raw crawled data permanently in cloud object storage services such as Google Cloud Storage (GCP) or Amazon S3.\n- THE system SHALL maintain a duplicate copy of raw data in local file storage.\n\n### 3.2 Local Storage TTL\n- THE system SHALL enforce a Time To Live (TTL) policy on local file storage copies such that files older than one month are deleted.\n\n### 3.3 Data Integrity and Duplication\n- THE system SHALL manage and track duplication of data to prevent redundant storage.\n- THE system SHALL provide mechanisms to verify consistency between cloud and local storage.\n\n## 4. LLM Post-Processing Requirements\n\n### 4.1 Overview\n- THE system SHALL process raw news data using large language models (LLMs) to generate value-added content.\n- THE system SHALL use inexpensive LLM variants and optimize prompt engineering techniques to achieve cost efficiency.\n\n### 4.2 Content Generation Features\n- THE system SHALL generate at least two distinct content types:\n  - Summaries and Highlights: concise rendition of articles.\n  - Analysis: deeper, contextual insights on political news.\n- THE system SHALL be designed to support additional future content generation features as they are identified and prioritized.\n\n### 4.3 Data Retention\n- THE system SHALL store both raw data and generated processed content.\n- THE system SHALL maintain metadata tracking for each piece of content including generation time and source.\n\n### 4.4 Processing Pipeline\n- WHEN new raw news data is available,\n  THEN THE system SHALL enqueue it for LLM processing.\n- THE system SHALL prioritize timely processing to support near real-time availability of processed content.\n\n## 5. Popularity Algorithm Requirements\n\n### 5.1 Popularity Computation Goals\n- THE system SHALL compute popularity scores for political news topics based on custom, proprietary algorithms.\n\n### 5.2 Metrics Considered\n- THE system SHALL consider multiple signals such as article frequency, source authority, recency, user engagement metrics (if available), and content affinity.\n\n### 5.3 Real-Time Processing\n- The popularity algorithms SHALL operate in real-time or near real-time to enable up-to-date hot topic identification.\n- The system SHALL balance real-time responsiveness with crawling and processing constraints.\n\n### 5.4 Adaptive Scaling\n- THE system SHALL adjust algorithm parameters dynamically based on traffic loads and data volumes to maintain performance.\n\n## 6. API Endpoint Requirements\n\n### 6.1 Endpoint Flexibility\n- THE system SHALL provide a set of flexible API endpoints for frontend consumption.\n- THE endpoints SHALL include:\n  - Retrieval of top N popular political topics, refreshed daily or in near real-time.\n  - Query endpoints supporting filters such as category, time range, or keyword search.\n\n### 6.2 Access and Permissions\n- THE system SHALL expose all endpoints without user authentication or role-based access control.\n\n### 6.3 Response Requirements\n- THE API responses SHALL include metadata sufficient to justify popularity rankings.\n- THE responses SHALL provide both summary/highlight and analytical content where available.\n\n### 6.4 Performance Expectations\n- API responses SHALL be delivered within 2 seconds under typical loads to provide a responsive user experience.\n\n## 7. Glossary and Definitions\n\n- **Crawler**: Component responsible for fetching data from external sources.\n- **LLM (Large Language Model)**: AI models used for natural language processing tasks.\n- **TTL (Time To Live)**: Duration data is retained before being deleted.\n- **Popularity Algorithm**: Custom business logic calculating relevance and interest scores for news topics.\n\n---\n\nThis document provides business requirements only. All decisions regarding technical implementation, system architecture, database design, and API specification are fully within the developers' autonomy. This document describes WHAT the system should do, not HOW it should be built.\n\n---\n\n```mermaid\ngraph LR\n  subgraph \"Crawling Process\"\n    A[\"Start Crawling\"] --> B{\"Is Source Domain Fixed?\"}\n    B -->|\"Yes\"| C[\"Direct Domain Crawl\"]\n    B -->|\"No\"| D[\"Search API or News API Crawl\"]\n    C --> E[\"Filter South Korean Politics News\"]\n    D --> E\n    E --> F[\"Store Raw Data\"]\n    F --> G[\"Enqueue for LLM Processing\"]\n  end\n\n  subgraph \"LLM Processing\"\n    G --> H[\"Generate Summaries and Highlights\"]\n    G --> I[\"Generate Analysis Content\"]\n    H --> J[\"Store Processed Data\"]\n    I --> J\n  end\n\n  subgraph \"Popularity Computation\"\n    J --> K[\"Analyze Data\"]\n    K --> L[\"Calculate Popularity Scores\"]\n    L --> M[\"Prepare API Data\"]\n  end\n\n  subgraph \"API Serving\"\n    M --> N[\"Serve Popular Topics API\"]\n  end\n\n  F -.->|\"Ban/Error Handling\"| O[\"Backoff & Retry Mechanism\"]\n```\n\nThis diagram represents major data flow and business process interactions.\n\n---\n\nDetailed requirements ensure backend developers understand the scope, business logic, and expected system behavior fully and can proceed to design and implementation with clarity and confidence."},{"reason":"To specify data storage strategies, including cloud object storage and local caching with TTL, backup policies, and data lifecycle management.","filename":"09-storage-strategy.md","documentType":"requirement","outline":["Cloud Storage of Raw Data","Local File Storage and TTL","Data Duplication Strategies","Data Retention and Deletion"],"content":"# Storage Strategy for politicalNewsCrawler Backend Service\n\n## 1. Introduction\n\nThe storage strategy defines how raw political news data collected by the politicalNewsCrawler backend is securely stored, redundantly maintained, and efficiently managed. The strategy ensures durability and availability through cloud object storage complemented by local file storage caching with strict time-to-live (TTL) policies.\n\n## 2. Cloud Storage of Raw Data\n\n### 2.1 Purpose and Requirements\nTHE system SHALL store all raw data collected from crawling operations primarily in cloud object storage services such as Google Cloud Platform (GCP) or Amazon S3. This cloud storage serves as the authoritative, durable repository for all raw news data and must support high availability, fault tolerance, and scalability to accommodate growth.\n\n### 2.2 Storage Locations\nTHE system SHALL support configurable selection or switching between supported cloud object storage providers.\n\n### 2.3 Data Format and Metadata\nTHE system SHALL store raw data in structured or semi-structured formats compatible with downstream processing, such as JSON or XML. Each stored item SHALL include metadata comprising:\n- Source identifier or channel\n- Crawl timestamp with ISO 8601 date format\n- Content type\n- Unique identifier or hash for duplicate detection\n\n## 3. Local File Storage and TTL\n\n### 3.1 Purpose and Scope\nTHE system SHALL maintain a duplicate cache of raw data in local file storage to enable faster retrieval and provide resiliency against temporary cloud storage access issues.\n\n### 3.2 Duplication Policies\nTHE system SHALL automatically replicate all raw data stored in cloud storage to local file storage, ensuring consistency between both layers.\n\n### 3.3 TTL and Automated Deletion\nWHEN data items in local storage reach a time-to-live (TTL) of one month,\nTHEN THE system SHALL automatically delete those items to free up local storage resources.\n\nTHE system SHALL log deletions and verify successful completion.\n\n## 4. Data Duplication Strategies\n\n### 4.1 Cloud and Local Duplication\nTHE system SHALL ensure data redundancy by duplicating raw data in both cloud object storage and local file storage.\n\n### 4.2 Consistency and Synchronization\nTHE system SHALL periodically verify synchronization between cloud and local storage. If inconsistencies or failures occur during duplication, THE system SHALL automatically retry synchronization according to configured policies.\n\n## 5. Data Retention and Deletion\n\n### 5.1 Retention Periods\nTHE system SHALL retain raw data indefinitely in cloud storage to enable future analyses and archival.\n\nTHE system SHALL enforce a strict one-month TTL policy for local file storage data.\n\n### 5.2 Automated Deletion\nTHE system SHALL automatically delete expired local cache data following the TTL policy.\n\nTHE system MAY provide administrative tools for manual purging of cloud storage data if required for compliance or cost management.\n\n### 5.3 Audit and Compliance\nTHE system SHALL maintain logs of all retention and deletion activities for audit and regulatory compliance purposes.\n\n## 6. Error Handling and Data Integrity\n\nIF data storage operations fail (write or delete),\nTHEN THE system SHALL log detailed error information and automatically retry these operations.\n\nIn case of repeated failures, alerts SHALL be generated to notify system operators.\n\n## 7. Performance and Scalability Considerations\n\nTHE system SHALL perform storage operations asynchronously to avoid blocking core crawling and processing workflows.\n\nTHE system SHALL scale cloud storage capacity seamlessly to handle increasing data volumes without performance degradation.\n\n## 8. Security and Access Control\n\nTHE system SHALL enforce strict authentication and authorization controls on all storage systems.\n\nTHE system SHALL encrypt data in transit and at rest to protect against unauthorized access.\n\n## 9. Data Flow Diagram\n\n```mermaid\ngraph LR\n  A[\"Crawler\"] --> B[\"Local File Storage\"]\n  B --> C[\"Cloud Object Storage (GCP/S3)\"]\n  subgraph \"Storage Data Flow\"\n    B --> D[\"TTL Enforcement (1 month) & Deletion\"]\n    C --> E[\"Backup & Historical Data Retention\"]\n  end\n  F[\"Data Processing (LLM)\"] --> C\n```\n\n## 10. Summary\n\nThe storage strategy ensures all raw political news data is durably stored and redundantly cached locally with a one-month TTL to balance availability, performance, and operational cost.\n\nThis approach ensures data integrity, scalability, and compliance while supporting the backend's crawling, processing, and API serving functions.\n\n---\n\nThis document provides business requirements only. All technical implementations including architecture, storage technologies, encryption methods, and operational procedures are the responsibility of the development team. The developers have full discretion over how to implement these requirements to achieve the described outcomes successfully."},{"reason":"To establish non-functional requirements including performance expectations, rate limits, error handling, and compliance with crawling constraints.","filename":"10-non-functional-requirements.md","documentType":"requirement","outline":["Performance Expectations","Crawling Rate Limits","Error and Ban Recovery","Reliability and Scalability","Compliance Considerations"],"content":"# Functional Requirements Specification for Political News Crawler Backend\n\n## 1. Introduction\n\nThe politicalNewsCrawler backend is a system designed to aggregate political news related to South Korean politics from a wide variety of sources. It performs multi-channel crawling, processes the data using cost-effective large language models (LLMs), stores both raw and processed data, calculates real-time popularity scores for political topics, and provides flexible API endpoints without requiring user authentication.\n\nThis specification provides detailed business requirements to guide developers in building the backend system. All requirements are stated clearly using EARS to ensure unambiguous understanding. This document covers crawling logic, storage policies, content post-processing, popularity computation, APIs, and includes detailed error handling and performance expectations.\n\n## 2. Crawling Requirements\n\n### 2.1 Data Source Diversity and Crawling Methods\n- THE system SHALL crawl political news about South Korean politics from diverse sources including:\n  - Fixed specific news websites (e.g., known Korean political magazines, internationally recognized sources such as New York Times).\n  - Search engine APIs (e.g., SERP APIs) for dynamic news discovery.\n  - Third-party news APIs and services (e.g., Tavily) for additional data.\n- THE system SHALL support adding new crawling sources dynamically without downtime.\n\n### 2.2 Crawling Scheduling\n- WHEN starting to crawl a new source, THE system SHALL determine a crawling schedule adapted to the source's update frequency.\n- THE system SHALL typically schedule crawl intervals between 15 and 30 minutes.\n- IF a source enforces crawl limits, THEN THE system SHALL respect those by adapting crawl intervals and reducing frequency.\n\n### 2.3 Filtering Relevance\n- THE system SHALL filter collected data to ensure only political news relevant to South Korean politics is retained.\n\n### 2.4 Crawling Error Handling and Ban Mitigation\n- IF a crawling attempt fails due to network errors, HTTP errors, or bans (such as HTTP 403 or 429), THEN THE system SHALL implement exponential backoff and retry strategies.\n- IF repeated crawl failures occur for a source beyond a configured threshold, THEN THE system SHALL temporarily disable crawling for that source and notify system monitoring.\n\n### 2.5 Real-Time Crawling Considerations\n- THE system SHALL attempt to crawl frequently and update its data near real-time but SHALL maintain crawl intervals sufficient to avoid bans or blocks.\n\n## 3. Data Storage Requirements\n\n### 3.1 Raw Data Storage\n- THE system SHALL store all raw crawled data persistently in cloud object storage such as Google Cloud Storage or Amazon S3.\n\n### 3.2 Local File Storage Caching\n- THE system SHALL maintain a duplicate cache of raw data on local file storage.\n- THE system SHALL enforce a time-to-live (TTL) policy with a maximum retention of 1 month for local cached data.\n- WHEN data age exceeds 1 month in local storage, THE system SHALL delete the expired data automatically and log the deletion.\n\n### 3.3 Data Consistency and Duplication Handling\n- THE system SHALL ensure data consistency between cloud storage and local cache, and maintain mechanisms to detect and remediate duplication issues.\n\n## 4. LLM Post-Processing Requirements\n\n### 4.1 Cost-Effective LLM Usage\n- THE system SHALL use inexpensive large language models (LLMs) combined with prompt engineering to generate value-added content.\n\n### 4.2 Content Generation Features\n- THE system SHALL produce the following content types for each news item:\n  - Summaries and highlights of news articles.\n  - Analytical insights contextualizing political news.\n  - Additional content types may be added in the future.\n\n### 4.3 Data Storage for Processed Content\n- THE system SHALL store both raw data and processed content along with metadata such as generation timestamps and source references.\n\n### 4.4 Processing Workflow\n- WHEN new raw data is added, THE system SHALL enqueue it promptly for LLM post-processing.\n- THE system SHALL process data timely to support near real-time availability of enriched content.\n\n### 4.5 Error Handling\n- IF LLM processing fails, THEN THE system SHALL retry processing with exponential backoff up to a configurable maximum retry count.\n- IF processing consistently fails, THEN THE system SHALL flag the data item for manual inspection.\n\n## 5. Popularity Algorithm Requirements\n\n### 5.1 Popularity Metrics\n- THE system SHALL compute popularity scores based on metrics including:\n  - Recency of news publication.\n  - Frequency of topic mentions across multiple articles.\n  - Diversity of sources reporting the topic.\n  - Content generation volume and relevance.\n\n### 5.2 Algorithm Behavior\n- THE algorithm SHALL aggregate data within configurable time windows (e.g., 24 hours).\n- THE algorithm SHALL apply recency decay functions to prioritize recent topics.\n- THE algorithm SHALL normalize and rank topics according to computed popularity scores.\n\n### 5.3 Real-Time Processing\n- THE system SHALL update popularity scores in near real-time or at least every 15 minutes.\n- THE system SHALL support incremental computation for efficiency.\n\n### 5.4 Adaptive Scaling\n- THE system SHALL dynamically adjust algorithm parameters (such as thresholds) according to system load and data volume.\n\n### 5.5 Error Handling\n- IF input data is incomplete or corrupted, THEN THE algorithm SHALL exclude such data and log the incident.\n- IF computation fails, THEN THE system SHALL revert to last known stable popularity state.\n\n## 6. API Endpoint Requirements\n\n### 6.1 Endpoint Types\n- The backend SHALL provide unauthenticated public API endpoints that include:\n  - Retrieval of popular hot political topics, supporting filter parameters for time ranges and categories.\n  - Retrieval of summarized and analyzed news content.\n  - Metadata and health check endpoints.\n\n### 6.2 Response Structures\n- API responses SHALL include:\n  - Unique identifiers for news items and topics.\n  - Metadata including source information, crawl timestamps.\n  - Content summaries, highlights, and analytic insights.\n  - Popularity scores and ranking information.\n\n### 6.3 Real-Time Updates\n- API endpoints SHALL support near real-time update delivery with response latency under 2 seconds.\n\n### 6.4 Error Handling\n- THE API SHALL return clear error messages and codes for invalid requests or unavailable data.\n\n### 6.5 Rate Limiting\n- THE system SHALL implement rate limiting to protect endpoints from excessive requests, returning standard error responses for rate violations.\n\n## 7. Glossary\n\n- Crawler: Component responsible for collecting news data from external sources.\n- LLM: Large Language Model used for natural language processing tasks.\n- TTL: Time To Live, duration before cached data is deleted.\n- Popularity Algorithm: Custom method for ranking trending news topics.\n\n---\n\nAll requirements specified are expressed in natural language business terms following EARS conventions to remove ambiguity and ensure testability. Technical implementation details, API schema designs, database schemas, and system architecture decisions are excluded as they remain at the discretion of the development team. This document defines WHAT the politicalNewsCrawler backend system SHALL do, not HOW.\n\n\n## Mermaid Diagram: System Functional Overview\n\n```mermaid\ngraph LR\n  A[\"Initiate Crawl\"] --> B{\"Fixed Domain?\"}\n  B -->|\"Yes\"| C[\"Crawl Specific News Website\"]\n  B -->|\"No\"| D[\"Use Search/News APIs\"]\n  C --> E[\"Store Raw Data (Cloud and Local Cache)\"]\n  D --> E\n  E --> F[\"Enqueue LLM Post-Processing\"]\n  F --> G[\"Generate Summaries and Analyses\"]\n  G --> H[\"Store Processed Content\"]\n  H --> I[\"Compute Popularity Scores\"]\n  I --> J[\"Update API Endpoints\"]\n  J --> K[\"Serve API Responses\"]\n  K --> L[\"End\"]\n\n  E -.->|\"Error or Ban Handling\"| M[\"Backoff and Retry\"]\n  M --> A\n```\n\n"},{"reason":"To define business analytics requirements for monitoring the crawler status, LLM processing, API usage statistics, and popularity trends.","filename":"11-analytics-reporting.md","documentType":"requirement","outline":["Crawler Monitoring","Processing Pipeline Metrics","API Usage Analytics","Popularity Trend Reports","Alerts and Reporting"],"content":"# Functional Requirements Specification for Political News Crawler Backend\n\n## 1. Introduction\n\nThis document specifies the detailed functional business requirements for the \"politicalNewsCrawler\" backend system. Its purpose is to enable backend developers to build a robust, scalable service that crawls political news from diverse sources, processes this data using cost-effective large language models (LLMs), stores raw and processed data appropriately, computes real-time popularity of news topics, and exposes flexible API endpoints for frontend use. This document focuses exclusively on business requirements, not on technical implementation details.\n\nThe service primarily targets news on South Korean politics by aggregating information from multiple distinct channels including direct website crawling, search engine APIs, third-party news APIs, and public data aggregators.\n\n## 2. Crawling Requirements\n\n### 2.1 Overview\nThe system shall collect political news related to South Korean politics from as many diverse sources as possible to provide a wide, multiperspective view. This includes:\n- Direct crawling of news websites (e.g., New York Times, Korean magazines)\n- Using search engine APIs (e.g., SERP APIs)\n- Utilizing third-party news APIs (e.g., Tavily)\n\n### 2.2 Crawling Scheduling\n- WHEN the system initializes crawling for a given source, THE system SHALL determine and adapt crawling frequency based on the source's update patterns.\n- THE system SHALL attempt crawling intervals typically between 15 and 30 minutes per source unless adjusted for source limitations or bans.\n- The system SHALL comply with each source's crawling policies to avoid bans, including respecting rate limits and crawl delays.\n\n### 2.3 Crawling Modes\n- THE system SHALL support multiple crawling methods:\n  - Focused crawling within fixed website domains.\n  - Search queries through search engine APIs to discover news articles.\n  - Consuming news through official news APIs from various providers.\n- THE system SHALL allow configuration of specific website domains to crawl directly.\n\n### 2.4 Data Filtering\n- THE system SHALL only collect data relevant to South Korean politics based on source meta-information and text content filtering.\n\n### 2.5 Error and Ban Handling\n- IF crawling of a source is denied or results in errors due to bans or forbiddance,\n  THEN THE system SHALL back off and retry with exponential delay and notify system monitoring components.\n\n### 2.6 Real-Time Considerations\n- WHEN possible, THE system SHALL crawl frequently and process data for near real-time updates.\n- THE system SHALL limit crawling speed to avoid triggering source bans while maintaining freshness.\n\n## 3. Data Storage Requirements\n\n### 3.1 Raw Data Storage\n- THE system SHALL store all raw crawled data permanently in cloud object storage services such as Google Cloud Storage (GCP) or Amazon S3.\n- THE system SHALL maintain a duplicate copy of raw data in local file storage.\n\n### 3.2 Local Storage TTL\n- THE system SHALL enforce a Time To Live (TTL) policy on local file storage copies such that files older than one month are deleted.\n\n### 3.3 Data Integrity and Duplication\n- THE system SHALL manage and track duplication of data to prevent redundant storage.\n- THE system SHALL provide mechanisms to verify consistency between cloud and local storage.\n\n## 4. LLM Post-Processing Requirements\n\n### 4.1 Overview\n- THE system SHALL process raw news data using large language models (LLMs) to generate value-added content.\n- THE system SHALL use inexpensive LLM variants and optimize prompt engineering techniques to achieve cost efficiency.\n\n### 4.2 Content Generation Features\n- THE system SHALL generate at least two distinct content types:\n  - Summaries and Highlights: concise rendition of articles.\n  - Analysis: deeper, contextual insights on political news.\n- THE system SHALL be designed to support additional future content generation features as they are identified and prioritized.\n\n### 4.3 Data Retention\n- THE system SHALL store both raw data and generated processed content.\n- THE system SHALL maintain metadata tracking for each piece of content including generation time and source.\n\n### 4.4 Processing Pipeline\n- WHEN new raw news data is available,\n  THEN THE system SHALL enqueue it for LLM processing.\n- THE system SHALL prioritize timely processing to support near real-time availability of processed content.\n\n## 5. Popularity Algorithm Requirements\n\n### 5.1 Popularity Computation Goals\n- THE system SHALL compute popularity scores for political news topics based on custom, proprietary algorithms.\n\n### 5.2 Metrics Considered\n- THE system SHALL consider multiple signals such as article frequency, source authority, recency, user engagement metrics (if available), and content affinity.\n\n### 5.3 Real-Time Processing\n- The popularity algorithms SHALL operate in real-time or near real-time to enable up-to-date hot topic identification.\n- The system SHALL balance real-time responsiveness with crawling and processing constraints.\n\n### 5.4 Adaptive Scaling\n- THE system SHALL adjust algorithm parameters dynamically based on traffic loads and data volumes to maintain performance.\n\n## 6. API Endpoint Requirements\n\n### 6.1 Endpoint Flexibility\n- THE system SHALL provide a set of flexible API endpoints for frontend consumption.\n- THE endpoints SHALL include:\n  - Retrieval of top N popular political topics, refreshed daily or in near real-time.\n  - Query endpoints supporting filters such as category, time range, or keyword search.\n\n### 6.2 Access and Permissions\n- THE system SHALL expose all endpoints without user authentication or role-based access control.\n\n### 6.3 Response Requirements\n- THE API responses SHALL include metadata sufficient to justify popularity rankings.\n- THE responses SHALL provide both summary/highlight and analytical content where available.\n\n### 6.4 Performance Expectations\n- API responses SHALL be delivered within 2 seconds under typical loads to provide a responsive user experience.\n\n## 7. Glossary and Definitions\n\n- **Crawler**: Component responsible for fetching data from external sources.\n- **LLM (Large Language Model)**: AI models used for natural language processing tasks.\n- **TTL (Time To Live)**: Duration data is retained before being deleted.\n- **Popularity Algorithm**: Custom business logic calculating relevance and interest scores for news topics.\n\n---\n\nThis document provides business requirements only. All decisions regarding technical implementation, system architecture, database design, and API specification are fully within the developers' autonomy. This document describes WHAT the system should do, not HOW it should be built.\n\n---\n\n```mermaid\ngraph LR\n  subgraph \"Crawling Process\"\n    A[\"Start Crawling\"] --> B{\"Is Source Domain Fixed?\"}\n    B -->|\"Yes\"| C[\"Direct Domain Crawl\"]\n    B -->|\"No\"| D[\"Search API or News API Crawl\"]\n    C --> E[\"Filter South Korean Politics News\"]\n    D --> E\n    E --> F[\"Store Raw Data\"]\n    F --> G[\"Enqueue for LLM Processing\"]\n  end\n\n  subgraph \"LLM Processing\"\n    G --> H[\"Generate Summaries and Highlights\"]\n    G --> I[\"Generate Analysis Content\"]\n    H --> J[\"Store Processed Data\"]\n    I --> J\n  end\n\n  subgraph \"Popularity Computation\"\n    J --> K[\"Analyze Data\"]\n    K --> L[\"Calculate Popularity Scores\"]\n    L --> M[\"Prepare API Data\"]\n  end\n\n  subgraph \"API Serving\"\n    M --> N[\"Serve Popular Topics API\"]\n  end\n\n  F -.->|\"Ban/Error Handling\"| O[\"Backoff & Retry Mechanism\"]\n```\n\nThis diagram represents major data flow and business process interactions.\n\n---\n\nDetailed requirements ensure backend developers understand the scope, business logic, and expected system behavior fully and can proceed to design and implementation with clarity and confidence."}],"created_at":"2025-09-14T06:20:32.953Z","completed_at":"2025-09-14T06:35:10.275Z","step":0},{"id":"019946f0-320c-719f-81d8-39e685130897","type":"userMessage","contents":[{"type":"text","text":"Design the database schema."}],"created_at":"2025-09-14T06:36:10.636Z"},{"type":"prisma","id":"019946f2-4f1b-75fb-899c-297afcebe635","reason":"Generate database schema for backend application that crawls South Korean political news from multiple sources, stores raw and processed news data, supports LLM generated content (summaries, highlights, analysis), manages crawling schedules and source information, and tracks popularity of hot topics for flexible real-time endpoints.","schemas":{"schema-01-systematic.prisma":"/// Represents political news crawling sources configuration. Contains source\n/// URLs, status, and metadata for controlling crawl initiation and\n/// processing. Used to manage diverse data feed points for\n/// politicalNewsCrawler.\n///\n/// @namespace Systematic\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawl_sources {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Unique identifier code for the crawl source.\n  source_code String\n  \n  /// The base URL of the crawl source website or API.\n  source_url String @db.VarChar(80000)\n  \n  /// Flag indicating whether the crawl source is active and enabled for\n  /// crawling.\n  is_active Boolean\n  \n  /// Optional description of the crawl source.\n  description String?\n  \n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n  \n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n  \n  /// Soft delete timestamp, if record is deleted.\n  deleted_at DateTime? @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  political_news_crawler_crawl_schedules political_news_crawler_crawl_schedules[]\n  political_news_crawler_crawl_jobs political_news_crawler_crawl_jobs[]\n  political_news_crawler_raw_data_storage political_news_crawler_raw_data_storage[]\n  political_news_crawler_llm_jobs political_news_crawler_llm_jobs[]\n  political_news_crawler_crawl_alerts political_news_crawler_crawl_alerts[]\n  \n  @@unique([source_code])\n  @@unique([source_url])\n  @@index([is_active, created_at])\n}\n\n/// Configuration for crawl policies governing crawling frequency, retry, and\n/// error handling for political news sources. Ensures adaptive and\n/// respectful crawling behavior according to source limits and bans.\n///\n/// @namespace Systematic\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawl_policies {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Unique name identifier for the crawl policy.\n  policy_name String\n  \n  /// Maximum allowed crawl frequency in minutes.\n  max_crawl_frequency_minutes Int @db.Integer\n  \n  /// Maximum number of retry attempts after failures.\n  max_retry_attempts Int @db.Integer\n  \n  /// Multiplier factor for exponential backoff on retries.\n  backoff_multiplier Float @db.DoublePrecision\n  \n  /// Flag to enable detection and handling of bans during crawling.\n  ban_detection_enabled Boolean\n  \n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n  \n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n  \n  /// Soft delete timestamp, if record is deleted.\n  deleted_at DateTime? @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  political_news_crawler_crawl_schedules political_news_crawler_crawl_schedules[]\n  \n  @@unique([policy_name])\n  @@index([max_crawl_frequency_minutes, ban_detection_enabled], map: \"political_news_crawler_crawl_policies_max_crawl_freque_a5d20f2f\")\n}\n\n/// Schedules defining when and how often crawling runs for each political\n/// news source. References the crawl source and policy to enable adaptive\n/// scheduling and coordination.\n///\n/// @namespace Systematic\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawl_schedules {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Reference to Crawling Source. {@link\n  /// political_news_crawler_crawl_sources.id}\n  crawl_source_id String @db.Uuid\n  \n  /// Reference to Crawl Policy. {@link\n  /// political_news_crawler_crawl_policies.id}\n  crawl_policy_id String @db.Uuid\n  \n  /// Cron expression defining the crawl schedule timing.\n  schedule_expression String\n  \n  /// Timestamp when the crawl last occurred.\n  last_crawled_at DateTime? @db.Timestamptz\n  \n  /// Timestamp for the next scheduled crawl.\n  next_crawl_at DateTime? @db.Timestamptz\n  \n  /// Flag indicating if this schedule is enabled.\n  is_enabled Boolean\n  \n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n  \n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n  \n  /// Soft delete timestamp, if record is deleted.\n  deleted_at DateTime? @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  crawlSource political_news_crawler_crawl_sources @relation(fields: [crawl_source_id], references: [id], onDelete: Cascade)\n  crawlPolicy political_news_crawler_crawl_policies @relation(fields: [crawl_policy_id], references: [id], onDelete: Cascade)\n  \n  political_news_crawler_crawl_jobs political_news_crawler_crawl_jobs[]\n  \n  @@index([crawl_source_id, is_enabled, next_crawl_at], map: \"political_news_crawler_crawl_schedules_crawl_source_id_bb22a9cd\")\n  @@index([crawl_policy_id])\n}","schema-02-actors.prisma":"/// Stores political news crawler guest user information representing\n/// unauthenticated users accessing APIs. Captures identification via IP and\n/// user agent, includes timestamps for auditing and soft deletion support.\n/// Guests are limited to read-only access with no password or login\n/// credentials.\n///\n/// @namespace Actors\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_guests {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// IP address of the guest user.\n  ip_address String\n  \n  /// User agent string presented by the guest.\n  user_agent String?\n  \n  /// Timestamp when the guest record was created.\n  created_at DateTime @db.Timestamptz\n  \n  /// Timestamp when the guest record was last updated.\n  updated_at DateTime @db.Timestamptz\n  \n  /// Timestamp of soft deletion for the guest record.\n  deleted_at DateTime? @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  @@unique([ip_address, user_agent])\n  @@index([created_at])\n}","schema-03-crawling.prisma":"/// Represents scheduled crawling jobs assigned to specific crawl sources and\n/// schedules, managing operational parameters and state for recurring\n/// political news retrieval tasks.\n///\n/// @namespace Crawling\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawl_jobs {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Referenced crawl source identifier. {@link\n  /// political_news_crawler_crawl_sources.id}\n  crawl_source_id String @db.Uuid\n  \n  /// Referenced crawl schedule identifier. {@link\n  /// political_news_crawler_crawl_schedules.id}\n  crawl_schedule_id String @db.Uuid\n  \n  /// Flag indicating if this crawl job is active and scheduled to run.\n  active Boolean\n  \n  /// Timestamp when the last run of the crawl job started, null if never run.\n  last_run_started_at DateTime? @db.Timestamptz\n  \n  /// Timestamp when the last run of the crawl job completed, null if still\n  /// running or never run.\n  last_run_completed_at DateTime? @db.Timestamptz\n  \n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n  \n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n  \n  /// Soft deletion timestamp, if set the job is considered deleted and ignored.\n  deleted_at DateTime? @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  crawlSource political_news_crawler_crawl_sources @relation(fields: [crawl_source_id], references: [id], onDelete: Cascade)\n  crawlSchedule political_news_crawler_crawl_schedules @relation(fields: [crawl_schedule_id], references: [id], onDelete: Cascade)\n  \n  political_news_crawler_crawl_attempts political_news_crawler_crawl_attempts[]\n  political_news_crawler_raw_data_storage political_news_crawler_raw_data_storage[]\n  \n  @@index([crawl_schedule_id])\n  \n  @@unique([crawl_source_id, crawl_schedule_id], map: \"political_news_crawler_crawl_jobs_crawl_source_id_craw_1330ef11\")\n  @@index([last_run_started_at, active], map: \"political_news_crawler_crawl_jobs_last_run_started_at__a5b9f998\")\n  @@index([active, last_run_completed_at], map: \"political_news_crawler_crawl_jobs_active_last_run_comp_3d4bd054\")\n}\n\n/// Records individual execution attempts of crawl jobs, tracking start and\n/// completion times, success status, errors, and associated raw data\n/// references to enable detailed auditing and failure analysis.\n///\n/// @namespace Crawling\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawl_attempts {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Associated crawl job identifier. {@link\n  /// political_news_crawler_crawl_jobs.id}\n  crawl_job_id String @db.Uuid\n  \n  /// Reference to raw data storage entry for the crawl result. {@link\n  /// political_news_crawler_raw_data_storage.id}\n  raw_data_storage_id String? @db.Uuid\n  \n  /// Timestamp when this crawl attempt started.\n  started_at DateTime @db.Timestamptz\n  \n  /// Timestamp when this crawl attempt ended; null if still running.\n  completed_at DateTime? @db.Timestamptz\n  \n  /// Indicator whether this crawl attempt was successful.\n  success Boolean\n  \n  /// Error message details if the crawl attempt failed.\n  error_message String?\n  \n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n  \n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  crawlJob political_news_crawler_crawl_jobs @relation(fields: [crawl_job_id], references: [id], onDelete: Cascade)\n  rawDataStorage political_news_crawler_raw_data_storage? @relation(fields: [raw_data_storage_id], references: [id], onDelete: Cascade)\n  \n  political_news_crawler_crawled_news political_news_crawler_crawled_news[]\n  \n  @@index([raw_data_storage_id])\n  \n  @@index([started_at, success])\n  @@index([crawl_job_id, started_at], map: \"political_news_crawler_crawl_attempts_crawl_job_id_sta_a468595a\")\n}\n\n/// Contains metadata for crawled political news articles, linking to the\n/// crawl attempt that obtained the raw content and providing key attributes\n/// for management and filtering.\n///\n/// @namespace Crawling\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawled_news {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Associated crawl attempt identifier. {@link\n  /// political_news_crawler_crawl_attempts.id}\n  crawl_attempt_id String @db.Uuid\n  \n  /// URL of the crawled news article.\n  url String\n  \n  /// Title of the news article, if available.\n  title String?\n  \n  /// Publish timestamp of the news article, if known.\n  published_at DateTime? @db.Timestamptz\n  \n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n  \n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  crawlAttempt political_news_crawler_crawl_attempts @relation(fields: [crawl_attempt_id], references: [id], onDelete: Cascade)\n  \n  political_news_crawler_topic_mentions political_news_crawler_topic_mentions[]\n  \n  @@index([crawl_attempt_id])\n  \n  @@unique([url])\n  @@index([published_at])\n}","schema-04-storage.prisma":"/// Stores metadata and references for raw political news data collected from\n/// various crawling sources. Ensures durable and consistent storage links to\n/// cloud object storage. Tracks source information, crawl job association,\n/// and data integrity validations. Includes audit timestamps for\n/// traceability.\n///\n/// @namespace Storage\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_raw_data_storage {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Belonged crawl source's political_news_crawler_crawl_sources.id.\n  crawl_source_id String @db.Uuid\n  \n  /// Optional crawl job reference to political_news_crawler_crawl_jobs.id.\n  crawl_job_id String? @db.Uuid\n  \n  /// Unique key or path identifying storage location in cloud object storage\n  /// (e.g., GCP or AWS S3).\n  storage_key String\n  \n  /// Format of the raw data file such as JSON or XML for processing\n  /// compatibility.\n  file_format String\n  \n  /// Size of the raw data file in bytes.\n  file_size_bytes Int @db.Integer\n  \n  /// Checksum hash to verify file integrity.\n  checksum String?\n  \n  /// Timestamp when the raw data was crawled, used for data freshness and\n  /// scheduling.\n  crawl_timestamp DateTime @db.Timestamptz\n  \n  /// Creation timestamp record.\n  created_at DateTime @db.Timestamptz\n  \n  /// Last update timestamp record.\n  updated_at DateTime @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  crawlSource political_news_crawler_crawl_sources @relation(fields: [crawl_source_id], references: [id], onDelete: Cascade)\n  crawlJob political_news_crawler_crawl_jobs? @relation(fields: [crawl_job_id], references: [id], onDelete: Cascade)\n  \n  political_news_crawler_crawl_attempts political_news_crawler_crawl_attempts[]\n  political_news_crawler_local_cache_files political_news_crawler_local_cache_files[]\n  political_news_crawler_processed_content political_news_crawler_processed_content[]\n  \n  @@index([crawl_job_id])\n  \n  @@unique([storage_key])\n  @@index([crawl_source_id, crawl_timestamp], map: \"political_news_crawler_raw_data_storage_crawl_source_i_a4e59727\")\n}\n\n/// Tracks local file cache copies of raw crawled political news data with\n/// TTL enforcement and deletion status. Enables fast retrieval during cloud\n/// storage outages and manages file lifecycle with audit timestamps.\n///\n/// @namespace Storage\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_local_cache_files {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Reference to related raw data storage record,\n  /// political_news_crawler_raw_data_storage.id.\n  raw_data_storage_id String @db.Uuid\n  \n  /// Filesystem path or identifier for the local cached file copy.\n  local_file_path String\n  \n  /// Size of the local cached file in bytes.\n  file_size_bytes Int @db.Integer\n  \n  /// Datetime when the cached file expires and is due for deletion under TTL\n  /// policy.\n  ttl_expiration_at DateTime @db.Timestamptz\n  \n  /// Soft delete timestamp indicating when the cached file was deleted, if\n  /// applicable.\n  deleted_at DateTime? @db.Timestamptz\n  \n  /// Creation timestamp record.\n  created_at DateTime @db.Timestamptz\n  \n  /// Last update timestamp record.\n  updated_at DateTime @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  rawDataStorage political_news_crawler_raw_data_storage @relation(fields: [raw_data_storage_id], references: [id], onDelete: Cascade, map: \"political_news_crawler_local_cache_files_raw_data_stor_39036344\")\n  \n  @@index([raw_data_storage_id], map: \"political_news_crawler_local_cache_files_raw_data_stor_e96143ec\")\n  \n  @@unique([local_file_path])\n  @@index([ttl_expiration_at])\n}\n\n/// Stores processed political news content generated by LLM post-processing,\n/// including summaries, highlights, and analysis. Links content to raw data\n/// storage and optionally to the LLM job that generated it. Contains content\n/// type, full text body, generation timestamp, and audit timestamps.\n/// Supports text search through GIN index on content body.\n///\n/// @namespace Storage\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_processed_content {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Foreign key to the raw data storage record,\n  /// political_news_crawler_raw_data_storage.id.\n  raw_data_storage_id String @db.Uuid\n  \n  /// Foreign key to associated LLM job, political_news_crawler_llm_jobs.id.\n  llm_job_id String? @db.Uuid\n  \n  /// Type of processed content, e.g., summary, highlight, or analysis.\n  content_type String\n  \n  /// Full textual content produced by LLM processing.\n  content_body String\n  \n  /// Timestamp when this content was generated.\n  generation_timestamp DateTime @db.Timestamptz\n  \n  /// Record creation timestamp, typically same or near generation time.\n  created_at DateTime @db.Timestamptz\n  \n  /// Last update timestamp record.\n  updated_at DateTime @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  rawDataStorage political_news_crawler_raw_data_storage @relation(fields: [raw_data_storage_id], references: [id], onDelete: Cascade, map: \"political_news_crawler_processed_content_raw_data_stor_b512d013\")\n  llmJob political_news_crawler_llm_jobs? @relation(fields: [llm_job_id], references: [id], onDelete: Cascade)\n  \n  @@index([llm_job_id])\n  \n  @@unique([raw_data_storage_id, content_type], map: \"political_news_crawler_processed_content_raw_data_stor_910af992\")\n  @@index([content_type])\n  @@index([content_body(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}","schema-05-processing.prisma":"/// LLM jobs represent individual processing tasks queued or executed for\n/// political news data. They track the job status, parameters, and\n/// processing flags. This model supports the management and monitoring of\n/// asynchronous LLM post-processing tasks such as generating summaries and\n/// analysis.\n///\n/// @namespace Processing\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_llm_jobs {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// The source channel from which the raw news data originated, referencing\n  /// political_news_crawler_crawl_sources.id.\n  crawl_source_id String @db.Uuid\n  \n  /// Processing status of the job, e.g., 'pending', 'running', 'completed',\n  /// 'failed'.\n  status String\n  \n  /// JSON string of parameters or prompts used for this LLM job.\n  parameters String\n  \n  /// Job creation timestamp.\n  created_at DateTime @db.Timestamptz\n  \n  /// Job last update timestamp.\n  updated_at DateTime @db.Timestamptz\n  \n  /// Soft delete timestamp, null if not deleted.\n  deleted_at DateTime? @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  crawlSource political_news_crawler_crawl_sources @relation(fields: [crawl_source_id], references: [id], onDelete: Cascade)\n  \n  political_news_crawler_processed_content political_news_crawler_processed_content[]\n  political_news_crawler_llm_results political_news_crawler_llm_results[]\n  political_news_crawler_processing_metadata political_news_crawler_processing_metadata[]\n  \n  @@index([crawl_source_id, status, created_at], map: \"political_news_crawler_llm_jobs_crawl_source_id_status_12346833\")\n  @@index([parameters(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// LLM results store the output content generated by LLM jobs, including\n/// summaries, highlights, and analyses. This model links back to the\n/// originating LLM job and preserves output details for retrieval and audit\n/// purposes.\n///\n/// @namespace Processing\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_llm_results {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Associated LLM job's political_news_crawler_llm_jobs.id.\n  llm_job_id String @db.Uuid\n  \n  /// Type of generated content, e.g., 'summary', 'highlight', 'analysis'.\n  content_type String\n  \n  /// Generated content text by the LLM.\n  content_text String\n  \n  /// Timestamp when the output was created.\n  created_at DateTime @db.Timestamptz\n  \n  /// Timestamp when the output was last updated.\n  updated_at DateTime @db.Timestamptz\n  \n  /// Soft delete timestamp, null if not deleted.\n  deleted_at DateTime? @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  llmJob political_news_crawler_llm_jobs @relation(fields: [llm_job_id], references: [id], onDelete: Cascade)\n  \n  @@index([llm_job_id, content_type])\n  @@index([content_text(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// Metadata entries for LLM processing capturing auxiliary information\n/// related to jobs or overall processing context. This table stores\n/// additional attributes to support enhancements and auditability.\n///\n/// @namespace Processing\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_processing_metadata {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Associated LLM job's political_news_crawler_llm_jobs.id.\n  llm_job_id String @db.Uuid\n  \n  /// Key name of the metadata attribute.\n  metadata_key String\n  \n  /// Value of the metadata attribute.\n  metadata_value String\n  \n  /// Metadata entry creation timestamp.\n  created_at DateTime @db.Timestamptz\n  \n  /// Metadata entry last update timestamp.\n  updated_at DateTime @db.Timestamptz\n  \n  /// Soft delete timestamp, null if not deleted.\n  deleted_at DateTime? @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  llmJob political_news_crawler_llm_jobs @relation(fields: [llm_job_id], references: [id], onDelete: Cascade)\n  \n  @@index([llm_job_id, metadata_key], map: \"political_news_crawler_processing_metadata_llm_job_id__f59c62c3\")\n}","schema-06-popularity.prisma":"/// Snapshot table capturing computed popularity scores for political topics\n/// at specific timestamps. Each record represents a historical state of a\n/// popularity calculation for auditing and trend analysis purposes.\n/// References the related popular topic. Includes score metrics and aging\n/// fields consistent with time-decayed ranking models.\n///\n/// @namespace Popularity\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_popularity_scores {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Referenced popular topic's {@link\n  /// political_news_crawler_popular_topics.id}.\n  political_news_crawler_popular_topic_id String @db.Uuid\n  \n  /// Calculated popularity score for the topic at this snapshot.\n  score Float @db.DoublePrecision\n  \n  /// Decay factor applied to the score based on the age of the topic mention.\n  decay_factor Float @db.DoublePrecision\n  \n  /// Timestamp when this popularity score snapshot was taken.\n  snapshot_at DateTime @db.Timestamptz\n  \n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n  \n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n  \n  /// Soft deletion timestamp if applicable, otherwise null.\n  deleted_at DateTime? @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  popularTopic political_news_crawler_popular_topics @relation(fields: [political_news_crawler_popular_topic_id], references: [id], onDelete: Cascade, map: \"political_news_crawler_popularity_scores_political_new_bd39518d\")\n  \n  @@index([political_news_crawler_popular_topic_id, snapshot_at], map: \"political_news_crawler_popularity_scores_political_new_670bf173\")\n}\n\n/// Primary table listing all current political news topics with computed\n/// popularity rankings. Maintains unique topic identifiers, titles, and\n/// metadata for efficient querying and API response. Supports independent\n/// management of topics and serves as the main entity for popularity-related\n/// queries.\n///\n/// @namespace Popularity\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_popular_topics {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Unique code identifier for the political topic.\n  topic_code String\n  \n  /// Official title or name of the popular topic.\n  title String\n  \n  /// Optional detailed description or context about the popular topic.\n  description String?\n  \n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n  \n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n  \n  /// Soft deletion timestamp if applicable, otherwise null.\n  deleted_at DateTime? @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  political_news_crawler_popularity_scores political_news_crawler_popularity_scores[]\n  political_news_crawler_topic_mentions political_news_crawler_topic_mentions[]\n  \n  @@unique([topic_code])\n  @@index([created_at])\n  @@index([title(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// Subsidiary table recording mentions of political topics within news\n/// articles. Establishes many-to-one relationships with both topics and\n/// crawled news records. Supports detailed traceability of topic references\n/// and feeds data for popularity calculations. Managed as supporting entity\n/// for topic analytics.\n///\n/// @namespace Popularity\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_topic_mentions {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Referenced popular topic's {@link\n  /// political_news_crawler_popular_topics.id}.\n  political_news_crawler_popular_topic_id String @db.Uuid\n  \n  /// Referenced crawled news item's {@link\n  /// political_news_crawler_crawled_news.id}.\n  political_news_crawler_crawled_news_id String @db.Uuid\n  \n  /// Optional text snippet or context where the topic is mentioned within the\n  /// article.\n  mention_context String?\n  \n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n  \n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n  \n  /// Soft deletion timestamp if applicable, otherwise null.\n  deleted_at DateTime? @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  popularTopic political_news_crawler_popular_topics @relation(fields: [political_news_crawler_popular_topic_id], references: [id], onDelete: Cascade, map: \"political_news_crawler_topic_mentions_political_news_c_ef19f1c7\")\n  crawledNews political_news_crawler_crawled_news @relation(fields: [political_news_crawler_crawled_news_id], references: [id], onDelete: Cascade, map: \"political_news_crawler_topic_mentions_political_news_c_ea889267\")\n  \n  @@index([political_news_crawler_popular_topic_id], map: \"political_news_crawler_topic_mentions_political_news_c_a5a42e74\")\n  @@index([political_news_crawler_crawled_news_id], map: \"political_news_crawler_topic_mentions_political_news_c_6f8a44b9\")\n  @@index([mention_context(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}","schema-07-api.prisma":"/// Records detailed log entries for every API access to track client\n/// requests, including request method, path, response status, client IP\n/// address, user agent, request duration in milliseconds, and timestamp.\n/// Supports comprehensive API usage analytics and operational monitoring.\n///\n/// @namespace API\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_api_access_logs {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// HTTP request method used in the API call, e.g., GET, POST, PUT.\n  http_method String\n  \n  /// API endpoint path being accessed, e.g., /api/v1/popular_topics.\n  path String\n  \n  /// HTTP response status code returned to the client.\n  status_code Int @db.Integer\n  \n  /// IP address of the client making the API request.\n  client_ip String\n  \n  /// User agent string of the client or application making the request.\n  user_agent String\n  \n  /// Duration of the API request processing in milliseconds.\n  duration_ms Int @db.Integer\n  \n  /// Timestamp when the log entry was created.\n  created_at DateTime @db.Timestamptz\n  \n  /// Timestamp when the log entry was last updated.\n  updated_at DateTime @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  @@index([http_method, path, status_code, created_at], map: \"political_news_crawler_api_access_logs_http_method_pat_90ce5ccb\")\n  @@index([client_ip, created_at])\n  @@index([user_agent, created_at], map: \"political_news_crawler_api_access_logs_user_agent_crea_1a375cdb\")\n  @@index([created_at])\n  @@index([path(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n  @@index([user_agent(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// Captures detailed records of API errors, including the API path, error\n/// code, error message, client IP, user agent, occurrence timestamp, and\n/// update timestamp. Enables error analysis and system troubleshooting for\n/// API endpoints.\n///\n/// @namespace API\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_api_error_logs {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// API endpoint path where the error occurred.\n  path String\n  \n  /// Error code identifying the type of API error.\n  error_code String\n  \n  /// Descriptive error message to assist debugging.\n  error_message String\n  \n  /// IP address of the client causing the error.\n  client_ip String\n  \n  /// User agent string of the client application.\n  user_agent String\n  \n  /// Timestamp when the error log was created.\n  created_at DateTime @db.Timestamptz\n  \n  /// Timestamp when the error log was last updated.\n  updated_at DateTime @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  @@index([path, error_code, created_at], map: \"political_news_crawler_api_error_logs_path_error_code__086a81a1\")\n  @@index([client_ip, created_at])\n  @@index([user_agent, created_at])\n  @@index([created_at])\n  @@index([path(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n  @@index([error_message(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n  @@index([user_agent(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// Aggregated API usage metrics capturing total counts of API calls by\n/// method and path over specific time periods, including maximum response\n/// times and average durations. Supports performance monitoring and traffic\n/// analysis for API endpoints.\n///\n/// @namespace API\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_api_usage_metrics {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// HTTP method for which metrics are aggregated.\n  http_method String\n  \n  /// API endpoint path for which metrics are aggregated.\n  path String\n  \n  /// Start timestamp of the aggregation period.\n  period_start DateTime @db.Timestamptz\n  \n  /// End timestamp of the aggregation period.\n  period_end DateTime @db.Timestamptz\n  \n  /// Total number of API calls observed in the aggregation period.\n  total_calls Int @db.Integer\n  \n  /// Maximum response time in milliseconds recorded during the period.\n  max_response_ms Int @db.Integer\n  \n  /// Average response time in milliseconds over the period.\n  avg_response_ms Int @db.Integer\n  \n  /// Timestamp when this aggregated record was created.\n  created_at DateTime @db.Timestamptz\n  \n  /// Timestamp when this aggregated record was last updated.\n  updated_at DateTime @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  @@unique([http_method, path, period_start], map: \"political_news_crawler_api_usage_metrics_http_method_p_5151a9d6\")\n  @@index([http_method, path, period_start, period_end], map: \"political_news_crawler_api_usage_metrics_http_method_p_bb640350\")\n  @@index([created_at])\n  @@index([path(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}","schema-08-alerts.prisma":"/// Stores alert events related to crawling operations, capturing failures,\n/// bans, or throttle notifications from crawl sources. Links alerts to\n/// specific crawl sources for traceability. Contains timestamp, severity\n/// level, and descriptive message for operational monitoring.\n///\n/// @namespace Alerts\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawl_alerts {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Referenced crawl source's {@link political_news_crawler_crawl_sources.id}\n  /// which triggered the alert.\n  crawl_source_id String @db.Uuid\n  \n  /// Type of alert event indicating the category, e.g., 'ban_detected',\n  /// 'network_error', 'throttle_warning'.\n  alert_type String\n  \n  /// Detailed description of the alert event and context for operational\n  /// understanding.\n  message String\n  \n  /// Severity level of the alert such as 'info', 'warning', 'critical'.\n  severity String\n  \n  /// Timestamp when the alert was created.\n  created_at DateTime @db.Timestamptz\n  \n  /// Timestamp when the alert was last updated.\n  updated_at DateTime @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  crawlSource political_news_crawler_crawl_sources @relation(fields: [crawl_source_id], references: [id], onDelete: Cascade)\n  \n  @@unique([crawl_source_id, alert_type, created_at], map: \"political_news_crawler_crawl_alerts_crawl_source_id_al_6ad89660\")\n  @@index([created_at])\n  @@index([severity])\n  @@index([message(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// Captures alert events related to processing pipeline failures including\n/// LLM processing errors, queue backlogs, or retry escalations. Provides\n/// detailed messages and timestamp info for system diagnostics and\n/// resolution procedures.\n///\n/// @namespace Alerts\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_processing_alerts {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Category of processing alert such as 'llm_failure', 'queue_overflow',\n  /// 'retry_limit_reached'.\n  alert_type String\n  \n  /// Detailed description of the processing alert event for operational use.\n  message String\n  \n  /// Severity level of the alert (e.g., 'info', 'warning', 'critical').\n  severity String\n  \n  /// Timestamp when the alert was created.\n  created_at DateTime @db.Timestamptz\n  \n  /// Timestamp for last update of the alert.\n  updated_at DateTime @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  @@unique([alert_type, created_at], map: \"political_news_crawler_processing_alerts_alert_type_cr_ed4a0c20\")\n  @@index([created_at])\n  @@index([severity])\n  @@index([message(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// Contains alert records related to API subsystem errors including rate\n/// limiting, endpoint failures, and error spikes. Supports operational\n/// monitoring by storing detailed messages and timestamps of occurrence.\n///\n/// @namespace Alerts\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_api_alerts {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n  \n  /// Type of API alert event such as 'rate_limit_exceeded', 'endpoint_error',\n  /// 'error_spike'.\n  alert_type String\n  \n  /// Detailed message describing the API alert context.\n  message String\n  \n  /// Severity level of the alert such as 'info', 'warning', 'critical'.\n  severity String\n  \n  /// Timestamp when the alert was created.\n  created_at DateTime @db.Timestamptz\n  \n  /// Timestamp when the alert was last updated.\n  updated_at DateTime @db.Timestamptz\n  \n  //----\n  // RELATIONS\n  //----\n  @@unique([alert_type, created_at])\n  @@index([created_at])\n  @@index([severity])\n  @@index([message(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}","main.prisma":"generator client {\n  provider        = \"prisma-client-js\"\n  previewFeatures = [\"postgresqlExtensions\", \"views\"]\n  binaryTargets   = [\"native\"]\n}\ndatasource db {\n  provider   = \"postgresql\"\n  url        = env(\"DATABASE_URL\")\n  extensions = [pg_trgm]\n}\ngenerator markdown {\n  provider = \"prisma-markdown\"\n  output   = \"../../docs/ERD.md\"\n}"},"result":{"success":true,"data":{"files":[{"filename":"schema-01-systematic.prisma","namespace":"Systematic","models":[{"name":"political_news_crawler_crawl_sources","description":"Represents political news crawling sources configuration. Contains source URLs, status, and metadata for controlling crawl initiation and processing. Used to manage diverse data feed points for politicalNewsCrawler.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[],"plainFields":[{"name":"source_code","type":"string","nullable":false,"description":"Unique identifier code for the crawl source."},{"name":"source_url","type":"uri","nullable":false,"description":"The base URL of the crawl source website or API."},{"name":"is_active","type":"boolean","nullable":false,"description":"Flag indicating whether the crawl source is active and enabled for crawling."},{"name":"description","type":"string","nullable":true,"description":"Optional description of the crawl source."},{"name":"created_at","type":"datetime","nullable":false,"description":"Record creation timestamp."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Record last update timestamp."},{"name":"deleted_at","type":"datetime","nullable":true,"description":"Soft delete timestamp, if record is deleted."}],"uniqueIndexes":[{"fieldNames":["source_code"],"unique":true},{"fieldNames":["source_url"],"unique":true}],"plainIndexes":[{"fieldNames":["is_active","created_at"]}],"ginIndexes":[]},{"name":"political_news_crawler_crawl_policies","description":"Configuration for crawl policies governing crawling frequency, retry, and error handling for political news sources. Ensures adaptive and respectful crawling behavior according to source limits and bans.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[],"plainFields":[{"name":"policy_name","type":"string","nullable":false,"description":"Unique name identifier for the crawl policy."},{"name":"max_crawl_frequency_minutes","type":"int","nullable":false,"description":"Maximum allowed crawl frequency in minutes."},{"name":"max_retry_attempts","type":"int","nullable":false,"description":"Maximum number of retry attempts after failures."},{"name":"backoff_multiplier","type":"double","nullable":false,"description":"Multiplier factor for exponential backoff on retries."},{"name":"ban_detection_enabled","type":"boolean","nullable":false,"description":"Flag to enable detection and handling of bans during crawling."},{"name":"created_at","type":"datetime","nullable":false,"description":"Record creation timestamp."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Record last update timestamp."},{"name":"deleted_at","type":"datetime","nullable":true,"description":"Soft delete timestamp, if record is deleted."}],"uniqueIndexes":[{"fieldNames":["policy_name"],"unique":true}],"plainIndexes":[{"fieldNames":["max_crawl_frequency_minutes","ban_detection_enabled"]}],"ginIndexes":[]},{"name":"political_news_crawler_crawl_schedules","description":"Schedules defining when and how often crawling runs for each political news source. References the crawl source and policy to enable adaptive scheduling and coordination.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[{"name":"crawl_source_id","type":"uuid","nullable":false,"description":"Reference to Crawling Source. {@link political_news_crawler_crawl_sources.id}","relation":{"name":"crawlSource","targetModel":"political_news_crawler_crawl_sources"},"unique":false},{"name":"crawl_policy_id","type":"uuid","nullable":false,"description":"Reference to Crawl Policy. {@link political_news_crawler_crawl_policies.id}","relation":{"name":"crawlPolicy","targetModel":"political_news_crawler_crawl_policies"},"unique":false}],"plainFields":[{"name":"schedule_expression","type":"string","nullable":false,"description":"Cron expression defining the crawl schedule timing."},{"name":"last_crawled_at","type":"datetime","nullable":true,"description":"Timestamp when the crawl last occurred."},{"name":"next_crawl_at","type":"datetime","nullable":true,"description":"Timestamp for the next scheduled crawl."},{"name":"is_enabled","type":"boolean","nullable":false,"description":"Flag indicating if this schedule is enabled."},{"name":"created_at","type":"datetime","nullable":false,"description":"Record creation timestamp."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Record last update timestamp."},{"name":"deleted_at","type":"datetime","nullable":true,"description":"Soft delete timestamp, if record is deleted."}],"uniqueIndexes":[],"plainIndexes":[{"fieldNames":["crawl_source_id","is_enabled","next_crawl_at"]},{"fieldNames":["crawl_policy_id"]}],"ginIndexes":[]}]},{"filename":"schema-02-actors.prisma","namespace":"Actors","models":[{"name":"political_news_crawler_guests","description":"Stores political news crawler guest user information representing unauthenticated users accessing APIs. Captures identification via IP and user agent, includes timestamps for auditing and soft deletion support. Guests are limited to read-only access with no password or login credentials.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[],"plainFields":[{"name":"ip_address","type":"string","nullable":false,"description":"IP address of the guest user."},{"name":"user_agent","type":"string","nullable":true,"description":"User agent string presented by the guest."},{"name":"created_at","type":"datetime","nullable":false,"description":"Timestamp when the guest record was created."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Timestamp when the guest record was last updated."},{"name":"deleted_at","type":"datetime","nullable":true,"description":"Timestamp of soft deletion for the guest record."}],"uniqueIndexes":[{"fieldNames":["ip_address","user_agent"],"unique":true}],"plainIndexes":[{"fieldNames":["created_at"]}],"ginIndexes":[]}]},{"filename":"schema-03-crawling.prisma","namespace":"Crawling","models":[{"name":"political_news_crawler_crawl_jobs","description":"Represents scheduled crawling jobs assigned to specific crawl sources and schedules, managing operational parameters and state for recurring political news retrieval tasks.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[{"name":"crawl_source_id","type":"uuid","description":"Referenced crawl source identifier. {@link political_news_crawler_crawl_sources.id}","relation":{"name":"crawlSource","targetModel":"political_news_crawler_crawl_sources"},"unique":false,"nullable":false},{"name":"crawl_schedule_id","type":"uuid","description":"Referenced crawl schedule identifier. {@link political_news_crawler_crawl_schedules.id}","relation":{"name":"crawlSchedule","targetModel":"political_news_crawler_crawl_schedules"},"unique":false,"nullable":false}],"plainFields":[{"name":"active","type":"boolean","nullable":false,"description":"Flag indicating if this crawl job is active and scheduled to run."},{"name":"last_run_started_at","type":"datetime","nullable":true,"description":"Timestamp when the last run of the crawl job started, null if never run."},{"name":"last_run_completed_at","type":"datetime","nullable":true,"description":"Timestamp when the last run of the crawl job completed, null if still running or never run."},{"name":"created_at","type":"datetime","nullable":false,"description":"Record creation timestamp."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Record last update timestamp."},{"name":"deleted_at","type":"datetime","nullable":true,"description":"Soft deletion timestamp, if set the job is considered deleted and ignored."}],"uniqueIndexes":[{"fieldNames":["crawl_source_id","crawl_schedule_id"],"unique":true}],"plainIndexes":[{"fieldNames":["last_run_started_at","active"]},{"fieldNames":["active","last_run_completed_at"]}],"ginIndexes":[]},{"name":"political_news_crawler_crawl_attempts","description":"Records individual execution attempts of crawl jobs, tracking start and completion times, success status, errors, and associated raw data references to enable detailed auditing and failure analysis.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[{"name":"crawl_job_id","type":"uuid","description":"Associated crawl job identifier. {@link political_news_crawler_crawl_jobs.id}","relation":{"name":"crawlJob","targetModel":"political_news_crawler_crawl_jobs"},"unique":false,"nullable":false},{"name":"raw_data_storage_id","type":"uuid","description":"Reference to raw data storage entry for the crawl result. {@link political_news_crawler_raw_data_storage.id}","relation":{"name":"rawDataStorage","targetModel":"political_news_crawler_raw_data_storage"},"unique":false,"nullable":true}],"plainFields":[{"name":"started_at","type":"datetime","nullable":false,"description":"Timestamp when this crawl attempt started."},{"name":"completed_at","type":"datetime","nullable":true,"description":"Timestamp when this crawl attempt ended; null if still running."},{"name":"success","type":"boolean","nullable":false,"description":"Indicator whether this crawl attempt was successful."},{"name":"error_message","type":"string","nullable":true,"description":"Error message details if the crawl attempt failed."},{"name":"created_at","type":"datetime","nullable":false,"description":"Record creation timestamp."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Record last update timestamp."}],"uniqueIndexes":[],"plainIndexes":[{"fieldNames":["started_at","success"]},{"fieldNames":["crawl_job_id","started_at"]}],"ginIndexes":[]},{"name":"political_news_crawler_crawled_news","description":"Contains metadata for crawled political news articles, linking to the crawl attempt that obtained the raw content and providing key attributes for management and filtering.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[{"name":"crawl_attempt_id","type":"uuid","description":"Associated crawl attempt identifier. {@link political_news_crawler_crawl_attempts.id}","relation":{"name":"crawlAttempt","targetModel":"political_news_crawler_crawl_attempts"},"unique":false,"nullable":false}],"plainFields":[{"name":"url","type":"string","nullable":false,"description":"URL of the crawled news article."},{"name":"title","type":"string","nullable":true,"description":"Title of the news article, if available."},{"name":"published_at","type":"datetime","nullable":true,"description":"Publish timestamp of the news article, if known."},{"name":"created_at","type":"datetime","nullable":false,"description":"Record creation timestamp."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Record last update timestamp."}],"uniqueIndexes":[{"fieldNames":["url"],"unique":true}],"plainIndexes":[{"fieldNames":["published_at"]}],"ginIndexes":[]}]},{"filename":"schema-04-storage.prisma","namespace":"Storage","models":[{"name":"political_news_crawler_raw_data_storage","description":"Stores metadata and references for raw political news data collected from various crawling sources. Ensures durable and consistent storage links to cloud object storage. Tracks source information, crawl job association, and data integrity validations. Includes audit timestamps for traceability.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[{"name":"crawl_source_id","type":"uuid","description":"Belonged crawl source's political_news_crawler_crawl_sources.id.","relation":{"name":"crawlSource","targetModel":"political_news_crawler_crawl_sources"},"unique":false,"nullable":false},{"name":"crawl_job_id","type":"uuid","description":"Optional crawl job reference to political_news_crawler_crawl_jobs.id.","relation":{"name":"crawlJob","targetModel":"political_news_crawler_crawl_jobs"},"unique":false,"nullable":true}],"plainFields":[{"name":"storage_key","type":"string","description":"Unique key or path identifying storage location in cloud object storage (e.g., GCP or AWS S3).","nullable":false},{"name":"file_format","type":"string","description":"Format of the raw data file such as JSON or XML for processing compatibility.","nullable":false},{"name":"file_size_bytes","type":"int","description":"Size of the raw data file in bytes.","nullable":false},{"name":"checksum","type":"string","description":"Checksum hash to verify file integrity.","nullable":true},{"name":"crawl_timestamp","type":"datetime","description":"Timestamp when the raw data was crawled, used for data freshness and scheduling.","nullable":false},{"name":"created_at","type":"datetime","description":"Creation timestamp record.","nullable":false},{"name":"updated_at","type":"datetime","description":"Last update timestamp record.","nullable":false}],"uniqueIndexes":[{"fieldNames":["storage_key"],"unique":true}],"plainIndexes":[{"fieldNames":["crawl_source_id","crawl_timestamp"]}],"ginIndexes":[]},{"name":"political_news_crawler_local_cache_files","description":"Tracks local file cache copies of raw crawled political news data with TTL enforcement and deletion status. Enables fast retrieval during cloud storage outages and manages file lifecycle with audit timestamps.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[{"name":"raw_data_storage_id","type":"uuid","description":"Reference to related raw data storage record, political_news_crawler_raw_data_storage.id.","relation":{"name":"rawDataStorage","targetModel":"political_news_crawler_raw_data_storage"},"unique":false,"nullable":false}],"plainFields":[{"name":"local_file_path","type":"string","description":"Filesystem path or identifier for the local cached file copy.","nullable":false},{"name":"file_size_bytes","type":"int","description":"Size of the local cached file in bytes.","nullable":false},{"name":"ttl_expiration_at","type":"datetime","description":"Datetime when the cached file expires and is due for deletion under TTL policy.","nullable":false},{"name":"deleted_at","type":"datetime","description":"Soft delete timestamp indicating when the cached file was deleted, if applicable.","nullable":true},{"name":"created_at","type":"datetime","description":"Creation timestamp record.","nullable":false},{"name":"updated_at","type":"datetime","description":"Last update timestamp record.","nullable":false}],"uniqueIndexes":[{"fieldNames":["local_file_path"],"unique":true}],"plainIndexes":[{"fieldNames":["ttl_expiration_at"]}],"ginIndexes":[]},{"name":"political_news_crawler_processed_content","description":"Stores processed political news content generated by LLM post-processing, including summaries, highlights, and analysis. Links content to raw data storage and optionally to the LLM job that generated it. Contains content type, full text body, generation timestamp, and audit timestamps. Supports text search through GIN index on content body.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[{"name":"raw_data_storage_id","type":"uuid","description":"Foreign key to the raw data storage record, political_news_crawler_raw_data_storage.id.","relation":{"name":"rawDataStorage","targetModel":"political_news_crawler_raw_data_storage"},"unique":false,"nullable":false},{"name":"llm_job_id","type":"uuid","description":"Foreign key to associated LLM job, political_news_crawler_llm_jobs.id.","relation":{"name":"llmJob","targetModel":"political_news_crawler_llm_jobs"},"unique":false,"nullable":true}],"plainFields":[{"name":"content_type","type":"string","description":"Type of processed content, e.g., summary, highlight, or analysis.","nullable":false},{"name":"content_body","type":"string","description":"Full textual content produced by LLM processing.","nullable":false},{"name":"generation_timestamp","type":"datetime","description":"Timestamp when this content was generated.","nullable":false},{"name":"created_at","type":"datetime","description":"Record creation timestamp, typically same or near generation time.","nullable":false},{"name":"updated_at","type":"datetime","description":"Last update timestamp record.","nullable":false}],"uniqueIndexes":[{"fieldNames":["raw_data_storage_id","content_type"],"unique":true}],"plainIndexes":[{"fieldNames":["content_type"]}],"ginIndexes":[{"fieldName":"content_body"}]}]},{"filename":"schema-05-processing.prisma","namespace":"Processing","models":[{"name":"political_news_crawler_llm_jobs","description":"LLM jobs represent individual processing tasks queued or executed for political news data. They track the job status, parameters, and processing flags. This model supports the management and monitoring of asynchronous LLM post-processing tasks such as generating summaries and analysis.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[{"name":"crawl_source_id","type":"uuid","description":"The source channel from which the raw news data originated, referencing political_news_crawler_crawl_sources.id.","relation":{"name":"crawlSource","targetModel":"political_news_crawler_crawl_sources"},"unique":false,"nullable":false}],"plainFields":[{"name":"status","type":"string","nullable":false,"description":"Processing status of the job, e.g., 'pending', 'running', 'completed', 'failed'."},{"name":"parameters","type":"string","nullable":false,"description":"JSON string of parameters or prompts used for this LLM job."},{"name":"created_at","type":"datetime","nullable":false,"description":"Job creation timestamp."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Job last update timestamp."},{"name":"deleted_at","type":"datetime","nullable":true,"description":"Soft delete timestamp, null if not deleted."}],"uniqueIndexes":[],"plainIndexes":[{"fieldNames":["crawl_source_id","status","created_at"]}],"ginIndexes":[{"fieldName":"parameters"}]},{"name":"political_news_crawler_llm_results","description":"LLM results store the output content generated by LLM jobs, including summaries, highlights, and analyses. This model links back to the originating LLM job and preserves output details for retrieval and audit purposes.","material":false,"stance":"subsidiary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[{"name":"llm_job_id","type":"uuid","description":"Associated LLM job's political_news_crawler_llm_jobs.id.","relation":{"name":"llmJob","targetModel":"political_news_crawler_llm_jobs"},"unique":false,"nullable":false}],"plainFields":[{"name":"content_type","type":"string","nullable":false,"description":"Type of generated content, e.g., 'summary', 'highlight', 'analysis'."},{"name":"content_text","type":"string","nullable":false,"description":"Generated content text by the LLM."},{"name":"created_at","type":"datetime","nullable":false,"description":"Timestamp when the output was created."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Timestamp when the output was last updated."},{"name":"deleted_at","type":"datetime","nullable":true,"description":"Soft delete timestamp, null if not deleted."}],"uniqueIndexes":[],"plainIndexes":[{"fieldNames":["llm_job_id","content_type"]}],"ginIndexes":[{"fieldName":"content_text"}]},{"name":"political_news_crawler_processing_metadata","description":"Metadata entries for LLM processing capturing auxiliary information related to jobs or overall processing context. This table stores additional attributes to support enhancements and auditability.","material":false,"stance":"subsidiary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[{"name":"llm_job_id","type":"uuid","description":"Associated LLM job's political_news_crawler_llm_jobs.id.","relation":{"name":"llmJob","targetModel":"political_news_crawler_llm_jobs"},"unique":false,"nullable":false}],"plainFields":[{"name":"metadata_key","type":"string","nullable":false,"description":"Key name of the metadata attribute."},{"name":"metadata_value","type":"string","nullable":false,"description":"Value of the metadata attribute."},{"name":"created_at","type":"datetime","nullable":false,"description":"Metadata entry creation timestamp."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Metadata entry last update timestamp."},{"name":"deleted_at","type":"datetime","nullable":true,"description":"Soft delete timestamp, null if not deleted."}],"uniqueIndexes":[],"plainIndexes":[{"fieldNames":["llm_job_id","metadata_key"]}],"ginIndexes":[]}]},{"filename":"schema-06-popularity.prisma","namespace":"Popularity","models":[{"name":"political_news_crawler_popularity_scores","description":"Snapshot table capturing computed popularity scores for political topics at specific timestamps. Each record represents a historical state of a popularity calculation for auditing and trend analysis purposes. References the related popular topic. Includes score metrics and aging fields consistent with time-decayed ranking models.","material":false,"stance":"snapshot","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[{"name":"political_news_crawler_popular_topic_id","type":"uuid","description":"Referenced popular topic's {@link political_news_crawler_popular_topics.id}.","relation":{"name":"popularTopic","targetModel":"political_news_crawler_popular_topics"},"unique":false,"nullable":false}],"plainFields":[{"name":"score","type":"double","nullable":false,"description":"Calculated popularity score for the topic at this snapshot."},{"name":"decay_factor","type":"double","nullable":false,"description":"Decay factor applied to the score based on the age of the topic mention."},{"name":"snapshot_at","type":"datetime","nullable":false,"description":"Timestamp when this popularity score snapshot was taken."},{"name":"created_at","type":"datetime","nullable":false,"description":"Record creation timestamp."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Record last update timestamp."},{"name":"deleted_at","type":"datetime","nullable":true,"description":"Soft deletion timestamp if applicable, otherwise null."}],"uniqueIndexes":[],"plainIndexes":[{"fieldNames":["political_news_crawler_popular_topic_id","snapshot_at"]}],"ginIndexes":[]},{"name":"political_news_crawler_popular_topics","description":"Primary table listing all current political news topics with computed popularity rankings. Maintains unique topic identifiers, titles, and metadata for efficient querying and API response. Supports independent management of topics and serves as the main entity for popularity-related queries.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[],"plainFields":[{"name":"topic_code","type":"string","nullable":false,"description":"Unique code identifier for the political topic."},{"name":"title","type":"string","nullable":false,"description":"Official title or name of the popular topic."},{"name":"description","type":"string","nullable":true,"description":"Optional detailed description or context about the popular topic."},{"name":"created_at","type":"datetime","nullable":false,"description":"Record creation timestamp."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Record last update timestamp."},{"name":"deleted_at","type":"datetime","nullable":true,"description":"Soft deletion timestamp if applicable, otherwise null."}],"uniqueIndexes":[{"fieldNames":["topic_code"],"unique":true}],"plainIndexes":[{"fieldNames":["created_at"]}],"ginIndexes":[{"fieldName":"title"}]},{"name":"political_news_crawler_topic_mentions","description":"Subsidiary table recording mentions of political topics within news articles. Establishes many-to-one relationships with both topics and crawled news records. Supports detailed traceability of topic references and feeds data for popularity calculations. Managed as supporting entity for topic analytics.","material":false,"stance":"subsidiary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[{"name":"political_news_crawler_popular_topic_id","type":"uuid","description":"Referenced popular topic's {@link political_news_crawler_popular_topics.id}.","relation":{"name":"popularTopic","targetModel":"political_news_crawler_popular_topics"},"unique":false,"nullable":false},{"name":"political_news_crawler_crawled_news_id","type":"uuid","description":"Referenced crawled news item's {@link political_news_crawler_crawled_news.id}.","relation":{"name":"crawledNews","targetModel":"political_news_crawler_crawled_news"},"unique":false,"nullable":false}],"plainFields":[{"name":"mention_context","type":"string","nullable":true,"description":"Optional text snippet or context where the topic is mentioned within the article."},{"name":"created_at","type":"datetime","nullable":false,"description":"Record creation timestamp."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Record last update timestamp."},{"name":"deleted_at","type":"datetime","nullable":true,"description":"Soft deletion timestamp if applicable, otherwise null."}],"uniqueIndexes":[],"plainIndexes":[{"fieldNames":["political_news_crawler_popular_topic_id"]},{"fieldNames":["political_news_crawler_crawled_news_id"]}],"ginIndexes":[{"fieldName":"mention_context"}]}]},{"filename":"schema-07-api.prisma","namespace":"API","models":[{"name":"political_news_crawler_api_access_logs","description":"Records detailed log entries for every API access to track client requests, including request method, path, response status, client IP address, user agent, request duration in milliseconds, and timestamp. Supports comprehensive API usage analytics and operational monitoring.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[],"plainFields":[{"name":"http_method","type":"string","nullable":false,"description":"HTTP request method used in the API call, e.g., GET, POST, PUT."},{"name":"path","type":"string","nullable":false,"description":"API endpoint path being accessed, e.g., /api/v1/popular_topics."},{"name":"status_code","type":"int","nullable":false,"description":"HTTP response status code returned to the client."},{"name":"client_ip","type":"string","nullable":false,"description":"IP address of the client making the API request."},{"name":"user_agent","type":"string","nullable":false,"description":"User agent string of the client or application making the request."},{"name":"duration_ms","type":"int","nullable":false,"description":"Duration of the API request processing in milliseconds."},{"name":"created_at","type":"datetime","nullable":false,"description":"Timestamp when the log entry was created."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Timestamp when the log entry was last updated."}],"uniqueIndexes":[],"plainIndexes":[{"fieldNames":["http_method","path","status_code","created_at"]},{"fieldNames":["client_ip","created_at"]},{"fieldNames":["user_agent","created_at"]},{"fieldNames":["created_at"]}],"ginIndexes":[{"fieldName":"path"},{"fieldName":"user_agent"}]},{"name":"political_news_crawler_api_error_logs","description":"Captures detailed records of API errors, including the API path, error code, error message, client IP, user agent, occurrence timestamp, and update timestamp. Enables error analysis and system troubleshooting for API endpoints.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[],"plainFields":[{"name":"path","type":"string","nullable":false,"description":"API endpoint path where the error occurred."},{"name":"error_code","type":"string","nullable":false,"description":"Error code identifying the type of API error."},{"name":"error_message","type":"string","nullable":false,"description":"Descriptive error message to assist debugging."},{"name":"client_ip","type":"string","nullable":false,"description":"IP address of the client causing the error."},{"name":"user_agent","type":"string","nullable":false,"description":"User agent string of the client application."},{"name":"created_at","type":"datetime","nullable":false,"description":"Timestamp when the error log was created."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Timestamp when the error log was last updated."}],"uniqueIndexes":[],"plainIndexes":[{"fieldNames":["path","error_code","created_at"]},{"fieldNames":["client_ip","created_at"]},{"fieldNames":["user_agent","created_at"]},{"fieldNames":["created_at"]}],"ginIndexes":[{"fieldName":"path"},{"fieldName":"error_message"},{"fieldName":"user_agent"}]},{"name":"political_news_crawler_api_usage_metrics","description":"Aggregated API usage metrics capturing total counts of API calls by method and path over specific time periods, including maximum response times and average durations. Supports performance monitoring and traffic analysis for API endpoints.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[],"plainFields":[{"name":"http_method","type":"string","nullable":false,"description":"HTTP method for which metrics are aggregated."},{"name":"path","type":"string","nullable":false,"description":"API endpoint path for which metrics are aggregated."},{"name":"period_start","type":"datetime","nullable":false,"description":"Start timestamp of the aggregation period."},{"name":"period_end","type":"datetime","nullable":false,"description":"End timestamp of the aggregation period."},{"name":"total_calls","type":"int","nullable":false,"description":"Total number of API calls observed in the aggregation period."},{"name":"max_response_ms","type":"int","nullable":false,"description":"Maximum response time in milliseconds recorded during the period."},{"name":"avg_response_ms","type":"int","nullable":false,"description":"Average response time in milliseconds over the period."},{"name":"created_at","type":"datetime","nullable":false,"description":"Timestamp when this aggregated record was created."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Timestamp when this aggregated record was last updated."}],"uniqueIndexes":[{"fieldNames":["http_method","path","period_start"],"unique":true}],"plainIndexes":[{"fieldNames":["http_method","path","period_start","period_end"]},{"fieldNames":["created_at"]}],"ginIndexes":[{"fieldName":"path"}]}]},{"filename":"schema-08-alerts.prisma","namespace":"Alerts","models":[{"name":"political_news_crawler_crawl_alerts","description":"Stores alert events related to crawling operations, capturing failures, bans, or throttle notifications from crawl sources. Links alerts to specific crawl sources for traceability. Contains timestamp, severity level, and descriptive message for operational monitoring.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[{"name":"crawl_source_id","type":"uuid","description":"Referenced crawl source's {@link political_news_crawler_crawl_sources.id} which triggered the alert.","relation":{"name":"crawlSource","targetModel":"political_news_crawler_crawl_sources"},"unique":false,"nullable":false}],"plainFields":[{"name":"alert_type","type":"string","nullable":false,"description":"Type of alert event indicating the category, e.g., 'ban_detected', 'network_error', 'throttle_warning'."},{"name":"message","type":"string","nullable":false,"description":"Detailed description of the alert event and context for operational understanding."},{"name":"severity","type":"string","nullable":false,"description":"Severity level of the alert such as 'info', 'warning', 'critical'."},{"name":"created_at","type":"datetime","nullable":false,"description":"Timestamp when the alert was created."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Timestamp when the alert was last updated."}],"uniqueIndexes":[{"fieldNames":["crawl_source_id","alert_type","created_at"],"unique":true}],"plainIndexes":[{"fieldNames":["created_at"]},{"fieldNames":["severity"]}],"ginIndexes":[{"fieldName":"message"}]},{"name":"political_news_crawler_processing_alerts","description":"Captures alert events related to processing pipeline failures including LLM processing errors, queue backlogs, or retry escalations. Provides detailed messages and timestamp info for system diagnostics and resolution procedures.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[],"plainFields":[{"name":"alert_type","type":"string","nullable":false,"description":"Category of processing alert such as 'llm_failure', 'queue_overflow', 'retry_limit_reached'."},{"name":"message","type":"string","nullable":false,"description":"Detailed description of the processing alert event for operational use."},{"name":"severity","type":"string","nullable":false,"description":"Severity level of the alert (e.g., 'info', 'warning', 'critical')."},{"name":"created_at","type":"datetime","nullable":false,"description":"Timestamp when the alert was created."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Timestamp for last update of the alert."}],"uniqueIndexes":[{"fieldNames":["alert_type","created_at"],"unique":true}],"plainIndexes":[{"fieldNames":["created_at"]},{"fieldNames":["severity"]}],"ginIndexes":[{"fieldName":"message"}]},{"name":"political_news_crawler_api_alerts","description":"Contains alert records related to API subsystem errors including rate limiting, endpoint failures, and error spikes. Supports operational monitoring by storing detailed messages and timestamps of occurrence.","material":false,"stance":"primary","primaryField":{"name":"id","type":"uuid","description":"Primary Key."},"foreignFields":[],"plainFields":[{"name":"alert_type","type":"string","nullable":false,"description":"Type of API alert event such as 'rate_limit_exceeded', 'endpoint_error', 'error_spike'."},{"name":"message","type":"string","nullable":false,"description":"Detailed message describing the API alert context."},{"name":"severity","type":"string","nullable":false,"description":"Severity level of the alert such as 'info', 'warning', 'critical'."},{"name":"created_at","type":"datetime","nullable":false,"description":"Timestamp when the alert was created."},{"name":"updated_at","type":"datetime","nullable":false,"description":"Timestamp when the alert was last updated."}],"uniqueIndexes":[{"fieldNames":["alert_type","created_at"],"unique":true}],"plainIndexes":[{"fieldNames":["created_at"]},{"fieldNames":["severity"]}],"ginIndexes":[{"fieldName":"message"}]}]}]}},"compiled":{"type":"success","schemas":{"schema-01-systematic.prisma":"/// Represents political news crawling sources configuration. Contains source\n/// URLs, status, and metadata for controlling crawl initiation and\n/// processing. Used to manage diverse data feed points for\n/// politicalNewsCrawler.\n///\n/// @namespace Systematic\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawl_sources {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Unique identifier code for the crawl source.\n  source_code String\n\n  /// The base URL of the crawl source website or API.\n  source_url String @db.VarChar(80000)\n\n  /// Flag indicating whether the crawl source is active and enabled for\n  /// crawling.\n  is_active Boolean\n\n  /// Optional description of the crawl source.\n  description String?\n\n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n\n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n\n  /// Soft delete timestamp, if record is deleted.\n  deleted_at DateTime? @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  political_news_crawler_crawl_schedules  political_news_crawler_crawl_schedules[]\n  political_news_crawler_crawl_jobs       political_news_crawler_crawl_jobs[]\n  political_news_crawler_raw_data_storage political_news_crawler_raw_data_storage[]\n  political_news_crawler_llm_jobs         political_news_crawler_llm_jobs[]\n  political_news_crawler_crawl_alerts     political_news_crawler_crawl_alerts[]\n\n  @@unique([source_code])\n  @@unique([source_url])\n  @@index([is_active, created_at])\n}\n\n/// Configuration for crawl policies governing crawling frequency, retry, and\n/// error handling for political news sources. Ensures adaptive and\n/// respectful crawling behavior according to source limits and bans.\n///\n/// @namespace Systematic\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawl_policies {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Unique name identifier for the crawl policy.\n  policy_name String\n\n  /// Maximum allowed crawl frequency in minutes.\n  max_crawl_frequency_minutes Int @db.Integer\n\n  /// Maximum number of retry attempts after failures.\n  max_retry_attempts Int @db.Integer\n\n  /// Multiplier factor for exponential backoff on retries.\n  backoff_multiplier Float @db.DoublePrecision\n\n  /// Flag to enable detection and handling of bans during crawling.\n  ban_detection_enabled Boolean\n\n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n\n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n\n  /// Soft delete timestamp, if record is deleted.\n  deleted_at DateTime? @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  political_news_crawler_crawl_schedules political_news_crawler_crawl_schedules[]\n\n  @@unique([policy_name])\n  @@index([max_crawl_frequency_minutes, ban_detection_enabled], map: \"political_news_crawler_crawl_policies_max_crawl_freque_a5d20f2f\")\n}\n\n/// Schedules defining when and how often crawling runs for each political\n/// news source. References the crawl source and policy to enable adaptive\n/// scheduling and coordination.\n///\n/// @namespace Systematic\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawl_schedules {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Reference to Crawling Source. {@link\n  /// political_news_crawler_crawl_sources.id}\n  crawl_source_id String @db.Uuid\n\n  /// Reference to Crawl Policy. {@link\n  /// political_news_crawler_crawl_policies.id}\n  crawl_policy_id String @db.Uuid\n\n  /// Cron expression defining the crawl schedule timing.\n  schedule_expression String\n\n  /// Timestamp when the crawl last occurred.\n  last_crawled_at DateTime? @db.Timestamptz\n\n  /// Timestamp for the next scheduled crawl.\n  next_crawl_at DateTime? @db.Timestamptz\n\n  /// Flag indicating if this schedule is enabled.\n  is_enabled Boolean\n\n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n\n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n\n  /// Soft delete timestamp, if record is deleted.\n  deleted_at DateTime? @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  crawlSource political_news_crawler_crawl_sources  @relation(fields: [crawl_source_id], references: [id], onDelete: Cascade)\n  crawlPolicy political_news_crawler_crawl_policies @relation(fields: [crawl_policy_id], references: [id], onDelete: Cascade)\n\n  political_news_crawler_crawl_jobs political_news_crawler_crawl_jobs[]\n\n  @@index([crawl_source_id, is_enabled, next_crawl_at], map: \"political_news_crawler_crawl_schedules_crawl_source_id_bb22a9cd\")\n  @@index([crawl_policy_id])\n}\n","schema-02-actors.prisma":"/// Stores political news crawler guest user information representing\n/// unauthenticated users accessing APIs. Captures identification via IP and\n/// user agent, includes timestamps for auditing and soft deletion support.\n/// Guests are limited to read-only access with no password or login\n/// credentials.\n///\n/// @namespace Actors\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_guests {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// IP address of the guest user.\n  ip_address String\n\n  /// User agent string presented by the guest.\n  user_agent String?\n\n  /// Timestamp when the guest record was created.\n  created_at DateTime @db.Timestamptz\n\n  /// Timestamp when the guest record was last updated.\n  updated_at DateTime @db.Timestamptz\n\n  /// Timestamp of soft deletion for the guest record.\n  deleted_at DateTime? @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  @@unique([ip_address, user_agent])\n  @@index([created_at])\n}\n","schema-03-crawling.prisma":"/// Represents scheduled crawling jobs assigned to specific crawl sources and\n/// schedules, managing operational parameters and state for recurring\n/// political news retrieval tasks.\n///\n/// @namespace Crawling\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawl_jobs {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Referenced crawl source identifier. {@link\n  /// political_news_crawler_crawl_sources.id}\n  crawl_source_id String @db.Uuid\n\n  /// Referenced crawl schedule identifier. {@link\n  /// political_news_crawler_crawl_schedules.id}\n  crawl_schedule_id String @db.Uuid\n\n  /// Flag indicating if this crawl job is active and scheduled to run.\n  active Boolean\n\n  /// Timestamp when the last run of the crawl job started, null if never run.\n  last_run_started_at DateTime? @db.Timestamptz\n\n  /// Timestamp when the last run of the crawl job completed, null if still\n  /// running or never run.\n  last_run_completed_at DateTime? @db.Timestamptz\n\n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n\n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n\n  /// Soft deletion timestamp, if set the job is considered deleted and ignored.\n  deleted_at DateTime? @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  crawlSource   political_news_crawler_crawl_sources   @relation(fields: [crawl_source_id], references: [id], onDelete: Cascade)\n  crawlSchedule political_news_crawler_crawl_schedules @relation(fields: [crawl_schedule_id], references: [id], onDelete: Cascade)\n\n  political_news_crawler_crawl_attempts   political_news_crawler_crawl_attempts[]\n  political_news_crawler_raw_data_storage political_news_crawler_raw_data_storage[]\n\n  @@unique([crawl_source_id, crawl_schedule_id], map: \"political_news_crawler_crawl_jobs_crawl_source_id_craw_1330ef11\")\n  @@index([crawl_schedule_id])\n  @@index([last_run_started_at, active], map: \"political_news_crawler_crawl_jobs_last_run_started_at__a5b9f998\")\n  @@index([active, last_run_completed_at], map: \"political_news_crawler_crawl_jobs_active_last_run_comp_3d4bd054\")\n}\n\n/// Records individual execution attempts of crawl jobs, tracking start and\n/// completion times, success status, errors, and associated raw data\n/// references to enable detailed auditing and failure analysis.\n///\n/// @namespace Crawling\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawl_attempts {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Associated crawl job identifier. {@link\n  /// political_news_crawler_crawl_jobs.id}\n  crawl_job_id String @db.Uuid\n\n  /// Reference to raw data storage entry for the crawl result. {@link\n  /// political_news_crawler_raw_data_storage.id}\n  raw_data_storage_id String? @db.Uuid\n\n  /// Timestamp when this crawl attempt started.\n  started_at DateTime @db.Timestamptz\n\n  /// Timestamp when this crawl attempt ended; null if still running.\n  completed_at DateTime? @db.Timestamptz\n\n  /// Indicator whether this crawl attempt was successful.\n  success Boolean\n\n  /// Error message details if the crawl attempt failed.\n  error_message String?\n\n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n\n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  crawlJob       political_news_crawler_crawl_jobs        @relation(fields: [crawl_job_id], references: [id], onDelete: Cascade)\n  rawDataStorage political_news_crawler_raw_data_storage? @relation(fields: [raw_data_storage_id], references: [id], onDelete: Cascade)\n\n  political_news_crawler_crawled_news political_news_crawler_crawled_news[]\n\n  @@index([raw_data_storage_id])\n  @@index([started_at, success])\n  @@index([crawl_job_id, started_at], map: \"political_news_crawler_crawl_attempts_crawl_job_id_sta_a468595a\")\n}\n\n/// Contains metadata for crawled political news articles, linking to the\n/// crawl attempt that obtained the raw content and providing key attributes\n/// for management and filtering.\n///\n/// @namespace Crawling\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawled_news {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Associated crawl attempt identifier. {@link\n  /// political_news_crawler_crawl_attempts.id}\n  crawl_attempt_id String @db.Uuid\n\n  /// URL of the crawled news article.\n  url String\n\n  /// Title of the news article, if available.\n  title String?\n\n  /// Publish timestamp of the news article, if known.\n  published_at DateTime? @db.Timestamptz\n\n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n\n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  crawlAttempt political_news_crawler_crawl_attempts @relation(fields: [crawl_attempt_id], references: [id], onDelete: Cascade)\n\n  political_news_crawler_topic_mentions political_news_crawler_topic_mentions[]\n\n  @@unique([url])\n  @@index([crawl_attempt_id])\n  @@index([published_at])\n}\n","schema-04-storage.prisma":"/// Stores metadata and references for raw political news data collected from\n/// various crawling sources. Ensures durable and consistent storage links to\n/// cloud object storage. Tracks source information, crawl job association,\n/// and data integrity validations. Includes audit timestamps for\n/// traceability.\n///\n/// @namespace Storage\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_raw_data_storage {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Belonged crawl source's political_news_crawler_crawl_sources.id.\n  crawl_source_id String @db.Uuid\n\n  /// Optional crawl job reference to political_news_crawler_crawl_jobs.id.\n  crawl_job_id String? @db.Uuid\n\n  /// Unique key or path identifying storage location in cloud object storage\n  /// (e.g., GCP or AWS S3).\n  storage_key String\n\n  /// Format of the raw data file such as JSON or XML for processing\n  /// compatibility.\n  file_format String\n\n  /// Size of the raw data file in bytes.\n  file_size_bytes Int @db.Integer\n\n  /// Checksum hash to verify file integrity.\n  checksum String?\n\n  /// Timestamp when the raw data was crawled, used for data freshness and\n  /// scheduling.\n  crawl_timestamp DateTime @db.Timestamptz\n\n  /// Creation timestamp record.\n  created_at DateTime @db.Timestamptz\n\n  /// Last update timestamp record.\n  updated_at DateTime @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  crawlSource political_news_crawler_crawl_sources @relation(fields: [crawl_source_id], references: [id], onDelete: Cascade)\n  crawlJob    political_news_crawler_crawl_jobs?   @relation(fields: [crawl_job_id], references: [id], onDelete: Cascade)\n\n  political_news_crawler_crawl_attempts    political_news_crawler_crawl_attempts[]\n  political_news_crawler_local_cache_files political_news_crawler_local_cache_files[]\n  political_news_crawler_processed_content political_news_crawler_processed_content[]\n\n  @@unique([storage_key])\n  @@index([crawl_job_id])\n  @@index([crawl_source_id, crawl_timestamp], map: \"political_news_crawler_raw_data_storage_crawl_source_i_a4e59727\")\n}\n\n/// Tracks local file cache copies of raw crawled political news data with\n/// TTL enforcement and deletion status. Enables fast retrieval during cloud\n/// storage outages and manages file lifecycle with audit timestamps.\n///\n/// @namespace Storage\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_local_cache_files {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Reference to related raw data storage record,\n  /// political_news_crawler_raw_data_storage.id.\n  raw_data_storage_id String @db.Uuid\n\n  /// Filesystem path or identifier for the local cached file copy.\n  local_file_path String\n\n  /// Size of the local cached file in bytes.\n  file_size_bytes Int @db.Integer\n\n  /// Datetime when the cached file expires and is due for deletion under TTL\n  /// policy.\n  ttl_expiration_at DateTime @db.Timestamptz\n\n  /// Soft delete timestamp indicating when the cached file was deleted, if\n  /// applicable.\n  deleted_at DateTime? @db.Timestamptz\n\n  /// Creation timestamp record.\n  created_at DateTime @db.Timestamptz\n\n  /// Last update timestamp record.\n  updated_at DateTime @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  rawDataStorage political_news_crawler_raw_data_storage @relation(fields: [raw_data_storage_id], references: [id], onDelete: Cascade, map: \"political_news_crawler_local_cache_files_raw_data_stor_39036344\")\n\n  @@unique([local_file_path])\n  @@index([raw_data_storage_id], map: \"political_news_crawler_local_cache_files_raw_data_stor_e96143ec\")\n  @@index([ttl_expiration_at])\n}\n\n/// Stores processed political news content generated by LLM post-processing,\n/// including summaries, highlights, and analysis. Links content to raw data\n/// storage and optionally to the LLM job that generated it. Contains content\n/// type, full text body, generation timestamp, and audit timestamps.\n/// Supports text search through GIN index on content body.\n///\n/// @namespace Storage\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_processed_content {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Foreign key to the raw data storage record,\n  /// political_news_crawler_raw_data_storage.id.\n  raw_data_storage_id String @db.Uuid\n\n  /// Foreign key to associated LLM job, political_news_crawler_llm_jobs.id.\n  llm_job_id String? @db.Uuid\n\n  /// Type of processed content, e.g., summary, highlight, or analysis.\n  content_type String\n\n  /// Full textual content produced by LLM processing.\n  content_body String\n\n  /// Timestamp when this content was generated.\n  generation_timestamp DateTime @db.Timestamptz\n\n  /// Record creation timestamp, typically same or near generation time.\n  created_at DateTime @db.Timestamptz\n\n  /// Last update timestamp record.\n  updated_at DateTime @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  rawDataStorage political_news_crawler_raw_data_storage @relation(fields: [raw_data_storage_id], references: [id], onDelete: Cascade, map: \"political_news_crawler_processed_content_raw_data_stor_b512d013\")\n  llmJob         political_news_crawler_llm_jobs?        @relation(fields: [llm_job_id], references: [id], onDelete: Cascade)\n\n  @@unique([raw_data_storage_id, content_type], map: \"political_news_crawler_processed_content_raw_data_stor_910af992\")\n  @@index([llm_job_id])\n  @@index([content_type])\n  @@index([content_body(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n","schema-05-processing.prisma":"/// LLM jobs represent individual processing tasks queued or executed for\n/// political news data. They track the job status, parameters, and\n/// processing flags. This model supports the management and monitoring of\n/// asynchronous LLM post-processing tasks such as generating summaries and\n/// analysis.\n///\n/// @namespace Processing\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_llm_jobs {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// The source channel from which the raw news data originated, referencing\n  /// political_news_crawler_crawl_sources.id.\n  crawl_source_id String @db.Uuid\n\n  /// Processing status of the job, e.g., 'pending', 'running', 'completed',\n  /// 'failed'.\n  status String\n\n  /// JSON string of parameters or prompts used for this LLM job.\n  parameters String\n\n  /// Job creation timestamp.\n  created_at DateTime @db.Timestamptz\n\n  /// Job last update timestamp.\n  updated_at DateTime @db.Timestamptz\n\n  /// Soft delete timestamp, null if not deleted.\n  deleted_at DateTime? @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  crawlSource political_news_crawler_crawl_sources @relation(fields: [crawl_source_id], references: [id], onDelete: Cascade)\n\n  political_news_crawler_processed_content   political_news_crawler_processed_content[]\n  political_news_crawler_llm_results         political_news_crawler_llm_results[]\n  political_news_crawler_processing_metadata political_news_crawler_processing_metadata[]\n\n  @@index([crawl_source_id, status, created_at], map: \"political_news_crawler_llm_jobs_crawl_source_id_status_12346833\")\n  @@index([parameters(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// LLM results store the output content generated by LLM jobs, including\n/// summaries, highlights, and analyses. This model links back to the\n/// originating LLM job and preserves output details for retrieval and audit\n/// purposes.\n///\n/// @namespace Processing\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_llm_results {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Associated LLM job's political_news_crawler_llm_jobs.id.\n  llm_job_id String @db.Uuid\n\n  /// Type of generated content, e.g., 'summary', 'highlight', 'analysis'.\n  content_type String\n\n  /// Generated content text by the LLM.\n  content_text String\n\n  /// Timestamp when the output was created.\n  created_at DateTime @db.Timestamptz\n\n  /// Timestamp when the output was last updated.\n  updated_at DateTime @db.Timestamptz\n\n  /// Soft delete timestamp, null if not deleted.\n  deleted_at DateTime? @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  llmJob political_news_crawler_llm_jobs @relation(fields: [llm_job_id], references: [id], onDelete: Cascade)\n\n  @@index([llm_job_id, content_type])\n  @@index([content_text(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// Metadata entries for LLM processing capturing auxiliary information\n/// related to jobs or overall processing context. This table stores\n/// additional attributes to support enhancements and auditability.\n///\n/// @namespace Processing\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_processing_metadata {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Associated LLM job's political_news_crawler_llm_jobs.id.\n  llm_job_id String @db.Uuid\n\n  /// Key name of the metadata attribute.\n  metadata_key String\n\n  /// Value of the metadata attribute.\n  metadata_value String\n\n  /// Metadata entry creation timestamp.\n  created_at DateTime @db.Timestamptz\n\n  /// Metadata entry last update timestamp.\n  updated_at DateTime @db.Timestamptz\n\n  /// Soft delete timestamp, null if not deleted.\n  deleted_at DateTime? @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  llmJob political_news_crawler_llm_jobs @relation(fields: [llm_job_id], references: [id], onDelete: Cascade)\n\n  @@index([llm_job_id, metadata_key], map: \"political_news_crawler_processing_metadata_llm_job_id__f59c62c3\")\n}\n","schema-06-popularity.prisma":"/// Snapshot table capturing computed popularity scores for political topics\n/// at specific timestamps. Each record represents a historical state of a\n/// popularity calculation for auditing and trend analysis purposes.\n/// References the related popular topic. Includes score metrics and aging\n/// fields consistent with time-decayed ranking models.\n///\n/// @namespace Popularity\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_popularity_scores {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Referenced popular topic's {@link\n  /// political_news_crawler_popular_topics.id}.\n  political_news_crawler_popular_topic_id String @db.Uuid\n\n  /// Calculated popularity score for the topic at this snapshot.\n  score Float @db.DoublePrecision\n\n  /// Decay factor applied to the score based on the age of the topic mention.\n  decay_factor Float @db.DoublePrecision\n\n  /// Timestamp when this popularity score snapshot was taken.\n  snapshot_at DateTime @db.Timestamptz\n\n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n\n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n\n  /// Soft deletion timestamp if applicable, otherwise null.\n  deleted_at DateTime? @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  popularTopic political_news_crawler_popular_topics @relation(fields: [political_news_crawler_popular_topic_id], references: [id], onDelete: Cascade, map: \"political_news_crawler_popularity_scores_political_new_bd39518d\")\n\n  @@index([political_news_crawler_popular_topic_id, snapshot_at], map: \"political_news_crawler_popularity_scores_political_new_670bf173\")\n}\n\n/// Primary table listing all current political news topics with computed\n/// popularity rankings. Maintains unique topic identifiers, titles, and\n/// metadata for efficient querying and API response. Supports independent\n/// management of topics and serves as the main entity for popularity-related\n/// queries.\n///\n/// @namespace Popularity\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_popular_topics {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Unique code identifier for the political topic.\n  topic_code String\n\n  /// Official title or name of the popular topic.\n  title String\n\n  /// Optional detailed description or context about the popular topic.\n  description String?\n\n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n\n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n\n  /// Soft deletion timestamp if applicable, otherwise null.\n  deleted_at DateTime? @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  political_news_crawler_popularity_scores political_news_crawler_popularity_scores[]\n  political_news_crawler_topic_mentions    political_news_crawler_topic_mentions[]\n\n  @@unique([topic_code])\n  @@index([created_at])\n  @@index([title(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// Subsidiary table recording mentions of political topics within news\n/// articles. Establishes many-to-one relationships with both topics and\n/// crawled news records. Supports detailed traceability of topic references\n/// and feeds data for popularity calculations. Managed as supporting entity\n/// for topic analytics.\n///\n/// @namespace Popularity\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_topic_mentions {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Referenced popular topic's {@link\n  /// political_news_crawler_popular_topics.id}.\n  political_news_crawler_popular_topic_id String @db.Uuid\n\n  /// Referenced crawled news item's {@link\n  /// political_news_crawler_crawled_news.id}.\n  political_news_crawler_crawled_news_id String @db.Uuid\n\n  /// Optional text snippet or context where the topic is mentioned within the\n  /// article.\n  mention_context String?\n\n  /// Record creation timestamp.\n  created_at DateTime @db.Timestamptz\n\n  /// Record last update timestamp.\n  updated_at DateTime @db.Timestamptz\n\n  /// Soft deletion timestamp if applicable, otherwise null.\n  deleted_at DateTime? @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  popularTopic political_news_crawler_popular_topics @relation(fields: [political_news_crawler_popular_topic_id], references: [id], onDelete: Cascade, map: \"political_news_crawler_topic_mentions_political_news_c_ef19f1c7\")\n  crawledNews  political_news_crawler_crawled_news   @relation(fields: [political_news_crawler_crawled_news_id], references: [id], onDelete: Cascade, map: \"political_news_crawler_topic_mentions_political_news_c_ea889267\")\n\n  @@index([political_news_crawler_popular_topic_id], map: \"political_news_crawler_topic_mentions_political_news_c_a5a42e74\")\n  @@index([political_news_crawler_crawled_news_id], map: \"political_news_crawler_topic_mentions_political_news_c_6f8a44b9\")\n  @@index([mention_context(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n","schema-07-api.prisma":"/// Records detailed log entries for every API access to track client\n/// requests, including request method, path, response status, client IP\n/// address, user agent, request duration in milliseconds, and timestamp.\n/// Supports comprehensive API usage analytics and operational monitoring.\n///\n/// @namespace API\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_api_access_logs {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// HTTP request method used in the API call, e.g., GET, POST, PUT.\n  http_method String\n\n  /// API endpoint path being accessed, e.g., /api/v1/popular_topics.\n  path String\n\n  /// HTTP response status code returned to the client.\n  status_code Int @db.Integer\n\n  /// IP address of the client making the API request.\n  client_ip String\n\n  /// User agent string of the client or application making the request.\n  user_agent String\n\n  /// Duration of the API request processing in milliseconds.\n  duration_ms Int @db.Integer\n\n  /// Timestamp when the log entry was created.\n  created_at DateTime @db.Timestamptz\n\n  /// Timestamp when the log entry was last updated.\n  updated_at DateTime @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  @@index([http_method, path, status_code, created_at], map: \"political_news_crawler_api_access_logs_http_method_pat_90ce5ccb\")\n  @@index([client_ip, created_at])\n  @@index([user_agent, created_at], map: \"political_news_crawler_api_access_logs_user_agent_crea_1a375cdb\")\n  @@index([created_at])\n  @@index([path(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n  @@index([user_agent(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// Captures detailed records of API errors, including the API path, error\n/// code, error message, client IP, user agent, occurrence timestamp, and\n/// update timestamp. Enables error analysis and system troubleshooting for\n/// API endpoints.\n///\n/// @namespace API\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_api_error_logs {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// API endpoint path where the error occurred.\n  path String\n\n  /// Error code identifying the type of API error.\n  error_code String\n\n  /// Descriptive error message to assist debugging.\n  error_message String\n\n  /// IP address of the client causing the error.\n  client_ip String\n\n  /// User agent string of the client application.\n  user_agent String\n\n  /// Timestamp when the error log was created.\n  created_at DateTime @db.Timestamptz\n\n  /// Timestamp when the error log was last updated.\n  updated_at DateTime @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  @@index([path, error_code, created_at], map: \"political_news_crawler_api_error_logs_path_error_code__086a81a1\")\n  @@index([client_ip, created_at])\n  @@index([user_agent, created_at])\n  @@index([created_at])\n  @@index([path(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n  @@index([error_message(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n  @@index([user_agent(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// Aggregated API usage metrics capturing total counts of API calls by\n/// method and path over specific time periods, including maximum response\n/// times and average durations. Supports performance monitoring and traffic\n/// analysis for API endpoints.\n///\n/// @namespace API\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_api_usage_metrics {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// HTTP method for which metrics are aggregated.\n  http_method String\n\n  /// API endpoint path for which metrics are aggregated.\n  path String\n\n  /// Start timestamp of the aggregation period.\n  period_start DateTime @db.Timestamptz\n\n  /// End timestamp of the aggregation period.\n  period_end DateTime @db.Timestamptz\n\n  /// Total number of API calls observed in the aggregation period.\n  total_calls Int @db.Integer\n\n  /// Maximum response time in milliseconds recorded during the period.\n  max_response_ms Int @db.Integer\n\n  /// Average response time in milliseconds over the period.\n  avg_response_ms Int @db.Integer\n\n  /// Timestamp when this aggregated record was created.\n  created_at DateTime @db.Timestamptz\n\n  /// Timestamp when this aggregated record was last updated.\n  updated_at DateTime @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  @@unique([http_method, path, period_start], map: \"political_news_crawler_api_usage_metrics_http_method_p_5151a9d6\")\n  @@index([http_method, path, period_start, period_end], map: \"political_news_crawler_api_usage_metrics_http_method_p_bb640350\")\n  @@index([created_at])\n  @@index([path(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n","schema-08-alerts.prisma":"/// Stores alert events related to crawling operations, capturing failures,\n/// bans, or throttle notifications from crawl sources. Links alerts to\n/// specific crawl sources for traceability. Contains timestamp, severity\n/// level, and descriptive message for operational monitoring.\n///\n/// @namespace Alerts\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_crawl_alerts {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Referenced crawl source's {@link political_news_crawler_crawl_sources.id}\n  /// which triggered the alert.\n  crawl_source_id String @db.Uuid\n\n  /// Type of alert event indicating the category, e.g., 'ban_detected',\n  /// 'network_error', 'throttle_warning'.\n  alert_type String\n\n  /// Detailed description of the alert event and context for operational\n  /// understanding.\n  message String\n\n  /// Severity level of the alert such as 'info', 'warning', 'critical'.\n  severity String\n\n  /// Timestamp when the alert was created.\n  created_at DateTime @db.Timestamptz\n\n  /// Timestamp when the alert was last updated.\n  updated_at DateTime @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  crawlSource political_news_crawler_crawl_sources @relation(fields: [crawl_source_id], references: [id], onDelete: Cascade)\n\n  @@unique([crawl_source_id, alert_type, created_at], map: \"political_news_crawler_crawl_alerts_crawl_source_id_al_6ad89660\")\n  @@index([created_at])\n  @@index([severity])\n  @@index([message(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// Captures alert events related to processing pipeline failures including\n/// LLM processing errors, queue backlogs, or retry escalations. Provides\n/// detailed messages and timestamp info for system diagnostics and\n/// resolution procedures.\n///\n/// @namespace Alerts\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_processing_alerts {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Category of processing alert such as 'llm_failure', 'queue_overflow',\n  /// 'retry_limit_reached'.\n  alert_type String\n\n  /// Detailed description of the processing alert event for operational use.\n  message String\n\n  /// Severity level of the alert (e.g., 'info', 'warning', 'critical').\n  severity String\n\n  /// Timestamp when the alert was created.\n  created_at DateTime @db.Timestamptz\n\n  /// Timestamp for last update of the alert.\n  updated_at DateTime @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  @@unique([alert_type, created_at], map: \"political_news_crawler_processing_alerts_alert_type_cr_ed4a0c20\")\n  @@index([created_at])\n  @@index([severity])\n  @@index([message(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n\n/// Contains alert records related to API subsystem errors including rate\n/// limiting, endpoint failures, and error spikes. Supports operational\n/// monitoring by storing detailed messages and timestamps of occurrence.\n///\n/// @namespace Alerts\n/// @author AutoBE - https://github.com/wrtnlabs/autobe\nmodel political_news_crawler_api_alerts {\n  //----\n  // COLUMNS\n  //----\n  /// Primary Key.\n  id String @id @db.Uuid\n\n  /// Type of API alert event such as 'rate_limit_exceeded', 'endpoint_error',\n  /// 'error_spike'.\n  alert_type String\n\n  /// Detailed message describing the API alert context.\n  message String\n\n  /// Severity level of the alert such as 'info', 'warning', 'critical'.\n  severity String\n\n  /// Timestamp when the alert was created.\n  created_at DateTime @db.Timestamptz\n\n  /// Timestamp when the alert was last updated.\n  updated_at DateTime @db.Timestamptz\n\n  //----\n  // RELATIONS\n  //----\n  @@unique([alert_type, created_at])\n  @@index([created_at])\n  @@index([severity])\n  @@index([message(ops: raw(\"gin_trgm_ops\"))], type: Gin)\n}\n","main.prisma":"generator client {\n  provider        = \"prisma-client-js\"\n  previewFeatures = [\"postgresqlExtensions\", \"views\"]\n  binaryTargets   = [\"native\"]\n}\n\ndatasource db {\n  provider   = \"postgresql\"\n  url        = env(\"DATABASE_URL\")\n  extensions = [pg_trgm]\n}\n\ngenerator markdown {\n  provider = \"prisma-markdown\"\n  output   = \"../../docs/ERD.md\"\n}\n"},"nodeModules":{"node_modules/.prisma/client/client.d.ts":"export * from \"./index\"","node_modules/.prisma/client/default.d.ts":"export * from \"./index\"","node_modules/.prisma/client/edge.d.ts":"export * from \"./default\"","node_modules/.prisma/client/index.d.ts":"\n/**\n * Client\n**/\n\nimport * as runtime from './runtime/library.js';\nimport $Types = runtime.Types // general types\nimport $Public = runtime.Types.Public\nimport $Utils = runtime.Types.Utils\nimport $Extensions = runtime.Types.Extensions\nimport $Result = runtime.Types.Result\n\nexport type PrismaPromise<T> = $Public.PrismaPromise<T>\n\n\n/**\n * Model political_news_crawler_crawl_sources\n * Represents political news crawling sources configuration. Contains source\n * URLs, status, and metadata for controlling crawl initiation and\n * processing. Used to manage diverse data feed points for\n * politicalNewsCrawler.\n * \n * @namespace Systematic\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_crawl_sources = $Result.DefaultSelection<Prisma.$political_news_crawler_crawl_sourcesPayload>\n/**\n * Model political_news_crawler_crawl_policies\n * Configuration for crawl policies governing crawling frequency, retry, and\n * error handling for political news sources. Ensures adaptive and\n * respectful crawling behavior according to source limits and bans.\n * \n * @namespace Systematic\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_crawl_policies = $Result.DefaultSelection<Prisma.$political_news_crawler_crawl_policiesPayload>\n/**\n * Model political_news_crawler_crawl_schedules\n * Schedules defining when and how often crawling runs for each political\n * news source. References the crawl source and policy to enable adaptive\n * scheduling and coordination.\n * \n * @namespace Systematic\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_crawl_schedules = $Result.DefaultSelection<Prisma.$political_news_crawler_crawl_schedulesPayload>\n/**\n * Model political_news_crawler_guests\n * Stores political news crawler guest user information representing\n * unauthenticated users accessing APIs. Captures identification via IP and\n * user agent, includes timestamps for auditing and soft deletion support.\n * Guests are limited to read-only access with no password or login\n * credentials.\n * \n * @namespace Actors\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_guests = $Result.DefaultSelection<Prisma.$political_news_crawler_guestsPayload>\n/**\n * Model political_news_crawler_crawl_jobs\n * Represents scheduled crawling jobs assigned to specific crawl sources and\n * schedules, managing operational parameters and state for recurring\n * political news retrieval tasks.\n * \n * @namespace Crawling\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_crawl_jobs = $Result.DefaultSelection<Prisma.$political_news_crawler_crawl_jobsPayload>\n/**\n * Model political_news_crawler_crawl_attempts\n * Records individual execution attempts of crawl jobs, tracking start and\n * completion times, success status, errors, and associated raw data\n * references to enable detailed auditing and failure analysis.\n * \n * @namespace Crawling\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_crawl_attempts = $Result.DefaultSelection<Prisma.$political_news_crawler_crawl_attemptsPayload>\n/**\n * Model political_news_crawler_crawled_news\n * Contains metadata for crawled political news articles, linking to the\n * crawl attempt that obtained the raw content and providing key attributes\n * for management and filtering.\n * \n * @namespace Crawling\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_crawled_news = $Result.DefaultSelection<Prisma.$political_news_crawler_crawled_newsPayload>\n/**\n * Model political_news_crawler_raw_data_storage\n * Stores metadata and references for raw political news data collected from\n * various crawling sources. Ensures durable and consistent storage links to\n * cloud object storage. Tracks source information, crawl job association,\n * and data integrity validations. Includes audit timestamps for\n * traceability.\n * \n * @namespace Storage\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_raw_data_storage = $Result.DefaultSelection<Prisma.$political_news_crawler_raw_data_storagePayload>\n/**\n * Model political_news_crawler_local_cache_files\n * Tracks local file cache copies of raw crawled political news data with\n * TTL enforcement and deletion status. Enables fast retrieval during cloud\n * storage outages and manages file lifecycle with audit timestamps.\n * \n * @namespace Storage\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_local_cache_files = $Result.DefaultSelection<Prisma.$political_news_crawler_local_cache_filesPayload>\n/**\n * Model political_news_crawler_processed_content\n * Stores processed political news content generated by LLM post-processing,\n * including summaries, highlights, and analysis. Links content to raw data\n * storage and optionally to the LLM job that generated it. Contains content\n * type, full text body, generation timestamp, and audit timestamps.\n * Supports text search through GIN index on content body.\n * \n * @namespace Storage\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_processed_content = $Result.DefaultSelection<Prisma.$political_news_crawler_processed_contentPayload>\n/**\n * Model political_news_crawler_llm_jobs\n * LLM jobs represent individual processing tasks queued or executed for\n * political news data. They track the job status, parameters, and\n * processing flags. This model supports the management and monitoring of\n * asynchronous LLM post-processing tasks such as generating summaries and\n * analysis.\n * \n * @namespace Processing\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_llm_jobs = $Result.DefaultSelection<Prisma.$political_news_crawler_llm_jobsPayload>\n/**\n * Model political_news_crawler_llm_results\n * LLM results store the output content generated by LLM jobs, including\n * summaries, highlights, and analyses. This model links back to the\n * originating LLM job and preserves output details for retrieval and audit\n * purposes.\n * \n * @namespace Processing\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_llm_results = $Result.DefaultSelection<Prisma.$political_news_crawler_llm_resultsPayload>\n/**\n * Model political_news_crawler_processing_metadata\n * Metadata entries for LLM processing capturing auxiliary information\n * related to jobs or overall processing context. This table stores\n * additional attributes to support enhancements and auditability.\n * \n * @namespace Processing\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_processing_metadata = $Result.DefaultSelection<Prisma.$political_news_crawler_processing_metadataPayload>\n/**\n * Model political_news_crawler_popularity_scores\n * Snapshot table capturing computed popularity scores for political topics\n * at specific timestamps. Each record represents a historical state of a\n * popularity calculation for auditing and trend analysis purposes.\n * References the related popular topic. Includes score metrics and aging\n * fields consistent with time-decayed ranking models.\n * \n * @namespace Popularity\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_popularity_scores = $Result.DefaultSelection<Prisma.$political_news_crawler_popularity_scoresPayload>\n/**\n * Model political_news_crawler_popular_topics\n * Primary table listing all current political news topics with computed\n * popularity rankings. Maintains unique topic identifiers, titles, and\n * metadata for efficient querying and API response. Supports independent\n * management of topics and serves as the main entity for popularity-related\n * queries.\n * \n * @namespace Popularity\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_popular_topics = $Result.DefaultSelection<Prisma.$political_news_crawler_popular_topicsPayload>\n/**\n * Model political_news_crawler_topic_mentions\n * Subsidiary table recording mentions of political topics within news\n * articles. Establishes many-to-one relationships with both topics and\n * crawled news records. Supports detailed traceability of topic references\n * and feeds data for popularity calculations. Managed as supporting entity\n * for topic analytics.\n * \n * @namespace Popularity\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_topic_mentions = $Result.DefaultSelection<Prisma.$political_news_crawler_topic_mentionsPayload>\n/**\n * Model political_news_crawler_api_access_logs\n * Records detailed log entries for every API access to track client\n * requests, including request method, path, response status, client IP\n * address, user agent, request duration in milliseconds, and timestamp.\n * Supports comprehensive API usage analytics and operational monitoring.\n * \n * @namespace API\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_api_access_logs = $Result.DefaultSelection<Prisma.$political_news_crawler_api_access_logsPayload>\n/**\n * Model political_news_crawler_api_error_logs\n * Captures detailed records of API errors, including the API path, error\n * code, error message, client IP, user agent, occurrence timestamp, and\n * update timestamp. Enables error analysis and system troubleshooting for\n * API endpoints.\n * \n * @namespace API\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_api_error_logs = $Result.DefaultSelection<Prisma.$political_news_crawler_api_error_logsPayload>\n/**\n * Model political_news_crawler_api_usage_metrics\n * Aggregated API usage metrics capturing total counts of API calls by\n * method and path over specific time periods, including maximum response\n * times and average durations. Supports performance monitoring and traffic\n * analysis for API endpoints.\n * \n * @namespace API\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_api_usage_metrics = $Result.DefaultSelection<Prisma.$political_news_crawler_api_usage_metricsPayload>\n/**\n * Model political_news_crawler_crawl_alerts\n * Stores alert events related to crawling operations, capturing failures,\n * bans, or throttle notifications from crawl sources. Links alerts to\n * specific crawl sources for traceability. Contains timestamp, severity\n * level, and descriptive message for operational monitoring.\n * \n * @namespace Alerts\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_crawl_alerts = $Result.DefaultSelection<Prisma.$political_news_crawler_crawl_alertsPayload>\n/**\n * Model political_news_crawler_processing_alerts\n * Captures alert events related to processing pipeline failures including\n * LLM processing errors, queue backlogs, or retry escalations. Provides\n * detailed messages and timestamp info for system diagnostics and\n * resolution procedures.\n * \n * @namespace Alerts\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_processing_alerts = $Result.DefaultSelection<Prisma.$political_news_crawler_processing_alertsPayload>\n/**\n * Model political_news_crawler_api_alerts\n * Contains alert records related to API subsystem errors including rate\n * limiting, endpoint failures, and error spikes. Supports operational\n * monitoring by storing detailed messages and timestamps of occurrence.\n * \n * @namespace Alerts\n * @author AutoBE - https://github.com/wrtnlabs/autobe\n */\nexport type political_news_crawler_api_alerts = $Result.DefaultSelection<Prisma.$political_news_crawler_api_alertsPayload>\n\n/**\n * ##  Prisma Client ʲˢ\n *\n * Type-safe database client for TypeScript & Node.js\n * @example\n * ```\n * const prisma = new PrismaClient()\n * // Fetch zero or more Political_news_crawler_crawl_sources\n * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.findMany()\n * ```\n *\n *\n * Read more in our [docs](https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-client).\n */\nexport class PrismaClient<\n  ClientOptions extends Prisma.PrismaClientOptions = Prisma.PrismaClientOptions,\n  const U = 'log' extends keyof ClientOptions ? ClientOptions['log'] extends Array<Prisma.LogLevel | Prisma.LogDefinition> ? Prisma.GetEvents<ClientOptions['log']> : never : never,\n  ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs\n> {\n  [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['other'] }\n\n    /**\n   * ##  Prisma Client ʲˢ\n   *\n   * Type-safe database client for TypeScript & Node.js\n   * @example\n   * ```\n   * const prisma = new PrismaClient()\n   * // Fetch zero or more Political_news_crawler_crawl_sources\n   * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.findMany()\n   * ```\n   *\n   *\n   * Read more in our [docs](https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-client).\n   */\n\n  constructor(optionsArg ?: Prisma.Subset<ClientOptions, Prisma.PrismaClientOptions>);\n  $on<V extends U>(eventType: V, callback: (event: V extends 'query' ? Prisma.QueryEvent : Prisma.LogEvent) => void): PrismaClient;\n\n  /**\n   * Connect with the database\n   */\n  $connect(): $Utils.JsPromise<void>;\n\n  /**\n   * Disconnect from the database\n   */\n  $disconnect(): $Utils.JsPromise<void>;\n\n/**\n   * Executes a prepared raw query and returns the number of affected rows.\n   * @example\n   * ```\n   * const result = await prisma.$executeRaw`UPDATE User SET cool = ${true} WHERE email = ${'user@email.com'};`\n   * ```\n   *\n   * Read more in our [docs](https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-client/raw-database-access).\n   */\n  $executeRaw<T = unknown>(query: TemplateStringsArray | Prisma.Sql, ...values: any[]): Prisma.PrismaPromise<number>;\n\n  /**\n   * Executes a raw query and returns the number of affected rows.\n   * Susceptible to SQL injections, see documentation.\n   * @example\n   * ```\n   * const result = await prisma.$executeRawUnsafe('UPDATE User SET cool = $1 WHERE email = $2 ;', true, 'user@email.com')\n   * ```\n   *\n   * Read more in our [docs](https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-client/raw-database-access).\n   */\n  $executeRawUnsafe<T = unknown>(query: string, ...values: any[]): Prisma.PrismaPromise<number>;\n\n  /**\n   * Performs a prepared raw query and returns the `SELECT` data.\n   * @example\n   * ```\n   * const result = await prisma.$queryRaw`SELECT * FROM User WHERE id = ${1} OR email = ${'user@email.com'};`\n   * ```\n   *\n   * Read more in our [docs](https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-client/raw-database-access).\n   */\n  $queryRaw<T = unknown>(query: TemplateStringsArray | Prisma.Sql, ...values: any[]): Prisma.PrismaPromise<T>;\n\n  /**\n   * Performs a raw query and returns the `SELECT` data.\n   * Susceptible to SQL injections, see documentation.\n   * @example\n   * ```\n   * const result = await prisma.$queryRawUnsafe('SELECT * FROM User WHERE id = $1 OR email = $2;', 1, 'user@email.com')\n   * ```\n   *\n   * Read more in our [docs](https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-client/raw-database-access).\n   */\n  $queryRawUnsafe<T = unknown>(query: string, ...values: any[]): Prisma.PrismaPromise<T>;\n\n\n  /**\n   * Allows the running of a sequence of read/write operations that are guaranteed to either succeed or fail as a whole.\n   * @example\n   * ```\n   * const [george, bob, alice] = await prisma.$transaction([\n   *   prisma.user.create({ data: { name: 'George' } }),\n   *   prisma.user.create({ data: { name: 'Bob' } }),\n   *   prisma.user.create({ data: { name: 'Alice' } }),\n   * ])\n   * ```\n   * \n   * Read more in our [docs](https://www.prisma.io/docs/concepts/components/prisma-client/transactions).\n   */\n  $transaction<P extends Prisma.PrismaPromise<any>[]>(arg: [...P], options?: { isolationLevel?: Prisma.TransactionIsolationLevel }): $Utils.JsPromise<runtime.Types.Utils.UnwrapTuple<P>>\n\n  $transaction<R>(fn: (prisma: Omit<PrismaClient, runtime.ITXClientDenyList>) => $Utils.JsPromise<R>, options?: { maxWait?: number, timeout?: number, isolationLevel?: Prisma.TransactionIsolationLevel }): $Utils.JsPromise<R>\n\n\n  $extends: $Extensions.ExtendsHook<\"extends\", Prisma.TypeMapCb<ClientOptions>, ExtArgs, $Utils.Call<Prisma.TypeMapCb<ClientOptions>, {\n    extArgs: ExtArgs\n  }>>\n\n      /**\n   * `prisma.political_news_crawler_crawl_sources`: Exposes CRUD operations for the **political_news_crawler_crawl_sources** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_crawl_sources\n    * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.findMany()\n    * ```\n    */\n  get political_news_crawler_crawl_sources(): Prisma.political_news_crawler_crawl_sourcesDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_crawl_policies`: Exposes CRUD operations for the **political_news_crawler_crawl_policies** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_crawl_policies\n    * const political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.findMany()\n    * ```\n    */\n  get political_news_crawler_crawl_policies(): Prisma.political_news_crawler_crawl_policiesDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_crawl_schedules`: Exposes CRUD operations for the **political_news_crawler_crawl_schedules** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_crawl_schedules\n    * const political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.findMany()\n    * ```\n    */\n  get political_news_crawler_crawl_schedules(): Prisma.political_news_crawler_crawl_schedulesDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_guests`: Exposes CRUD operations for the **political_news_crawler_guests** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_guests\n    * const political_news_crawler_guests = await prisma.political_news_crawler_guests.findMany()\n    * ```\n    */\n  get political_news_crawler_guests(): Prisma.political_news_crawler_guestsDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_crawl_jobs`: Exposes CRUD operations for the **political_news_crawler_crawl_jobs** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_crawl_jobs\n    * const political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.findMany()\n    * ```\n    */\n  get political_news_crawler_crawl_jobs(): Prisma.political_news_crawler_crawl_jobsDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_crawl_attempts`: Exposes CRUD operations for the **political_news_crawler_crawl_attempts** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_crawl_attempts\n    * const political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.findMany()\n    * ```\n    */\n  get political_news_crawler_crawl_attempts(): Prisma.political_news_crawler_crawl_attemptsDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_crawled_news`: Exposes CRUD operations for the **political_news_crawler_crawled_news** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_crawled_news\n    * const political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.findMany()\n    * ```\n    */\n  get political_news_crawler_crawled_news(): Prisma.political_news_crawler_crawled_newsDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_raw_data_storage`: Exposes CRUD operations for the **political_news_crawler_raw_data_storage** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_raw_data_storages\n    * const political_news_crawler_raw_data_storages = await prisma.political_news_crawler_raw_data_storage.findMany()\n    * ```\n    */\n  get political_news_crawler_raw_data_storage(): Prisma.political_news_crawler_raw_data_storageDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_local_cache_files`: Exposes CRUD operations for the **political_news_crawler_local_cache_files** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_local_cache_files\n    * const political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.findMany()\n    * ```\n    */\n  get political_news_crawler_local_cache_files(): Prisma.political_news_crawler_local_cache_filesDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_processed_content`: Exposes CRUD operations for the **political_news_crawler_processed_content** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_processed_contents\n    * const political_news_crawler_processed_contents = await prisma.political_news_crawler_processed_content.findMany()\n    * ```\n    */\n  get political_news_crawler_processed_content(): Prisma.political_news_crawler_processed_contentDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_llm_jobs`: Exposes CRUD operations for the **political_news_crawler_llm_jobs** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_llm_jobs\n    * const political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.findMany()\n    * ```\n    */\n  get political_news_crawler_llm_jobs(): Prisma.political_news_crawler_llm_jobsDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_llm_results`: Exposes CRUD operations for the **political_news_crawler_llm_results** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_llm_results\n    * const political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.findMany()\n    * ```\n    */\n  get political_news_crawler_llm_results(): Prisma.political_news_crawler_llm_resultsDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_processing_metadata`: Exposes CRUD operations for the **political_news_crawler_processing_metadata** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_processing_metadata\n    * const political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.findMany()\n    * ```\n    */\n  get political_news_crawler_processing_metadata(): Prisma.political_news_crawler_processing_metadataDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_popularity_scores`: Exposes CRUD operations for the **political_news_crawler_popularity_scores** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_popularity_scores\n    * const political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.findMany()\n    * ```\n    */\n  get political_news_crawler_popularity_scores(): Prisma.political_news_crawler_popularity_scoresDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_popular_topics`: Exposes CRUD operations for the **political_news_crawler_popular_topics** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_popular_topics\n    * const political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.findMany()\n    * ```\n    */\n  get political_news_crawler_popular_topics(): Prisma.political_news_crawler_popular_topicsDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_topic_mentions`: Exposes CRUD operations for the **political_news_crawler_topic_mentions** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_topic_mentions\n    * const political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.findMany()\n    * ```\n    */\n  get political_news_crawler_topic_mentions(): Prisma.political_news_crawler_topic_mentionsDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_api_access_logs`: Exposes CRUD operations for the **political_news_crawler_api_access_logs** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_api_access_logs\n    * const political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.findMany()\n    * ```\n    */\n  get political_news_crawler_api_access_logs(): Prisma.political_news_crawler_api_access_logsDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_api_error_logs`: Exposes CRUD operations for the **political_news_crawler_api_error_logs** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_api_error_logs\n    * const political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.findMany()\n    * ```\n    */\n  get political_news_crawler_api_error_logs(): Prisma.political_news_crawler_api_error_logsDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_api_usage_metrics`: Exposes CRUD operations for the **political_news_crawler_api_usage_metrics** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_api_usage_metrics\n    * const political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.findMany()\n    * ```\n    */\n  get political_news_crawler_api_usage_metrics(): Prisma.political_news_crawler_api_usage_metricsDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_crawl_alerts`: Exposes CRUD operations for the **political_news_crawler_crawl_alerts** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_crawl_alerts\n    * const political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.findMany()\n    * ```\n    */\n  get political_news_crawler_crawl_alerts(): Prisma.political_news_crawler_crawl_alertsDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_processing_alerts`: Exposes CRUD operations for the **political_news_crawler_processing_alerts** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_processing_alerts\n    * const political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.findMany()\n    * ```\n    */\n  get political_news_crawler_processing_alerts(): Prisma.political_news_crawler_processing_alertsDelegate<ExtArgs, ClientOptions>;\n\n  /**\n   * `prisma.political_news_crawler_api_alerts`: Exposes CRUD operations for the **political_news_crawler_api_alerts** model.\n    * Example usage:\n    * ```ts\n    * // Fetch zero or more Political_news_crawler_api_alerts\n    * const political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.findMany()\n    * ```\n    */\n  get political_news_crawler_api_alerts(): Prisma.political_news_crawler_api_alertsDelegate<ExtArgs, ClientOptions>;\n}\n\nexport namespace Prisma {\n  export import DMMF = runtime.DMMF\n\n  export type PrismaPromise<T> = $Public.PrismaPromise<T>\n\n  /**\n   * Validator\n   */\n  export import validator = runtime.Public.validator\n\n  /**\n   * Prisma Errors\n   */\n  export import PrismaClientKnownRequestError = runtime.PrismaClientKnownRequestError\n  export import PrismaClientUnknownRequestError = runtime.PrismaClientUnknownRequestError\n  export import PrismaClientRustPanicError = runtime.PrismaClientRustPanicError\n  export import PrismaClientInitializationError = runtime.PrismaClientInitializationError\n  export import PrismaClientValidationError = runtime.PrismaClientValidationError\n\n  /**\n   * Re-export of sql-template-tag\n   */\n  export import sql = runtime.sqltag\n  export import empty = runtime.empty\n  export import join = runtime.join\n  export import raw = runtime.raw\n  export import Sql = runtime.Sql\n\n\n\n  /**\n   * Decimal.js\n   */\n  export import Decimal = runtime.Decimal\n\n  export type DecimalJsLike = runtime.DecimalJsLike\n\n  /**\n   * Metrics\n   */\n  export type Metrics = runtime.Metrics\n  export type Metric<T> = runtime.Metric<T>\n  export type MetricHistogram = runtime.MetricHistogram\n  export type MetricHistogramBucket = runtime.MetricHistogramBucket\n\n  /**\n  * Extensions\n  */\n  export import Extension = $Extensions.UserArgs\n  export import getExtensionContext = runtime.Extensions.getExtensionContext\n  export import Args = $Public.Args\n  export import Payload = $Public.Payload\n  export import Result = $Public.Result\n  export import Exact = $Public.Exact\n\n  /**\n   * Prisma Client JS version: local\n   * Query Engine version: local\n   */\n  export type PrismaVersion = {\n    client: string\n  }\n\n  export const prismaVersion: PrismaVersion\n\n  /**\n   * Utility Types\n   */\n\n\n  export import JsonObject = runtime.JsonObject\n  export import JsonArray = runtime.JsonArray\n  export import JsonValue = runtime.JsonValue\n  export import InputJsonObject = runtime.InputJsonObject\n  export import InputJsonArray = runtime.InputJsonArray\n  export import InputJsonValue = runtime.InputJsonValue\n\n  /**\n   * Types of the values used to represent different kinds of `null` values when working with JSON fields.\n   *\n   * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-on-a-json-field\n   */\n  namespace NullTypes {\n    /**\n    * Type of `Prisma.DbNull`.\n    *\n    * You cannot use other instances of this class. Please use the `Prisma.DbNull` value.\n    *\n    * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-on-a-json-field\n    */\n    class DbNull {\n      private DbNull: never\n      private constructor()\n    }\n\n    /**\n    * Type of `Prisma.JsonNull`.\n    *\n    * You cannot use other instances of this class. Please use the `Prisma.JsonNull` value.\n    *\n    * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-on-a-json-field\n    */\n    class JsonNull {\n      private JsonNull: never\n      private constructor()\n    }\n\n    /**\n    * Type of `Prisma.AnyNull`.\n    *\n    * You cannot use other instances of this class. Please use the `Prisma.AnyNull` value.\n    *\n    * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-on-a-json-field\n    */\n    class AnyNull {\n      private AnyNull: never\n      private constructor()\n    }\n  }\n\n  /**\n   * Helper for filtering JSON entries that have `null` on the database (empty on the db)\n   *\n   * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-on-a-json-field\n   */\n  export const DbNull: NullTypes.DbNull\n\n  /**\n   * Helper for filtering JSON entries that have JSON `null` values (not empty on the db)\n   *\n   * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-on-a-json-field\n   */\n  export const JsonNull: NullTypes.JsonNull\n\n  /**\n   * Helper for filtering JSON entries that are `Prisma.DbNull` or `Prisma.JsonNull`\n   *\n   * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-on-a-json-field\n   */\n  export const AnyNull: NullTypes.AnyNull\n\n  type SelectAndInclude = {\n    select: any\n    include: any\n  }\n\n  type SelectAndOmit = {\n    select: any\n    omit: any\n  }\n\n  /**\n   * Get the type of the value, that the Promise holds.\n   */\n  export type PromiseType<T extends PromiseLike<any>> = T extends PromiseLike<infer U> ? U : T;\n\n  /**\n   * Get the return type of a function which returns a Promise.\n   */\n  export type PromiseReturnType<T extends (...args: any) => $Utils.JsPromise<any>> = PromiseType<ReturnType<T>>\n\n  /**\n   * From T, pick a set of properties whose keys are in the union K\n   */\n  type Prisma__Pick<T, K extends keyof T> = {\n      [P in K]: T[P];\n  };\n\n\n  export type Enumerable<T> = T | Array<T>;\n\n  export type RequiredKeys<T> = {\n    [K in keyof T]-?: {} extends Prisma__Pick<T, K> ? never : K\n  }[keyof T]\n\n  export type TruthyKeys<T> = keyof {\n    [K in keyof T as T[K] extends false | undefined | null ? never : K]: K\n  }\n\n  export type TrueKeys<T> = TruthyKeys<Prisma__Pick<T, RequiredKeys<T>>>\n\n  /**\n   * Subset\n   * @desc From `T` pick properties that exist in `U`. Simple version of Intersection\n   */\n  export type Subset<T, U> = {\n    [key in keyof T]: key extends keyof U ? T[key] : never;\n  };\n\n  /**\n   * SelectSubset\n   * @desc From `T` pick properties that exist in `U`. Simple version of Intersection.\n   * Additionally, it validates, if both select and include are present. If the case, it errors.\n   */\n  export type SelectSubset<T, U> = {\n    [key in keyof T]: key extends keyof U ? T[key] : never\n  } &\n    (T extends SelectAndInclude\n      ? 'Please either choose `select` or `include`.'\n      : T extends SelectAndOmit\n        ? 'Please either choose `select` or `omit`.'\n        : {})\n\n  /**\n   * Subset + Intersection\n   * @desc From `T` pick properties that exist in `U` and intersect `K`\n   */\n  export type SubsetIntersection<T, U, K> = {\n    [key in keyof T]: key extends keyof U ? T[key] : never\n  } &\n    K\n\n  type Without<T, U> = { [P in Exclude<keyof T, keyof U>]?: never };\n\n  /**\n   * XOR is needed to have a real mutually exclusive union type\n   * https://stackoverflow.com/questions/42123407/does-typescript-support-mutually-exclusive-types\n   */\n  type XOR<T, U> =\n    T extends object ?\n    U extends object ?\n      (Without<T, U> & U) | (Without<U, T> & T)\n    : U : T\n\n\n  /**\n   * Is T a Record?\n   */\n  type IsObject<T extends any> = T extends Array<any>\n  ? False\n  : T extends Date\n  ? False\n  : T extends Uint8Array\n  ? False\n  : T extends BigInt\n  ? False\n  : T extends object\n  ? True\n  : False\n\n\n  /**\n   * If it's T[], return T\n   */\n  export type UnEnumerate<T extends unknown> = T extends Array<infer U> ? U : T\n\n  /**\n   * From ts-toolbelt\n   */\n\n  type __Either<O extends object, K extends Key> = Omit<O, K> &\n    {\n      // Merge all but K\n      [P in K]: Prisma__Pick<O, P & keyof O> // With K possibilities\n    }[K]\n\n  type EitherStrict<O extends object, K extends Key> = Strict<__Either<O, K>>\n\n  type EitherLoose<O extends object, K extends Key> = ComputeRaw<__Either<O, K>>\n\n  type _Either<\n    O extends object,\n    K extends Key,\n    strict extends Boolean\n  > = {\n    1: EitherStrict<O, K>\n    0: EitherLoose<O, K>\n  }[strict]\n\n  type Either<\n    O extends object,\n    K extends Key,\n    strict extends Boolean = 1\n  > = O extends unknown ? _Either<O, K, strict> : never\n\n  export type Union = any\n\n  type PatchUndefined<O extends object, O1 extends object> = {\n    [K in keyof O]: O[K] extends undefined ? At<O1, K> : O[K]\n  } & {}\n\n  /** Helper Types for \"Merge\" **/\n  export type IntersectOf<U extends Union> = (\n    U extends unknown ? (k: U) => void : never\n  ) extends (k: infer I) => void\n    ? I\n    : never\n\n  export type Overwrite<O extends object, O1 extends object> = {\n      [K in keyof O]: K extends keyof O1 ? O1[K] : O[K];\n  } & {};\n\n  type _Merge<U extends object> = IntersectOf<Overwrite<U, {\n      [K in keyof U]-?: At<U, K>;\n  }>>;\n\n  type Key = string | number | symbol;\n  type AtBasic<O extends object, K extends Key> = K extends keyof O ? O[K] : never;\n  type AtStrict<O extends object, K extends Key> = O[K & keyof O];\n  type AtLoose<O extends object, K extends Key> = O extends unknown ? AtStrict<O, K> : never;\n  export type At<O extends object, K extends Key, strict extends Boolean = 1> = {\n      1: AtStrict<O, K>;\n      0: AtLoose<O, K>;\n  }[strict];\n\n  export type ComputeRaw<A extends any> = A extends Function ? A : {\n    [K in keyof A]: A[K];\n  } & {};\n\n  export type OptionalFlat<O> = {\n    [K in keyof O]?: O[K];\n  } & {};\n\n  type _Record<K extends keyof any, T> = {\n    [P in K]: T;\n  };\n\n  // cause typescript not to expand types and preserve names\n  type NoExpand<T> = T extends unknown ? T : never;\n\n  // this type assumes the passed object is entirely optional\n  type AtLeast<O extends object, K extends string> = NoExpand<\n    O extends unknown\n    ? | (K extends keyof O ? { [P in K]: O[P] } & O : O)\n      | {[P in keyof O as P extends K ? P : never]-?: O[P]} & O\n    : never>;\n\n  type _Strict<U, _U = U> = U extends unknown ? U & OptionalFlat<_Record<Exclude<Keys<_U>, keyof U>, never>> : never;\n\n  export type Strict<U extends object> = ComputeRaw<_Strict<U>>;\n  /** End Helper Types for \"Merge\" **/\n\n  export type Merge<U extends object> = ComputeRaw<_Merge<Strict<U>>>;\n\n  /**\n  A [[Boolean]]\n  */\n  export type Boolean = True | False\n\n  // /**\n  // 1\n  // */\n  export type True = 1\n\n  /**\n  0\n  */\n  export type False = 0\n\n  export type Not<B extends Boolean> = {\n    0: 1\n    1: 0\n  }[B]\n\n  export type Extends<A1 extends any, A2 extends any> = [A1] extends [never]\n    ? 0 // anything `never` is false\n    : A1 extends A2\n    ? 1\n    : 0\n\n  export type Has<U extends Union, U1 extends Union> = Not<\n    Extends<Exclude<U1, U>, U1>\n  >\n\n  export type Or<B1 extends Boolean, B2 extends Boolean> = {\n    0: {\n      0: 0\n      1: 1\n    }\n    1: {\n      0: 1\n      1: 1\n    }\n  }[B1][B2]\n\n  export type Keys<U extends Union> = U extends unknown ? keyof U : never\n\n  type Cast<A, B> = A extends B ? A : B;\n\n  export const type: unique symbol;\n\n\n\n  /**\n   * Used by group by\n   */\n\n  export type GetScalarType<T, O> = O extends object ? {\n    [P in keyof T]: P extends keyof O\n      ? O[P]\n      : never\n  } : never\n\n  type FieldPaths<\n    T,\n    U = Omit<T, '_avg' | '_sum' | '_count' | '_min' | '_max'>\n  > = IsObject<T> extends True ? U : T\n\n  type GetHavingFields<T> = {\n    [K in keyof T]: Or<\n      Or<Extends<'OR', K>, Extends<'AND', K>>,\n      Extends<'NOT', K>\n    > extends True\n      ? // infer is only needed to not hit TS limit\n        // based on the brilliant idea of Pierre-Antoine Mills\n        // https://github.com/microsoft/TypeScript/issues/30188#issuecomment-478938437\n        T[K] extends infer TK\n        ? GetHavingFields<UnEnumerate<TK> extends object ? Merge<UnEnumerate<TK>> : never>\n        : never\n      : {} extends FieldPaths<T[K]>\n      ? never\n      : K\n  }[keyof T]\n\n  /**\n   * Convert tuple to union\n   */\n  type _TupleToUnion<T> = T extends (infer E)[] ? E : never\n  type TupleToUnion<K extends readonly any[]> = _TupleToUnion<K>\n  type MaybeTupleToUnion<T> = T extends any[] ? TupleToUnion<T> : T\n\n  /**\n   * Like `Pick`, but additionally can also accept an array of keys\n   */\n  type PickEnumerable<T, K extends Enumerable<keyof T> | keyof T> = Prisma__Pick<T, MaybeTupleToUnion<K>>\n\n  /**\n   * Exclude all keys with underscores\n   */\n  type ExcludeUnderscoreKeys<T extends string> = T extends `_${string}` ? never : T\n\n\n  export type FieldRef<Model, FieldType> = runtime.FieldRef<Model, FieldType>\n\n  type FieldRefInputType<Model, FieldType> = Model extends never ? never : FieldRef<Model, FieldType>\n\n\n  export const ModelName: {\n    political_news_crawler_crawl_sources: 'political_news_crawler_crawl_sources',\n    political_news_crawler_crawl_policies: 'political_news_crawler_crawl_policies',\n    political_news_crawler_crawl_schedules: 'political_news_crawler_crawl_schedules',\n    political_news_crawler_guests: 'political_news_crawler_guests',\n    political_news_crawler_crawl_jobs: 'political_news_crawler_crawl_jobs',\n    political_news_crawler_crawl_attempts: 'political_news_crawler_crawl_attempts',\n    political_news_crawler_crawled_news: 'political_news_crawler_crawled_news',\n    political_news_crawler_raw_data_storage: 'political_news_crawler_raw_data_storage',\n    political_news_crawler_local_cache_files: 'political_news_crawler_local_cache_files',\n    political_news_crawler_processed_content: 'political_news_crawler_processed_content',\n    political_news_crawler_llm_jobs: 'political_news_crawler_llm_jobs',\n    political_news_crawler_llm_results: 'political_news_crawler_llm_results',\n    political_news_crawler_processing_metadata: 'political_news_crawler_processing_metadata',\n    political_news_crawler_popularity_scores: 'political_news_crawler_popularity_scores',\n    political_news_crawler_popular_topics: 'political_news_crawler_popular_topics',\n    political_news_crawler_topic_mentions: 'political_news_crawler_topic_mentions',\n    political_news_crawler_api_access_logs: 'political_news_crawler_api_access_logs',\n    political_news_crawler_api_error_logs: 'political_news_crawler_api_error_logs',\n    political_news_crawler_api_usage_metrics: 'political_news_crawler_api_usage_metrics',\n    political_news_crawler_crawl_alerts: 'political_news_crawler_crawl_alerts',\n    political_news_crawler_processing_alerts: 'political_news_crawler_processing_alerts',\n    political_news_crawler_api_alerts: 'political_news_crawler_api_alerts'\n  };\n\n  export type ModelName = (typeof ModelName)[keyof typeof ModelName]\n\n\n  export type Datasources = {\n    db?: Datasource\n  }\n\n  interface TypeMapCb<ClientOptions = {}> extends $Utils.Fn<{extArgs: $Extensions.InternalArgs }, $Utils.Record<string, any>> {\n    returns: Prisma.TypeMap<this['params']['extArgs'], ClientOptions extends { omit: infer OmitOptions } ? OmitOptions : {}>\n  }\n\n  export type TypeMap<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> = {\n    globalOmitOptions: {\n      omit: GlobalOmitOptions\n    }\n    meta: {\n      modelProps: \"political_news_crawler_crawl_sources\" | \"political_news_crawler_crawl_policies\" | \"political_news_crawler_crawl_schedules\" | \"political_news_crawler_guests\" | \"political_news_crawler_crawl_jobs\" | \"political_news_crawler_crawl_attempts\" | \"political_news_crawler_crawled_news\" | \"political_news_crawler_raw_data_storage\" | \"political_news_crawler_local_cache_files\" | \"political_news_crawler_processed_content\" | \"political_news_crawler_llm_jobs\" | \"political_news_crawler_llm_results\" | \"political_news_crawler_processing_metadata\" | \"political_news_crawler_popularity_scores\" | \"political_news_crawler_popular_topics\" | \"political_news_crawler_topic_mentions\" | \"political_news_crawler_api_access_logs\" | \"political_news_crawler_api_error_logs\" | \"political_news_crawler_api_usage_metrics\" | \"political_news_crawler_crawl_alerts\" | \"political_news_crawler_processing_alerts\" | \"political_news_crawler_api_alerts\"\n      txIsolationLevel: Prisma.TransactionIsolationLevel\n    }\n    model: {\n      political_news_crawler_crawl_sources: {\n        payload: Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_crawl_sourcesFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_crawl_sourcesFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_sourcesPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_crawl_sourcesFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_sourcesPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_crawl_sourcesFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_sourcesPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_crawl_sourcesFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_sourcesPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_crawl_sourcesFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_sourcesPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_crawl_sourcesCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_sourcesPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_crawl_sourcesCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_crawl_sourcesCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_sourcesPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_crawl_sourcesDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_sourcesPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_crawl_sourcesUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_sourcesPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_crawl_sourcesDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_crawl_sourcesUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_crawl_sourcesUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_sourcesPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_crawl_sourcesUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_sourcesPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_crawl_sourcesAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_crawl_sources>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_crawl_sourcesGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawl_sourcesGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_crawl_sourcesCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawl_sourcesCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_crawl_policies: {\n        payload: Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_crawl_policiesFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_crawl_policiesFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_policiesPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_crawl_policiesFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_policiesPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_crawl_policiesFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_policiesPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_crawl_policiesFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_policiesPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_crawl_policiesFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_policiesPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_crawl_policiesCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_policiesPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_crawl_policiesCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_crawl_policiesCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_policiesPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_crawl_policiesDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_policiesPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_crawl_policiesUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_policiesPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_crawl_policiesDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_crawl_policiesUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_crawl_policiesUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_policiesPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_crawl_policiesUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_policiesPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_crawl_policiesAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_crawl_policies>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_crawl_policiesGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawl_policiesGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_crawl_policiesCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawl_policiesCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_crawl_schedules: {\n        payload: Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_crawl_schedulesFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_crawl_schedulesFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_schedulesPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_crawl_schedulesFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_schedulesPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_crawl_schedulesFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_schedulesPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_crawl_schedulesFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_schedulesPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_crawl_schedulesFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_schedulesPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_crawl_schedulesCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_schedulesPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_crawl_schedulesCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_crawl_schedulesCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_schedulesPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_crawl_schedulesDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_schedulesPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_crawl_schedulesUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_schedulesPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_crawl_schedulesDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_crawl_schedulesUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_crawl_schedulesUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_schedulesPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_crawl_schedulesUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_schedulesPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_crawl_schedulesAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_crawl_schedules>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_crawl_schedulesGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawl_schedulesGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_crawl_schedulesCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawl_schedulesCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_guests: {\n        payload: Prisma.$political_news_crawler_guestsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_guestsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_guestsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_guestsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_guestsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_guestsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_guestsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_guestsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_guestsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_guestsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_guestsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_guestsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_guestsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_guestsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_guestsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_guestsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_guestsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_guestsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_guestsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_guestsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_guestsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_guestsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_guestsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_guestsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_guestsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_guestsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_guestsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_guestsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_guests>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_guestsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_guestsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_guestsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_guestsCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_crawl_jobs: {\n        payload: Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_crawl_jobsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_crawl_jobsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_jobsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_crawl_jobsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_jobsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_crawl_jobsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_jobsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_crawl_jobsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_jobsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_crawl_jobsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_jobsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_crawl_jobsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_jobsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_crawl_jobsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_crawl_jobsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_jobsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_crawl_jobsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_jobsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_crawl_jobsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_jobsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_crawl_jobsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_crawl_jobsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_crawl_jobsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_jobsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_crawl_jobsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_jobsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_crawl_jobsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_crawl_jobs>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_crawl_jobsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawl_jobsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_crawl_jobsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawl_jobsCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_crawl_attempts: {\n        payload: Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_crawl_attemptsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_crawl_attemptsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_attemptsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_crawl_attemptsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_attemptsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_crawl_attemptsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_attemptsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_crawl_attemptsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_attemptsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_crawl_attemptsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_attemptsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_crawl_attemptsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_attemptsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_crawl_attemptsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_crawl_attemptsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_attemptsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_crawl_attemptsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_attemptsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_crawl_attemptsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_attemptsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_crawl_attemptsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_crawl_attemptsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_crawl_attemptsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_attemptsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_crawl_attemptsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_attemptsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_crawl_attemptsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_crawl_attempts>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_crawl_attemptsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawl_attemptsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_crawl_attemptsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawl_attemptsCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_crawled_news: {\n        payload: Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_crawled_newsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_crawled_newsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawled_newsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_crawled_newsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawled_newsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_crawled_newsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawled_newsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_crawled_newsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawled_newsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_crawled_newsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawled_newsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_crawled_newsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawled_newsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_crawled_newsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_crawled_newsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawled_newsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_crawled_newsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawled_newsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_crawled_newsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawled_newsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_crawled_newsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_crawled_newsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_crawled_newsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawled_newsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_crawled_newsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawled_newsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_crawled_newsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_crawled_news>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_crawled_newsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawled_newsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_crawled_newsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawled_newsCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_raw_data_storage: {\n        payload: Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>\n        fields: Prisma.political_news_crawler_raw_data_storageFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_raw_data_storageFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_raw_data_storagePayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_raw_data_storageFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_raw_data_storagePayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_raw_data_storageFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_raw_data_storagePayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_raw_data_storageFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_raw_data_storagePayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_raw_data_storageFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_raw_data_storagePayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_raw_data_storageCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_raw_data_storagePayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_raw_data_storageCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_raw_data_storageCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_raw_data_storagePayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_raw_data_storageDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_raw_data_storagePayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_raw_data_storageUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_raw_data_storagePayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_raw_data_storageDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_raw_data_storageUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_raw_data_storageUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_raw_data_storagePayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_raw_data_storageUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_raw_data_storagePayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_raw_data_storageAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_raw_data_storage>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_raw_data_storageGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_raw_data_storageGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_raw_data_storageCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_raw_data_storageCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_local_cache_files: {\n        payload: Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_local_cache_filesFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_local_cache_filesFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_local_cache_filesPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_local_cache_filesFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_local_cache_filesPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_local_cache_filesFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_local_cache_filesPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_local_cache_filesFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_local_cache_filesPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_local_cache_filesFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_local_cache_filesPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_local_cache_filesCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_local_cache_filesPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_local_cache_filesCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_local_cache_filesCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_local_cache_filesPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_local_cache_filesDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_local_cache_filesPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_local_cache_filesUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_local_cache_filesPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_local_cache_filesDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_local_cache_filesUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_local_cache_filesUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_local_cache_filesPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_local_cache_filesUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_local_cache_filesPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_local_cache_filesAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_local_cache_files>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_local_cache_filesGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_local_cache_filesGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_local_cache_filesCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_local_cache_filesCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_processed_content: {\n        payload: Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_processed_contentFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_processed_contentFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processed_contentPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_processed_contentFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processed_contentPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_processed_contentFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processed_contentPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_processed_contentFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processed_contentPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_processed_contentFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processed_contentPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_processed_contentCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processed_contentPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_processed_contentCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_processed_contentCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processed_contentPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_processed_contentDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processed_contentPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_processed_contentUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processed_contentPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_processed_contentDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_processed_contentUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_processed_contentUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processed_contentPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_processed_contentUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processed_contentPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_processed_contentAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_processed_content>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_processed_contentGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_processed_contentGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_processed_contentCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_processed_contentCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_llm_jobs: {\n        payload: Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_llm_jobsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_llm_jobsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_jobsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_llm_jobsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_jobsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_llm_jobsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_jobsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_llm_jobsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_jobsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_llm_jobsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_jobsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_llm_jobsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_jobsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_llm_jobsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_llm_jobsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_jobsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_llm_jobsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_jobsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_llm_jobsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_jobsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_llm_jobsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_llm_jobsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_llm_jobsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_jobsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_llm_jobsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_jobsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_llm_jobsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_llm_jobs>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_llm_jobsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_llm_jobsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_llm_jobsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_llm_jobsCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_llm_results: {\n        payload: Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_llm_resultsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_llm_resultsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_resultsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_llm_resultsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_resultsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_llm_resultsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_resultsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_llm_resultsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_resultsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_llm_resultsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_resultsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_llm_resultsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_resultsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_llm_resultsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_llm_resultsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_resultsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_llm_resultsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_resultsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_llm_resultsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_resultsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_llm_resultsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_llm_resultsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_llm_resultsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_resultsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_llm_resultsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_llm_resultsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_llm_resultsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_llm_results>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_llm_resultsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_llm_resultsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_llm_resultsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_llm_resultsCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_processing_metadata: {\n        payload: Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_processing_metadataFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_processing_metadataFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_metadataPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_processing_metadataFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_metadataPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_processing_metadataFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_metadataPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_processing_metadataFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_metadataPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_processing_metadataFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_metadataPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_processing_metadataCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_metadataPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_processing_metadataCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_processing_metadataCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_metadataPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_processing_metadataDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_metadataPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_processing_metadataUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_metadataPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_processing_metadataDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_processing_metadataUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_processing_metadataUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_metadataPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_processing_metadataUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_metadataPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_processing_metadataAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_processing_metadata>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_processing_metadataGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_processing_metadataGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_processing_metadataCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_processing_metadataCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_popularity_scores: {\n        payload: Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_popularity_scoresFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_popularity_scoresFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popularity_scoresPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_popularity_scoresFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popularity_scoresPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_popularity_scoresFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popularity_scoresPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_popularity_scoresFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popularity_scoresPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_popularity_scoresFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popularity_scoresPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_popularity_scoresCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popularity_scoresPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_popularity_scoresCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_popularity_scoresCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popularity_scoresPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_popularity_scoresDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popularity_scoresPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_popularity_scoresUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popularity_scoresPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_popularity_scoresDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_popularity_scoresUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_popularity_scoresUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popularity_scoresPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_popularity_scoresUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popularity_scoresPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_popularity_scoresAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_popularity_scores>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_popularity_scoresGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_popularity_scoresGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_popularity_scoresCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_popularity_scoresCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_popular_topics: {\n        payload: Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_popular_topicsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_popular_topicsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popular_topicsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_popular_topicsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popular_topicsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_popular_topicsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popular_topicsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_popular_topicsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popular_topicsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_popular_topicsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popular_topicsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_popular_topicsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popular_topicsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_popular_topicsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_popular_topicsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popular_topicsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_popular_topicsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popular_topicsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_popular_topicsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popular_topicsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_popular_topicsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_popular_topicsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_popular_topicsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popular_topicsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_popular_topicsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_popular_topicsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_popular_topicsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_popular_topics>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_popular_topicsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_popular_topicsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_popular_topicsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_popular_topicsCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_topic_mentions: {\n        payload: Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_topic_mentionsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_topic_mentionsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_topic_mentionsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_topic_mentionsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_topic_mentionsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_topic_mentionsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_topic_mentionsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_topic_mentionsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_topic_mentionsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_topic_mentionsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_topic_mentionsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_topic_mentionsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_topic_mentionsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_topic_mentionsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_topic_mentionsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_topic_mentionsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_topic_mentionsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_topic_mentionsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_topic_mentionsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_topic_mentionsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_topic_mentionsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_topic_mentionsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_topic_mentionsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_topic_mentionsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_topic_mentionsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_topic_mentionsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_topic_mentionsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_topic_mentions>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_topic_mentionsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_topic_mentionsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_topic_mentionsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_topic_mentionsCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_api_access_logs: {\n        payload: Prisma.$political_news_crawler_api_access_logsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_api_access_logsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_api_access_logsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_access_logsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_api_access_logsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_access_logsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_api_access_logsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_access_logsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_api_access_logsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_access_logsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_api_access_logsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_access_logsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_api_access_logsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_access_logsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_api_access_logsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_api_access_logsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_access_logsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_api_access_logsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_access_logsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_api_access_logsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_access_logsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_api_access_logsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_api_access_logsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_api_access_logsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_access_logsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_api_access_logsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_access_logsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_api_access_logsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_api_access_logs>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_api_access_logsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_api_access_logsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_api_access_logsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_api_access_logsCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_api_error_logs: {\n        payload: Prisma.$political_news_crawler_api_error_logsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_api_error_logsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_api_error_logsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_error_logsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_api_error_logsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_error_logsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_api_error_logsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_error_logsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_api_error_logsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_error_logsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_api_error_logsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_error_logsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_api_error_logsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_error_logsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_api_error_logsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_api_error_logsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_error_logsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_api_error_logsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_error_logsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_api_error_logsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_error_logsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_api_error_logsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_api_error_logsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_api_error_logsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_error_logsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_api_error_logsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_error_logsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_api_error_logsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_api_error_logs>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_api_error_logsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_api_error_logsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_api_error_logsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_api_error_logsCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_api_usage_metrics: {\n        payload: Prisma.$political_news_crawler_api_usage_metricsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_api_usage_metricsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_api_usage_metricsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_usage_metricsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_api_usage_metricsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_usage_metricsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_api_usage_metricsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_usage_metricsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_api_usage_metricsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_usage_metricsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_api_usage_metricsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_usage_metricsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_api_usage_metricsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_usage_metricsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_api_usage_metricsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_api_usage_metricsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_usage_metricsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_api_usage_metricsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_usage_metricsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_api_usage_metricsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_usage_metricsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_api_usage_metricsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_api_usage_metricsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_api_usage_metricsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_usage_metricsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_api_usage_metricsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_usage_metricsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_api_usage_metricsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_api_usage_metrics>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_api_usage_metricsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_api_usage_metricsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_api_usage_metricsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_api_usage_metricsCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_crawl_alerts: {\n        payload: Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_crawl_alertsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_crawl_alertsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_alertsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_crawl_alertsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_alertsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_crawl_alertsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_alertsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_crawl_alertsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_alertsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_crawl_alertsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_alertsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_crawl_alertsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_alertsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_crawl_alertsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_crawl_alertsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_alertsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_crawl_alertsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_alertsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_crawl_alertsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_alertsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_crawl_alertsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_crawl_alertsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_crawl_alertsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_alertsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_crawl_alertsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_crawl_alertsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_crawl_alertsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_crawl_alerts>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_crawl_alertsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawl_alertsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_crawl_alertsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_crawl_alertsCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_processing_alerts: {\n        payload: Prisma.$political_news_crawler_processing_alertsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_processing_alertsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_processing_alertsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_alertsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_processing_alertsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_alertsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_processing_alertsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_alertsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_processing_alertsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_alertsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_processing_alertsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_alertsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_processing_alertsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_alertsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_processing_alertsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_processing_alertsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_alertsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_processing_alertsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_alertsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_processing_alertsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_alertsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_processing_alertsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_processing_alertsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_processing_alertsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_alertsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_processing_alertsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_processing_alertsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_processing_alertsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_processing_alerts>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_processing_alertsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_processing_alertsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_processing_alertsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_processing_alertsCountAggregateOutputType> | number\n          }\n        }\n      }\n      political_news_crawler_api_alerts: {\n        payload: Prisma.$political_news_crawler_api_alertsPayload<ExtArgs>\n        fields: Prisma.political_news_crawler_api_alertsFieldRefs\n        operations: {\n          findUnique: {\n            args: Prisma.political_news_crawler_api_alertsFindUniqueArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_alertsPayload> | null\n          }\n          findUniqueOrThrow: {\n            args: Prisma.political_news_crawler_api_alertsFindUniqueOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_alertsPayload>\n          }\n          findFirst: {\n            args: Prisma.political_news_crawler_api_alertsFindFirstArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_alertsPayload> | null\n          }\n          findFirstOrThrow: {\n            args: Prisma.political_news_crawler_api_alertsFindFirstOrThrowArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_alertsPayload>\n          }\n          findMany: {\n            args: Prisma.political_news_crawler_api_alertsFindManyArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_alertsPayload>[]\n          }\n          create: {\n            args: Prisma.political_news_crawler_api_alertsCreateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_alertsPayload>\n          }\n          createMany: {\n            args: Prisma.political_news_crawler_api_alertsCreateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          createManyAndReturn: {\n            args: Prisma.political_news_crawler_api_alertsCreateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_alertsPayload>[]\n          }\n          delete: {\n            args: Prisma.political_news_crawler_api_alertsDeleteArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_alertsPayload>\n          }\n          update: {\n            args: Prisma.political_news_crawler_api_alertsUpdateArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_alertsPayload>\n          }\n          deleteMany: {\n            args: Prisma.political_news_crawler_api_alertsDeleteManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateMany: {\n            args: Prisma.political_news_crawler_api_alertsUpdateManyArgs<ExtArgs>\n            result: BatchPayload\n          }\n          updateManyAndReturn: {\n            args: Prisma.political_news_crawler_api_alertsUpdateManyAndReturnArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_alertsPayload>[]\n          }\n          upsert: {\n            args: Prisma.political_news_crawler_api_alertsUpsertArgs<ExtArgs>\n            result: $Utils.PayloadToResult<Prisma.$political_news_crawler_api_alertsPayload>\n          }\n          aggregate: {\n            args: Prisma.Political_news_crawler_api_alertsAggregateArgs<ExtArgs>\n            result: $Utils.Optional<AggregatePolitical_news_crawler_api_alerts>\n          }\n          groupBy: {\n            args: Prisma.political_news_crawler_api_alertsGroupByArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_api_alertsGroupByOutputType>[]\n          }\n          count: {\n            args: Prisma.political_news_crawler_api_alertsCountArgs<ExtArgs>\n            result: $Utils.Optional<Political_news_crawler_api_alertsCountAggregateOutputType> | number\n          }\n        }\n      }\n    }\n  } & {\n    other: {\n      payload: any\n      operations: {\n        $executeRaw: {\n          args: [query: TemplateStringsArray | Prisma.Sql, ...values: any[]],\n          result: any\n        }\n        $executeRawUnsafe: {\n          args: [query: string, ...values: any[]],\n          result: any\n        }\n        $queryRaw: {\n          args: [query: TemplateStringsArray | Prisma.Sql, ...values: any[]],\n          result: any\n        }\n        $queryRawUnsafe: {\n          args: [query: string, ...values: any[]],\n          result: any\n        }\n      }\n    }\n  }\n  export const defineExtension: $Extensions.ExtendsHook<\"define\", Prisma.TypeMapCb, $Extensions.DefaultArgs>\n  export type DefaultPrismaClient = PrismaClient\n  export type ErrorFormat = 'pretty' | 'colorless' | 'minimal'\n  export interface PrismaClientOptions {\n    /**\n     * Overwrites the datasource url from your schema.prisma file\n     */\n    datasources?: Datasources\n    /**\n     * Overwrites the datasource url from your schema.prisma file\n     */\n    datasourceUrl?: string\n    /**\n     * @default \"colorless\"\n     */\n    errorFormat?: ErrorFormat\n    /**\n     * @example\n     * ```\n     * // Shorthand for `emit: 'stdout'`\n     * log: ['query', 'info', 'warn', 'error']\n     * \n     * // Emit as events only\n     * log: [\n     *   { emit: 'event', level: 'query' },\n     *   { emit: 'event', level: 'info' },\n     *   { emit: 'event', level: 'warn' }\n     *   { emit: 'event', level: 'error' }\n     * ]\n     * \n     * / Emit as events and log to stdout\n     * og: [\n     *  { emit: 'stdout', level: 'query' },\n     *  { emit: 'stdout', level: 'info' },\n     *  { emit: 'stdout', level: 'warn' }\n     *  { emit: 'stdout', level: 'error' }\n     * \n     * ```\n     * Read more in our [docs](https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-client/logging#the-log-option).\n     */\n    log?: (LogLevel | LogDefinition)[]\n    /**\n     * The default values for transactionOptions\n     * maxWait ?= 2000\n     * timeout ?= 5000\n     */\n    transactionOptions?: {\n      maxWait?: number\n      timeout?: number\n      isolationLevel?: Prisma.TransactionIsolationLevel\n    }\n    /**\n     * Global configuration for omitting model fields by default.\n     * \n     * @example\n     * ```\n     * const prisma = new PrismaClient({\n     *   omit: {\n     *     user: {\n     *       password: true\n     *     }\n     *   }\n     * })\n     * ```\n     */\n    omit?: Prisma.GlobalOmitConfig\n  }\n  export type GlobalOmitConfig = {\n    political_news_crawler_crawl_sources?: political_news_crawler_crawl_sourcesOmit\n    political_news_crawler_crawl_policies?: political_news_crawler_crawl_policiesOmit\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesOmit\n    political_news_crawler_guests?: political_news_crawler_guestsOmit\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsOmit\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsOmit\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsOmit\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageOmit\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesOmit\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentOmit\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsOmit\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsOmit\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataOmit\n    political_news_crawler_popularity_scores?: political_news_crawler_popularity_scoresOmit\n    political_news_crawler_popular_topics?: political_news_crawler_popular_topicsOmit\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsOmit\n    political_news_crawler_api_access_logs?: political_news_crawler_api_access_logsOmit\n    political_news_crawler_api_error_logs?: political_news_crawler_api_error_logsOmit\n    political_news_crawler_api_usage_metrics?: political_news_crawler_api_usage_metricsOmit\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsOmit\n    political_news_crawler_processing_alerts?: political_news_crawler_processing_alertsOmit\n    political_news_crawler_api_alerts?: political_news_crawler_api_alertsOmit\n  }\n\n  /* Types for Logging */\n  export type LogLevel = 'info' | 'query' | 'warn' | 'error'\n  export type LogDefinition = {\n    level: LogLevel\n    emit: 'stdout' | 'event'\n  }\n\n  export type CheckIsLogLevel<T> = T extends LogLevel ? T : never;\n\n  export type GetLogType<T> = CheckIsLogLevel<\n    T extends LogDefinition ? T['level'] : T\n  >;\n\n  export type GetEvents<T extends any[]> = T extends Array<LogLevel | LogDefinition>\n    ? GetLogType<T[number]>\n    : never;\n\n  export type QueryEvent = {\n    timestamp: Date\n    query: string\n    params: string\n    duration: number\n    target: string\n  }\n\n  export type LogEvent = {\n    timestamp: Date\n    message: string\n    target: string\n  }\n  /* End Types for Logging */\n\n\n  export type PrismaAction =\n    | 'findUnique'\n    | 'findUniqueOrThrow'\n    | 'findMany'\n    | 'findFirst'\n    | 'findFirstOrThrow'\n    | 'create'\n    | 'createMany'\n    | 'createManyAndReturn'\n    | 'update'\n    | 'updateMany'\n    | 'updateManyAndReturn'\n    | 'upsert'\n    | 'delete'\n    | 'deleteMany'\n    | 'executeRaw'\n    | 'queryRaw'\n    | 'aggregate'\n    | 'count'\n    | 'runCommandRaw'\n    | 'findRaw'\n    | 'groupBy'\n\n  // tested in getLogLevel.test.ts\n  export function getLogLevel(log: Array<LogLevel | LogDefinition>): LogLevel | undefined;\n\n  /**\n   * `PrismaClient` proxy available in interactive transactions.\n   */\n  export type TransactionClient = Omit<Prisma.DefaultPrismaClient, runtime.ITXClientDenyList>\n\n  export type Datasource = {\n    url?: string\n  }\n\n  /**\n   * Count Types\n   */\n\n\n  /**\n   * Count Type Political_news_crawler_crawl_sourcesCountOutputType\n   */\n\n  export type Political_news_crawler_crawl_sourcesCountOutputType = {\n    political_news_crawler_crawl_schedules: number\n    political_news_crawler_crawl_jobs: number\n    political_news_crawler_raw_data_storage: number\n    political_news_crawler_llm_jobs: number\n    political_news_crawler_crawl_alerts: number\n  }\n\n  export type Political_news_crawler_crawl_sourcesCountOutputTypeSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    political_news_crawler_crawl_schedules?: boolean | Political_news_crawler_crawl_sourcesCountOutputTypeCountPolitical_news_crawler_crawl_schedulesArgs\n    political_news_crawler_crawl_jobs?: boolean | Political_news_crawler_crawl_sourcesCountOutputTypeCountPolitical_news_crawler_crawl_jobsArgs\n    political_news_crawler_raw_data_storage?: boolean | Political_news_crawler_crawl_sourcesCountOutputTypeCountPolitical_news_crawler_raw_data_storageArgs\n    political_news_crawler_llm_jobs?: boolean | Political_news_crawler_crawl_sourcesCountOutputTypeCountPolitical_news_crawler_llm_jobsArgs\n    political_news_crawler_crawl_alerts?: boolean | Political_news_crawler_crawl_sourcesCountOutputTypeCountPolitical_news_crawler_crawl_alertsArgs\n  }\n\n  // Custom InputTypes\n  /**\n   * Political_news_crawler_crawl_sourcesCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_sourcesCountOutputTypeDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the Political_news_crawler_crawl_sourcesCountOutputType\n     */\n    select?: Political_news_crawler_crawl_sourcesCountOutputTypeSelect<ExtArgs> | null\n  }\n\n  /**\n   * Political_news_crawler_crawl_sourcesCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_sourcesCountOutputTypeCountPolitical_news_crawler_crawl_schedulesArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawl_schedulesWhereInput\n  }\n\n  /**\n   * Political_news_crawler_crawl_sourcesCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_sourcesCountOutputTypeCountPolitical_news_crawler_crawl_jobsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawl_jobsWhereInput\n  }\n\n  /**\n   * Political_news_crawler_crawl_sourcesCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_sourcesCountOutputTypeCountPolitical_news_crawler_raw_data_storageArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_raw_data_storageWhereInput\n  }\n\n  /**\n   * Political_news_crawler_crawl_sourcesCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_sourcesCountOutputTypeCountPolitical_news_crawler_llm_jobsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_llm_jobsWhereInput\n  }\n\n  /**\n   * Political_news_crawler_crawl_sourcesCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_sourcesCountOutputTypeCountPolitical_news_crawler_crawl_alertsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawl_alertsWhereInput\n  }\n\n\n  /**\n   * Count Type Political_news_crawler_crawl_policiesCountOutputType\n   */\n\n  export type Political_news_crawler_crawl_policiesCountOutputType = {\n    political_news_crawler_crawl_schedules: number\n  }\n\n  export type Political_news_crawler_crawl_policiesCountOutputTypeSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    political_news_crawler_crawl_schedules?: boolean | Political_news_crawler_crawl_policiesCountOutputTypeCountPolitical_news_crawler_crawl_schedulesArgs\n  }\n\n  // Custom InputTypes\n  /**\n   * Political_news_crawler_crawl_policiesCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_policiesCountOutputTypeDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the Political_news_crawler_crawl_policiesCountOutputType\n     */\n    select?: Political_news_crawler_crawl_policiesCountOutputTypeSelect<ExtArgs> | null\n  }\n\n  /**\n   * Political_news_crawler_crawl_policiesCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_policiesCountOutputTypeCountPolitical_news_crawler_crawl_schedulesArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawl_schedulesWhereInput\n  }\n\n\n  /**\n   * Count Type Political_news_crawler_crawl_schedulesCountOutputType\n   */\n\n  export type Political_news_crawler_crawl_schedulesCountOutputType = {\n    political_news_crawler_crawl_jobs: number\n  }\n\n  export type Political_news_crawler_crawl_schedulesCountOutputTypeSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    political_news_crawler_crawl_jobs?: boolean | Political_news_crawler_crawl_schedulesCountOutputTypeCountPolitical_news_crawler_crawl_jobsArgs\n  }\n\n  // Custom InputTypes\n  /**\n   * Political_news_crawler_crawl_schedulesCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_schedulesCountOutputTypeDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the Political_news_crawler_crawl_schedulesCountOutputType\n     */\n    select?: Political_news_crawler_crawl_schedulesCountOutputTypeSelect<ExtArgs> | null\n  }\n\n  /**\n   * Political_news_crawler_crawl_schedulesCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_schedulesCountOutputTypeCountPolitical_news_crawler_crawl_jobsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawl_jobsWhereInput\n  }\n\n\n  /**\n   * Count Type Political_news_crawler_crawl_jobsCountOutputType\n   */\n\n  export type Political_news_crawler_crawl_jobsCountOutputType = {\n    political_news_crawler_crawl_attempts: number\n    political_news_crawler_raw_data_storage: number\n  }\n\n  export type Political_news_crawler_crawl_jobsCountOutputTypeSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    political_news_crawler_crawl_attempts?: boolean | Political_news_crawler_crawl_jobsCountOutputTypeCountPolitical_news_crawler_crawl_attemptsArgs\n    political_news_crawler_raw_data_storage?: boolean | Political_news_crawler_crawl_jobsCountOutputTypeCountPolitical_news_crawler_raw_data_storageArgs\n  }\n\n  // Custom InputTypes\n  /**\n   * Political_news_crawler_crawl_jobsCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_jobsCountOutputTypeDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the Political_news_crawler_crawl_jobsCountOutputType\n     */\n    select?: Political_news_crawler_crawl_jobsCountOutputTypeSelect<ExtArgs> | null\n  }\n\n  /**\n   * Political_news_crawler_crawl_jobsCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_jobsCountOutputTypeCountPolitical_news_crawler_crawl_attemptsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawl_attemptsWhereInput\n  }\n\n  /**\n   * Political_news_crawler_crawl_jobsCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_jobsCountOutputTypeCountPolitical_news_crawler_raw_data_storageArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_raw_data_storageWhereInput\n  }\n\n\n  /**\n   * Count Type Political_news_crawler_crawl_attemptsCountOutputType\n   */\n\n  export type Political_news_crawler_crawl_attemptsCountOutputType = {\n    political_news_crawler_crawled_news: number\n  }\n\n  export type Political_news_crawler_crawl_attemptsCountOutputTypeSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    political_news_crawler_crawled_news?: boolean | Political_news_crawler_crawl_attemptsCountOutputTypeCountPolitical_news_crawler_crawled_newsArgs\n  }\n\n  // Custom InputTypes\n  /**\n   * Political_news_crawler_crawl_attemptsCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_attemptsCountOutputTypeDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the Political_news_crawler_crawl_attemptsCountOutputType\n     */\n    select?: Political_news_crawler_crawl_attemptsCountOutputTypeSelect<ExtArgs> | null\n  }\n\n  /**\n   * Political_news_crawler_crawl_attemptsCountOutputType without action\n   */\n  export type Political_news_crawler_crawl_attemptsCountOutputTypeCountPolitical_news_crawler_crawled_newsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawled_newsWhereInput\n  }\n\n\n  /**\n   * Count Type Political_news_crawler_crawled_newsCountOutputType\n   */\n\n  export type Political_news_crawler_crawled_newsCountOutputType = {\n    political_news_crawler_topic_mentions: number\n  }\n\n  export type Political_news_crawler_crawled_newsCountOutputTypeSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    political_news_crawler_topic_mentions?: boolean | Political_news_crawler_crawled_newsCountOutputTypeCountPolitical_news_crawler_topic_mentionsArgs\n  }\n\n  // Custom InputTypes\n  /**\n   * Political_news_crawler_crawled_newsCountOutputType without action\n   */\n  export type Political_news_crawler_crawled_newsCountOutputTypeDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the Political_news_crawler_crawled_newsCountOutputType\n     */\n    select?: Political_news_crawler_crawled_newsCountOutputTypeSelect<ExtArgs> | null\n  }\n\n  /**\n   * Political_news_crawler_crawled_newsCountOutputType without action\n   */\n  export type Political_news_crawler_crawled_newsCountOutputTypeCountPolitical_news_crawler_topic_mentionsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_topic_mentionsWhereInput\n  }\n\n\n  /**\n   * Count Type Political_news_crawler_raw_data_storageCountOutputType\n   */\n\n  export type Political_news_crawler_raw_data_storageCountOutputType = {\n    political_news_crawler_crawl_attempts: number\n    political_news_crawler_local_cache_files: number\n    political_news_crawler_processed_content: number\n  }\n\n  export type Political_news_crawler_raw_data_storageCountOutputTypeSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    political_news_crawler_crawl_attempts?: boolean | Political_news_crawler_raw_data_storageCountOutputTypeCountPolitical_news_crawler_crawl_attemptsArgs\n    political_news_crawler_local_cache_files?: boolean | Political_news_crawler_raw_data_storageCountOutputTypeCountPolitical_news_crawler_local_cache_filesArgs\n    political_news_crawler_processed_content?: boolean | Political_news_crawler_raw_data_storageCountOutputTypeCountPolitical_news_crawler_processed_contentArgs\n  }\n\n  // Custom InputTypes\n  /**\n   * Political_news_crawler_raw_data_storageCountOutputType without action\n   */\n  export type Political_news_crawler_raw_data_storageCountOutputTypeDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the Political_news_crawler_raw_data_storageCountOutputType\n     */\n    select?: Political_news_crawler_raw_data_storageCountOutputTypeSelect<ExtArgs> | null\n  }\n\n  /**\n   * Political_news_crawler_raw_data_storageCountOutputType without action\n   */\n  export type Political_news_crawler_raw_data_storageCountOutputTypeCountPolitical_news_crawler_crawl_attemptsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawl_attemptsWhereInput\n  }\n\n  /**\n   * Political_news_crawler_raw_data_storageCountOutputType without action\n   */\n  export type Political_news_crawler_raw_data_storageCountOutputTypeCountPolitical_news_crawler_local_cache_filesArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_local_cache_filesWhereInput\n  }\n\n  /**\n   * Political_news_crawler_raw_data_storageCountOutputType without action\n   */\n  export type Political_news_crawler_raw_data_storageCountOutputTypeCountPolitical_news_crawler_processed_contentArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_processed_contentWhereInput\n  }\n\n\n  /**\n   * Count Type Political_news_crawler_llm_jobsCountOutputType\n   */\n\n  export type Political_news_crawler_llm_jobsCountOutputType = {\n    political_news_crawler_processed_content: number\n    political_news_crawler_llm_results: number\n    political_news_crawler_processing_metadata: number\n  }\n\n  export type Political_news_crawler_llm_jobsCountOutputTypeSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    political_news_crawler_processed_content?: boolean | Political_news_crawler_llm_jobsCountOutputTypeCountPolitical_news_crawler_processed_contentArgs\n    political_news_crawler_llm_results?: boolean | Political_news_crawler_llm_jobsCountOutputTypeCountPolitical_news_crawler_llm_resultsArgs\n    political_news_crawler_processing_metadata?: boolean | Political_news_crawler_llm_jobsCountOutputTypeCountPolitical_news_crawler_processing_metadataArgs\n  }\n\n  // Custom InputTypes\n  /**\n   * Political_news_crawler_llm_jobsCountOutputType without action\n   */\n  export type Political_news_crawler_llm_jobsCountOutputTypeDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the Political_news_crawler_llm_jobsCountOutputType\n     */\n    select?: Political_news_crawler_llm_jobsCountOutputTypeSelect<ExtArgs> | null\n  }\n\n  /**\n   * Political_news_crawler_llm_jobsCountOutputType without action\n   */\n  export type Political_news_crawler_llm_jobsCountOutputTypeCountPolitical_news_crawler_processed_contentArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_processed_contentWhereInput\n  }\n\n  /**\n   * Political_news_crawler_llm_jobsCountOutputType without action\n   */\n  export type Political_news_crawler_llm_jobsCountOutputTypeCountPolitical_news_crawler_llm_resultsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_llm_resultsWhereInput\n  }\n\n  /**\n   * Political_news_crawler_llm_jobsCountOutputType without action\n   */\n  export type Political_news_crawler_llm_jobsCountOutputTypeCountPolitical_news_crawler_processing_metadataArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_processing_metadataWhereInput\n  }\n\n\n  /**\n   * Count Type Political_news_crawler_popular_topicsCountOutputType\n   */\n\n  export type Political_news_crawler_popular_topicsCountOutputType = {\n    political_news_crawler_popularity_scores: number\n    political_news_crawler_topic_mentions: number\n  }\n\n  export type Political_news_crawler_popular_topicsCountOutputTypeSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    political_news_crawler_popularity_scores?: boolean | Political_news_crawler_popular_topicsCountOutputTypeCountPolitical_news_crawler_popularity_scoresArgs\n    political_news_crawler_topic_mentions?: boolean | Political_news_crawler_popular_topicsCountOutputTypeCountPolitical_news_crawler_topic_mentionsArgs\n  }\n\n  // Custom InputTypes\n  /**\n   * Political_news_crawler_popular_topicsCountOutputType without action\n   */\n  export type Political_news_crawler_popular_topicsCountOutputTypeDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the Political_news_crawler_popular_topicsCountOutputType\n     */\n    select?: Political_news_crawler_popular_topicsCountOutputTypeSelect<ExtArgs> | null\n  }\n\n  /**\n   * Political_news_crawler_popular_topicsCountOutputType without action\n   */\n  export type Political_news_crawler_popular_topicsCountOutputTypeCountPolitical_news_crawler_popularity_scoresArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_popularity_scoresWhereInput\n  }\n\n  /**\n   * Political_news_crawler_popular_topicsCountOutputType without action\n   */\n  export type Political_news_crawler_popular_topicsCountOutputTypeCountPolitical_news_crawler_topic_mentionsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_topic_mentionsWhereInput\n  }\n\n\n  /**\n   * Models\n   */\n\n  /**\n   * Model political_news_crawler_crawl_sources\n   */\n\n  export type AggregatePolitical_news_crawler_crawl_sources = {\n    _count: Political_news_crawler_crawl_sourcesCountAggregateOutputType | null\n    _min: Political_news_crawler_crawl_sourcesMinAggregateOutputType | null\n    _max: Political_news_crawler_crawl_sourcesMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_crawl_sourcesMinAggregateOutputType = {\n    id: string | null\n    source_code: string | null\n    source_url: string | null\n    is_active: boolean | null\n    description: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_crawl_sourcesMaxAggregateOutputType = {\n    id: string | null\n    source_code: string | null\n    source_url: string | null\n    is_active: boolean | null\n    description: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_crawl_sourcesCountAggregateOutputType = {\n    id: number\n    source_code: number\n    source_url: number\n    is_active: number\n    description: number\n    created_at: number\n    updated_at: number\n    deleted_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_crawl_sourcesMinAggregateInputType = {\n    id?: true\n    source_code?: true\n    source_url?: true\n    is_active?: true\n    description?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_crawl_sourcesMaxAggregateInputType = {\n    id?: true\n    source_code?: true\n    source_url?: true\n    is_active?: true\n    description?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_crawl_sourcesCountAggregateInputType = {\n    id?: true\n    source_code?: true\n    source_url?: true\n    is_active?: true\n    description?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_crawl_sourcesAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawl_sources to aggregate.\n     */\n    where?: political_news_crawler_crawl_sourcesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_sources to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_sourcesOrderByWithRelationInput | political_news_crawler_crawl_sourcesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_crawl_sourcesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_sources from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_sources.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_crawl_sources\n    **/\n    _count?: true | Political_news_crawler_crawl_sourcesCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_crawl_sourcesMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_crawl_sourcesMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_crawl_sourcesAggregateType<T extends Political_news_crawler_crawl_sourcesAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_crawl_sources]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_crawl_sources[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_crawl_sources[P]>\n  }\n\n\n\n\n  export type political_news_crawler_crawl_sourcesGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawl_sourcesWhereInput\n    orderBy?: political_news_crawler_crawl_sourcesOrderByWithAggregationInput | political_news_crawler_crawl_sourcesOrderByWithAggregationInput[]\n    by: Political_news_crawler_crawl_sourcesScalarFieldEnum[] | Political_news_crawler_crawl_sourcesScalarFieldEnum\n    having?: political_news_crawler_crawl_sourcesScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_crawl_sourcesCountAggregateInputType | true\n    _min?: Political_news_crawler_crawl_sourcesMinAggregateInputType\n    _max?: Political_news_crawler_crawl_sourcesMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_crawl_sourcesGroupByOutputType = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description: string | null\n    created_at: Date\n    updated_at: Date\n    deleted_at: Date | null\n    _count: Political_news_crawler_crawl_sourcesCountAggregateOutputType | null\n    _min: Political_news_crawler_crawl_sourcesMinAggregateOutputType | null\n    _max: Political_news_crawler_crawl_sourcesMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_crawl_sourcesGroupByPayload<T extends political_news_crawler_crawl_sourcesGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_crawl_sourcesGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_crawl_sourcesGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_crawl_sourcesGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_crawl_sourcesGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_crawl_sourcesSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    source_code?: boolean\n    source_url?: boolean\n    is_active?: boolean\n    description?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    political_news_crawler_crawl_schedules?: boolean | political_news_crawler_crawl_sources$political_news_crawler_crawl_schedulesArgs<ExtArgs>\n    political_news_crawler_crawl_jobs?: boolean | political_news_crawler_crawl_sources$political_news_crawler_crawl_jobsArgs<ExtArgs>\n    political_news_crawler_raw_data_storage?: boolean | political_news_crawler_crawl_sources$political_news_crawler_raw_data_storageArgs<ExtArgs>\n    political_news_crawler_llm_jobs?: boolean | political_news_crawler_crawl_sources$political_news_crawler_llm_jobsArgs<ExtArgs>\n    political_news_crawler_crawl_alerts?: boolean | political_news_crawler_crawl_sources$political_news_crawler_crawl_alertsArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_crawl_sourcesCountOutputTypeDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_sources\"]>\n\n  export type political_news_crawler_crawl_sourcesSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    source_code?: boolean\n    source_url?: boolean\n    is_active?: boolean\n    description?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_sources\"]>\n\n  export type political_news_crawler_crawl_sourcesSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    source_code?: boolean\n    source_url?: boolean\n    is_active?: boolean\n    description?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_sources\"]>\n\n  export type political_news_crawler_crawl_sourcesSelectScalar = {\n    id?: boolean\n    source_code?: boolean\n    source_url?: boolean\n    is_active?: boolean\n    description?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }\n\n  export type political_news_crawler_crawl_sourcesOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"source_code\" | \"source_url\" | \"is_active\" | \"description\" | \"created_at\" | \"updated_at\" | \"deleted_at\", ExtArgs[\"result\"][\"political_news_crawler_crawl_sources\"]>\n  export type political_news_crawler_crawl_sourcesInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    political_news_crawler_crawl_schedules?: boolean | political_news_crawler_crawl_sources$political_news_crawler_crawl_schedulesArgs<ExtArgs>\n    political_news_crawler_crawl_jobs?: boolean | political_news_crawler_crawl_sources$political_news_crawler_crawl_jobsArgs<ExtArgs>\n    political_news_crawler_raw_data_storage?: boolean | political_news_crawler_crawl_sources$political_news_crawler_raw_data_storageArgs<ExtArgs>\n    political_news_crawler_llm_jobs?: boolean | political_news_crawler_crawl_sources$political_news_crawler_llm_jobsArgs<ExtArgs>\n    political_news_crawler_crawl_alerts?: boolean | political_news_crawler_crawl_sources$political_news_crawler_crawl_alertsArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_crawl_sourcesCountOutputTypeDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_crawl_sourcesIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {}\n  export type political_news_crawler_crawl_sourcesIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {}\n\n  export type $political_news_crawler_crawl_sourcesPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_crawl_sources\"\n    objects: {\n      political_news_crawler_crawl_schedules: Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>[]\n      political_news_crawler_crawl_jobs: Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>[]\n      political_news_crawler_raw_data_storage: Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>[]\n      political_news_crawler_llm_jobs: Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>[]\n      political_news_crawler_crawl_alerts: Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>[]\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Unique identifier code for the crawl source.\n       */\n      source_code: string\n      /**\n       * The base URL of the crawl source website or API.\n       */\n      source_url: string\n      /**\n       * Flag indicating whether the crawl source is active and enabled for\n       * crawling.\n       */\n      is_active: boolean\n      /**\n       * Optional description of the crawl source.\n       */\n      description: string | null\n      /**\n       * Record creation timestamp.\n       */\n      created_at: Date\n      /**\n       * Record last update timestamp.\n       */\n      updated_at: Date\n      /**\n       * Soft delete timestamp, if record is deleted.\n       */\n      deleted_at: Date | null\n    }, ExtArgs[\"result\"][\"political_news_crawler_crawl_sources\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_crawl_sourcesGetPayload<S extends boolean | null | undefined | political_news_crawler_crawl_sourcesDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload, S>\n\n  type political_news_crawler_crawl_sourcesCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_crawl_sourcesFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_crawl_sourcesCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_crawl_sourcesDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_crawl_sources'], meta: { name: 'political_news_crawler_crawl_sources' } }\n    /**\n     * Find zero or one Political_news_crawler_crawl_sources that matches the filter.\n     * @param {political_news_crawler_crawl_sourcesFindUniqueArgs} args - Arguments to find a Political_news_crawler_crawl_sources\n     * @example\n     * // Get one Political_news_crawler_crawl_sources\n     * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_crawl_sourcesFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_crawl_sourcesFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_sourcesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_crawl_sources that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_crawl_sourcesFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_crawl_sources\n     * @example\n     * // Get one Political_news_crawler_crawl_sources\n     * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_crawl_sourcesFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_crawl_sourcesFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_sourcesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawl_sources that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_sourcesFindFirstArgs} args - Arguments to find a Political_news_crawler_crawl_sources\n     * @example\n     * // Get one Political_news_crawler_crawl_sources\n     * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_crawl_sourcesFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_crawl_sourcesFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_sourcesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawl_sources that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_sourcesFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_crawl_sources\n     * @example\n     * // Get one Political_news_crawler_crawl_sources\n     * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_crawl_sourcesFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_crawl_sourcesFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_sourcesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_crawl_sources that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_sourcesFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_crawl_sources\n     * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.findMany()\n     * \n     * // Get first 10 Political_news_crawler_crawl_sources\n     * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_crawl_sourcesWithIdOnly = await prisma.political_news_crawler_crawl_sources.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_crawl_sourcesFindManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_sourcesFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_crawl_sources.\n     * @param {political_news_crawler_crawl_sourcesCreateArgs} args - Arguments to create a Political_news_crawler_crawl_sources.\n     * @example\n     * // Create one Political_news_crawler_crawl_sources\n     * const Political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_crawl_sources\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_crawl_sourcesCreateArgs>(args: SelectSubset<T, political_news_crawler_crawl_sourcesCreateArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_sourcesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_crawl_sources.\n     * @param {political_news_crawler_crawl_sourcesCreateManyArgs} args - Arguments to create many Political_news_crawler_crawl_sources.\n     * @example\n     * // Create many Political_news_crawler_crawl_sources\n     * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_crawl_sourcesCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_sourcesCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_crawl_sources and returns the data saved in the database.\n     * @param {political_news_crawler_crawl_sourcesCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_crawl_sources.\n     * @example\n     * // Create many Political_news_crawler_crawl_sources\n     * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_crawl_sources and only return the `id`\n     * const political_news_crawler_crawl_sourcesWithIdOnly = await prisma.political_news_crawler_crawl_sources.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_crawl_sourcesCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_crawl_sourcesCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_crawl_sources.\n     * @param {political_news_crawler_crawl_sourcesDeleteArgs} args - Arguments to delete one Political_news_crawler_crawl_sources.\n     * @example\n     * // Delete one Political_news_crawler_crawl_sources\n     * const Political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_crawl_sources\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_crawl_sourcesDeleteArgs>(args: SelectSubset<T, political_news_crawler_crawl_sourcesDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_sourcesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_crawl_sources.\n     * @param {political_news_crawler_crawl_sourcesUpdateArgs} args - Arguments to update one Political_news_crawler_crawl_sources.\n     * @example\n     * // Update one Political_news_crawler_crawl_sources\n     * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_crawl_sourcesUpdateArgs>(args: SelectSubset<T, political_news_crawler_crawl_sourcesUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_sourcesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_crawl_sources.\n     * @param {political_news_crawler_crawl_sourcesDeleteManyArgs} args - Arguments to filter Political_news_crawler_crawl_sources to delete.\n     * @example\n     * // Delete a few Political_news_crawler_crawl_sources\n     * const { count } = await prisma.political_news_crawler_crawl_sources.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_crawl_sourcesDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_sourcesDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawl_sources.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_sourcesUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_crawl_sources\n     * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_crawl_sourcesUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_crawl_sourcesUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawl_sources and returns the data updated in the database.\n     * @param {political_news_crawler_crawl_sourcesUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_crawl_sources.\n     * @example\n     * // Update many Political_news_crawler_crawl_sources\n     * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_crawl_sources and only return the `id`\n     * const political_news_crawler_crawl_sourcesWithIdOnly = await prisma.political_news_crawler_crawl_sources.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_crawl_sourcesUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_crawl_sourcesUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_crawl_sources.\n     * @param {political_news_crawler_crawl_sourcesUpsertArgs} args - Arguments to update or create a Political_news_crawler_crawl_sources.\n     * @example\n     * // Update or create a Political_news_crawler_crawl_sources\n     * const political_news_crawler_crawl_sources = await prisma.political_news_crawler_crawl_sources.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_crawl_sources\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawl_sources we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_crawl_sourcesUpsertArgs>(args: SelectSubset<T, political_news_crawler_crawl_sourcesUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_sourcesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_crawl_sources.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_sourcesCountArgs} args - Arguments to filter Political_news_crawler_crawl_sources to count.\n     * @example\n     * // Count the number of Political_news_crawler_crawl_sources\n     * const count = await prisma.political_news_crawler_crawl_sources.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawl_sources we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_crawl_sourcesCountArgs>(\n      args?: Subset<T, political_news_crawler_crawl_sourcesCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_crawl_sourcesCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_crawl_sources.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_crawl_sourcesAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_crawl_sourcesAggregateArgs>(args: Subset<T, Political_news_crawler_crawl_sourcesAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_crawl_sourcesAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_crawl_sources.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_sourcesGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_crawl_sourcesGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_crawl_sourcesGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_crawl_sourcesGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_crawl_sourcesGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_crawl_sourcesGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_crawl_sources model\n   */\n  readonly fields: political_news_crawler_crawl_sourcesFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_crawl_sources.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_crawl_sourcesClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    political_news_crawler_crawl_schedules<T extends political_news_crawler_crawl_sources$political_news_crawler_crawl_schedulesArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_sources$political_news_crawler_crawl_schedulesArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    political_news_crawler_crawl_jobs<T extends political_news_crawler_crawl_sources$political_news_crawler_crawl_jobsArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_sources$political_news_crawler_crawl_jobsArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    political_news_crawler_raw_data_storage<T extends political_news_crawler_crawl_sources$political_news_crawler_raw_data_storageArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_sources$political_news_crawler_raw_data_storageArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    political_news_crawler_llm_jobs<T extends political_news_crawler_crawl_sources$political_news_crawler_llm_jobsArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_sources$political_news_crawler_llm_jobsArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    political_news_crawler_crawl_alerts<T extends political_news_crawler_crawl_sources$political_news_crawler_crawl_alertsArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_sources$political_news_crawler_crawl_alertsArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_crawl_sources model\n   */\n  interface political_news_crawler_crawl_sourcesFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_crawl_sources\", 'String'>\n    readonly source_code: FieldRef<\"political_news_crawler_crawl_sources\", 'String'>\n    readonly source_url: FieldRef<\"political_news_crawler_crawl_sources\", 'String'>\n    readonly is_active: FieldRef<\"political_news_crawler_crawl_sources\", 'Boolean'>\n    readonly description: FieldRef<\"political_news_crawler_crawl_sources\", 'String'>\n    readonly created_at: FieldRef<\"political_news_crawler_crawl_sources\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_crawl_sources\", 'DateTime'>\n    readonly deleted_at: FieldRef<\"political_news_crawler_crawl_sources\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_crawl_sources findUnique\n   */\n  export type political_news_crawler_crawl_sourcesFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_sources\n     */\n    select?: political_news_crawler_crawl_sourcesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_sources\n     */\n    omit?: political_news_crawler_crawl_sourcesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_sourcesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_sources to fetch.\n     */\n    where: political_news_crawler_crawl_sourcesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_sources findUniqueOrThrow\n   */\n  export type political_news_crawler_crawl_sourcesFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_sources\n     */\n    select?: political_news_crawler_crawl_sourcesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_sources\n     */\n    omit?: political_news_crawler_crawl_sourcesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_sourcesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_sources to fetch.\n     */\n    where: political_news_crawler_crawl_sourcesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_sources findFirst\n   */\n  export type political_news_crawler_crawl_sourcesFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_sources\n     */\n    select?: political_news_crawler_crawl_sourcesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_sources\n     */\n    omit?: political_news_crawler_crawl_sourcesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_sourcesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_sources to fetch.\n     */\n    where?: political_news_crawler_crawl_sourcesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_sources to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_sourcesOrderByWithRelationInput | political_news_crawler_crawl_sourcesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawl_sources.\n     */\n    cursor?: political_news_crawler_crawl_sourcesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_sources from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_sources.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawl_sources.\n     */\n    distinct?: Political_news_crawler_crawl_sourcesScalarFieldEnum | Political_news_crawler_crawl_sourcesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_sources findFirstOrThrow\n   */\n  export type political_news_crawler_crawl_sourcesFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_sources\n     */\n    select?: political_news_crawler_crawl_sourcesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_sources\n     */\n    omit?: political_news_crawler_crawl_sourcesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_sourcesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_sources to fetch.\n     */\n    where?: political_news_crawler_crawl_sourcesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_sources to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_sourcesOrderByWithRelationInput | political_news_crawler_crawl_sourcesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawl_sources.\n     */\n    cursor?: political_news_crawler_crawl_sourcesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_sources from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_sources.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawl_sources.\n     */\n    distinct?: Political_news_crawler_crawl_sourcesScalarFieldEnum | Political_news_crawler_crawl_sourcesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_sources findMany\n   */\n  export type political_news_crawler_crawl_sourcesFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_sources\n     */\n    select?: political_news_crawler_crawl_sourcesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_sources\n     */\n    omit?: political_news_crawler_crawl_sourcesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_sourcesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_sources to fetch.\n     */\n    where?: political_news_crawler_crawl_sourcesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_sources to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_sourcesOrderByWithRelationInput | political_news_crawler_crawl_sourcesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_crawl_sources.\n     */\n    cursor?: political_news_crawler_crawl_sourcesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_sources from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_sources.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_crawl_sourcesScalarFieldEnum | Political_news_crawler_crawl_sourcesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_sources create\n   */\n  export type political_news_crawler_crawl_sourcesCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_sources\n     */\n    select?: political_news_crawler_crawl_sourcesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_sources\n     */\n    omit?: political_news_crawler_crawl_sourcesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_sourcesInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_crawl_sources.\n     */\n    data: XOR<political_news_crawler_crawl_sourcesCreateInput, political_news_crawler_crawl_sourcesUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_crawl_sources createMany\n   */\n  export type political_news_crawler_crawl_sourcesCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_crawl_sources.\n     */\n    data: political_news_crawler_crawl_sourcesCreateManyInput | political_news_crawler_crawl_sourcesCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_crawl_sources createManyAndReturn\n   */\n  export type political_news_crawler_crawl_sourcesCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_sources\n     */\n    select?: political_news_crawler_crawl_sourcesSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_sources\n     */\n    omit?: political_news_crawler_crawl_sourcesOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_crawl_sources.\n     */\n    data: political_news_crawler_crawl_sourcesCreateManyInput | political_news_crawler_crawl_sourcesCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_crawl_sources update\n   */\n  export type political_news_crawler_crawl_sourcesUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_sources\n     */\n    select?: political_news_crawler_crawl_sourcesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_sources\n     */\n    omit?: political_news_crawler_crawl_sourcesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_sourcesInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_crawl_sources.\n     */\n    data: XOR<political_news_crawler_crawl_sourcesUpdateInput, political_news_crawler_crawl_sourcesUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_crawl_sources to update.\n     */\n    where: political_news_crawler_crawl_sourcesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_sources updateMany\n   */\n  export type political_news_crawler_crawl_sourcesUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_crawl_sources.\n     */\n    data: XOR<political_news_crawler_crawl_sourcesUpdateManyMutationInput, political_news_crawler_crawl_sourcesUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawl_sources to update\n     */\n    where?: political_news_crawler_crawl_sourcesWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_sources to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_sources updateManyAndReturn\n   */\n  export type political_news_crawler_crawl_sourcesUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_sources\n     */\n    select?: political_news_crawler_crawl_sourcesSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_sources\n     */\n    omit?: political_news_crawler_crawl_sourcesOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_crawl_sources.\n     */\n    data: XOR<political_news_crawler_crawl_sourcesUpdateManyMutationInput, political_news_crawler_crawl_sourcesUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawl_sources to update\n     */\n    where?: political_news_crawler_crawl_sourcesWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_sources to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_sources upsert\n   */\n  export type political_news_crawler_crawl_sourcesUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_sources\n     */\n    select?: political_news_crawler_crawl_sourcesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_sources\n     */\n    omit?: political_news_crawler_crawl_sourcesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_sourcesInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_crawl_sources to update in case it exists.\n     */\n    where: political_news_crawler_crawl_sourcesWhereUniqueInput\n    /**\n     * In case the political_news_crawler_crawl_sources found by the `where` argument doesn't exist, create a new political_news_crawler_crawl_sources with this data.\n     */\n    create: XOR<political_news_crawler_crawl_sourcesCreateInput, political_news_crawler_crawl_sourcesUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_crawl_sources was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_crawl_sourcesUpdateInput, political_news_crawler_crawl_sourcesUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_crawl_sources delete\n   */\n  export type political_news_crawler_crawl_sourcesDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_sources\n     */\n    select?: political_news_crawler_crawl_sourcesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_sources\n     */\n    omit?: political_news_crawler_crawl_sourcesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_sourcesInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_crawl_sources to delete.\n     */\n    where: political_news_crawler_crawl_sourcesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_sources deleteMany\n   */\n  export type political_news_crawler_crawl_sourcesDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawl_sources to delete\n     */\n    where?: political_news_crawler_crawl_sourcesWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_sources to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_sources.political_news_crawler_crawl_schedules\n   */\n  export type political_news_crawler_crawl_sources$political_news_crawler_crawl_schedulesArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesInclude<ExtArgs> | null\n    where?: political_news_crawler_crawl_schedulesWhereInput\n    orderBy?: political_news_crawler_crawl_schedulesOrderByWithRelationInput | political_news_crawler_crawl_schedulesOrderByWithRelationInput[]\n    cursor?: political_news_crawler_crawl_schedulesWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_crawl_schedulesScalarFieldEnum | Political_news_crawler_crawl_schedulesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_sources.political_news_crawler_crawl_jobs\n   */\n  export type political_news_crawler_crawl_sources$political_news_crawler_crawl_jobsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsInclude<ExtArgs> | null\n    where?: political_news_crawler_crawl_jobsWhereInput\n    orderBy?: political_news_crawler_crawl_jobsOrderByWithRelationInput | political_news_crawler_crawl_jobsOrderByWithRelationInput[]\n    cursor?: political_news_crawler_crawl_jobsWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_crawl_jobsScalarFieldEnum | Political_news_crawler_crawl_jobsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_sources.political_news_crawler_raw_data_storage\n   */\n  export type political_news_crawler_crawl_sources$political_news_crawler_raw_data_storageArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageInclude<ExtArgs> | null\n    where?: political_news_crawler_raw_data_storageWhereInput\n    orderBy?: political_news_crawler_raw_data_storageOrderByWithRelationInput | political_news_crawler_raw_data_storageOrderByWithRelationInput[]\n    cursor?: political_news_crawler_raw_data_storageWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_raw_data_storageScalarFieldEnum | Political_news_crawler_raw_data_storageScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_sources.political_news_crawler_llm_jobs\n   */\n  export type political_news_crawler_crawl_sources$political_news_crawler_llm_jobsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsInclude<ExtArgs> | null\n    where?: political_news_crawler_llm_jobsWhereInput\n    orderBy?: political_news_crawler_llm_jobsOrderByWithRelationInput | political_news_crawler_llm_jobsOrderByWithRelationInput[]\n    cursor?: political_news_crawler_llm_jobsWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_llm_jobsScalarFieldEnum | Political_news_crawler_llm_jobsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_sources.political_news_crawler_crawl_alerts\n   */\n  export type political_news_crawler_crawl_sources$political_news_crawler_crawl_alertsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_alerts\n     */\n    select?: political_news_crawler_crawl_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_alerts\n     */\n    omit?: political_news_crawler_crawl_alertsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_alertsInclude<ExtArgs> | null\n    where?: political_news_crawler_crawl_alertsWhereInput\n    orderBy?: political_news_crawler_crawl_alertsOrderByWithRelationInput | political_news_crawler_crawl_alertsOrderByWithRelationInput[]\n    cursor?: political_news_crawler_crawl_alertsWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_crawl_alertsScalarFieldEnum | Political_news_crawler_crawl_alertsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_sources without action\n   */\n  export type political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_sources\n     */\n    select?: political_news_crawler_crawl_sourcesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_sources\n     */\n    omit?: political_news_crawler_crawl_sourcesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_sourcesInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_crawl_policies\n   */\n\n  export type AggregatePolitical_news_crawler_crawl_policies = {\n    _count: Political_news_crawler_crawl_policiesCountAggregateOutputType | null\n    _avg: Political_news_crawler_crawl_policiesAvgAggregateOutputType | null\n    _sum: Political_news_crawler_crawl_policiesSumAggregateOutputType | null\n    _min: Political_news_crawler_crawl_policiesMinAggregateOutputType | null\n    _max: Political_news_crawler_crawl_policiesMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_crawl_policiesAvgAggregateOutputType = {\n    max_crawl_frequency_minutes: number | null\n    max_retry_attempts: number | null\n    backoff_multiplier: number | null\n  }\n\n  export type Political_news_crawler_crawl_policiesSumAggregateOutputType = {\n    max_crawl_frequency_minutes: number | null\n    max_retry_attempts: number | null\n    backoff_multiplier: number | null\n  }\n\n  export type Political_news_crawler_crawl_policiesMinAggregateOutputType = {\n    id: string | null\n    policy_name: string | null\n    max_crawl_frequency_minutes: number | null\n    max_retry_attempts: number | null\n    backoff_multiplier: number | null\n    ban_detection_enabled: boolean | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_crawl_policiesMaxAggregateOutputType = {\n    id: string | null\n    policy_name: string | null\n    max_crawl_frequency_minutes: number | null\n    max_retry_attempts: number | null\n    backoff_multiplier: number | null\n    ban_detection_enabled: boolean | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_crawl_policiesCountAggregateOutputType = {\n    id: number\n    policy_name: number\n    max_crawl_frequency_minutes: number\n    max_retry_attempts: number\n    backoff_multiplier: number\n    ban_detection_enabled: number\n    created_at: number\n    updated_at: number\n    deleted_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_crawl_policiesAvgAggregateInputType = {\n    max_crawl_frequency_minutes?: true\n    max_retry_attempts?: true\n    backoff_multiplier?: true\n  }\n\n  export type Political_news_crawler_crawl_policiesSumAggregateInputType = {\n    max_crawl_frequency_minutes?: true\n    max_retry_attempts?: true\n    backoff_multiplier?: true\n  }\n\n  export type Political_news_crawler_crawl_policiesMinAggregateInputType = {\n    id?: true\n    policy_name?: true\n    max_crawl_frequency_minutes?: true\n    max_retry_attempts?: true\n    backoff_multiplier?: true\n    ban_detection_enabled?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_crawl_policiesMaxAggregateInputType = {\n    id?: true\n    policy_name?: true\n    max_crawl_frequency_minutes?: true\n    max_retry_attempts?: true\n    backoff_multiplier?: true\n    ban_detection_enabled?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_crawl_policiesCountAggregateInputType = {\n    id?: true\n    policy_name?: true\n    max_crawl_frequency_minutes?: true\n    max_retry_attempts?: true\n    backoff_multiplier?: true\n    ban_detection_enabled?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_crawl_policiesAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawl_policies to aggregate.\n     */\n    where?: political_news_crawler_crawl_policiesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_policies to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_policiesOrderByWithRelationInput | political_news_crawler_crawl_policiesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_crawl_policiesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_policies from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_policies.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_crawl_policies\n    **/\n    _count?: true | Political_news_crawler_crawl_policiesCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to average\n    **/\n    _avg?: Political_news_crawler_crawl_policiesAvgAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to sum\n    **/\n    _sum?: Political_news_crawler_crawl_policiesSumAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_crawl_policiesMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_crawl_policiesMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_crawl_policiesAggregateType<T extends Political_news_crawler_crawl_policiesAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_crawl_policies]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_crawl_policies[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_crawl_policies[P]>\n  }\n\n\n\n\n  export type political_news_crawler_crawl_policiesGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawl_policiesWhereInput\n    orderBy?: political_news_crawler_crawl_policiesOrderByWithAggregationInput | political_news_crawler_crawl_policiesOrderByWithAggregationInput[]\n    by: Political_news_crawler_crawl_policiesScalarFieldEnum[] | Political_news_crawler_crawl_policiesScalarFieldEnum\n    having?: political_news_crawler_crawl_policiesScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_crawl_policiesCountAggregateInputType | true\n    _avg?: Political_news_crawler_crawl_policiesAvgAggregateInputType\n    _sum?: Political_news_crawler_crawl_policiesSumAggregateInputType\n    _min?: Political_news_crawler_crawl_policiesMinAggregateInputType\n    _max?: Political_news_crawler_crawl_policiesMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_crawl_policiesGroupByOutputType = {\n    id: string\n    policy_name: string\n    max_crawl_frequency_minutes: number\n    max_retry_attempts: number\n    backoff_multiplier: number\n    ban_detection_enabled: boolean\n    created_at: Date\n    updated_at: Date\n    deleted_at: Date | null\n    _count: Political_news_crawler_crawl_policiesCountAggregateOutputType | null\n    _avg: Political_news_crawler_crawl_policiesAvgAggregateOutputType | null\n    _sum: Political_news_crawler_crawl_policiesSumAggregateOutputType | null\n    _min: Political_news_crawler_crawl_policiesMinAggregateOutputType | null\n    _max: Political_news_crawler_crawl_policiesMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_crawl_policiesGroupByPayload<T extends political_news_crawler_crawl_policiesGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_crawl_policiesGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_crawl_policiesGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_crawl_policiesGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_crawl_policiesGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_crawl_policiesSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    policy_name?: boolean\n    max_crawl_frequency_minutes?: boolean\n    max_retry_attempts?: boolean\n    backoff_multiplier?: boolean\n    ban_detection_enabled?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    political_news_crawler_crawl_schedules?: boolean | political_news_crawler_crawl_policies$political_news_crawler_crawl_schedulesArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_crawl_policiesCountOutputTypeDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_policies\"]>\n\n  export type political_news_crawler_crawl_policiesSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    policy_name?: boolean\n    max_crawl_frequency_minutes?: boolean\n    max_retry_attempts?: boolean\n    backoff_multiplier?: boolean\n    ban_detection_enabled?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_policies\"]>\n\n  export type political_news_crawler_crawl_policiesSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    policy_name?: boolean\n    max_crawl_frequency_minutes?: boolean\n    max_retry_attempts?: boolean\n    backoff_multiplier?: boolean\n    ban_detection_enabled?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_policies\"]>\n\n  export type political_news_crawler_crawl_policiesSelectScalar = {\n    id?: boolean\n    policy_name?: boolean\n    max_crawl_frequency_minutes?: boolean\n    max_retry_attempts?: boolean\n    backoff_multiplier?: boolean\n    ban_detection_enabled?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }\n\n  export type political_news_crawler_crawl_policiesOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"policy_name\" | \"max_crawl_frequency_minutes\" | \"max_retry_attempts\" | \"backoff_multiplier\" | \"ban_detection_enabled\" | \"created_at\" | \"updated_at\" | \"deleted_at\", ExtArgs[\"result\"][\"political_news_crawler_crawl_policies\"]>\n  export type political_news_crawler_crawl_policiesInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    political_news_crawler_crawl_schedules?: boolean | political_news_crawler_crawl_policies$political_news_crawler_crawl_schedulesArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_crawl_policiesCountOutputTypeDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_crawl_policiesIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {}\n  export type political_news_crawler_crawl_policiesIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {}\n\n  export type $political_news_crawler_crawl_policiesPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_crawl_policies\"\n    objects: {\n      political_news_crawler_crawl_schedules: Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>[]\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Unique name identifier for the crawl policy.\n       */\n      policy_name: string\n      /**\n       * Maximum allowed crawl frequency in minutes.\n       */\n      max_crawl_frequency_minutes: number\n      /**\n       * Maximum number of retry attempts after failures.\n       */\n      max_retry_attempts: number\n      /**\n       * Multiplier factor for exponential backoff on retries.\n       */\n      backoff_multiplier: number\n      /**\n       * Flag to enable detection and handling of bans during crawling.\n       */\n      ban_detection_enabled: boolean\n      /**\n       * Record creation timestamp.\n       */\n      created_at: Date\n      /**\n       * Record last update timestamp.\n       */\n      updated_at: Date\n      /**\n       * Soft delete timestamp, if record is deleted.\n       */\n      deleted_at: Date | null\n    }, ExtArgs[\"result\"][\"political_news_crawler_crawl_policies\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_crawl_policiesGetPayload<S extends boolean | null | undefined | political_news_crawler_crawl_policiesDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_crawl_policiesPayload, S>\n\n  type political_news_crawler_crawl_policiesCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_crawl_policiesFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_crawl_policiesCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_crawl_policiesDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_crawl_policies'], meta: { name: 'political_news_crawler_crawl_policies' } }\n    /**\n     * Find zero or one Political_news_crawler_crawl_policies that matches the filter.\n     * @param {political_news_crawler_crawl_policiesFindUniqueArgs} args - Arguments to find a Political_news_crawler_crawl_policies\n     * @example\n     * // Get one Political_news_crawler_crawl_policies\n     * const political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_crawl_policiesFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_crawl_policiesFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_policiesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_crawl_policies that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_crawl_policiesFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_crawl_policies\n     * @example\n     * // Get one Political_news_crawler_crawl_policies\n     * const political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_crawl_policiesFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_crawl_policiesFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_policiesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawl_policies that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_policiesFindFirstArgs} args - Arguments to find a Political_news_crawler_crawl_policies\n     * @example\n     * // Get one Political_news_crawler_crawl_policies\n     * const political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_crawl_policiesFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_crawl_policiesFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_policiesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawl_policies that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_policiesFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_crawl_policies\n     * @example\n     * // Get one Political_news_crawler_crawl_policies\n     * const political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_crawl_policiesFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_crawl_policiesFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_policiesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_crawl_policies that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_policiesFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_crawl_policies\n     * const political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.findMany()\n     * \n     * // Get first 10 Political_news_crawler_crawl_policies\n     * const political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_crawl_policiesWithIdOnly = await prisma.political_news_crawler_crawl_policies.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_crawl_policiesFindManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_policiesFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_crawl_policies.\n     * @param {political_news_crawler_crawl_policiesCreateArgs} args - Arguments to create a Political_news_crawler_crawl_policies.\n     * @example\n     * // Create one Political_news_crawler_crawl_policies\n     * const Political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_crawl_policies\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_crawl_policiesCreateArgs>(args: SelectSubset<T, political_news_crawler_crawl_policiesCreateArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_policiesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_crawl_policies.\n     * @param {political_news_crawler_crawl_policiesCreateManyArgs} args - Arguments to create many Political_news_crawler_crawl_policies.\n     * @example\n     * // Create many Political_news_crawler_crawl_policies\n     * const political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_crawl_policiesCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_policiesCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_crawl_policies and returns the data saved in the database.\n     * @param {political_news_crawler_crawl_policiesCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_crawl_policies.\n     * @example\n     * // Create many Political_news_crawler_crawl_policies\n     * const political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_crawl_policies and only return the `id`\n     * const political_news_crawler_crawl_policiesWithIdOnly = await prisma.political_news_crawler_crawl_policies.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_crawl_policiesCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_crawl_policiesCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_crawl_policies.\n     * @param {political_news_crawler_crawl_policiesDeleteArgs} args - Arguments to delete one Political_news_crawler_crawl_policies.\n     * @example\n     * // Delete one Political_news_crawler_crawl_policies\n     * const Political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_crawl_policies\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_crawl_policiesDeleteArgs>(args: SelectSubset<T, political_news_crawler_crawl_policiesDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_policiesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_crawl_policies.\n     * @param {political_news_crawler_crawl_policiesUpdateArgs} args - Arguments to update one Political_news_crawler_crawl_policies.\n     * @example\n     * // Update one Political_news_crawler_crawl_policies\n     * const political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_crawl_policiesUpdateArgs>(args: SelectSubset<T, political_news_crawler_crawl_policiesUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_policiesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_crawl_policies.\n     * @param {political_news_crawler_crawl_policiesDeleteManyArgs} args - Arguments to filter Political_news_crawler_crawl_policies to delete.\n     * @example\n     * // Delete a few Political_news_crawler_crawl_policies\n     * const { count } = await prisma.political_news_crawler_crawl_policies.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_crawl_policiesDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_policiesDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawl_policies.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_policiesUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_crawl_policies\n     * const political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_crawl_policiesUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_crawl_policiesUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawl_policies and returns the data updated in the database.\n     * @param {political_news_crawler_crawl_policiesUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_crawl_policies.\n     * @example\n     * // Update many Political_news_crawler_crawl_policies\n     * const political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_crawl_policies and only return the `id`\n     * const political_news_crawler_crawl_policiesWithIdOnly = await prisma.political_news_crawler_crawl_policies.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_crawl_policiesUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_crawl_policiesUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_crawl_policies.\n     * @param {political_news_crawler_crawl_policiesUpsertArgs} args - Arguments to update or create a Political_news_crawler_crawl_policies.\n     * @example\n     * // Update or create a Political_news_crawler_crawl_policies\n     * const political_news_crawler_crawl_policies = await prisma.political_news_crawler_crawl_policies.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_crawl_policies\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawl_policies we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_crawl_policiesUpsertArgs>(args: SelectSubset<T, political_news_crawler_crawl_policiesUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_policiesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_crawl_policies.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_policiesCountArgs} args - Arguments to filter Political_news_crawler_crawl_policies to count.\n     * @example\n     * // Count the number of Political_news_crawler_crawl_policies\n     * const count = await prisma.political_news_crawler_crawl_policies.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawl_policies we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_crawl_policiesCountArgs>(\n      args?: Subset<T, political_news_crawler_crawl_policiesCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_crawl_policiesCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_crawl_policies.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_crawl_policiesAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_crawl_policiesAggregateArgs>(args: Subset<T, Political_news_crawler_crawl_policiesAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_crawl_policiesAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_crawl_policies.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_policiesGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_crawl_policiesGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_crawl_policiesGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_crawl_policiesGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_crawl_policiesGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_crawl_policiesGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_crawl_policies model\n   */\n  readonly fields: political_news_crawler_crawl_policiesFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_crawl_policies.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_crawl_policiesClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    political_news_crawler_crawl_schedules<T extends political_news_crawler_crawl_policies$political_news_crawler_crawl_schedulesArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_policies$political_news_crawler_crawl_schedulesArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_crawl_policies model\n   */\n  interface political_news_crawler_crawl_policiesFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_crawl_policies\", 'String'>\n    readonly policy_name: FieldRef<\"political_news_crawler_crawl_policies\", 'String'>\n    readonly max_crawl_frequency_minutes: FieldRef<\"political_news_crawler_crawl_policies\", 'Int'>\n    readonly max_retry_attempts: FieldRef<\"political_news_crawler_crawl_policies\", 'Int'>\n    readonly backoff_multiplier: FieldRef<\"political_news_crawler_crawl_policies\", 'Float'>\n    readonly ban_detection_enabled: FieldRef<\"political_news_crawler_crawl_policies\", 'Boolean'>\n    readonly created_at: FieldRef<\"political_news_crawler_crawl_policies\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_crawl_policies\", 'DateTime'>\n    readonly deleted_at: FieldRef<\"political_news_crawler_crawl_policies\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_crawl_policies findUnique\n   */\n  export type political_news_crawler_crawl_policiesFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_policies\n     */\n    select?: political_news_crawler_crawl_policiesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_policies\n     */\n    omit?: political_news_crawler_crawl_policiesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_policiesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_policies to fetch.\n     */\n    where: political_news_crawler_crawl_policiesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_policies findUniqueOrThrow\n   */\n  export type political_news_crawler_crawl_policiesFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_policies\n     */\n    select?: political_news_crawler_crawl_policiesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_policies\n     */\n    omit?: political_news_crawler_crawl_policiesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_policiesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_policies to fetch.\n     */\n    where: political_news_crawler_crawl_policiesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_policies findFirst\n   */\n  export type political_news_crawler_crawl_policiesFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_policies\n     */\n    select?: political_news_crawler_crawl_policiesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_policies\n     */\n    omit?: political_news_crawler_crawl_policiesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_policiesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_policies to fetch.\n     */\n    where?: political_news_crawler_crawl_policiesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_policies to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_policiesOrderByWithRelationInput | political_news_crawler_crawl_policiesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawl_policies.\n     */\n    cursor?: political_news_crawler_crawl_policiesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_policies from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_policies.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawl_policies.\n     */\n    distinct?: Political_news_crawler_crawl_policiesScalarFieldEnum | Political_news_crawler_crawl_policiesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_policies findFirstOrThrow\n   */\n  export type political_news_crawler_crawl_policiesFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_policies\n     */\n    select?: political_news_crawler_crawl_policiesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_policies\n     */\n    omit?: political_news_crawler_crawl_policiesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_policiesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_policies to fetch.\n     */\n    where?: political_news_crawler_crawl_policiesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_policies to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_policiesOrderByWithRelationInput | political_news_crawler_crawl_policiesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawl_policies.\n     */\n    cursor?: political_news_crawler_crawl_policiesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_policies from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_policies.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawl_policies.\n     */\n    distinct?: Political_news_crawler_crawl_policiesScalarFieldEnum | Political_news_crawler_crawl_policiesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_policies findMany\n   */\n  export type political_news_crawler_crawl_policiesFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_policies\n     */\n    select?: political_news_crawler_crawl_policiesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_policies\n     */\n    omit?: political_news_crawler_crawl_policiesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_policiesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_policies to fetch.\n     */\n    where?: political_news_crawler_crawl_policiesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_policies to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_policiesOrderByWithRelationInput | political_news_crawler_crawl_policiesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_crawl_policies.\n     */\n    cursor?: political_news_crawler_crawl_policiesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_policies from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_policies.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_crawl_policiesScalarFieldEnum | Political_news_crawler_crawl_policiesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_policies create\n   */\n  export type political_news_crawler_crawl_policiesCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_policies\n     */\n    select?: political_news_crawler_crawl_policiesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_policies\n     */\n    omit?: political_news_crawler_crawl_policiesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_policiesInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_crawl_policies.\n     */\n    data: XOR<political_news_crawler_crawl_policiesCreateInput, political_news_crawler_crawl_policiesUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_crawl_policies createMany\n   */\n  export type political_news_crawler_crawl_policiesCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_crawl_policies.\n     */\n    data: political_news_crawler_crawl_policiesCreateManyInput | political_news_crawler_crawl_policiesCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_crawl_policies createManyAndReturn\n   */\n  export type political_news_crawler_crawl_policiesCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_policies\n     */\n    select?: political_news_crawler_crawl_policiesSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_policies\n     */\n    omit?: political_news_crawler_crawl_policiesOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_crawl_policies.\n     */\n    data: political_news_crawler_crawl_policiesCreateManyInput | political_news_crawler_crawl_policiesCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_crawl_policies update\n   */\n  export type political_news_crawler_crawl_policiesUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_policies\n     */\n    select?: political_news_crawler_crawl_policiesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_policies\n     */\n    omit?: political_news_crawler_crawl_policiesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_policiesInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_crawl_policies.\n     */\n    data: XOR<political_news_crawler_crawl_policiesUpdateInput, political_news_crawler_crawl_policiesUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_crawl_policies to update.\n     */\n    where: political_news_crawler_crawl_policiesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_policies updateMany\n   */\n  export type political_news_crawler_crawl_policiesUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_crawl_policies.\n     */\n    data: XOR<political_news_crawler_crawl_policiesUpdateManyMutationInput, political_news_crawler_crawl_policiesUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawl_policies to update\n     */\n    where?: political_news_crawler_crawl_policiesWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_policies to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_policies updateManyAndReturn\n   */\n  export type political_news_crawler_crawl_policiesUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_policies\n     */\n    select?: political_news_crawler_crawl_policiesSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_policies\n     */\n    omit?: political_news_crawler_crawl_policiesOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_crawl_policies.\n     */\n    data: XOR<political_news_crawler_crawl_policiesUpdateManyMutationInput, political_news_crawler_crawl_policiesUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawl_policies to update\n     */\n    where?: political_news_crawler_crawl_policiesWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_policies to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_policies upsert\n   */\n  export type political_news_crawler_crawl_policiesUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_policies\n     */\n    select?: political_news_crawler_crawl_policiesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_policies\n     */\n    omit?: political_news_crawler_crawl_policiesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_policiesInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_crawl_policies to update in case it exists.\n     */\n    where: political_news_crawler_crawl_policiesWhereUniqueInput\n    /**\n     * In case the political_news_crawler_crawl_policies found by the `where` argument doesn't exist, create a new political_news_crawler_crawl_policies with this data.\n     */\n    create: XOR<political_news_crawler_crawl_policiesCreateInput, political_news_crawler_crawl_policiesUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_crawl_policies was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_crawl_policiesUpdateInput, political_news_crawler_crawl_policiesUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_crawl_policies delete\n   */\n  export type political_news_crawler_crawl_policiesDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_policies\n     */\n    select?: political_news_crawler_crawl_policiesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_policies\n     */\n    omit?: political_news_crawler_crawl_policiesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_policiesInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_crawl_policies to delete.\n     */\n    where: political_news_crawler_crawl_policiesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_policies deleteMany\n   */\n  export type political_news_crawler_crawl_policiesDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawl_policies to delete\n     */\n    where?: political_news_crawler_crawl_policiesWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_policies to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_policies.political_news_crawler_crawl_schedules\n   */\n  export type political_news_crawler_crawl_policies$political_news_crawler_crawl_schedulesArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesInclude<ExtArgs> | null\n    where?: political_news_crawler_crawl_schedulesWhereInput\n    orderBy?: political_news_crawler_crawl_schedulesOrderByWithRelationInput | political_news_crawler_crawl_schedulesOrderByWithRelationInput[]\n    cursor?: political_news_crawler_crawl_schedulesWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_crawl_schedulesScalarFieldEnum | Political_news_crawler_crawl_schedulesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_policies without action\n   */\n  export type political_news_crawler_crawl_policiesDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_policies\n     */\n    select?: political_news_crawler_crawl_policiesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_policies\n     */\n    omit?: political_news_crawler_crawl_policiesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_policiesInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_crawl_schedules\n   */\n\n  export type AggregatePolitical_news_crawler_crawl_schedules = {\n    _count: Political_news_crawler_crawl_schedulesCountAggregateOutputType | null\n    _min: Political_news_crawler_crawl_schedulesMinAggregateOutputType | null\n    _max: Political_news_crawler_crawl_schedulesMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_crawl_schedulesMinAggregateOutputType = {\n    id: string | null\n    crawl_source_id: string | null\n    crawl_policy_id: string | null\n    schedule_expression: string | null\n    last_crawled_at: Date | null\n    next_crawl_at: Date | null\n    is_enabled: boolean | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_crawl_schedulesMaxAggregateOutputType = {\n    id: string | null\n    crawl_source_id: string | null\n    crawl_policy_id: string | null\n    schedule_expression: string | null\n    last_crawled_at: Date | null\n    next_crawl_at: Date | null\n    is_enabled: boolean | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_crawl_schedulesCountAggregateOutputType = {\n    id: number\n    crawl_source_id: number\n    crawl_policy_id: number\n    schedule_expression: number\n    last_crawled_at: number\n    next_crawl_at: number\n    is_enabled: number\n    created_at: number\n    updated_at: number\n    deleted_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_crawl_schedulesMinAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    crawl_policy_id?: true\n    schedule_expression?: true\n    last_crawled_at?: true\n    next_crawl_at?: true\n    is_enabled?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_crawl_schedulesMaxAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    crawl_policy_id?: true\n    schedule_expression?: true\n    last_crawled_at?: true\n    next_crawl_at?: true\n    is_enabled?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_crawl_schedulesCountAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    crawl_policy_id?: true\n    schedule_expression?: true\n    last_crawled_at?: true\n    next_crawl_at?: true\n    is_enabled?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_crawl_schedulesAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawl_schedules to aggregate.\n     */\n    where?: political_news_crawler_crawl_schedulesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_schedules to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_schedulesOrderByWithRelationInput | political_news_crawler_crawl_schedulesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_crawl_schedulesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_schedules from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_schedules.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_crawl_schedules\n    **/\n    _count?: true | Political_news_crawler_crawl_schedulesCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_crawl_schedulesMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_crawl_schedulesMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_crawl_schedulesAggregateType<T extends Political_news_crawler_crawl_schedulesAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_crawl_schedules]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_crawl_schedules[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_crawl_schedules[P]>\n  }\n\n\n\n\n  export type political_news_crawler_crawl_schedulesGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawl_schedulesWhereInput\n    orderBy?: political_news_crawler_crawl_schedulesOrderByWithAggregationInput | political_news_crawler_crawl_schedulesOrderByWithAggregationInput[]\n    by: Political_news_crawler_crawl_schedulesScalarFieldEnum[] | Political_news_crawler_crawl_schedulesScalarFieldEnum\n    having?: political_news_crawler_crawl_schedulesScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_crawl_schedulesCountAggregateInputType | true\n    _min?: Political_news_crawler_crawl_schedulesMinAggregateInputType\n    _max?: Political_news_crawler_crawl_schedulesMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_crawl_schedulesGroupByOutputType = {\n    id: string\n    crawl_source_id: string\n    crawl_policy_id: string\n    schedule_expression: string\n    last_crawled_at: Date | null\n    next_crawl_at: Date | null\n    is_enabled: boolean\n    created_at: Date\n    updated_at: Date\n    deleted_at: Date | null\n    _count: Political_news_crawler_crawl_schedulesCountAggregateOutputType | null\n    _min: Political_news_crawler_crawl_schedulesMinAggregateOutputType | null\n    _max: Political_news_crawler_crawl_schedulesMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_crawl_schedulesGroupByPayload<T extends political_news_crawler_crawl_schedulesGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_crawl_schedulesGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_crawl_schedulesGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_crawl_schedulesGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_crawl_schedulesGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_crawl_schedulesSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    crawl_policy_id?: boolean\n    schedule_expression?: boolean\n    last_crawled_at?: boolean\n    next_crawl_at?: boolean\n    is_enabled?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlPolicy?: boolean | political_news_crawler_crawl_policiesDefaultArgs<ExtArgs>\n    political_news_crawler_crawl_jobs?: boolean | political_news_crawler_crawl_schedules$political_news_crawler_crawl_jobsArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_crawl_schedulesCountOutputTypeDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_schedules\"]>\n\n  export type political_news_crawler_crawl_schedulesSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    crawl_policy_id?: boolean\n    schedule_expression?: boolean\n    last_crawled_at?: boolean\n    next_crawl_at?: boolean\n    is_enabled?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlPolicy?: boolean | political_news_crawler_crawl_policiesDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_schedules\"]>\n\n  export type political_news_crawler_crawl_schedulesSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    crawl_policy_id?: boolean\n    schedule_expression?: boolean\n    last_crawled_at?: boolean\n    next_crawl_at?: boolean\n    is_enabled?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlPolicy?: boolean | political_news_crawler_crawl_policiesDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_schedules\"]>\n\n  export type political_news_crawler_crawl_schedulesSelectScalar = {\n    id?: boolean\n    crawl_source_id?: boolean\n    crawl_policy_id?: boolean\n    schedule_expression?: boolean\n    last_crawled_at?: boolean\n    next_crawl_at?: boolean\n    is_enabled?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }\n\n  export type political_news_crawler_crawl_schedulesOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"crawl_source_id\" | \"crawl_policy_id\" | \"schedule_expression\" | \"last_crawled_at\" | \"next_crawl_at\" | \"is_enabled\" | \"created_at\" | \"updated_at\" | \"deleted_at\", ExtArgs[\"result\"][\"political_news_crawler_crawl_schedules\"]>\n  export type political_news_crawler_crawl_schedulesInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlPolicy?: boolean | political_news_crawler_crawl_policiesDefaultArgs<ExtArgs>\n    political_news_crawler_crawl_jobs?: boolean | political_news_crawler_crawl_schedules$political_news_crawler_crawl_jobsArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_crawl_schedulesCountOutputTypeDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_crawl_schedulesIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlPolicy?: boolean | political_news_crawler_crawl_policiesDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_crawl_schedulesIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlPolicy?: boolean | political_news_crawler_crawl_policiesDefaultArgs<ExtArgs>\n  }\n\n  export type $political_news_crawler_crawl_schedulesPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_crawl_schedules\"\n    objects: {\n      crawlSource: Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>\n      crawlPolicy: Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>\n      political_news_crawler_crawl_jobs: Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>[]\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Reference to Crawling Source. {@link\n       * political_news_crawler_crawl_sources.id}\n       */\n      crawl_source_id: string\n      /**\n       * Reference to Crawl Policy. {@link\n       * political_news_crawler_crawl_policies.id}\n       */\n      crawl_policy_id: string\n      /**\n       * Cron expression defining the crawl schedule timing.\n       */\n      schedule_expression: string\n      /**\n       * Timestamp when the crawl last occurred.\n       */\n      last_crawled_at: Date | null\n      /**\n       * Timestamp for the next scheduled crawl.\n       */\n      next_crawl_at: Date | null\n      /**\n       * Flag indicating if this schedule is enabled.\n       */\n      is_enabled: boolean\n      /**\n       * Record creation timestamp.\n       */\n      created_at: Date\n      /**\n       * Record last update timestamp.\n       */\n      updated_at: Date\n      /**\n       * Soft delete timestamp, if record is deleted.\n       */\n      deleted_at: Date | null\n    }, ExtArgs[\"result\"][\"political_news_crawler_crawl_schedules\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_crawl_schedulesGetPayload<S extends boolean | null | undefined | political_news_crawler_crawl_schedulesDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload, S>\n\n  type political_news_crawler_crawl_schedulesCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_crawl_schedulesFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_crawl_schedulesCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_crawl_schedulesDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_crawl_schedules'], meta: { name: 'political_news_crawler_crawl_schedules' } }\n    /**\n     * Find zero or one Political_news_crawler_crawl_schedules that matches the filter.\n     * @param {political_news_crawler_crawl_schedulesFindUniqueArgs} args - Arguments to find a Political_news_crawler_crawl_schedules\n     * @example\n     * // Get one Political_news_crawler_crawl_schedules\n     * const political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_crawl_schedulesFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_crawl_schedulesFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_schedulesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_crawl_schedules that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_crawl_schedulesFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_crawl_schedules\n     * @example\n     * // Get one Political_news_crawler_crawl_schedules\n     * const political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_crawl_schedulesFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_crawl_schedulesFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_schedulesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawl_schedules that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_schedulesFindFirstArgs} args - Arguments to find a Political_news_crawler_crawl_schedules\n     * @example\n     * // Get one Political_news_crawler_crawl_schedules\n     * const political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_crawl_schedulesFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_crawl_schedulesFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_schedulesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawl_schedules that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_schedulesFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_crawl_schedules\n     * @example\n     * // Get one Political_news_crawler_crawl_schedules\n     * const political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_crawl_schedulesFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_crawl_schedulesFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_schedulesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_crawl_schedules that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_schedulesFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_crawl_schedules\n     * const political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.findMany()\n     * \n     * // Get first 10 Political_news_crawler_crawl_schedules\n     * const political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_crawl_schedulesWithIdOnly = await prisma.political_news_crawler_crawl_schedules.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_crawl_schedulesFindManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_schedulesFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_crawl_schedules.\n     * @param {political_news_crawler_crawl_schedulesCreateArgs} args - Arguments to create a Political_news_crawler_crawl_schedules.\n     * @example\n     * // Create one Political_news_crawler_crawl_schedules\n     * const Political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_crawl_schedules\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_crawl_schedulesCreateArgs>(args: SelectSubset<T, political_news_crawler_crawl_schedulesCreateArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_schedulesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_crawl_schedules.\n     * @param {political_news_crawler_crawl_schedulesCreateManyArgs} args - Arguments to create many Political_news_crawler_crawl_schedules.\n     * @example\n     * // Create many Political_news_crawler_crawl_schedules\n     * const political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_crawl_schedulesCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_schedulesCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_crawl_schedules and returns the data saved in the database.\n     * @param {political_news_crawler_crawl_schedulesCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_crawl_schedules.\n     * @example\n     * // Create many Political_news_crawler_crawl_schedules\n     * const political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_crawl_schedules and only return the `id`\n     * const political_news_crawler_crawl_schedulesWithIdOnly = await prisma.political_news_crawler_crawl_schedules.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_crawl_schedulesCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_crawl_schedulesCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_crawl_schedules.\n     * @param {political_news_crawler_crawl_schedulesDeleteArgs} args - Arguments to delete one Political_news_crawler_crawl_schedules.\n     * @example\n     * // Delete one Political_news_crawler_crawl_schedules\n     * const Political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_crawl_schedules\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_crawl_schedulesDeleteArgs>(args: SelectSubset<T, political_news_crawler_crawl_schedulesDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_schedulesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_crawl_schedules.\n     * @param {political_news_crawler_crawl_schedulesUpdateArgs} args - Arguments to update one Political_news_crawler_crawl_schedules.\n     * @example\n     * // Update one Political_news_crawler_crawl_schedules\n     * const political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_crawl_schedulesUpdateArgs>(args: SelectSubset<T, political_news_crawler_crawl_schedulesUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_schedulesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_crawl_schedules.\n     * @param {political_news_crawler_crawl_schedulesDeleteManyArgs} args - Arguments to filter Political_news_crawler_crawl_schedules to delete.\n     * @example\n     * // Delete a few Political_news_crawler_crawl_schedules\n     * const { count } = await prisma.political_news_crawler_crawl_schedules.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_crawl_schedulesDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_schedulesDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawl_schedules.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_schedulesUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_crawl_schedules\n     * const political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_crawl_schedulesUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_crawl_schedulesUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawl_schedules and returns the data updated in the database.\n     * @param {political_news_crawler_crawl_schedulesUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_crawl_schedules.\n     * @example\n     * // Update many Political_news_crawler_crawl_schedules\n     * const political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_crawl_schedules and only return the `id`\n     * const political_news_crawler_crawl_schedulesWithIdOnly = await prisma.political_news_crawler_crawl_schedules.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_crawl_schedulesUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_crawl_schedulesUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_crawl_schedules.\n     * @param {political_news_crawler_crawl_schedulesUpsertArgs} args - Arguments to update or create a Political_news_crawler_crawl_schedules.\n     * @example\n     * // Update or create a Political_news_crawler_crawl_schedules\n     * const political_news_crawler_crawl_schedules = await prisma.political_news_crawler_crawl_schedules.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_crawl_schedules\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawl_schedules we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_crawl_schedulesUpsertArgs>(args: SelectSubset<T, political_news_crawler_crawl_schedulesUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_schedulesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_crawl_schedules.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_schedulesCountArgs} args - Arguments to filter Political_news_crawler_crawl_schedules to count.\n     * @example\n     * // Count the number of Political_news_crawler_crawl_schedules\n     * const count = await prisma.political_news_crawler_crawl_schedules.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawl_schedules we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_crawl_schedulesCountArgs>(\n      args?: Subset<T, political_news_crawler_crawl_schedulesCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_crawl_schedulesCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_crawl_schedules.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_crawl_schedulesAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_crawl_schedulesAggregateArgs>(args: Subset<T, Political_news_crawler_crawl_schedulesAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_crawl_schedulesAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_crawl_schedules.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_schedulesGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_crawl_schedulesGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_crawl_schedulesGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_crawl_schedulesGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_crawl_schedulesGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_crawl_schedulesGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_crawl_schedules model\n   */\n  readonly fields: political_news_crawler_crawl_schedulesFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_crawl_schedules.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_crawl_schedulesClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    crawlSource<T extends political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_sourcesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    crawlPolicy<T extends political_news_crawler_crawl_policiesDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_policiesDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_policiesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_policiesPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    political_news_crawler_crawl_jobs<T extends political_news_crawler_crawl_schedules$political_news_crawler_crawl_jobsArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_schedules$political_news_crawler_crawl_jobsArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_crawl_schedules model\n   */\n  interface political_news_crawler_crawl_schedulesFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_crawl_schedules\", 'String'>\n    readonly crawl_source_id: FieldRef<\"political_news_crawler_crawl_schedules\", 'String'>\n    readonly crawl_policy_id: FieldRef<\"political_news_crawler_crawl_schedules\", 'String'>\n    readonly schedule_expression: FieldRef<\"political_news_crawler_crawl_schedules\", 'String'>\n    readonly last_crawled_at: FieldRef<\"political_news_crawler_crawl_schedules\", 'DateTime'>\n    readonly next_crawl_at: FieldRef<\"political_news_crawler_crawl_schedules\", 'DateTime'>\n    readonly is_enabled: FieldRef<\"political_news_crawler_crawl_schedules\", 'Boolean'>\n    readonly created_at: FieldRef<\"political_news_crawler_crawl_schedules\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_crawl_schedules\", 'DateTime'>\n    readonly deleted_at: FieldRef<\"political_news_crawler_crawl_schedules\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_crawl_schedules findUnique\n   */\n  export type political_news_crawler_crawl_schedulesFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_schedules to fetch.\n     */\n    where: political_news_crawler_crawl_schedulesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules findUniqueOrThrow\n   */\n  export type political_news_crawler_crawl_schedulesFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_schedules to fetch.\n     */\n    where: political_news_crawler_crawl_schedulesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules findFirst\n   */\n  export type political_news_crawler_crawl_schedulesFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_schedules to fetch.\n     */\n    where?: political_news_crawler_crawl_schedulesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_schedules to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_schedulesOrderByWithRelationInput | political_news_crawler_crawl_schedulesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawl_schedules.\n     */\n    cursor?: political_news_crawler_crawl_schedulesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_schedules from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_schedules.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawl_schedules.\n     */\n    distinct?: Political_news_crawler_crawl_schedulesScalarFieldEnum | Political_news_crawler_crawl_schedulesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules findFirstOrThrow\n   */\n  export type political_news_crawler_crawl_schedulesFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_schedules to fetch.\n     */\n    where?: political_news_crawler_crawl_schedulesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_schedules to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_schedulesOrderByWithRelationInput | political_news_crawler_crawl_schedulesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawl_schedules.\n     */\n    cursor?: political_news_crawler_crawl_schedulesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_schedules from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_schedules.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawl_schedules.\n     */\n    distinct?: Political_news_crawler_crawl_schedulesScalarFieldEnum | Political_news_crawler_crawl_schedulesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules findMany\n   */\n  export type political_news_crawler_crawl_schedulesFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_schedules to fetch.\n     */\n    where?: political_news_crawler_crawl_schedulesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_schedules to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_schedulesOrderByWithRelationInput | political_news_crawler_crawl_schedulesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_crawl_schedules.\n     */\n    cursor?: political_news_crawler_crawl_schedulesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_schedules from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_schedules.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_crawl_schedulesScalarFieldEnum | Political_news_crawler_crawl_schedulesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules create\n   */\n  export type political_news_crawler_crawl_schedulesCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_crawl_schedules.\n     */\n    data: XOR<political_news_crawler_crawl_schedulesCreateInput, political_news_crawler_crawl_schedulesUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules createMany\n   */\n  export type political_news_crawler_crawl_schedulesCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_crawl_schedules.\n     */\n    data: political_news_crawler_crawl_schedulesCreateManyInput | political_news_crawler_crawl_schedulesCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules createManyAndReturn\n   */\n  export type political_news_crawler_crawl_schedulesCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_crawl_schedules.\n     */\n    data: political_news_crawler_crawl_schedulesCreateManyInput | political_news_crawler_crawl_schedulesCreateManyInput[]\n    skipDuplicates?: boolean\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesIncludeCreateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules update\n   */\n  export type political_news_crawler_crawl_schedulesUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_crawl_schedules.\n     */\n    data: XOR<political_news_crawler_crawl_schedulesUpdateInput, political_news_crawler_crawl_schedulesUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_crawl_schedules to update.\n     */\n    where: political_news_crawler_crawl_schedulesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules updateMany\n   */\n  export type political_news_crawler_crawl_schedulesUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_crawl_schedules.\n     */\n    data: XOR<political_news_crawler_crawl_schedulesUpdateManyMutationInput, political_news_crawler_crawl_schedulesUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawl_schedules to update\n     */\n    where?: political_news_crawler_crawl_schedulesWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_schedules to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules updateManyAndReturn\n   */\n  export type political_news_crawler_crawl_schedulesUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_crawl_schedules.\n     */\n    data: XOR<political_news_crawler_crawl_schedulesUpdateManyMutationInput, political_news_crawler_crawl_schedulesUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawl_schedules to update\n     */\n    where?: political_news_crawler_crawl_schedulesWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_schedules to update.\n     */\n    limit?: number\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesIncludeUpdateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules upsert\n   */\n  export type political_news_crawler_crawl_schedulesUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_crawl_schedules to update in case it exists.\n     */\n    where: political_news_crawler_crawl_schedulesWhereUniqueInput\n    /**\n     * In case the political_news_crawler_crawl_schedules found by the `where` argument doesn't exist, create a new political_news_crawler_crawl_schedules with this data.\n     */\n    create: XOR<political_news_crawler_crawl_schedulesCreateInput, political_news_crawler_crawl_schedulesUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_crawl_schedules was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_crawl_schedulesUpdateInput, political_news_crawler_crawl_schedulesUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules delete\n   */\n  export type political_news_crawler_crawl_schedulesDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_crawl_schedules to delete.\n     */\n    where: political_news_crawler_crawl_schedulesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules deleteMany\n   */\n  export type political_news_crawler_crawl_schedulesDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawl_schedules to delete\n     */\n    where?: political_news_crawler_crawl_schedulesWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_schedules to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules.political_news_crawler_crawl_jobs\n   */\n  export type political_news_crawler_crawl_schedules$political_news_crawler_crawl_jobsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsInclude<ExtArgs> | null\n    where?: political_news_crawler_crawl_jobsWhereInput\n    orderBy?: political_news_crawler_crawl_jobsOrderByWithRelationInput | political_news_crawler_crawl_jobsOrderByWithRelationInput[]\n    cursor?: political_news_crawler_crawl_jobsWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_crawl_jobsScalarFieldEnum | Political_news_crawler_crawl_jobsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_schedules without action\n   */\n  export type political_news_crawler_crawl_schedulesDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_schedules\n     */\n    select?: political_news_crawler_crawl_schedulesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_schedules\n     */\n    omit?: political_news_crawler_crawl_schedulesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_schedulesInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_guests\n   */\n\n  export type AggregatePolitical_news_crawler_guests = {\n    _count: Political_news_crawler_guestsCountAggregateOutputType | null\n    _min: Political_news_crawler_guestsMinAggregateOutputType | null\n    _max: Political_news_crawler_guestsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_guestsMinAggregateOutputType = {\n    id: string | null\n    ip_address: string | null\n    user_agent: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_guestsMaxAggregateOutputType = {\n    id: string | null\n    ip_address: string | null\n    user_agent: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_guestsCountAggregateOutputType = {\n    id: number\n    ip_address: number\n    user_agent: number\n    created_at: number\n    updated_at: number\n    deleted_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_guestsMinAggregateInputType = {\n    id?: true\n    ip_address?: true\n    user_agent?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_guestsMaxAggregateInputType = {\n    id?: true\n    ip_address?: true\n    user_agent?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_guestsCountAggregateInputType = {\n    id?: true\n    ip_address?: true\n    user_agent?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_guestsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_guests to aggregate.\n     */\n    where?: political_news_crawler_guestsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_guests to fetch.\n     */\n    orderBy?: political_news_crawler_guestsOrderByWithRelationInput | political_news_crawler_guestsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_guestsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_guests from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_guests.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_guests\n    **/\n    _count?: true | Political_news_crawler_guestsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_guestsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_guestsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_guestsAggregateType<T extends Political_news_crawler_guestsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_guests]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_guests[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_guests[P]>\n  }\n\n\n\n\n  export type political_news_crawler_guestsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_guestsWhereInput\n    orderBy?: political_news_crawler_guestsOrderByWithAggregationInput | political_news_crawler_guestsOrderByWithAggregationInput[]\n    by: Political_news_crawler_guestsScalarFieldEnum[] | Political_news_crawler_guestsScalarFieldEnum\n    having?: political_news_crawler_guestsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_guestsCountAggregateInputType | true\n    _min?: Political_news_crawler_guestsMinAggregateInputType\n    _max?: Political_news_crawler_guestsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_guestsGroupByOutputType = {\n    id: string\n    ip_address: string\n    user_agent: string | null\n    created_at: Date\n    updated_at: Date\n    deleted_at: Date | null\n    _count: Political_news_crawler_guestsCountAggregateOutputType | null\n    _min: Political_news_crawler_guestsMinAggregateOutputType | null\n    _max: Political_news_crawler_guestsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_guestsGroupByPayload<T extends political_news_crawler_guestsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_guestsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_guestsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_guestsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_guestsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_guestsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    ip_address?: boolean\n    user_agent?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_guests\"]>\n\n  export type political_news_crawler_guestsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    ip_address?: boolean\n    user_agent?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_guests\"]>\n\n  export type political_news_crawler_guestsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    ip_address?: boolean\n    user_agent?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_guests\"]>\n\n  export type political_news_crawler_guestsSelectScalar = {\n    id?: boolean\n    ip_address?: boolean\n    user_agent?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }\n\n  export type political_news_crawler_guestsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"ip_address\" | \"user_agent\" | \"created_at\" | \"updated_at\" | \"deleted_at\", ExtArgs[\"result\"][\"political_news_crawler_guests\"]>\n\n  export type $political_news_crawler_guestsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_guests\"\n    objects: {}\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * IP address of the guest user.\n       */\n      ip_address: string\n      /**\n       * User agent string presented by the guest.\n       */\n      user_agent: string | null\n      /**\n       * Timestamp when the guest record was created.\n       */\n      created_at: Date\n      /**\n       * Timestamp when the guest record was last updated.\n       */\n      updated_at: Date\n      /**\n       * Timestamp of soft deletion for the guest record.\n       */\n      deleted_at: Date | null\n    }, ExtArgs[\"result\"][\"political_news_crawler_guests\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_guestsGetPayload<S extends boolean | null | undefined | political_news_crawler_guestsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_guestsPayload, S>\n\n  type political_news_crawler_guestsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_guestsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_guestsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_guestsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_guests'], meta: { name: 'political_news_crawler_guests' } }\n    /**\n     * Find zero or one Political_news_crawler_guests that matches the filter.\n     * @param {political_news_crawler_guestsFindUniqueArgs} args - Arguments to find a Political_news_crawler_guests\n     * @example\n     * // Get one Political_news_crawler_guests\n     * const political_news_crawler_guests = await prisma.political_news_crawler_guests.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_guestsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_guestsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_guestsClient<$Result.GetResult<Prisma.$political_news_crawler_guestsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_guests that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_guestsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_guests\n     * @example\n     * // Get one Political_news_crawler_guests\n     * const political_news_crawler_guests = await prisma.political_news_crawler_guests.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_guestsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_guestsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_guestsClient<$Result.GetResult<Prisma.$political_news_crawler_guestsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_guests that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_guestsFindFirstArgs} args - Arguments to find a Political_news_crawler_guests\n     * @example\n     * // Get one Political_news_crawler_guests\n     * const political_news_crawler_guests = await prisma.political_news_crawler_guests.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_guestsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_guestsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_guestsClient<$Result.GetResult<Prisma.$political_news_crawler_guestsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_guests that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_guestsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_guests\n     * @example\n     * // Get one Political_news_crawler_guests\n     * const political_news_crawler_guests = await prisma.political_news_crawler_guests.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_guestsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_guestsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_guestsClient<$Result.GetResult<Prisma.$political_news_crawler_guestsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_guests that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_guestsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_guests\n     * const political_news_crawler_guests = await prisma.political_news_crawler_guests.findMany()\n     * \n     * // Get first 10 Political_news_crawler_guests\n     * const political_news_crawler_guests = await prisma.political_news_crawler_guests.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_guestsWithIdOnly = await prisma.political_news_crawler_guests.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_guestsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_guestsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_guestsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_guests.\n     * @param {political_news_crawler_guestsCreateArgs} args - Arguments to create a Political_news_crawler_guests.\n     * @example\n     * // Create one Political_news_crawler_guests\n     * const Political_news_crawler_guests = await prisma.political_news_crawler_guests.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_guests\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_guestsCreateArgs>(args: SelectSubset<T, political_news_crawler_guestsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_guestsClient<$Result.GetResult<Prisma.$political_news_crawler_guestsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_guests.\n     * @param {political_news_crawler_guestsCreateManyArgs} args - Arguments to create many Political_news_crawler_guests.\n     * @example\n     * // Create many Political_news_crawler_guests\n     * const political_news_crawler_guests = await prisma.political_news_crawler_guests.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_guestsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_guestsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_guests and returns the data saved in the database.\n     * @param {political_news_crawler_guestsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_guests.\n     * @example\n     * // Create many Political_news_crawler_guests\n     * const political_news_crawler_guests = await prisma.political_news_crawler_guests.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_guests and only return the `id`\n     * const political_news_crawler_guestsWithIdOnly = await prisma.political_news_crawler_guests.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_guestsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_guestsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_guestsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_guests.\n     * @param {political_news_crawler_guestsDeleteArgs} args - Arguments to delete one Political_news_crawler_guests.\n     * @example\n     * // Delete one Political_news_crawler_guests\n     * const Political_news_crawler_guests = await prisma.political_news_crawler_guests.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_guests\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_guestsDeleteArgs>(args: SelectSubset<T, political_news_crawler_guestsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_guestsClient<$Result.GetResult<Prisma.$political_news_crawler_guestsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_guests.\n     * @param {political_news_crawler_guestsUpdateArgs} args - Arguments to update one Political_news_crawler_guests.\n     * @example\n     * // Update one Political_news_crawler_guests\n     * const political_news_crawler_guests = await prisma.political_news_crawler_guests.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_guestsUpdateArgs>(args: SelectSubset<T, political_news_crawler_guestsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_guestsClient<$Result.GetResult<Prisma.$political_news_crawler_guestsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_guests.\n     * @param {political_news_crawler_guestsDeleteManyArgs} args - Arguments to filter Political_news_crawler_guests to delete.\n     * @example\n     * // Delete a few Political_news_crawler_guests\n     * const { count } = await prisma.political_news_crawler_guests.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_guestsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_guestsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_guests.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_guestsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_guests\n     * const political_news_crawler_guests = await prisma.political_news_crawler_guests.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_guestsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_guestsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_guests and returns the data updated in the database.\n     * @param {political_news_crawler_guestsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_guests.\n     * @example\n     * // Update many Political_news_crawler_guests\n     * const political_news_crawler_guests = await prisma.political_news_crawler_guests.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_guests and only return the `id`\n     * const political_news_crawler_guestsWithIdOnly = await prisma.political_news_crawler_guests.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_guestsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_guestsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_guestsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_guests.\n     * @param {political_news_crawler_guestsUpsertArgs} args - Arguments to update or create a Political_news_crawler_guests.\n     * @example\n     * // Update or create a Political_news_crawler_guests\n     * const political_news_crawler_guests = await prisma.political_news_crawler_guests.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_guests\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_guests we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_guestsUpsertArgs>(args: SelectSubset<T, political_news_crawler_guestsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_guestsClient<$Result.GetResult<Prisma.$political_news_crawler_guestsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_guests.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_guestsCountArgs} args - Arguments to filter Political_news_crawler_guests to count.\n     * @example\n     * // Count the number of Political_news_crawler_guests\n     * const count = await prisma.political_news_crawler_guests.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_guests we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_guestsCountArgs>(\n      args?: Subset<T, political_news_crawler_guestsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_guestsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_guests.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_guestsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_guestsAggregateArgs>(args: Subset<T, Political_news_crawler_guestsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_guestsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_guests.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_guestsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_guestsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_guestsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_guestsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_guestsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_guestsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_guests model\n   */\n  readonly fields: political_news_crawler_guestsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_guests.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_guestsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_guests model\n   */\n  interface political_news_crawler_guestsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_guests\", 'String'>\n    readonly ip_address: FieldRef<\"political_news_crawler_guests\", 'String'>\n    readonly user_agent: FieldRef<\"political_news_crawler_guests\", 'String'>\n    readonly created_at: FieldRef<\"political_news_crawler_guests\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_guests\", 'DateTime'>\n    readonly deleted_at: FieldRef<\"political_news_crawler_guests\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_guests findUnique\n   */\n  export type political_news_crawler_guestsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_guests\n     */\n    select?: political_news_crawler_guestsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_guests\n     */\n    omit?: political_news_crawler_guestsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_guests to fetch.\n     */\n    where: political_news_crawler_guestsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_guests findUniqueOrThrow\n   */\n  export type political_news_crawler_guestsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_guests\n     */\n    select?: political_news_crawler_guestsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_guests\n     */\n    omit?: political_news_crawler_guestsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_guests to fetch.\n     */\n    where: political_news_crawler_guestsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_guests findFirst\n   */\n  export type political_news_crawler_guestsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_guests\n     */\n    select?: political_news_crawler_guestsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_guests\n     */\n    omit?: political_news_crawler_guestsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_guests to fetch.\n     */\n    where?: political_news_crawler_guestsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_guests to fetch.\n     */\n    orderBy?: political_news_crawler_guestsOrderByWithRelationInput | political_news_crawler_guestsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_guests.\n     */\n    cursor?: political_news_crawler_guestsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_guests from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_guests.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_guests.\n     */\n    distinct?: Political_news_crawler_guestsScalarFieldEnum | Political_news_crawler_guestsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_guests findFirstOrThrow\n   */\n  export type political_news_crawler_guestsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_guests\n     */\n    select?: political_news_crawler_guestsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_guests\n     */\n    omit?: political_news_crawler_guestsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_guests to fetch.\n     */\n    where?: political_news_crawler_guestsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_guests to fetch.\n     */\n    orderBy?: political_news_crawler_guestsOrderByWithRelationInput | political_news_crawler_guestsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_guests.\n     */\n    cursor?: political_news_crawler_guestsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_guests from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_guests.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_guests.\n     */\n    distinct?: Political_news_crawler_guestsScalarFieldEnum | Political_news_crawler_guestsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_guests findMany\n   */\n  export type political_news_crawler_guestsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_guests\n     */\n    select?: political_news_crawler_guestsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_guests\n     */\n    omit?: political_news_crawler_guestsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_guests to fetch.\n     */\n    where?: political_news_crawler_guestsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_guests to fetch.\n     */\n    orderBy?: political_news_crawler_guestsOrderByWithRelationInput | political_news_crawler_guestsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_guests.\n     */\n    cursor?: political_news_crawler_guestsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_guests from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_guests.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_guestsScalarFieldEnum | Political_news_crawler_guestsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_guests create\n   */\n  export type political_news_crawler_guestsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_guests\n     */\n    select?: political_news_crawler_guestsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_guests\n     */\n    omit?: political_news_crawler_guestsOmit<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_guests.\n     */\n    data: XOR<political_news_crawler_guestsCreateInput, political_news_crawler_guestsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_guests createMany\n   */\n  export type political_news_crawler_guestsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_guests.\n     */\n    data: political_news_crawler_guestsCreateManyInput | political_news_crawler_guestsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_guests createManyAndReturn\n   */\n  export type political_news_crawler_guestsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_guests\n     */\n    select?: political_news_crawler_guestsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_guests\n     */\n    omit?: political_news_crawler_guestsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_guests.\n     */\n    data: political_news_crawler_guestsCreateManyInput | political_news_crawler_guestsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_guests update\n   */\n  export type political_news_crawler_guestsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_guests\n     */\n    select?: political_news_crawler_guestsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_guests\n     */\n    omit?: political_news_crawler_guestsOmit<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_guests.\n     */\n    data: XOR<political_news_crawler_guestsUpdateInput, political_news_crawler_guestsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_guests to update.\n     */\n    where: political_news_crawler_guestsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_guests updateMany\n   */\n  export type political_news_crawler_guestsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_guests.\n     */\n    data: XOR<political_news_crawler_guestsUpdateManyMutationInput, political_news_crawler_guestsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_guests to update\n     */\n    where?: political_news_crawler_guestsWhereInput\n    /**\n     * Limit how many political_news_crawler_guests to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_guests updateManyAndReturn\n   */\n  export type political_news_crawler_guestsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_guests\n     */\n    select?: political_news_crawler_guestsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_guests\n     */\n    omit?: political_news_crawler_guestsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_guests.\n     */\n    data: XOR<political_news_crawler_guestsUpdateManyMutationInput, political_news_crawler_guestsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_guests to update\n     */\n    where?: political_news_crawler_guestsWhereInput\n    /**\n     * Limit how many political_news_crawler_guests to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_guests upsert\n   */\n  export type political_news_crawler_guestsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_guests\n     */\n    select?: political_news_crawler_guestsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_guests\n     */\n    omit?: political_news_crawler_guestsOmit<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_guests to update in case it exists.\n     */\n    where: political_news_crawler_guestsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_guests found by the `where` argument doesn't exist, create a new political_news_crawler_guests with this data.\n     */\n    create: XOR<political_news_crawler_guestsCreateInput, political_news_crawler_guestsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_guests was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_guestsUpdateInput, political_news_crawler_guestsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_guests delete\n   */\n  export type political_news_crawler_guestsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_guests\n     */\n    select?: political_news_crawler_guestsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_guests\n     */\n    omit?: political_news_crawler_guestsOmit<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_guests to delete.\n     */\n    where: political_news_crawler_guestsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_guests deleteMany\n   */\n  export type political_news_crawler_guestsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_guests to delete\n     */\n    where?: political_news_crawler_guestsWhereInput\n    /**\n     * Limit how many political_news_crawler_guests to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_guests without action\n   */\n  export type political_news_crawler_guestsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_guests\n     */\n    select?: political_news_crawler_guestsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_guests\n     */\n    omit?: political_news_crawler_guestsOmit<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_crawl_jobs\n   */\n\n  export type AggregatePolitical_news_crawler_crawl_jobs = {\n    _count: Political_news_crawler_crawl_jobsCountAggregateOutputType | null\n    _min: Political_news_crawler_crawl_jobsMinAggregateOutputType | null\n    _max: Political_news_crawler_crawl_jobsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_crawl_jobsMinAggregateOutputType = {\n    id: string | null\n    crawl_source_id: string | null\n    crawl_schedule_id: string | null\n    active: boolean | null\n    last_run_started_at: Date | null\n    last_run_completed_at: Date | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_crawl_jobsMaxAggregateOutputType = {\n    id: string | null\n    crawl_source_id: string | null\n    crawl_schedule_id: string | null\n    active: boolean | null\n    last_run_started_at: Date | null\n    last_run_completed_at: Date | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_crawl_jobsCountAggregateOutputType = {\n    id: number\n    crawl_source_id: number\n    crawl_schedule_id: number\n    active: number\n    last_run_started_at: number\n    last_run_completed_at: number\n    created_at: number\n    updated_at: number\n    deleted_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_crawl_jobsMinAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    crawl_schedule_id?: true\n    active?: true\n    last_run_started_at?: true\n    last_run_completed_at?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_crawl_jobsMaxAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    crawl_schedule_id?: true\n    active?: true\n    last_run_started_at?: true\n    last_run_completed_at?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_crawl_jobsCountAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    crawl_schedule_id?: true\n    active?: true\n    last_run_started_at?: true\n    last_run_completed_at?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_crawl_jobsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawl_jobs to aggregate.\n     */\n    where?: political_news_crawler_crawl_jobsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_jobs to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_jobsOrderByWithRelationInput | political_news_crawler_crawl_jobsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_crawl_jobsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_jobs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_jobs.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_crawl_jobs\n    **/\n    _count?: true | Political_news_crawler_crawl_jobsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_crawl_jobsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_crawl_jobsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_crawl_jobsAggregateType<T extends Political_news_crawler_crawl_jobsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_crawl_jobs]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_crawl_jobs[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_crawl_jobs[P]>\n  }\n\n\n\n\n  export type political_news_crawler_crawl_jobsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawl_jobsWhereInput\n    orderBy?: political_news_crawler_crawl_jobsOrderByWithAggregationInput | political_news_crawler_crawl_jobsOrderByWithAggregationInput[]\n    by: Political_news_crawler_crawl_jobsScalarFieldEnum[] | Political_news_crawler_crawl_jobsScalarFieldEnum\n    having?: political_news_crawler_crawl_jobsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_crawl_jobsCountAggregateInputType | true\n    _min?: Political_news_crawler_crawl_jobsMinAggregateInputType\n    _max?: Political_news_crawler_crawl_jobsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_crawl_jobsGroupByOutputType = {\n    id: string\n    crawl_source_id: string\n    crawl_schedule_id: string\n    active: boolean\n    last_run_started_at: Date | null\n    last_run_completed_at: Date | null\n    created_at: Date\n    updated_at: Date\n    deleted_at: Date | null\n    _count: Political_news_crawler_crawl_jobsCountAggregateOutputType | null\n    _min: Political_news_crawler_crawl_jobsMinAggregateOutputType | null\n    _max: Political_news_crawler_crawl_jobsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_crawl_jobsGroupByPayload<T extends political_news_crawler_crawl_jobsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_crawl_jobsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_crawl_jobsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_crawl_jobsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_crawl_jobsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_crawl_jobsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    crawl_schedule_id?: boolean\n    active?: boolean\n    last_run_started_at?: boolean\n    last_run_completed_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlSchedule?: boolean | political_news_crawler_crawl_schedulesDefaultArgs<ExtArgs>\n    political_news_crawler_crawl_attempts?: boolean | political_news_crawler_crawl_jobs$political_news_crawler_crawl_attemptsArgs<ExtArgs>\n    political_news_crawler_raw_data_storage?: boolean | political_news_crawler_crawl_jobs$political_news_crawler_raw_data_storageArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_crawl_jobsCountOutputTypeDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_jobs\"]>\n\n  export type political_news_crawler_crawl_jobsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    crawl_schedule_id?: boolean\n    active?: boolean\n    last_run_started_at?: boolean\n    last_run_completed_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlSchedule?: boolean | political_news_crawler_crawl_schedulesDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_jobs\"]>\n\n  export type political_news_crawler_crawl_jobsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    crawl_schedule_id?: boolean\n    active?: boolean\n    last_run_started_at?: boolean\n    last_run_completed_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlSchedule?: boolean | political_news_crawler_crawl_schedulesDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_jobs\"]>\n\n  export type political_news_crawler_crawl_jobsSelectScalar = {\n    id?: boolean\n    crawl_source_id?: boolean\n    crawl_schedule_id?: boolean\n    active?: boolean\n    last_run_started_at?: boolean\n    last_run_completed_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }\n\n  export type political_news_crawler_crawl_jobsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"crawl_source_id\" | \"crawl_schedule_id\" | \"active\" | \"last_run_started_at\" | \"last_run_completed_at\" | \"created_at\" | \"updated_at\" | \"deleted_at\", ExtArgs[\"result\"][\"political_news_crawler_crawl_jobs\"]>\n  export type political_news_crawler_crawl_jobsInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlSchedule?: boolean | political_news_crawler_crawl_schedulesDefaultArgs<ExtArgs>\n    political_news_crawler_crawl_attempts?: boolean | political_news_crawler_crawl_jobs$political_news_crawler_crawl_attemptsArgs<ExtArgs>\n    political_news_crawler_raw_data_storage?: boolean | political_news_crawler_crawl_jobs$political_news_crawler_raw_data_storageArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_crawl_jobsCountOutputTypeDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_crawl_jobsIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlSchedule?: boolean | political_news_crawler_crawl_schedulesDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_crawl_jobsIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlSchedule?: boolean | political_news_crawler_crawl_schedulesDefaultArgs<ExtArgs>\n  }\n\n  export type $political_news_crawler_crawl_jobsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_crawl_jobs\"\n    objects: {\n      crawlSource: Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>\n      crawlSchedule: Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>\n      political_news_crawler_crawl_attempts: Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>[]\n      political_news_crawler_raw_data_storage: Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>[]\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Referenced crawl source identifier. {@link\n       * political_news_crawler_crawl_sources.id}\n       */\n      crawl_source_id: string\n      /**\n       * Referenced crawl schedule identifier. {@link\n       * political_news_crawler_crawl_schedules.id}\n       */\n      crawl_schedule_id: string\n      /**\n       * Flag indicating if this crawl job is active and scheduled to run.\n       */\n      active: boolean\n      /**\n       * Timestamp when the last run of the crawl job started, null if never run.\n       */\n      last_run_started_at: Date | null\n      /**\n       * Timestamp when the last run of the crawl job completed, null if still\n       * running or never run.\n       */\n      last_run_completed_at: Date | null\n      /**\n       * Record creation timestamp.\n       */\n      created_at: Date\n      /**\n       * Record last update timestamp.\n       */\n      updated_at: Date\n      /**\n       * Soft deletion timestamp, if set the job is considered deleted and ignored.\n       */\n      deleted_at: Date | null\n    }, ExtArgs[\"result\"][\"political_news_crawler_crawl_jobs\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_crawl_jobsGetPayload<S extends boolean | null | undefined | political_news_crawler_crawl_jobsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload, S>\n\n  type political_news_crawler_crawl_jobsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_crawl_jobsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_crawl_jobsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_crawl_jobsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_crawl_jobs'], meta: { name: 'political_news_crawler_crawl_jobs' } }\n    /**\n     * Find zero or one Political_news_crawler_crawl_jobs that matches the filter.\n     * @param {political_news_crawler_crawl_jobsFindUniqueArgs} args - Arguments to find a Political_news_crawler_crawl_jobs\n     * @example\n     * // Get one Political_news_crawler_crawl_jobs\n     * const political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_crawl_jobsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_crawl_jobsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_crawl_jobs that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_crawl_jobsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_crawl_jobs\n     * @example\n     * // Get one Political_news_crawler_crawl_jobs\n     * const political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_crawl_jobsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_crawl_jobsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawl_jobs that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_jobsFindFirstArgs} args - Arguments to find a Political_news_crawler_crawl_jobs\n     * @example\n     * // Get one Political_news_crawler_crawl_jobs\n     * const political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_crawl_jobsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_crawl_jobsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawl_jobs that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_jobsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_crawl_jobs\n     * @example\n     * // Get one Political_news_crawler_crawl_jobs\n     * const political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_crawl_jobsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_crawl_jobsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_crawl_jobs that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_jobsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_crawl_jobs\n     * const political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.findMany()\n     * \n     * // Get first 10 Political_news_crawler_crawl_jobs\n     * const political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_crawl_jobsWithIdOnly = await prisma.political_news_crawler_crawl_jobs.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_crawl_jobsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_jobsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_crawl_jobs.\n     * @param {political_news_crawler_crawl_jobsCreateArgs} args - Arguments to create a Political_news_crawler_crawl_jobs.\n     * @example\n     * // Create one Political_news_crawler_crawl_jobs\n     * const Political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_crawl_jobs\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_crawl_jobsCreateArgs>(args: SelectSubset<T, political_news_crawler_crawl_jobsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_crawl_jobs.\n     * @param {political_news_crawler_crawl_jobsCreateManyArgs} args - Arguments to create many Political_news_crawler_crawl_jobs.\n     * @example\n     * // Create many Political_news_crawler_crawl_jobs\n     * const political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_crawl_jobsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_jobsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_crawl_jobs and returns the data saved in the database.\n     * @param {political_news_crawler_crawl_jobsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_crawl_jobs.\n     * @example\n     * // Create many Political_news_crawler_crawl_jobs\n     * const political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_crawl_jobs and only return the `id`\n     * const political_news_crawler_crawl_jobsWithIdOnly = await prisma.political_news_crawler_crawl_jobs.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_crawl_jobsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_crawl_jobsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_crawl_jobs.\n     * @param {political_news_crawler_crawl_jobsDeleteArgs} args - Arguments to delete one Political_news_crawler_crawl_jobs.\n     * @example\n     * // Delete one Political_news_crawler_crawl_jobs\n     * const Political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_crawl_jobs\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_crawl_jobsDeleteArgs>(args: SelectSubset<T, political_news_crawler_crawl_jobsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_crawl_jobs.\n     * @param {political_news_crawler_crawl_jobsUpdateArgs} args - Arguments to update one Political_news_crawler_crawl_jobs.\n     * @example\n     * // Update one Political_news_crawler_crawl_jobs\n     * const political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_crawl_jobsUpdateArgs>(args: SelectSubset<T, political_news_crawler_crawl_jobsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_crawl_jobs.\n     * @param {political_news_crawler_crawl_jobsDeleteManyArgs} args - Arguments to filter Political_news_crawler_crawl_jobs to delete.\n     * @example\n     * // Delete a few Political_news_crawler_crawl_jobs\n     * const { count } = await prisma.political_news_crawler_crawl_jobs.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_crawl_jobsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_jobsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawl_jobs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_jobsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_crawl_jobs\n     * const political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_crawl_jobsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_crawl_jobsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawl_jobs and returns the data updated in the database.\n     * @param {political_news_crawler_crawl_jobsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_crawl_jobs.\n     * @example\n     * // Update many Political_news_crawler_crawl_jobs\n     * const political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_crawl_jobs and only return the `id`\n     * const political_news_crawler_crawl_jobsWithIdOnly = await prisma.political_news_crawler_crawl_jobs.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_crawl_jobsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_crawl_jobsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_crawl_jobs.\n     * @param {political_news_crawler_crawl_jobsUpsertArgs} args - Arguments to update or create a Political_news_crawler_crawl_jobs.\n     * @example\n     * // Update or create a Political_news_crawler_crawl_jobs\n     * const political_news_crawler_crawl_jobs = await prisma.political_news_crawler_crawl_jobs.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_crawl_jobs\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawl_jobs we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_crawl_jobsUpsertArgs>(args: SelectSubset<T, political_news_crawler_crawl_jobsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_crawl_jobs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_jobsCountArgs} args - Arguments to filter Political_news_crawler_crawl_jobs to count.\n     * @example\n     * // Count the number of Political_news_crawler_crawl_jobs\n     * const count = await prisma.political_news_crawler_crawl_jobs.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawl_jobs we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_crawl_jobsCountArgs>(\n      args?: Subset<T, political_news_crawler_crawl_jobsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_crawl_jobsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_crawl_jobs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_crawl_jobsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_crawl_jobsAggregateArgs>(args: Subset<T, Political_news_crawler_crawl_jobsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_crawl_jobsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_crawl_jobs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_jobsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_crawl_jobsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_crawl_jobsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_crawl_jobsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_crawl_jobsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_crawl_jobsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_crawl_jobs model\n   */\n  readonly fields: political_news_crawler_crawl_jobsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_crawl_jobs.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_crawl_jobsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    crawlSource<T extends political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_sourcesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    crawlSchedule<T extends political_news_crawler_crawl_schedulesDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_schedulesDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_schedulesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_schedulesPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    political_news_crawler_crawl_attempts<T extends political_news_crawler_crawl_jobs$political_news_crawler_crawl_attemptsArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_jobs$political_news_crawler_crawl_attemptsArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    political_news_crawler_raw_data_storage<T extends political_news_crawler_crawl_jobs$political_news_crawler_raw_data_storageArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_jobs$political_news_crawler_raw_data_storageArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_crawl_jobs model\n   */\n  interface political_news_crawler_crawl_jobsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_crawl_jobs\", 'String'>\n    readonly crawl_source_id: FieldRef<\"political_news_crawler_crawl_jobs\", 'String'>\n    readonly crawl_schedule_id: FieldRef<\"political_news_crawler_crawl_jobs\", 'String'>\n    readonly active: FieldRef<\"political_news_crawler_crawl_jobs\", 'Boolean'>\n    readonly last_run_started_at: FieldRef<\"political_news_crawler_crawl_jobs\", 'DateTime'>\n    readonly last_run_completed_at: FieldRef<\"political_news_crawler_crawl_jobs\", 'DateTime'>\n    readonly created_at: FieldRef<\"political_news_crawler_crawl_jobs\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_crawl_jobs\", 'DateTime'>\n    readonly deleted_at: FieldRef<\"political_news_crawler_crawl_jobs\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_crawl_jobs findUnique\n   */\n  export type political_news_crawler_crawl_jobsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_jobs to fetch.\n     */\n    where: political_news_crawler_crawl_jobsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs findUniqueOrThrow\n   */\n  export type political_news_crawler_crawl_jobsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_jobs to fetch.\n     */\n    where: political_news_crawler_crawl_jobsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs findFirst\n   */\n  export type political_news_crawler_crawl_jobsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_jobs to fetch.\n     */\n    where?: political_news_crawler_crawl_jobsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_jobs to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_jobsOrderByWithRelationInput | political_news_crawler_crawl_jobsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawl_jobs.\n     */\n    cursor?: political_news_crawler_crawl_jobsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_jobs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_jobs.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawl_jobs.\n     */\n    distinct?: Political_news_crawler_crawl_jobsScalarFieldEnum | Political_news_crawler_crawl_jobsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs findFirstOrThrow\n   */\n  export type political_news_crawler_crawl_jobsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_jobs to fetch.\n     */\n    where?: political_news_crawler_crawl_jobsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_jobs to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_jobsOrderByWithRelationInput | political_news_crawler_crawl_jobsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawl_jobs.\n     */\n    cursor?: political_news_crawler_crawl_jobsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_jobs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_jobs.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawl_jobs.\n     */\n    distinct?: Political_news_crawler_crawl_jobsScalarFieldEnum | Political_news_crawler_crawl_jobsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs findMany\n   */\n  export type political_news_crawler_crawl_jobsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_jobs to fetch.\n     */\n    where?: political_news_crawler_crawl_jobsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_jobs to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_jobsOrderByWithRelationInput | political_news_crawler_crawl_jobsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_crawl_jobs.\n     */\n    cursor?: political_news_crawler_crawl_jobsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_jobs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_jobs.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_crawl_jobsScalarFieldEnum | Political_news_crawler_crawl_jobsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs create\n   */\n  export type political_news_crawler_crawl_jobsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_crawl_jobs.\n     */\n    data: XOR<political_news_crawler_crawl_jobsCreateInput, political_news_crawler_crawl_jobsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs createMany\n   */\n  export type political_news_crawler_crawl_jobsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_crawl_jobs.\n     */\n    data: political_news_crawler_crawl_jobsCreateManyInput | political_news_crawler_crawl_jobsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs createManyAndReturn\n   */\n  export type political_news_crawler_crawl_jobsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_crawl_jobs.\n     */\n    data: political_news_crawler_crawl_jobsCreateManyInput | political_news_crawler_crawl_jobsCreateManyInput[]\n    skipDuplicates?: boolean\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsIncludeCreateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs update\n   */\n  export type political_news_crawler_crawl_jobsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_crawl_jobs.\n     */\n    data: XOR<political_news_crawler_crawl_jobsUpdateInput, political_news_crawler_crawl_jobsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_crawl_jobs to update.\n     */\n    where: political_news_crawler_crawl_jobsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs updateMany\n   */\n  export type political_news_crawler_crawl_jobsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_crawl_jobs.\n     */\n    data: XOR<political_news_crawler_crawl_jobsUpdateManyMutationInput, political_news_crawler_crawl_jobsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawl_jobs to update\n     */\n    where?: political_news_crawler_crawl_jobsWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_jobs to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs updateManyAndReturn\n   */\n  export type political_news_crawler_crawl_jobsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_crawl_jobs.\n     */\n    data: XOR<political_news_crawler_crawl_jobsUpdateManyMutationInput, political_news_crawler_crawl_jobsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawl_jobs to update\n     */\n    where?: political_news_crawler_crawl_jobsWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_jobs to update.\n     */\n    limit?: number\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsIncludeUpdateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs upsert\n   */\n  export type political_news_crawler_crawl_jobsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_crawl_jobs to update in case it exists.\n     */\n    where: political_news_crawler_crawl_jobsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_crawl_jobs found by the `where` argument doesn't exist, create a new political_news_crawler_crawl_jobs with this data.\n     */\n    create: XOR<political_news_crawler_crawl_jobsCreateInput, political_news_crawler_crawl_jobsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_crawl_jobs was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_crawl_jobsUpdateInput, political_news_crawler_crawl_jobsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs delete\n   */\n  export type political_news_crawler_crawl_jobsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_crawl_jobs to delete.\n     */\n    where: political_news_crawler_crawl_jobsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs deleteMany\n   */\n  export type political_news_crawler_crawl_jobsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawl_jobs to delete\n     */\n    where?: political_news_crawler_crawl_jobsWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_jobs to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs.political_news_crawler_crawl_attempts\n   */\n  export type political_news_crawler_crawl_jobs$political_news_crawler_crawl_attemptsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsInclude<ExtArgs> | null\n    where?: political_news_crawler_crawl_attemptsWhereInput\n    orderBy?: political_news_crawler_crawl_attemptsOrderByWithRelationInput | political_news_crawler_crawl_attemptsOrderByWithRelationInput[]\n    cursor?: political_news_crawler_crawl_attemptsWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_crawl_attemptsScalarFieldEnum | Political_news_crawler_crawl_attemptsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs.political_news_crawler_raw_data_storage\n   */\n  export type political_news_crawler_crawl_jobs$political_news_crawler_raw_data_storageArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageInclude<ExtArgs> | null\n    where?: political_news_crawler_raw_data_storageWhereInput\n    orderBy?: political_news_crawler_raw_data_storageOrderByWithRelationInput | political_news_crawler_raw_data_storageOrderByWithRelationInput[]\n    cursor?: political_news_crawler_raw_data_storageWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_raw_data_storageScalarFieldEnum | Political_news_crawler_raw_data_storageScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_jobs without action\n   */\n  export type political_news_crawler_crawl_jobsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_crawl_attempts\n   */\n\n  export type AggregatePolitical_news_crawler_crawl_attempts = {\n    _count: Political_news_crawler_crawl_attemptsCountAggregateOutputType | null\n    _min: Political_news_crawler_crawl_attemptsMinAggregateOutputType | null\n    _max: Political_news_crawler_crawl_attemptsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_crawl_attemptsMinAggregateOutputType = {\n    id: string | null\n    crawl_job_id: string | null\n    raw_data_storage_id: string | null\n    started_at: Date | null\n    completed_at: Date | null\n    success: boolean | null\n    error_message: string | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_crawl_attemptsMaxAggregateOutputType = {\n    id: string | null\n    crawl_job_id: string | null\n    raw_data_storage_id: string | null\n    started_at: Date | null\n    completed_at: Date | null\n    success: boolean | null\n    error_message: string | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_crawl_attemptsCountAggregateOutputType = {\n    id: number\n    crawl_job_id: number\n    raw_data_storage_id: number\n    started_at: number\n    completed_at: number\n    success: number\n    error_message: number\n    created_at: number\n    updated_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_crawl_attemptsMinAggregateInputType = {\n    id?: true\n    crawl_job_id?: true\n    raw_data_storage_id?: true\n    started_at?: true\n    completed_at?: true\n    success?: true\n    error_message?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_crawl_attemptsMaxAggregateInputType = {\n    id?: true\n    crawl_job_id?: true\n    raw_data_storage_id?: true\n    started_at?: true\n    completed_at?: true\n    success?: true\n    error_message?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_crawl_attemptsCountAggregateInputType = {\n    id?: true\n    crawl_job_id?: true\n    raw_data_storage_id?: true\n    started_at?: true\n    completed_at?: true\n    success?: true\n    error_message?: true\n    created_at?: true\n    updated_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_crawl_attemptsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawl_attempts to aggregate.\n     */\n    where?: political_news_crawler_crawl_attemptsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_attempts to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_attemptsOrderByWithRelationInput | political_news_crawler_crawl_attemptsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_crawl_attemptsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_attempts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_attempts.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_crawl_attempts\n    **/\n    _count?: true | Political_news_crawler_crawl_attemptsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_crawl_attemptsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_crawl_attemptsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_crawl_attemptsAggregateType<T extends Political_news_crawler_crawl_attemptsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_crawl_attempts]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_crawl_attempts[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_crawl_attempts[P]>\n  }\n\n\n\n\n  export type political_news_crawler_crawl_attemptsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawl_attemptsWhereInput\n    orderBy?: political_news_crawler_crawl_attemptsOrderByWithAggregationInput | political_news_crawler_crawl_attemptsOrderByWithAggregationInput[]\n    by: Political_news_crawler_crawl_attemptsScalarFieldEnum[] | Political_news_crawler_crawl_attemptsScalarFieldEnum\n    having?: political_news_crawler_crawl_attemptsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_crawl_attemptsCountAggregateInputType | true\n    _min?: Political_news_crawler_crawl_attemptsMinAggregateInputType\n    _max?: Political_news_crawler_crawl_attemptsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_crawl_attemptsGroupByOutputType = {\n    id: string\n    crawl_job_id: string\n    raw_data_storage_id: string | null\n    started_at: Date\n    completed_at: Date | null\n    success: boolean\n    error_message: string | null\n    created_at: Date\n    updated_at: Date\n    _count: Political_news_crawler_crawl_attemptsCountAggregateOutputType | null\n    _min: Political_news_crawler_crawl_attemptsMinAggregateOutputType | null\n    _max: Political_news_crawler_crawl_attemptsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_crawl_attemptsGroupByPayload<T extends political_news_crawler_crawl_attemptsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_crawl_attemptsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_crawl_attemptsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_crawl_attemptsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_crawl_attemptsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_crawl_attemptsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_job_id?: boolean\n    raw_data_storage_id?: boolean\n    started_at?: boolean\n    completed_at?: boolean\n    success?: boolean\n    error_message?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    crawlJob?: boolean | political_news_crawler_crawl_jobsDefaultArgs<ExtArgs>\n    rawDataStorage?: boolean | political_news_crawler_crawl_attempts$rawDataStorageArgs<ExtArgs>\n    political_news_crawler_crawled_news?: boolean | political_news_crawler_crawl_attempts$political_news_crawler_crawled_newsArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_crawl_attemptsCountOutputTypeDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_attempts\"]>\n\n  export type political_news_crawler_crawl_attemptsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_job_id?: boolean\n    raw_data_storage_id?: boolean\n    started_at?: boolean\n    completed_at?: boolean\n    success?: boolean\n    error_message?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    crawlJob?: boolean | political_news_crawler_crawl_jobsDefaultArgs<ExtArgs>\n    rawDataStorage?: boolean | political_news_crawler_crawl_attempts$rawDataStorageArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_attempts\"]>\n\n  export type political_news_crawler_crawl_attemptsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_job_id?: boolean\n    raw_data_storage_id?: boolean\n    started_at?: boolean\n    completed_at?: boolean\n    success?: boolean\n    error_message?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    crawlJob?: boolean | political_news_crawler_crawl_jobsDefaultArgs<ExtArgs>\n    rawDataStorage?: boolean | political_news_crawler_crawl_attempts$rawDataStorageArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_attempts\"]>\n\n  export type political_news_crawler_crawl_attemptsSelectScalar = {\n    id?: boolean\n    crawl_job_id?: boolean\n    raw_data_storage_id?: boolean\n    started_at?: boolean\n    completed_at?: boolean\n    success?: boolean\n    error_message?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }\n\n  export type political_news_crawler_crawl_attemptsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"crawl_job_id\" | \"raw_data_storage_id\" | \"started_at\" | \"completed_at\" | \"success\" | \"error_message\" | \"created_at\" | \"updated_at\", ExtArgs[\"result\"][\"political_news_crawler_crawl_attempts\"]>\n  export type political_news_crawler_crawl_attemptsInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlJob?: boolean | political_news_crawler_crawl_jobsDefaultArgs<ExtArgs>\n    rawDataStorage?: boolean | political_news_crawler_crawl_attempts$rawDataStorageArgs<ExtArgs>\n    political_news_crawler_crawled_news?: boolean | political_news_crawler_crawl_attempts$political_news_crawler_crawled_newsArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_crawl_attemptsCountOutputTypeDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_crawl_attemptsIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlJob?: boolean | political_news_crawler_crawl_jobsDefaultArgs<ExtArgs>\n    rawDataStorage?: boolean | political_news_crawler_crawl_attempts$rawDataStorageArgs<ExtArgs>\n  }\n  export type political_news_crawler_crawl_attemptsIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlJob?: boolean | political_news_crawler_crawl_jobsDefaultArgs<ExtArgs>\n    rawDataStorage?: boolean | political_news_crawler_crawl_attempts$rawDataStorageArgs<ExtArgs>\n  }\n\n  export type $political_news_crawler_crawl_attemptsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_crawl_attempts\"\n    objects: {\n      crawlJob: Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>\n      rawDataStorage: Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs> | null\n      political_news_crawler_crawled_news: Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>[]\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Associated crawl job identifier. {@link\n       * political_news_crawler_crawl_jobs.id}\n       */\n      crawl_job_id: string\n      /**\n       * Reference to raw data storage entry for the crawl result. {@link\n       * political_news_crawler_raw_data_storage.id}\n       */\n      raw_data_storage_id: string | null\n      /**\n       * Timestamp when this crawl attempt started.\n       */\n      started_at: Date\n      /**\n       * Timestamp when this crawl attempt ended; null if still running.\n       */\n      completed_at: Date | null\n      /**\n       * Indicator whether this crawl attempt was successful.\n       */\n      success: boolean\n      /**\n       * Error message details if the crawl attempt failed.\n       */\n      error_message: string | null\n      /**\n       * Record creation timestamp.\n       */\n      created_at: Date\n      /**\n       * Record last update timestamp.\n       */\n      updated_at: Date\n    }, ExtArgs[\"result\"][\"political_news_crawler_crawl_attempts\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_crawl_attemptsGetPayload<S extends boolean | null | undefined | political_news_crawler_crawl_attemptsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload, S>\n\n  type political_news_crawler_crawl_attemptsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_crawl_attemptsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_crawl_attemptsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_crawl_attemptsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_crawl_attempts'], meta: { name: 'political_news_crawler_crawl_attempts' } }\n    /**\n     * Find zero or one Political_news_crawler_crawl_attempts that matches the filter.\n     * @param {political_news_crawler_crawl_attemptsFindUniqueArgs} args - Arguments to find a Political_news_crawler_crawl_attempts\n     * @example\n     * // Get one Political_news_crawler_crawl_attempts\n     * const political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_crawl_attemptsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_crawl_attemptsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_attemptsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_crawl_attempts that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_crawl_attemptsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_crawl_attempts\n     * @example\n     * // Get one Political_news_crawler_crawl_attempts\n     * const political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_crawl_attemptsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_crawl_attemptsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_attemptsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawl_attempts that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_attemptsFindFirstArgs} args - Arguments to find a Political_news_crawler_crawl_attempts\n     * @example\n     * // Get one Political_news_crawler_crawl_attempts\n     * const political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_crawl_attemptsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_crawl_attemptsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_attemptsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawl_attempts that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_attemptsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_crawl_attempts\n     * @example\n     * // Get one Political_news_crawler_crawl_attempts\n     * const political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_crawl_attemptsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_crawl_attemptsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_attemptsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_crawl_attempts that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_attemptsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_crawl_attempts\n     * const political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.findMany()\n     * \n     * // Get first 10 Political_news_crawler_crawl_attempts\n     * const political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_crawl_attemptsWithIdOnly = await prisma.political_news_crawler_crawl_attempts.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_crawl_attemptsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_attemptsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_crawl_attempts.\n     * @param {political_news_crawler_crawl_attemptsCreateArgs} args - Arguments to create a Political_news_crawler_crawl_attempts.\n     * @example\n     * // Create one Political_news_crawler_crawl_attempts\n     * const Political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_crawl_attempts\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_crawl_attemptsCreateArgs>(args: SelectSubset<T, political_news_crawler_crawl_attemptsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_attemptsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_crawl_attempts.\n     * @param {political_news_crawler_crawl_attemptsCreateManyArgs} args - Arguments to create many Political_news_crawler_crawl_attempts.\n     * @example\n     * // Create many Political_news_crawler_crawl_attempts\n     * const political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_crawl_attemptsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_attemptsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_crawl_attempts and returns the data saved in the database.\n     * @param {political_news_crawler_crawl_attemptsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_crawl_attempts.\n     * @example\n     * // Create many Political_news_crawler_crawl_attempts\n     * const political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_crawl_attempts and only return the `id`\n     * const political_news_crawler_crawl_attemptsWithIdOnly = await prisma.political_news_crawler_crawl_attempts.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_crawl_attemptsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_crawl_attemptsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_crawl_attempts.\n     * @param {political_news_crawler_crawl_attemptsDeleteArgs} args - Arguments to delete one Political_news_crawler_crawl_attempts.\n     * @example\n     * // Delete one Political_news_crawler_crawl_attempts\n     * const Political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_crawl_attempts\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_crawl_attemptsDeleteArgs>(args: SelectSubset<T, political_news_crawler_crawl_attemptsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_attemptsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_crawl_attempts.\n     * @param {political_news_crawler_crawl_attemptsUpdateArgs} args - Arguments to update one Political_news_crawler_crawl_attempts.\n     * @example\n     * // Update one Political_news_crawler_crawl_attempts\n     * const political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_crawl_attemptsUpdateArgs>(args: SelectSubset<T, political_news_crawler_crawl_attemptsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_attemptsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_crawl_attempts.\n     * @param {political_news_crawler_crawl_attemptsDeleteManyArgs} args - Arguments to filter Political_news_crawler_crawl_attempts to delete.\n     * @example\n     * // Delete a few Political_news_crawler_crawl_attempts\n     * const { count } = await prisma.political_news_crawler_crawl_attempts.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_crawl_attemptsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_attemptsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawl_attempts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_attemptsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_crawl_attempts\n     * const political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_crawl_attemptsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_crawl_attemptsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawl_attempts and returns the data updated in the database.\n     * @param {political_news_crawler_crawl_attemptsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_crawl_attempts.\n     * @example\n     * // Update many Political_news_crawler_crawl_attempts\n     * const political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_crawl_attempts and only return the `id`\n     * const political_news_crawler_crawl_attemptsWithIdOnly = await prisma.political_news_crawler_crawl_attempts.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_crawl_attemptsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_crawl_attemptsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_crawl_attempts.\n     * @param {political_news_crawler_crawl_attemptsUpsertArgs} args - Arguments to update or create a Political_news_crawler_crawl_attempts.\n     * @example\n     * // Update or create a Political_news_crawler_crawl_attempts\n     * const political_news_crawler_crawl_attempts = await prisma.political_news_crawler_crawl_attempts.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_crawl_attempts\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawl_attempts we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_crawl_attemptsUpsertArgs>(args: SelectSubset<T, political_news_crawler_crawl_attemptsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_attemptsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_crawl_attempts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_attemptsCountArgs} args - Arguments to filter Political_news_crawler_crawl_attempts to count.\n     * @example\n     * // Count the number of Political_news_crawler_crawl_attempts\n     * const count = await prisma.political_news_crawler_crawl_attempts.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawl_attempts we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_crawl_attemptsCountArgs>(\n      args?: Subset<T, political_news_crawler_crawl_attemptsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_crawl_attemptsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_crawl_attempts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_crawl_attemptsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_crawl_attemptsAggregateArgs>(args: Subset<T, Political_news_crawler_crawl_attemptsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_crawl_attemptsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_crawl_attempts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_attemptsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_crawl_attemptsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_crawl_attemptsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_crawl_attemptsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_crawl_attemptsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_crawl_attemptsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_crawl_attempts model\n   */\n  readonly fields: political_news_crawler_crawl_attemptsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_crawl_attempts.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_crawl_attemptsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    crawlJob<T extends political_news_crawler_crawl_jobsDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_jobsDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    rawDataStorage<T extends political_news_crawler_crawl_attempts$rawDataStorageArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_attempts$rawDataStorageArgs<ExtArgs>>): Prisma__political_news_crawler_raw_data_storageClient<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n    political_news_crawler_crawled_news<T extends political_news_crawler_crawl_attempts$political_news_crawler_crawled_newsArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_attempts$political_news_crawler_crawled_newsArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_crawl_attempts model\n   */\n  interface political_news_crawler_crawl_attemptsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_crawl_attempts\", 'String'>\n    readonly crawl_job_id: FieldRef<\"political_news_crawler_crawl_attempts\", 'String'>\n    readonly raw_data_storage_id: FieldRef<\"political_news_crawler_crawl_attempts\", 'String'>\n    readonly started_at: FieldRef<\"political_news_crawler_crawl_attempts\", 'DateTime'>\n    readonly completed_at: FieldRef<\"political_news_crawler_crawl_attempts\", 'DateTime'>\n    readonly success: FieldRef<\"political_news_crawler_crawl_attempts\", 'Boolean'>\n    readonly error_message: FieldRef<\"political_news_crawler_crawl_attempts\", 'String'>\n    readonly created_at: FieldRef<\"political_news_crawler_crawl_attempts\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_crawl_attempts\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_crawl_attempts findUnique\n   */\n  export type political_news_crawler_crawl_attemptsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_attempts to fetch.\n     */\n    where: political_news_crawler_crawl_attemptsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts findUniqueOrThrow\n   */\n  export type political_news_crawler_crawl_attemptsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_attempts to fetch.\n     */\n    where: political_news_crawler_crawl_attemptsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts findFirst\n   */\n  export type political_news_crawler_crawl_attemptsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_attempts to fetch.\n     */\n    where?: political_news_crawler_crawl_attemptsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_attempts to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_attemptsOrderByWithRelationInput | political_news_crawler_crawl_attemptsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawl_attempts.\n     */\n    cursor?: political_news_crawler_crawl_attemptsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_attempts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_attempts.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawl_attempts.\n     */\n    distinct?: Political_news_crawler_crawl_attemptsScalarFieldEnum | Political_news_crawler_crawl_attemptsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts findFirstOrThrow\n   */\n  export type political_news_crawler_crawl_attemptsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_attempts to fetch.\n     */\n    where?: political_news_crawler_crawl_attemptsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_attempts to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_attemptsOrderByWithRelationInput | political_news_crawler_crawl_attemptsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawl_attempts.\n     */\n    cursor?: political_news_crawler_crawl_attemptsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_attempts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_attempts.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawl_attempts.\n     */\n    distinct?: Political_news_crawler_crawl_attemptsScalarFieldEnum | Political_news_crawler_crawl_attemptsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts findMany\n   */\n  export type political_news_crawler_crawl_attemptsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_attempts to fetch.\n     */\n    where?: political_news_crawler_crawl_attemptsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_attempts to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_attemptsOrderByWithRelationInput | political_news_crawler_crawl_attemptsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_crawl_attempts.\n     */\n    cursor?: political_news_crawler_crawl_attemptsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_attempts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_attempts.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_crawl_attemptsScalarFieldEnum | Political_news_crawler_crawl_attemptsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts create\n   */\n  export type political_news_crawler_crawl_attemptsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_crawl_attempts.\n     */\n    data: XOR<political_news_crawler_crawl_attemptsCreateInput, political_news_crawler_crawl_attemptsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts createMany\n   */\n  export type political_news_crawler_crawl_attemptsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_crawl_attempts.\n     */\n    data: political_news_crawler_crawl_attemptsCreateManyInput | political_news_crawler_crawl_attemptsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts createManyAndReturn\n   */\n  export type political_news_crawler_crawl_attemptsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_crawl_attempts.\n     */\n    data: political_news_crawler_crawl_attemptsCreateManyInput | political_news_crawler_crawl_attemptsCreateManyInput[]\n    skipDuplicates?: boolean\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsIncludeCreateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts update\n   */\n  export type political_news_crawler_crawl_attemptsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_crawl_attempts.\n     */\n    data: XOR<political_news_crawler_crawl_attemptsUpdateInput, political_news_crawler_crawl_attemptsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_crawl_attempts to update.\n     */\n    where: political_news_crawler_crawl_attemptsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts updateMany\n   */\n  export type political_news_crawler_crawl_attemptsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_crawl_attempts.\n     */\n    data: XOR<political_news_crawler_crawl_attemptsUpdateManyMutationInput, political_news_crawler_crawl_attemptsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawl_attempts to update\n     */\n    where?: political_news_crawler_crawl_attemptsWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_attempts to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts updateManyAndReturn\n   */\n  export type political_news_crawler_crawl_attemptsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_crawl_attempts.\n     */\n    data: XOR<political_news_crawler_crawl_attemptsUpdateManyMutationInput, political_news_crawler_crawl_attemptsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawl_attempts to update\n     */\n    where?: political_news_crawler_crawl_attemptsWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_attempts to update.\n     */\n    limit?: number\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsIncludeUpdateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts upsert\n   */\n  export type political_news_crawler_crawl_attemptsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_crawl_attempts to update in case it exists.\n     */\n    where: political_news_crawler_crawl_attemptsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_crawl_attempts found by the `where` argument doesn't exist, create a new political_news_crawler_crawl_attempts with this data.\n     */\n    create: XOR<political_news_crawler_crawl_attemptsCreateInput, political_news_crawler_crawl_attemptsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_crawl_attempts was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_crawl_attemptsUpdateInput, political_news_crawler_crawl_attemptsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts delete\n   */\n  export type political_news_crawler_crawl_attemptsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_crawl_attempts to delete.\n     */\n    where: political_news_crawler_crawl_attemptsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts deleteMany\n   */\n  export type political_news_crawler_crawl_attemptsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawl_attempts to delete\n     */\n    where?: political_news_crawler_crawl_attemptsWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_attempts to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts.rawDataStorage\n   */\n  export type political_news_crawler_crawl_attempts$rawDataStorageArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageInclude<ExtArgs> | null\n    where?: political_news_crawler_raw_data_storageWhereInput\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts.political_news_crawler_crawled_news\n   */\n  export type political_news_crawler_crawl_attempts$political_news_crawler_crawled_newsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawled_news\n     */\n    select?: political_news_crawler_crawled_newsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawled_news\n     */\n    omit?: political_news_crawler_crawled_newsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawled_newsInclude<ExtArgs> | null\n    where?: political_news_crawler_crawled_newsWhereInput\n    orderBy?: political_news_crawler_crawled_newsOrderByWithRelationInput | political_news_crawler_crawled_newsOrderByWithRelationInput[]\n    cursor?: political_news_crawler_crawled_newsWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_crawled_newsScalarFieldEnum | Political_news_crawler_crawled_newsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_attempts without action\n   */\n  export type political_news_crawler_crawl_attemptsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_crawled_news\n   */\n\n  export type AggregatePolitical_news_crawler_crawled_news = {\n    _count: Political_news_crawler_crawled_newsCountAggregateOutputType | null\n    _min: Political_news_crawler_crawled_newsMinAggregateOutputType | null\n    _max: Political_news_crawler_crawled_newsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_crawled_newsMinAggregateOutputType = {\n    id: string | null\n    crawl_attempt_id: string | null\n    url: string | null\n    title: string | null\n    published_at: Date | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_crawled_newsMaxAggregateOutputType = {\n    id: string | null\n    crawl_attempt_id: string | null\n    url: string | null\n    title: string | null\n    published_at: Date | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_crawled_newsCountAggregateOutputType = {\n    id: number\n    crawl_attempt_id: number\n    url: number\n    title: number\n    published_at: number\n    created_at: number\n    updated_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_crawled_newsMinAggregateInputType = {\n    id?: true\n    crawl_attempt_id?: true\n    url?: true\n    title?: true\n    published_at?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_crawled_newsMaxAggregateInputType = {\n    id?: true\n    crawl_attempt_id?: true\n    url?: true\n    title?: true\n    published_at?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_crawled_newsCountAggregateInputType = {\n    id?: true\n    crawl_attempt_id?: true\n    url?: true\n    title?: true\n    published_at?: true\n    created_at?: true\n    updated_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_crawled_newsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawled_news to aggregate.\n     */\n    where?: political_news_crawler_crawled_newsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawled_news to fetch.\n     */\n    orderBy?: political_news_crawler_crawled_newsOrderByWithRelationInput | political_news_crawler_crawled_newsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_crawled_newsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawled_news from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawled_news.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_crawled_news\n    **/\n    _count?: true | Political_news_crawler_crawled_newsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_crawled_newsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_crawled_newsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_crawled_newsAggregateType<T extends Political_news_crawler_crawled_newsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_crawled_news]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_crawled_news[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_crawled_news[P]>\n  }\n\n\n\n\n  export type political_news_crawler_crawled_newsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawled_newsWhereInput\n    orderBy?: political_news_crawler_crawled_newsOrderByWithAggregationInput | political_news_crawler_crawled_newsOrderByWithAggregationInput[]\n    by: Political_news_crawler_crawled_newsScalarFieldEnum[] | Political_news_crawler_crawled_newsScalarFieldEnum\n    having?: political_news_crawler_crawled_newsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_crawled_newsCountAggregateInputType | true\n    _min?: Political_news_crawler_crawled_newsMinAggregateInputType\n    _max?: Political_news_crawler_crawled_newsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_crawled_newsGroupByOutputType = {\n    id: string\n    crawl_attempt_id: string\n    url: string\n    title: string | null\n    published_at: Date | null\n    created_at: Date\n    updated_at: Date\n    _count: Political_news_crawler_crawled_newsCountAggregateOutputType | null\n    _min: Political_news_crawler_crawled_newsMinAggregateOutputType | null\n    _max: Political_news_crawler_crawled_newsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_crawled_newsGroupByPayload<T extends political_news_crawler_crawled_newsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_crawled_newsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_crawled_newsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_crawled_newsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_crawled_newsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_crawled_newsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_attempt_id?: boolean\n    url?: boolean\n    title?: boolean\n    published_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    crawlAttempt?: boolean | political_news_crawler_crawl_attemptsDefaultArgs<ExtArgs>\n    political_news_crawler_topic_mentions?: boolean | political_news_crawler_crawled_news$political_news_crawler_topic_mentionsArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_crawled_newsCountOutputTypeDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawled_news\"]>\n\n  export type political_news_crawler_crawled_newsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_attempt_id?: boolean\n    url?: boolean\n    title?: boolean\n    published_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    crawlAttempt?: boolean | political_news_crawler_crawl_attemptsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawled_news\"]>\n\n  export type political_news_crawler_crawled_newsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_attempt_id?: boolean\n    url?: boolean\n    title?: boolean\n    published_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    crawlAttempt?: boolean | political_news_crawler_crawl_attemptsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawled_news\"]>\n\n  export type political_news_crawler_crawled_newsSelectScalar = {\n    id?: boolean\n    crawl_attempt_id?: boolean\n    url?: boolean\n    title?: boolean\n    published_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }\n\n  export type political_news_crawler_crawled_newsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"crawl_attempt_id\" | \"url\" | \"title\" | \"published_at\" | \"created_at\" | \"updated_at\", ExtArgs[\"result\"][\"political_news_crawler_crawled_news\"]>\n  export type political_news_crawler_crawled_newsInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlAttempt?: boolean | political_news_crawler_crawl_attemptsDefaultArgs<ExtArgs>\n    political_news_crawler_topic_mentions?: boolean | political_news_crawler_crawled_news$political_news_crawler_topic_mentionsArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_crawled_newsCountOutputTypeDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_crawled_newsIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlAttempt?: boolean | political_news_crawler_crawl_attemptsDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_crawled_newsIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlAttempt?: boolean | political_news_crawler_crawl_attemptsDefaultArgs<ExtArgs>\n  }\n\n  export type $political_news_crawler_crawled_newsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_crawled_news\"\n    objects: {\n      crawlAttempt: Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>\n      political_news_crawler_topic_mentions: Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>[]\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Associated crawl attempt identifier. {@link\n       * political_news_crawler_crawl_attempts.id}\n       */\n      crawl_attempt_id: string\n      /**\n       * URL of the crawled news article.\n       */\n      url: string\n      /**\n       * Title of the news article, if available.\n       */\n      title: string | null\n      /**\n       * Publish timestamp of the news article, if known.\n       */\n      published_at: Date | null\n      /**\n       * Record creation timestamp.\n       */\n      created_at: Date\n      /**\n       * Record last update timestamp.\n       */\n      updated_at: Date\n    }, ExtArgs[\"result\"][\"political_news_crawler_crawled_news\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_crawled_newsGetPayload<S extends boolean | null | undefined | political_news_crawler_crawled_newsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload, S>\n\n  type political_news_crawler_crawled_newsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_crawled_newsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_crawled_newsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_crawled_newsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_crawled_news'], meta: { name: 'political_news_crawler_crawled_news' } }\n    /**\n     * Find zero or one Political_news_crawler_crawled_news that matches the filter.\n     * @param {political_news_crawler_crawled_newsFindUniqueArgs} args - Arguments to find a Political_news_crawler_crawled_news\n     * @example\n     * // Get one Political_news_crawler_crawled_news\n     * const political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_crawled_newsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_crawled_newsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_crawled_newsClient<$Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_crawled_news that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_crawled_newsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_crawled_news\n     * @example\n     * // Get one Political_news_crawler_crawled_news\n     * const political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_crawled_newsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_crawled_newsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawled_newsClient<$Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawled_news that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawled_newsFindFirstArgs} args - Arguments to find a Political_news_crawler_crawled_news\n     * @example\n     * // Get one Political_news_crawler_crawled_news\n     * const political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_crawled_newsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_crawled_newsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_crawled_newsClient<$Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawled_news that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawled_newsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_crawled_news\n     * @example\n     * // Get one Political_news_crawler_crawled_news\n     * const political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_crawled_newsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_crawled_newsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawled_newsClient<$Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_crawled_news that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawled_newsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_crawled_news\n     * const political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.findMany()\n     * \n     * // Get first 10 Political_news_crawler_crawled_news\n     * const political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_crawled_newsWithIdOnly = await prisma.political_news_crawler_crawled_news.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_crawled_newsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_crawled_newsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_crawled_news.\n     * @param {political_news_crawler_crawled_newsCreateArgs} args - Arguments to create a Political_news_crawler_crawled_news.\n     * @example\n     * // Create one Political_news_crawler_crawled_news\n     * const Political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_crawled_news\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_crawled_newsCreateArgs>(args: SelectSubset<T, political_news_crawler_crawled_newsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_crawled_newsClient<$Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_crawled_news.\n     * @param {political_news_crawler_crawled_newsCreateManyArgs} args - Arguments to create many Political_news_crawler_crawled_news.\n     * @example\n     * // Create many Political_news_crawler_crawled_news\n     * const political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_crawled_newsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_crawled_newsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_crawled_news and returns the data saved in the database.\n     * @param {political_news_crawler_crawled_newsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_crawled_news.\n     * @example\n     * // Create many Political_news_crawler_crawled_news\n     * const political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_crawled_news and only return the `id`\n     * const political_news_crawler_crawled_newsWithIdOnly = await prisma.political_news_crawler_crawled_news.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_crawled_newsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_crawled_newsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_crawled_news.\n     * @param {political_news_crawler_crawled_newsDeleteArgs} args - Arguments to delete one Political_news_crawler_crawled_news.\n     * @example\n     * // Delete one Political_news_crawler_crawled_news\n     * const Political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_crawled_news\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_crawled_newsDeleteArgs>(args: SelectSubset<T, political_news_crawler_crawled_newsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_crawled_newsClient<$Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_crawled_news.\n     * @param {political_news_crawler_crawled_newsUpdateArgs} args - Arguments to update one Political_news_crawler_crawled_news.\n     * @example\n     * // Update one Political_news_crawler_crawled_news\n     * const political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_crawled_newsUpdateArgs>(args: SelectSubset<T, political_news_crawler_crawled_newsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_crawled_newsClient<$Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_crawled_news.\n     * @param {political_news_crawler_crawled_newsDeleteManyArgs} args - Arguments to filter Political_news_crawler_crawled_news to delete.\n     * @example\n     * // Delete a few Political_news_crawler_crawled_news\n     * const { count } = await prisma.political_news_crawler_crawled_news.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_crawled_newsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_crawled_newsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawled_news.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawled_newsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_crawled_news\n     * const political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_crawled_newsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_crawled_newsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawled_news and returns the data updated in the database.\n     * @param {political_news_crawler_crawled_newsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_crawled_news.\n     * @example\n     * // Update many Political_news_crawler_crawled_news\n     * const political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_crawled_news and only return the `id`\n     * const political_news_crawler_crawled_newsWithIdOnly = await prisma.political_news_crawler_crawled_news.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_crawled_newsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_crawled_newsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_crawled_news.\n     * @param {political_news_crawler_crawled_newsUpsertArgs} args - Arguments to update or create a Political_news_crawler_crawled_news.\n     * @example\n     * // Update or create a Political_news_crawler_crawled_news\n     * const political_news_crawler_crawled_news = await prisma.political_news_crawler_crawled_news.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_crawled_news\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawled_news we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_crawled_newsUpsertArgs>(args: SelectSubset<T, political_news_crawler_crawled_newsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_crawled_newsClient<$Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_crawled_news.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawled_newsCountArgs} args - Arguments to filter Political_news_crawler_crawled_news to count.\n     * @example\n     * // Count the number of Political_news_crawler_crawled_news\n     * const count = await prisma.political_news_crawler_crawled_news.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawled_news we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_crawled_newsCountArgs>(\n      args?: Subset<T, political_news_crawler_crawled_newsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_crawled_newsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_crawled_news.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_crawled_newsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_crawled_newsAggregateArgs>(args: Subset<T, Political_news_crawler_crawled_newsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_crawled_newsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_crawled_news.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawled_newsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_crawled_newsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_crawled_newsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_crawled_newsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_crawled_newsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_crawled_newsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_crawled_news model\n   */\n  readonly fields: political_news_crawler_crawled_newsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_crawled_news.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_crawled_newsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    crawlAttempt<T extends political_news_crawler_crawl_attemptsDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_attemptsDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_attemptsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    political_news_crawler_topic_mentions<T extends political_news_crawler_crawled_news$political_news_crawler_topic_mentionsArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawled_news$political_news_crawler_topic_mentionsArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_crawled_news model\n   */\n  interface political_news_crawler_crawled_newsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_crawled_news\", 'String'>\n    readonly crawl_attempt_id: FieldRef<\"political_news_crawler_crawled_news\", 'String'>\n    readonly url: FieldRef<\"political_news_crawler_crawled_news\", 'String'>\n    readonly title: FieldRef<\"political_news_crawler_crawled_news\", 'String'>\n    readonly published_at: FieldRef<\"political_news_crawler_crawled_news\", 'DateTime'>\n    readonly created_at: FieldRef<\"political_news_crawler_crawled_news\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_crawled_news\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_crawled_news findUnique\n   */\n  export type political_news_crawler_crawled_newsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawled_news\n     */\n    select?: political_news_crawler_crawled_newsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawled_news\n     */\n    omit?: political_news_crawler_crawled_newsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawled_newsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawled_news to fetch.\n     */\n    where: political_news_crawler_crawled_newsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawled_news findUniqueOrThrow\n   */\n  export type political_news_crawler_crawled_newsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawled_news\n     */\n    select?: political_news_crawler_crawled_newsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawled_news\n     */\n    omit?: political_news_crawler_crawled_newsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawled_newsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawled_news to fetch.\n     */\n    where: political_news_crawler_crawled_newsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawled_news findFirst\n   */\n  export type political_news_crawler_crawled_newsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawled_news\n     */\n    select?: political_news_crawler_crawled_newsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawled_news\n     */\n    omit?: political_news_crawler_crawled_newsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawled_newsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawled_news to fetch.\n     */\n    where?: political_news_crawler_crawled_newsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawled_news to fetch.\n     */\n    orderBy?: political_news_crawler_crawled_newsOrderByWithRelationInput | political_news_crawler_crawled_newsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawled_news.\n     */\n    cursor?: political_news_crawler_crawled_newsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawled_news from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawled_news.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawled_news.\n     */\n    distinct?: Political_news_crawler_crawled_newsScalarFieldEnum | Political_news_crawler_crawled_newsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawled_news findFirstOrThrow\n   */\n  export type political_news_crawler_crawled_newsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawled_news\n     */\n    select?: political_news_crawler_crawled_newsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawled_news\n     */\n    omit?: political_news_crawler_crawled_newsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawled_newsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawled_news to fetch.\n     */\n    where?: political_news_crawler_crawled_newsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawled_news to fetch.\n     */\n    orderBy?: political_news_crawler_crawled_newsOrderByWithRelationInput | political_news_crawler_crawled_newsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawled_news.\n     */\n    cursor?: political_news_crawler_crawled_newsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawled_news from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawled_news.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawled_news.\n     */\n    distinct?: Political_news_crawler_crawled_newsScalarFieldEnum | Political_news_crawler_crawled_newsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawled_news findMany\n   */\n  export type political_news_crawler_crawled_newsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawled_news\n     */\n    select?: political_news_crawler_crawled_newsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawled_news\n     */\n    omit?: political_news_crawler_crawled_newsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawled_newsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawled_news to fetch.\n     */\n    where?: political_news_crawler_crawled_newsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawled_news to fetch.\n     */\n    orderBy?: political_news_crawler_crawled_newsOrderByWithRelationInput | political_news_crawler_crawled_newsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_crawled_news.\n     */\n    cursor?: political_news_crawler_crawled_newsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawled_news from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawled_news.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_crawled_newsScalarFieldEnum | Political_news_crawler_crawled_newsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawled_news create\n   */\n  export type political_news_crawler_crawled_newsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawled_news\n     */\n    select?: political_news_crawler_crawled_newsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawled_news\n     */\n    omit?: political_news_crawler_crawled_newsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawled_newsInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_crawled_news.\n     */\n    data: XOR<political_news_crawler_crawled_newsCreateInput, political_news_crawler_crawled_newsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_crawled_news createMany\n   */\n  export type political_news_crawler_crawled_newsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_crawled_news.\n     */\n    data: political_news_crawler_crawled_newsCreateManyInput | political_news_crawler_crawled_newsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_crawled_news createManyAndReturn\n   */\n  export type political_news_crawler_crawled_newsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawled_news\n     */\n    select?: political_news_crawler_crawled_newsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawled_news\n     */\n    omit?: political_news_crawler_crawled_newsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_crawled_news.\n     */\n    data: political_news_crawler_crawled_newsCreateManyInput | political_news_crawler_crawled_newsCreateManyInput[]\n    skipDuplicates?: boolean\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawled_newsIncludeCreateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_crawled_news update\n   */\n  export type political_news_crawler_crawled_newsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawled_news\n     */\n    select?: political_news_crawler_crawled_newsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawled_news\n     */\n    omit?: political_news_crawler_crawled_newsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawled_newsInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_crawled_news.\n     */\n    data: XOR<political_news_crawler_crawled_newsUpdateInput, political_news_crawler_crawled_newsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_crawled_news to update.\n     */\n    where: political_news_crawler_crawled_newsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawled_news updateMany\n   */\n  export type political_news_crawler_crawled_newsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_crawled_news.\n     */\n    data: XOR<political_news_crawler_crawled_newsUpdateManyMutationInput, political_news_crawler_crawled_newsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawled_news to update\n     */\n    where?: political_news_crawler_crawled_newsWhereInput\n    /**\n     * Limit how many political_news_crawler_crawled_news to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawled_news updateManyAndReturn\n   */\n  export type political_news_crawler_crawled_newsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawled_news\n     */\n    select?: political_news_crawler_crawled_newsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawled_news\n     */\n    omit?: political_news_crawler_crawled_newsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_crawled_news.\n     */\n    data: XOR<political_news_crawler_crawled_newsUpdateManyMutationInput, political_news_crawler_crawled_newsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawled_news to update\n     */\n    where?: political_news_crawler_crawled_newsWhereInput\n    /**\n     * Limit how many political_news_crawler_crawled_news to update.\n     */\n    limit?: number\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawled_newsIncludeUpdateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_crawled_news upsert\n   */\n  export type political_news_crawler_crawled_newsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawled_news\n     */\n    select?: political_news_crawler_crawled_newsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawled_news\n     */\n    omit?: political_news_crawler_crawled_newsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawled_newsInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_crawled_news to update in case it exists.\n     */\n    where: political_news_crawler_crawled_newsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_crawled_news found by the `where` argument doesn't exist, create a new political_news_crawler_crawled_news with this data.\n     */\n    create: XOR<political_news_crawler_crawled_newsCreateInput, political_news_crawler_crawled_newsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_crawled_news was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_crawled_newsUpdateInput, political_news_crawler_crawled_newsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_crawled_news delete\n   */\n  export type political_news_crawler_crawled_newsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawled_news\n     */\n    select?: political_news_crawler_crawled_newsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawled_news\n     */\n    omit?: political_news_crawler_crawled_newsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawled_newsInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_crawled_news to delete.\n     */\n    where: political_news_crawler_crawled_newsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawled_news deleteMany\n   */\n  export type political_news_crawler_crawled_newsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawled_news to delete\n     */\n    where?: political_news_crawler_crawled_newsWhereInput\n    /**\n     * Limit how many political_news_crawler_crawled_news to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawled_news.political_news_crawler_topic_mentions\n   */\n  export type political_news_crawler_crawled_news$political_news_crawler_topic_mentionsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsInclude<ExtArgs> | null\n    where?: political_news_crawler_topic_mentionsWhereInput\n    orderBy?: political_news_crawler_topic_mentionsOrderByWithRelationInput | political_news_crawler_topic_mentionsOrderByWithRelationInput[]\n    cursor?: political_news_crawler_topic_mentionsWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_topic_mentionsScalarFieldEnum | Political_news_crawler_topic_mentionsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawled_news without action\n   */\n  export type political_news_crawler_crawled_newsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawled_news\n     */\n    select?: political_news_crawler_crawled_newsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawled_news\n     */\n    omit?: political_news_crawler_crawled_newsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawled_newsInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_raw_data_storage\n   */\n\n  export type AggregatePolitical_news_crawler_raw_data_storage = {\n    _count: Political_news_crawler_raw_data_storageCountAggregateOutputType | null\n    _avg: Political_news_crawler_raw_data_storageAvgAggregateOutputType | null\n    _sum: Political_news_crawler_raw_data_storageSumAggregateOutputType | null\n    _min: Political_news_crawler_raw_data_storageMinAggregateOutputType | null\n    _max: Political_news_crawler_raw_data_storageMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_raw_data_storageAvgAggregateOutputType = {\n    file_size_bytes: number | null\n  }\n\n  export type Political_news_crawler_raw_data_storageSumAggregateOutputType = {\n    file_size_bytes: number | null\n  }\n\n  export type Political_news_crawler_raw_data_storageMinAggregateOutputType = {\n    id: string | null\n    crawl_source_id: string | null\n    crawl_job_id: string | null\n    storage_key: string | null\n    file_format: string | null\n    file_size_bytes: number | null\n    checksum: string | null\n    crawl_timestamp: Date | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_raw_data_storageMaxAggregateOutputType = {\n    id: string | null\n    crawl_source_id: string | null\n    crawl_job_id: string | null\n    storage_key: string | null\n    file_format: string | null\n    file_size_bytes: number | null\n    checksum: string | null\n    crawl_timestamp: Date | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_raw_data_storageCountAggregateOutputType = {\n    id: number\n    crawl_source_id: number\n    crawl_job_id: number\n    storage_key: number\n    file_format: number\n    file_size_bytes: number\n    checksum: number\n    crawl_timestamp: number\n    created_at: number\n    updated_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_raw_data_storageAvgAggregateInputType = {\n    file_size_bytes?: true\n  }\n\n  export type Political_news_crawler_raw_data_storageSumAggregateInputType = {\n    file_size_bytes?: true\n  }\n\n  export type Political_news_crawler_raw_data_storageMinAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    crawl_job_id?: true\n    storage_key?: true\n    file_format?: true\n    file_size_bytes?: true\n    checksum?: true\n    crawl_timestamp?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_raw_data_storageMaxAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    crawl_job_id?: true\n    storage_key?: true\n    file_format?: true\n    file_size_bytes?: true\n    checksum?: true\n    crawl_timestamp?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_raw_data_storageCountAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    crawl_job_id?: true\n    storage_key?: true\n    file_format?: true\n    file_size_bytes?: true\n    checksum?: true\n    crawl_timestamp?: true\n    created_at?: true\n    updated_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_raw_data_storageAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_raw_data_storage to aggregate.\n     */\n    where?: political_news_crawler_raw_data_storageWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_raw_data_storages to fetch.\n     */\n    orderBy?: political_news_crawler_raw_data_storageOrderByWithRelationInput | political_news_crawler_raw_data_storageOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_raw_data_storageWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_raw_data_storages from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_raw_data_storages.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_raw_data_storages\n    **/\n    _count?: true | Political_news_crawler_raw_data_storageCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to average\n    **/\n    _avg?: Political_news_crawler_raw_data_storageAvgAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to sum\n    **/\n    _sum?: Political_news_crawler_raw_data_storageSumAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_raw_data_storageMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_raw_data_storageMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_raw_data_storageAggregateType<T extends Political_news_crawler_raw_data_storageAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_raw_data_storage]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_raw_data_storage[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_raw_data_storage[P]>\n  }\n\n\n\n\n  export type political_news_crawler_raw_data_storageGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_raw_data_storageWhereInput\n    orderBy?: political_news_crawler_raw_data_storageOrderByWithAggregationInput | political_news_crawler_raw_data_storageOrderByWithAggregationInput[]\n    by: Political_news_crawler_raw_data_storageScalarFieldEnum[] | Political_news_crawler_raw_data_storageScalarFieldEnum\n    having?: political_news_crawler_raw_data_storageScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_raw_data_storageCountAggregateInputType | true\n    _avg?: Political_news_crawler_raw_data_storageAvgAggregateInputType\n    _sum?: Political_news_crawler_raw_data_storageSumAggregateInputType\n    _min?: Political_news_crawler_raw_data_storageMinAggregateInputType\n    _max?: Political_news_crawler_raw_data_storageMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_raw_data_storageGroupByOutputType = {\n    id: string\n    crawl_source_id: string\n    crawl_job_id: string | null\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum: string | null\n    crawl_timestamp: Date\n    created_at: Date\n    updated_at: Date\n    _count: Political_news_crawler_raw_data_storageCountAggregateOutputType | null\n    _avg: Political_news_crawler_raw_data_storageAvgAggregateOutputType | null\n    _sum: Political_news_crawler_raw_data_storageSumAggregateOutputType | null\n    _min: Political_news_crawler_raw_data_storageMinAggregateOutputType | null\n    _max: Political_news_crawler_raw_data_storageMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_raw_data_storageGroupByPayload<T extends political_news_crawler_raw_data_storageGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_raw_data_storageGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_raw_data_storageGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_raw_data_storageGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_raw_data_storageGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_raw_data_storageSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    crawl_job_id?: boolean\n    storage_key?: boolean\n    file_format?: boolean\n    file_size_bytes?: boolean\n    checksum?: boolean\n    crawl_timestamp?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlJob?: boolean | political_news_crawler_raw_data_storage$crawlJobArgs<ExtArgs>\n    political_news_crawler_crawl_attempts?: boolean | political_news_crawler_raw_data_storage$political_news_crawler_crawl_attemptsArgs<ExtArgs>\n    political_news_crawler_local_cache_files?: boolean | political_news_crawler_raw_data_storage$political_news_crawler_local_cache_filesArgs<ExtArgs>\n    political_news_crawler_processed_content?: boolean | political_news_crawler_raw_data_storage$political_news_crawler_processed_contentArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_raw_data_storageCountOutputTypeDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_raw_data_storage\"]>\n\n  export type political_news_crawler_raw_data_storageSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    crawl_job_id?: boolean\n    storage_key?: boolean\n    file_format?: boolean\n    file_size_bytes?: boolean\n    checksum?: boolean\n    crawl_timestamp?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlJob?: boolean | political_news_crawler_raw_data_storage$crawlJobArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_raw_data_storage\"]>\n\n  export type political_news_crawler_raw_data_storageSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    crawl_job_id?: boolean\n    storage_key?: boolean\n    file_format?: boolean\n    file_size_bytes?: boolean\n    checksum?: boolean\n    crawl_timestamp?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlJob?: boolean | political_news_crawler_raw_data_storage$crawlJobArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_raw_data_storage\"]>\n\n  export type political_news_crawler_raw_data_storageSelectScalar = {\n    id?: boolean\n    crawl_source_id?: boolean\n    crawl_job_id?: boolean\n    storage_key?: boolean\n    file_format?: boolean\n    file_size_bytes?: boolean\n    checksum?: boolean\n    crawl_timestamp?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }\n\n  export type political_news_crawler_raw_data_storageOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"crawl_source_id\" | \"crawl_job_id\" | \"storage_key\" | \"file_format\" | \"file_size_bytes\" | \"checksum\" | \"crawl_timestamp\" | \"created_at\" | \"updated_at\", ExtArgs[\"result\"][\"political_news_crawler_raw_data_storage\"]>\n  export type political_news_crawler_raw_data_storageInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlJob?: boolean | political_news_crawler_raw_data_storage$crawlJobArgs<ExtArgs>\n    political_news_crawler_crawl_attempts?: boolean | political_news_crawler_raw_data_storage$political_news_crawler_crawl_attemptsArgs<ExtArgs>\n    political_news_crawler_local_cache_files?: boolean | political_news_crawler_raw_data_storage$political_news_crawler_local_cache_filesArgs<ExtArgs>\n    political_news_crawler_processed_content?: boolean | political_news_crawler_raw_data_storage$political_news_crawler_processed_contentArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_raw_data_storageCountOutputTypeDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_raw_data_storageIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlJob?: boolean | political_news_crawler_raw_data_storage$crawlJobArgs<ExtArgs>\n  }\n  export type political_news_crawler_raw_data_storageIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    crawlJob?: boolean | political_news_crawler_raw_data_storage$crawlJobArgs<ExtArgs>\n  }\n\n  export type $political_news_crawler_raw_data_storagePayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_raw_data_storage\"\n    objects: {\n      crawlSource: Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>\n      crawlJob: Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs> | null\n      political_news_crawler_crawl_attempts: Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>[]\n      political_news_crawler_local_cache_files: Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>[]\n      political_news_crawler_processed_content: Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>[]\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Belonged crawl source's political_news_crawler_crawl_sources.id.\n       */\n      crawl_source_id: string\n      /**\n       * Optional crawl job reference to political_news_crawler_crawl_jobs.id.\n       */\n      crawl_job_id: string | null\n      /**\n       * Unique key or path identifying storage location in cloud object storage\n       * (e.g., GCP or AWS S3).\n       */\n      storage_key: string\n      /**\n       * Format of the raw data file such as JSON or XML for processing\n       * compatibility.\n       */\n      file_format: string\n      /**\n       * Size of the raw data file in bytes.\n       */\n      file_size_bytes: number\n      /**\n       * Checksum hash to verify file integrity.\n       */\n      checksum: string | null\n      /**\n       * Timestamp when the raw data was crawled, used for data freshness and\n       * scheduling.\n       */\n      crawl_timestamp: Date\n      /**\n       * Creation timestamp record.\n       */\n      created_at: Date\n      /**\n       * Last update timestamp record.\n       */\n      updated_at: Date\n    }, ExtArgs[\"result\"][\"political_news_crawler_raw_data_storage\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_raw_data_storageGetPayload<S extends boolean | null | undefined | political_news_crawler_raw_data_storageDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload, S>\n\n  type political_news_crawler_raw_data_storageCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_raw_data_storageFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_raw_data_storageCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_raw_data_storageDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_raw_data_storage'], meta: { name: 'political_news_crawler_raw_data_storage' } }\n    /**\n     * Find zero or one Political_news_crawler_raw_data_storage that matches the filter.\n     * @param {political_news_crawler_raw_data_storageFindUniqueArgs} args - Arguments to find a Political_news_crawler_raw_data_storage\n     * @example\n     * // Get one Political_news_crawler_raw_data_storage\n     * const political_news_crawler_raw_data_storage = await prisma.political_news_crawler_raw_data_storage.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_raw_data_storageFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_raw_data_storageFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_raw_data_storageClient<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_raw_data_storage that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_raw_data_storageFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_raw_data_storage\n     * @example\n     * // Get one Political_news_crawler_raw_data_storage\n     * const political_news_crawler_raw_data_storage = await prisma.political_news_crawler_raw_data_storage.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_raw_data_storageFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_raw_data_storageFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_raw_data_storageClient<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_raw_data_storage that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_raw_data_storageFindFirstArgs} args - Arguments to find a Political_news_crawler_raw_data_storage\n     * @example\n     * // Get one Political_news_crawler_raw_data_storage\n     * const political_news_crawler_raw_data_storage = await prisma.political_news_crawler_raw_data_storage.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_raw_data_storageFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_raw_data_storageFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_raw_data_storageClient<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_raw_data_storage that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_raw_data_storageFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_raw_data_storage\n     * @example\n     * // Get one Political_news_crawler_raw_data_storage\n     * const political_news_crawler_raw_data_storage = await prisma.political_news_crawler_raw_data_storage.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_raw_data_storageFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_raw_data_storageFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_raw_data_storageClient<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_raw_data_storages that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_raw_data_storageFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_raw_data_storages\n     * const political_news_crawler_raw_data_storages = await prisma.political_news_crawler_raw_data_storage.findMany()\n     * \n     * // Get first 10 Political_news_crawler_raw_data_storages\n     * const political_news_crawler_raw_data_storages = await prisma.political_news_crawler_raw_data_storage.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_raw_data_storageWithIdOnly = await prisma.political_news_crawler_raw_data_storage.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_raw_data_storageFindManyArgs>(args?: SelectSubset<T, political_news_crawler_raw_data_storageFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_raw_data_storage.\n     * @param {political_news_crawler_raw_data_storageCreateArgs} args - Arguments to create a Political_news_crawler_raw_data_storage.\n     * @example\n     * // Create one Political_news_crawler_raw_data_storage\n     * const Political_news_crawler_raw_data_storage = await prisma.political_news_crawler_raw_data_storage.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_raw_data_storage\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_raw_data_storageCreateArgs>(args: SelectSubset<T, political_news_crawler_raw_data_storageCreateArgs<ExtArgs>>): Prisma__political_news_crawler_raw_data_storageClient<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_raw_data_storages.\n     * @param {political_news_crawler_raw_data_storageCreateManyArgs} args - Arguments to create many Political_news_crawler_raw_data_storages.\n     * @example\n     * // Create many Political_news_crawler_raw_data_storages\n     * const political_news_crawler_raw_data_storage = await prisma.political_news_crawler_raw_data_storage.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_raw_data_storageCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_raw_data_storageCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_raw_data_storages and returns the data saved in the database.\n     * @param {political_news_crawler_raw_data_storageCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_raw_data_storages.\n     * @example\n     * // Create many Political_news_crawler_raw_data_storages\n     * const political_news_crawler_raw_data_storage = await prisma.political_news_crawler_raw_data_storage.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_raw_data_storages and only return the `id`\n     * const political_news_crawler_raw_data_storageWithIdOnly = await prisma.political_news_crawler_raw_data_storage.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_raw_data_storageCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_raw_data_storageCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_raw_data_storage.\n     * @param {political_news_crawler_raw_data_storageDeleteArgs} args - Arguments to delete one Political_news_crawler_raw_data_storage.\n     * @example\n     * // Delete one Political_news_crawler_raw_data_storage\n     * const Political_news_crawler_raw_data_storage = await prisma.political_news_crawler_raw_data_storage.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_raw_data_storage\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_raw_data_storageDeleteArgs>(args: SelectSubset<T, political_news_crawler_raw_data_storageDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_raw_data_storageClient<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_raw_data_storage.\n     * @param {political_news_crawler_raw_data_storageUpdateArgs} args - Arguments to update one Political_news_crawler_raw_data_storage.\n     * @example\n     * // Update one Political_news_crawler_raw_data_storage\n     * const political_news_crawler_raw_data_storage = await prisma.political_news_crawler_raw_data_storage.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_raw_data_storageUpdateArgs>(args: SelectSubset<T, political_news_crawler_raw_data_storageUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_raw_data_storageClient<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_raw_data_storages.\n     * @param {political_news_crawler_raw_data_storageDeleteManyArgs} args - Arguments to filter Political_news_crawler_raw_data_storages to delete.\n     * @example\n     * // Delete a few Political_news_crawler_raw_data_storages\n     * const { count } = await prisma.political_news_crawler_raw_data_storage.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_raw_data_storageDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_raw_data_storageDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_raw_data_storages.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_raw_data_storageUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_raw_data_storages\n     * const political_news_crawler_raw_data_storage = await prisma.political_news_crawler_raw_data_storage.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_raw_data_storageUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_raw_data_storageUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_raw_data_storages and returns the data updated in the database.\n     * @param {political_news_crawler_raw_data_storageUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_raw_data_storages.\n     * @example\n     * // Update many Political_news_crawler_raw_data_storages\n     * const political_news_crawler_raw_data_storage = await prisma.political_news_crawler_raw_data_storage.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_raw_data_storages and only return the `id`\n     * const political_news_crawler_raw_data_storageWithIdOnly = await prisma.political_news_crawler_raw_data_storage.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_raw_data_storageUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_raw_data_storageUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_raw_data_storage.\n     * @param {political_news_crawler_raw_data_storageUpsertArgs} args - Arguments to update or create a Political_news_crawler_raw_data_storage.\n     * @example\n     * // Update or create a Political_news_crawler_raw_data_storage\n     * const political_news_crawler_raw_data_storage = await prisma.political_news_crawler_raw_data_storage.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_raw_data_storage\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_raw_data_storage we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_raw_data_storageUpsertArgs>(args: SelectSubset<T, political_news_crawler_raw_data_storageUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_raw_data_storageClient<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_raw_data_storages.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_raw_data_storageCountArgs} args - Arguments to filter Political_news_crawler_raw_data_storages to count.\n     * @example\n     * // Count the number of Political_news_crawler_raw_data_storages\n     * const count = await prisma.political_news_crawler_raw_data_storage.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_raw_data_storages we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_raw_data_storageCountArgs>(\n      args?: Subset<T, political_news_crawler_raw_data_storageCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_raw_data_storageCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_raw_data_storage.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_raw_data_storageAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_raw_data_storageAggregateArgs>(args: Subset<T, Political_news_crawler_raw_data_storageAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_raw_data_storageAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_raw_data_storage.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_raw_data_storageGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_raw_data_storageGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_raw_data_storageGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_raw_data_storageGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_raw_data_storageGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_raw_data_storageGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_raw_data_storage model\n   */\n  readonly fields: political_news_crawler_raw_data_storageFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_raw_data_storage.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_raw_data_storageClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    crawlSource<T extends political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_sourcesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    crawlJob<T extends political_news_crawler_raw_data_storage$crawlJobArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_raw_data_storage$crawlJobArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_jobsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n    political_news_crawler_crawl_attempts<T extends political_news_crawler_raw_data_storage$political_news_crawler_crawl_attemptsArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_raw_data_storage$political_news_crawler_crawl_attemptsArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_attemptsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    political_news_crawler_local_cache_files<T extends political_news_crawler_raw_data_storage$political_news_crawler_local_cache_filesArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_raw_data_storage$political_news_crawler_local_cache_filesArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    political_news_crawler_processed_content<T extends political_news_crawler_raw_data_storage$political_news_crawler_processed_contentArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_raw_data_storage$political_news_crawler_processed_contentArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_raw_data_storage model\n   */\n  interface political_news_crawler_raw_data_storageFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_raw_data_storage\", 'String'>\n    readonly crawl_source_id: FieldRef<\"political_news_crawler_raw_data_storage\", 'String'>\n    readonly crawl_job_id: FieldRef<\"political_news_crawler_raw_data_storage\", 'String'>\n    readonly storage_key: FieldRef<\"political_news_crawler_raw_data_storage\", 'String'>\n    readonly file_format: FieldRef<\"political_news_crawler_raw_data_storage\", 'String'>\n    readonly file_size_bytes: FieldRef<\"political_news_crawler_raw_data_storage\", 'Int'>\n    readonly checksum: FieldRef<\"political_news_crawler_raw_data_storage\", 'String'>\n    readonly crawl_timestamp: FieldRef<\"political_news_crawler_raw_data_storage\", 'DateTime'>\n    readonly created_at: FieldRef<\"political_news_crawler_raw_data_storage\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_raw_data_storage\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_raw_data_storage findUnique\n   */\n  export type political_news_crawler_raw_data_storageFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_raw_data_storage to fetch.\n     */\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage findUniqueOrThrow\n   */\n  export type political_news_crawler_raw_data_storageFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_raw_data_storage to fetch.\n     */\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage findFirst\n   */\n  export type political_news_crawler_raw_data_storageFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_raw_data_storage to fetch.\n     */\n    where?: political_news_crawler_raw_data_storageWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_raw_data_storages to fetch.\n     */\n    orderBy?: political_news_crawler_raw_data_storageOrderByWithRelationInput | political_news_crawler_raw_data_storageOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_raw_data_storages.\n     */\n    cursor?: political_news_crawler_raw_data_storageWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_raw_data_storages from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_raw_data_storages.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_raw_data_storages.\n     */\n    distinct?: Political_news_crawler_raw_data_storageScalarFieldEnum | Political_news_crawler_raw_data_storageScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage findFirstOrThrow\n   */\n  export type political_news_crawler_raw_data_storageFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_raw_data_storage to fetch.\n     */\n    where?: political_news_crawler_raw_data_storageWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_raw_data_storages to fetch.\n     */\n    orderBy?: political_news_crawler_raw_data_storageOrderByWithRelationInput | political_news_crawler_raw_data_storageOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_raw_data_storages.\n     */\n    cursor?: political_news_crawler_raw_data_storageWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_raw_data_storages from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_raw_data_storages.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_raw_data_storages.\n     */\n    distinct?: Political_news_crawler_raw_data_storageScalarFieldEnum | Political_news_crawler_raw_data_storageScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage findMany\n   */\n  export type political_news_crawler_raw_data_storageFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_raw_data_storages to fetch.\n     */\n    where?: political_news_crawler_raw_data_storageWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_raw_data_storages to fetch.\n     */\n    orderBy?: political_news_crawler_raw_data_storageOrderByWithRelationInput | political_news_crawler_raw_data_storageOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_raw_data_storages.\n     */\n    cursor?: political_news_crawler_raw_data_storageWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_raw_data_storages from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_raw_data_storages.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_raw_data_storageScalarFieldEnum | Political_news_crawler_raw_data_storageScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage create\n   */\n  export type political_news_crawler_raw_data_storageCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_raw_data_storage.\n     */\n    data: XOR<political_news_crawler_raw_data_storageCreateInput, political_news_crawler_raw_data_storageUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage createMany\n   */\n  export type political_news_crawler_raw_data_storageCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_raw_data_storages.\n     */\n    data: political_news_crawler_raw_data_storageCreateManyInput | political_news_crawler_raw_data_storageCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage createManyAndReturn\n   */\n  export type political_news_crawler_raw_data_storageCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_raw_data_storages.\n     */\n    data: political_news_crawler_raw_data_storageCreateManyInput | political_news_crawler_raw_data_storageCreateManyInput[]\n    skipDuplicates?: boolean\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageIncludeCreateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage update\n   */\n  export type political_news_crawler_raw_data_storageUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_raw_data_storage.\n     */\n    data: XOR<political_news_crawler_raw_data_storageUpdateInput, political_news_crawler_raw_data_storageUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_raw_data_storage to update.\n     */\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage updateMany\n   */\n  export type political_news_crawler_raw_data_storageUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_raw_data_storages.\n     */\n    data: XOR<political_news_crawler_raw_data_storageUpdateManyMutationInput, political_news_crawler_raw_data_storageUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_raw_data_storages to update\n     */\n    where?: political_news_crawler_raw_data_storageWhereInput\n    /**\n     * Limit how many political_news_crawler_raw_data_storages to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage updateManyAndReturn\n   */\n  export type political_news_crawler_raw_data_storageUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_raw_data_storages.\n     */\n    data: XOR<political_news_crawler_raw_data_storageUpdateManyMutationInput, political_news_crawler_raw_data_storageUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_raw_data_storages to update\n     */\n    where?: political_news_crawler_raw_data_storageWhereInput\n    /**\n     * Limit how many political_news_crawler_raw_data_storages to update.\n     */\n    limit?: number\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageIncludeUpdateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage upsert\n   */\n  export type political_news_crawler_raw_data_storageUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_raw_data_storage to update in case it exists.\n     */\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n    /**\n     * In case the political_news_crawler_raw_data_storage found by the `where` argument doesn't exist, create a new political_news_crawler_raw_data_storage with this data.\n     */\n    create: XOR<political_news_crawler_raw_data_storageCreateInput, political_news_crawler_raw_data_storageUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_raw_data_storage was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_raw_data_storageUpdateInput, political_news_crawler_raw_data_storageUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage delete\n   */\n  export type political_news_crawler_raw_data_storageDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_raw_data_storage to delete.\n     */\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage deleteMany\n   */\n  export type political_news_crawler_raw_data_storageDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_raw_data_storages to delete\n     */\n    where?: political_news_crawler_raw_data_storageWhereInput\n    /**\n     * Limit how many political_news_crawler_raw_data_storages to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage.crawlJob\n   */\n  export type political_news_crawler_raw_data_storage$crawlJobArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_jobs\n     */\n    select?: political_news_crawler_crawl_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_jobs\n     */\n    omit?: political_news_crawler_crawl_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_jobsInclude<ExtArgs> | null\n    where?: political_news_crawler_crawl_jobsWhereInput\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage.political_news_crawler_crawl_attempts\n   */\n  export type political_news_crawler_raw_data_storage$political_news_crawler_crawl_attemptsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_attempts\n     */\n    select?: political_news_crawler_crawl_attemptsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_attempts\n     */\n    omit?: political_news_crawler_crawl_attemptsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_attemptsInclude<ExtArgs> | null\n    where?: political_news_crawler_crawl_attemptsWhereInput\n    orderBy?: political_news_crawler_crawl_attemptsOrderByWithRelationInput | political_news_crawler_crawl_attemptsOrderByWithRelationInput[]\n    cursor?: political_news_crawler_crawl_attemptsWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_crawl_attemptsScalarFieldEnum | Political_news_crawler_crawl_attemptsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage.political_news_crawler_local_cache_files\n   */\n  export type political_news_crawler_raw_data_storage$political_news_crawler_local_cache_filesArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_local_cache_files\n     */\n    select?: political_news_crawler_local_cache_filesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_local_cache_files\n     */\n    omit?: political_news_crawler_local_cache_filesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_local_cache_filesInclude<ExtArgs> | null\n    where?: political_news_crawler_local_cache_filesWhereInput\n    orderBy?: political_news_crawler_local_cache_filesOrderByWithRelationInput | political_news_crawler_local_cache_filesOrderByWithRelationInput[]\n    cursor?: political_news_crawler_local_cache_filesWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_local_cache_filesScalarFieldEnum | Political_news_crawler_local_cache_filesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage.political_news_crawler_processed_content\n   */\n  export type political_news_crawler_raw_data_storage$political_news_crawler_processed_contentArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentInclude<ExtArgs> | null\n    where?: political_news_crawler_processed_contentWhereInput\n    orderBy?: political_news_crawler_processed_contentOrderByWithRelationInput | political_news_crawler_processed_contentOrderByWithRelationInput[]\n    cursor?: political_news_crawler_processed_contentWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_processed_contentScalarFieldEnum | Political_news_crawler_processed_contentScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_raw_data_storage without action\n   */\n  export type political_news_crawler_raw_data_storageDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_raw_data_storage\n     */\n    select?: political_news_crawler_raw_data_storageSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_raw_data_storage\n     */\n    omit?: political_news_crawler_raw_data_storageOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_raw_data_storageInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_local_cache_files\n   */\n\n  export type AggregatePolitical_news_crawler_local_cache_files = {\n    _count: Political_news_crawler_local_cache_filesCountAggregateOutputType | null\n    _avg: Political_news_crawler_local_cache_filesAvgAggregateOutputType | null\n    _sum: Political_news_crawler_local_cache_filesSumAggregateOutputType | null\n    _min: Political_news_crawler_local_cache_filesMinAggregateOutputType | null\n    _max: Political_news_crawler_local_cache_filesMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_local_cache_filesAvgAggregateOutputType = {\n    file_size_bytes: number | null\n  }\n\n  export type Political_news_crawler_local_cache_filesSumAggregateOutputType = {\n    file_size_bytes: number | null\n  }\n\n  export type Political_news_crawler_local_cache_filesMinAggregateOutputType = {\n    id: string | null\n    raw_data_storage_id: string | null\n    local_file_path: string | null\n    file_size_bytes: number | null\n    ttl_expiration_at: Date | null\n    deleted_at: Date | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_local_cache_filesMaxAggregateOutputType = {\n    id: string | null\n    raw_data_storage_id: string | null\n    local_file_path: string | null\n    file_size_bytes: number | null\n    ttl_expiration_at: Date | null\n    deleted_at: Date | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_local_cache_filesCountAggregateOutputType = {\n    id: number\n    raw_data_storage_id: number\n    local_file_path: number\n    file_size_bytes: number\n    ttl_expiration_at: number\n    deleted_at: number\n    created_at: number\n    updated_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_local_cache_filesAvgAggregateInputType = {\n    file_size_bytes?: true\n  }\n\n  export type Political_news_crawler_local_cache_filesSumAggregateInputType = {\n    file_size_bytes?: true\n  }\n\n  export type Political_news_crawler_local_cache_filesMinAggregateInputType = {\n    id?: true\n    raw_data_storage_id?: true\n    local_file_path?: true\n    file_size_bytes?: true\n    ttl_expiration_at?: true\n    deleted_at?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_local_cache_filesMaxAggregateInputType = {\n    id?: true\n    raw_data_storage_id?: true\n    local_file_path?: true\n    file_size_bytes?: true\n    ttl_expiration_at?: true\n    deleted_at?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_local_cache_filesCountAggregateInputType = {\n    id?: true\n    raw_data_storage_id?: true\n    local_file_path?: true\n    file_size_bytes?: true\n    ttl_expiration_at?: true\n    deleted_at?: true\n    created_at?: true\n    updated_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_local_cache_filesAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_local_cache_files to aggregate.\n     */\n    where?: political_news_crawler_local_cache_filesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_local_cache_files to fetch.\n     */\n    orderBy?: political_news_crawler_local_cache_filesOrderByWithRelationInput | political_news_crawler_local_cache_filesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_local_cache_filesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_local_cache_files from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_local_cache_files.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_local_cache_files\n    **/\n    _count?: true | Political_news_crawler_local_cache_filesCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to average\n    **/\n    _avg?: Political_news_crawler_local_cache_filesAvgAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to sum\n    **/\n    _sum?: Political_news_crawler_local_cache_filesSumAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_local_cache_filesMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_local_cache_filesMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_local_cache_filesAggregateType<T extends Political_news_crawler_local_cache_filesAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_local_cache_files]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_local_cache_files[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_local_cache_files[P]>\n  }\n\n\n\n\n  export type political_news_crawler_local_cache_filesGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_local_cache_filesWhereInput\n    orderBy?: political_news_crawler_local_cache_filesOrderByWithAggregationInput | political_news_crawler_local_cache_filesOrderByWithAggregationInput[]\n    by: Political_news_crawler_local_cache_filesScalarFieldEnum[] | Political_news_crawler_local_cache_filesScalarFieldEnum\n    having?: political_news_crawler_local_cache_filesScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_local_cache_filesCountAggregateInputType | true\n    _avg?: Political_news_crawler_local_cache_filesAvgAggregateInputType\n    _sum?: Political_news_crawler_local_cache_filesSumAggregateInputType\n    _min?: Political_news_crawler_local_cache_filesMinAggregateInputType\n    _max?: Political_news_crawler_local_cache_filesMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_local_cache_filesGroupByOutputType = {\n    id: string\n    raw_data_storage_id: string\n    local_file_path: string\n    file_size_bytes: number\n    ttl_expiration_at: Date\n    deleted_at: Date | null\n    created_at: Date\n    updated_at: Date\n    _count: Political_news_crawler_local_cache_filesCountAggregateOutputType | null\n    _avg: Political_news_crawler_local_cache_filesAvgAggregateOutputType | null\n    _sum: Political_news_crawler_local_cache_filesSumAggregateOutputType | null\n    _min: Political_news_crawler_local_cache_filesMinAggregateOutputType | null\n    _max: Political_news_crawler_local_cache_filesMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_local_cache_filesGroupByPayload<T extends political_news_crawler_local_cache_filesGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_local_cache_filesGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_local_cache_filesGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_local_cache_filesGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_local_cache_filesGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_local_cache_filesSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    raw_data_storage_id?: boolean\n    local_file_path?: boolean\n    file_size_bytes?: boolean\n    ttl_expiration_at?: boolean\n    deleted_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    rawDataStorage?: boolean | political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_local_cache_files\"]>\n\n  export type political_news_crawler_local_cache_filesSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    raw_data_storage_id?: boolean\n    local_file_path?: boolean\n    file_size_bytes?: boolean\n    ttl_expiration_at?: boolean\n    deleted_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    rawDataStorage?: boolean | political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_local_cache_files\"]>\n\n  export type political_news_crawler_local_cache_filesSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    raw_data_storage_id?: boolean\n    local_file_path?: boolean\n    file_size_bytes?: boolean\n    ttl_expiration_at?: boolean\n    deleted_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    rawDataStorage?: boolean | political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_local_cache_files\"]>\n\n  export type political_news_crawler_local_cache_filesSelectScalar = {\n    id?: boolean\n    raw_data_storage_id?: boolean\n    local_file_path?: boolean\n    file_size_bytes?: boolean\n    ttl_expiration_at?: boolean\n    deleted_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }\n\n  export type political_news_crawler_local_cache_filesOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"raw_data_storage_id\" | \"local_file_path\" | \"file_size_bytes\" | \"ttl_expiration_at\" | \"deleted_at\" | \"created_at\" | \"updated_at\", ExtArgs[\"result\"][\"political_news_crawler_local_cache_files\"]>\n  export type political_news_crawler_local_cache_filesInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    rawDataStorage?: boolean | political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_local_cache_filesIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    rawDataStorage?: boolean | political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_local_cache_filesIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    rawDataStorage?: boolean | political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>\n  }\n\n  export type $political_news_crawler_local_cache_filesPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_local_cache_files\"\n    objects: {\n      rawDataStorage: Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Reference to related raw data storage record,\n       * political_news_crawler_raw_data_storage.id.\n       */\n      raw_data_storage_id: string\n      /**\n       * Filesystem path or identifier for the local cached file copy.\n       */\n      local_file_path: string\n      /**\n       * Size of the local cached file in bytes.\n       */\n      file_size_bytes: number\n      /**\n       * Datetime when the cached file expires and is due for deletion under TTL\n       * policy.\n       */\n      ttl_expiration_at: Date\n      /**\n       * Soft delete timestamp indicating when the cached file was deleted, if\n       * applicable.\n       */\n      deleted_at: Date | null\n      /**\n       * Creation timestamp record.\n       */\n      created_at: Date\n      /**\n       * Last update timestamp record.\n       */\n      updated_at: Date\n    }, ExtArgs[\"result\"][\"political_news_crawler_local_cache_files\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_local_cache_filesGetPayload<S extends boolean | null | undefined | political_news_crawler_local_cache_filesDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_local_cache_filesPayload, S>\n\n  type political_news_crawler_local_cache_filesCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_local_cache_filesFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_local_cache_filesCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_local_cache_filesDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_local_cache_files'], meta: { name: 'political_news_crawler_local_cache_files' } }\n    /**\n     * Find zero or one Political_news_crawler_local_cache_files that matches the filter.\n     * @param {political_news_crawler_local_cache_filesFindUniqueArgs} args - Arguments to find a Political_news_crawler_local_cache_files\n     * @example\n     * // Get one Political_news_crawler_local_cache_files\n     * const political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_local_cache_filesFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_local_cache_filesFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_local_cache_filesClient<$Result.GetResult<Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_local_cache_files that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_local_cache_filesFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_local_cache_files\n     * @example\n     * // Get one Political_news_crawler_local_cache_files\n     * const political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_local_cache_filesFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_local_cache_filesFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_local_cache_filesClient<$Result.GetResult<Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_local_cache_files that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_local_cache_filesFindFirstArgs} args - Arguments to find a Political_news_crawler_local_cache_files\n     * @example\n     * // Get one Political_news_crawler_local_cache_files\n     * const political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_local_cache_filesFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_local_cache_filesFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_local_cache_filesClient<$Result.GetResult<Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_local_cache_files that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_local_cache_filesFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_local_cache_files\n     * @example\n     * // Get one Political_news_crawler_local_cache_files\n     * const political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_local_cache_filesFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_local_cache_filesFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_local_cache_filesClient<$Result.GetResult<Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_local_cache_files that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_local_cache_filesFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_local_cache_files\n     * const political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.findMany()\n     * \n     * // Get first 10 Political_news_crawler_local_cache_files\n     * const political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_local_cache_filesWithIdOnly = await prisma.political_news_crawler_local_cache_files.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_local_cache_filesFindManyArgs>(args?: SelectSubset<T, political_news_crawler_local_cache_filesFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_local_cache_files.\n     * @param {political_news_crawler_local_cache_filesCreateArgs} args - Arguments to create a Political_news_crawler_local_cache_files.\n     * @example\n     * // Create one Political_news_crawler_local_cache_files\n     * const Political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_local_cache_files\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_local_cache_filesCreateArgs>(args: SelectSubset<T, political_news_crawler_local_cache_filesCreateArgs<ExtArgs>>): Prisma__political_news_crawler_local_cache_filesClient<$Result.GetResult<Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_local_cache_files.\n     * @param {political_news_crawler_local_cache_filesCreateManyArgs} args - Arguments to create many Political_news_crawler_local_cache_files.\n     * @example\n     * // Create many Political_news_crawler_local_cache_files\n     * const political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_local_cache_filesCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_local_cache_filesCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_local_cache_files and returns the data saved in the database.\n     * @param {political_news_crawler_local_cache_filesCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_local_cache_files.\n     * @example\n     * // Create many Political_news_crawler_local_cache_files\n     * const political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_local_cache_files and only return the `id`\n     * const political_news_crawler_local_cache_filesWithIdOnly = await prisma.political_news_crawler_local_cache_files.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_local_cache_filesCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_local_cache_filesCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_local_cache_files.\n     * @param {political_news_crawler_local_cache_filesDeleteArgs} args - Arguments to delete one Political_news_crawler_local_cache_files.\n     * @example\n     * // Delete one Political_news_crawler_local_cache_files\n     * const Political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_local_cache_files\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_local_cache_filesDeleteArgs>(args: SelectSubset<T, political_news_crawler_local_cache_filesDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_local_cache_filesClient<$Result.GetResult<Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_local_cache_files.\n     * @param {political_news_crawler_local_cache_filesUpdateArgs} args - Arguments to update one Political_news_crawler_local_cache_files.\n     * @example\n     * // Update one Political_news_crawler_local_cache_files\n     * const political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_local_cache_filesUpdateArgs>(args: SelectSubset<T, political_news_crawler_local_cache_filesUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_local_cache_filesClient<$Result.GetResult<Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_local_cache_files.\n     * @param {political_news_crawler_local_cache_filesDeleteManyArgs} args - Arguments to filter Political_news_crawler_local_cache_files to delete.\n     * @example\n     * // Delete a few Political_news_crawler_local_cache_files\n     * const { count } = await prisma.political_news_crawler_local_cache_files.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_local_cache_filesDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_local_cache_filesDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_local_cache_files.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_local_cache_filesUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_local_cache_files\n     * const political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_local_cache_filesUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_local_cache_filesUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_local_cache_files and returns the data updated in the database.\n     * @param {political_news_crawler_local_cache_filesUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_local_cache_files.\n     * @example\n     * // Update many Political_news_crawler_local_cache_files\n     * const political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_local_cache_files and only return the `id`\n     * const political_news_crawler_local_cache_filesWithIdOnly = await prisma.political_news_crawler_local_cache_files.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_local_cache_filesUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_local_cache_filesUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_local_cache_files.\n     * @param {political_news_crawler_local_cache_filesUpsertArgs} args - Arguments to update or create a Political_news_crawler_local_cache_files.\n     * @example\n     * // Update or create a Political_news_crawler_local_cache_files\n     * const political_news_crawler_local_cache_files = await prisma.political_news_crawler_local_cache_files.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_local_cache_files\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_local_cache_files we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_local_cache_filesUpsertArgs>(args: SelectSubset<T, political_news_crawler_local_cache_filesUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_local_cache_filesClient<$Result.GetResult<Prisma.$political_news_crawler_local_cache_filesPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_local_cache_files.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_local_cache_filesCountArgs} args - Arguments to filter Political_news_crawler_local_cache_files to count.\n     * @example\n     * // Count the number of Political_news_crawler_local_cache_files\n     * const count = await prisma.political_news_crawler_local_cache_files.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_local_cache_files we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_local_cache_filesCountArgs>(\n      args?: Subset<T, political_news_crawler_local_cache_filesCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_local_cache_filesCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_local_cache_files.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_local_cache_filesAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_local_cache_filesAggregateArgs>(args: Subset<T, Political_news_crawler_local_cache_filesAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_local_cache_filesAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_local_cache_files.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_local_cache_filesGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_local_cache_filesGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_local_cache_filesGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_local_cache_filesGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_local_cache_filesGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_local_cache_filesGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_local_cache_files model\n   */\n  readonly fields: political_news_crawler_local_cache_filesFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_local_cache_files.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_local_cache_filesClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    rawDataStorage<T extends political_news_crawler_raw_data_storageDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_raw_data_storageClient<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_local_cache_files model\n   */\n  interface political_news_crawler_local_cache_filesFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_local_cache_files\", 'String'>\n    readonly raw_data_storage_id: FieldRef<\"political_news_crawler_local_cache_files\", 'String'>\n    readonly local_file_path: FieldRef<\"political_news_crawler_local_cache_files\", 'String'>\n    readonly file_size_bytes: FieldRef<\"political_news_crawler_local_cache_files\", 'Int'>\n    readonly ttl_expiration_at: FieldRef<\"political_news_crawler_local_cache_files\", 'DateTime'>\n    readonly deleted_at: FieldRef<\"political_news_crawler_local_cache_files\", 'DateTime'>\n    readonly created_at: FieldRef<\"political_news_crawler_local_cache_files\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_local_cache_files\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_local_cache_files findUnique\n   */\n  export type political_news_crawler_local_cache_filesFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_local_cache_files\n     */\n    select?: political_news_crawler_local_cache_filesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_local_cache_files\n     */\n    omit?: political_news_crawler_local_cache_filesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_local_cache_filesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_local_cache_files to fetch.\n     */\n    where: political_news_crawler_local_cache_filesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_local_cache_files findUniqueOrThrow\n   */\n  export type political_news_crawler_local_cache_filesFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_local_cache_files\n     */\n    select?: political_news_crawler_local_cache_filesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_local_cache_files\n     */\n    omit?: political_news_crawler_local_cache_filesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_local_cache_filesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_local_cache_files to fetch.\n     */\n    where: political_news_crawler_local_cache_filesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_local_cache_files findFirst\n   */\n  export type political_news_crawler_local_cache_filesFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_local_cache_files\n     */\n    select?: political_news_crawler_local_cache_filesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_local_cache_files\n     */\n    omit?: political_news_crawler_local_cache_filesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_local_cache_filesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_local_cache_files to fetch.\n     */\n    where?: political_news_crawler_local_cache_filesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_local_cache_files to fetch.\n     */\n    orderBy?: political_news_crawler_local_cache_filesOrderByWithRelationInput | political_news_crawler_local_cache_filesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_local_cache_files.\n     */\n    cursor?: political_news_crawler_local_cache_filesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_local_cache_files from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_local_cache_files.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_local_cache_files.\n     */\n    distinct?: Political_news_crawler_local_cache_filesScalarFieldEnum | Political_news_crawler_local_cache_filesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_local_cache_files findFirstOrThrow\n   */\n  export type political_news_crawler_local_cache_filesFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_local_cache_files\n     */\n    select?: political_news_crawler_local_cache_filesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_local_cache_files\n     */\n    omit?: political_news_crawler_local_cache_filesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_local_cache_filesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_local_cache_files to fetch.\n     */\n    where?: political_news_crawler_local_cache_filesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_local_cache_files to fetch.\n     */\n    orderBy?: political_news_crawler_local_cache_filesOrderByWithRelationInput | political_news_crawler_local_cache_filesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_local_cache_files.\n     */\n    cursor?: political_news_crawler_local_cache_filesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_local_cache_files from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_local_cache_files.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_local_cache_files.\n     */\n    distinct?: Political_news_crawler_local_cache_filesScalarFieldEnum | Political_news_crawler_local_cache_filesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_local_cache_files findMany\n   */\n  export type political_news_crawler_local_cache_filesFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_local_cache_files\n     */\n    select?: political_news_crawler_local_cache_filesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_local_cache_files\n     */\n    omit?: political_news_crawler_local_cache_filesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_local_cache_filesInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_local_cache_files to fetch.\n     */\n    where?: political_news_crawler_local_cache_filesWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_local_cache_files to fetch.\n     */\n    orderBy?: political_news_crawler_local_cache_filesOrderByWithRelationInput | political_news_crawler_local_cache_filesOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_local_cache_files.\n     */\n    cursor?: political_news_crawler_local_cache_filesWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_local_cache_files from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_local_cache_files.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_local_cache_filesScalarFieldEnum | Political_news_crawler_local_cache_filesScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_local_cache_files create\n   */\n  export type political_news_crawler_local_cache_filesCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_local_cache_files\n     */\n    select?: political_news_crawler_local_cache_filesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_local_cache_files\n     */\n    omit?: political_news_crawler_local_cache_filesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_local_cache_filesInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_local_cache_files.\n     */\n    data: XOR<political_news_crawler_local_cache_filesCreateInput, political_news_crawler_local_cache_filesUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_local_cache_files createMany\n   */\n  export type political_news_crawler_local_cache_filesCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_local_cache_files.\n     */\n    data: political_news_crawler_local_cache_filesCreateManyInput | political_news_crawler_local_cache_filesCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_local_cache_files createManyAndReturn\n   */\n  export type political_news_crawler_local_cache_filesCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_local_cache_files\n     */\n    select?: political_news_crawler_local_cache_filesSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_local_cache_files\n     */\n    omit?: political_news_crawler_local_cache_filesOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_local_cache_files.\n     */\n    data: political_news_crawler_local_cache_filesCreateManyInput | political_news_crawler_local_cache_filesCreateManyInput[]\n    skipDuplicates?: boolean\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_local_cache_filesIncludeCreateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_local_cache_files update\n   */\n  export type political_news_crawler_local_cache_filesUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_local_cache_files\n     */\n    select?: political_news_crawler_local_cache_filesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_local_cache_files\n     */\n    omit?: political_news_crawler_local_cache_filesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_local_cache_filesInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_local_cache_files.\n     */\n    data: XOR<political_news_crawler_local_cache_filesUpdateInput, political_news_crawler_local_cache_filesUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_local_cache_files to update.\n     */\n    where: political_news_crawler_local_cache_filesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_local_cache_files updateMany\n   */\n  export type political_news_crawler_local_cache_filesUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_local_cache_files.\n     */\n    data: XOR<political_news_crawler_local_cache_filesUpdateManyMutationInput, political_news_crawler_local_cache_filesUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_local_cache_files to update\n     */\n    where?: political_news_crawler_local_cache_filesWhereInput\n    /**\n     * Limit how many political_news_crawler_local_cache_files to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_local_cache_files updateManyAndReturn\n   */\n  export type political_news_crawler_local_cache_filesUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_local_cache_files\n     */\n    select?: political_news_crawler_local_cache_filesSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_local_cache_files\n     */\n    omit?: political_news_crawler_local_cache_filesOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_local_cache_files.\n     */\n    data: XOR<political_news_crawler_local_cache_filesUpdateManyMutationInput, political_news_crawler_local_cache_filesUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_local_cache_files to update\n     */\n    where?: political_news_crawler_local_cache_filesWhereInput\n    /**\n     * Limit how many political_news_crawler_local_cache_files to update.\n     */\n    limit?: number\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_local_cache_filesIncludeUpdateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_local_cache_files upsert\n   */\n  export type political_news_crawler_local_cache_filesUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_local_cache_files\n     */\n    select?: political_news_crawler_local_cache_filesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_local_cache_files\n     */\n    omit?: political_news_crawler_local_cache_filesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_local_cache_filesInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_local_cache_files to update in case it exists.\n     */\n    where: political_news_crawler_local_cache_filesWhereUniqueInput\n    /**\n     * In case the political_news_crawler_local_cache_files found by the `where` argument doesn't exist, create a new political_news_crawler_local_cache_files with this data.\n     */\n    create: XOR<political_news_crawler_local_cache_filesCreateInput, political_news_crawler_local_cache_filesUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_local_cache_files was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_local_cache_filesUpdateInput, political_news_crawler_local_cache_filesUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_local_cache_files delete\n   */\n  export type political_news_crawler_local_cache_filesDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_local_cache_files\n     */\n    select?: political_news_crawler_local_cache_filesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_local_cache_files\n     */\n    omit?: political_news_crawler_local_cache_filesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_local_cache_filesInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_local_cache_files to delete.\n     */\n    where: political_news_crawler_local_cache_filesWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_local_cache_files deleteMany\n   */\n  export type political_news_crawler_local_cache_filesDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_local_cache_files to delete\n     */\n    where?: political_news_crawler_local_cache_filesWhereInput\n    /**\n     * Limit how many political_news_crawler_local_cache_files to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_local_cache_files without action\n   */\n  export type political_news_crawler_local_cache_filesDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_local_cache_files\n     */\n    select?: political_news_crawler_local_cache_filesSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_local_cache_files\n     */\n    omit?: political_news_crawler_local_cache_filesOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_local_cache_filesInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_processed_content\n   */\n\n  export type AggregatePolitical_news_crawler_processed_content = {\n    _count: Political_news_crawler_processed_contentCountAggregateOutputType | null\n    _min: Political_news_crawler_processed_contentMinAggregateOutputType | null\n    _max: Political_news_crawler_processed_contentMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_processed_contentMinAggregateOutputType = {\n    id: string | null\n    raw_data_storage_id: string | null\n    llm_job_id: string | null\n    content_type: string | null\n    content_body: string | null\n    generation_timestamp: Date | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_processed_contentMaxAggregateOutputType = {\n    id: string | null\n    raw_data_storage_id: string | null\n    llm_job_id: string | null\n    content_type: string | null\n    content_body: string | null\n    generation_timestamp: Date | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_processed_contentCountAggregateOutputType = {\n    id: number\n    raw_data_storage_id: number\n    llm_job_id: number\n    content_type: number\n    content_body: number\n    generation_timestamp: number\n    created_at: number\n    updated_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_processed_contentMinAggregateInputType = {\n    id?: true\n    raw_data_storage_id?: true\n    llm_job_id?: true\n    content_type?: true\n    content_body?: true\n    generation_timestamp?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_processed_contentMaxAggregateInputType = {\n    id?: true\n    raw_data_storage_id?: true\n    llm_job_id?: true\n    content_type?: true\n    content_body?: true\n    generation_timestamp?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_processed_contentCountAggregateInputType = {\n    id?: true\n    raw_data_storage_id?: true\n    llm_job_id?: true\n    content_type?: true\n    content_body?: true\n    generation_timestamp?: true\n    created_at?: true\n    updated_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_processed_contentAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_processed_content to aggregate.\n     */\n    where?: political_news_crawler_processed_contentWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_processed_contents to fetch.\n     */\n    orderBy?: political_news_crawler_processed_contentOrderByWithRelationInput | political_news_crawler_processed_contentOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_processed_contentWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_processed_contents from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_processed_contents.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_processed_contents\n    **/\n    _count?: true | Political_news_crawler_processed_contentCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_processed_contentMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_processed_contentMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_processed_contentAggregateType<T extends Political_news_crawler_processed_contentAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_processed_content]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_processed_content[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_processed_content[P]>\n  }\n\n\n\n\n  export type political_news_crawler_processed_contentGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_processed_contentWhereInput\n    orderBy?: political_news_crawler_processed_contentOrderByWithAggregationInput | political_news_crawler_processed_contentOrderByWithAggregationInput[]\n    by: Political_news_crawler_processed_contentScalarFieldEnum[] | Political_news_crawler_processed_contentScalarFieldEnum\n    having?: political_news_crawler_processed_contentScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_processed_contentCountAggregateInputType | true\n    _min?: Political_news_crawler_processed_contentMinAggregateInputType\n    _max?: Political_news_crawler_processed_contentMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_processed_contentGroupByOutputType = {\n    id: string\n    raw_data_storage_id: string\n    llm_job_id: string | null\n    content_type: string\n    content_body: string\n    generation_timestamp: Date\n    created_at: Date\n    updated_at: Date\n    _count: Political_news_crawler_processed_contentCountAggregateOutputType | null\n    _min: Political_news_crawler_processed_contentMinAggregateOutputType | null\n    _max: Political_news_crawler_processed_contentMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_processed_contentGroupByPayload<T extends political_news_crawler_processed_contentGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_processed_contentGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_processed_contentGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_processed_contentGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_processed_contentGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_processed_contentSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    raw_data_storage_id?: boolean\n    llm_job_id?: boolean\n    content_type?: boolean\n    content_body?: boolean\n    generation_timestamp?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    rawDataStorage?: boolean | political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>\n    llmJob?: boolean | political_news_crawler_processed_content$llmJobArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_processed_content\"]>\n\n  export type political_news_crawler_processed_contentSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    raw_data_storage_id?: boolean\n    llm_job_id?: boolean\n    content_type?: boolean\n    content_body?: boolean\n    generation_timestamp?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    rawDataStorage?: boolean | political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>\n    llmJob?: boolean | political_news_crawler_processed_content$llmJobArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_processed_content\"]>\n\n  export type political_news_crawler_processed_contentSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    raw_data_storage_id?: boolean\n    llm_job_id?: boolean\n    content_type?: boolean\n    content_body?: boolean\n    generation_timestamp?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    rawDataStorage?: boolean | political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>\n    llmJob?: boolean | political_news_crawler_processed_content$llmJobArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_processed_content\"]>\n\n  export type political_news_crawler_processed_contentSelectScalar = {\n    id?: boolean\n    raw_data_storage_id?: boolean\n    llm_job_id?: boolean\n    content_type?: boolean\n    content_body?: boolean\n    generation_timestamp?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }\n\n  export type political_news_crawler_processed_contentOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"raw_data_storage_id\" | \"llm_job_id\" | \"content_type\" | \"content_body\" | \"generation_timestamp\" | \"created_at\" | \"updated_at\", ExtArgs[\"result\"][\"political_news_crawler_processed_content\"]>\n  export type political_news_crawler_processed_contentInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    rawDataStorage?: boolean | political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>\n    llmJob?: boolean | political_news_crawler_processed_content$llmJobArgs<ExtArgs>\n  }\n  export type political_news_crawler_processed_contentIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    rawDataStorage?: boolean | political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>\n    llmJob?: boolean | political_news_crawler_processed_content$llmJobArgs<ExtArgs>\n  }\n  export type political_news_crawler_processed_contentIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    rawDataStorage?: boolean | political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>\n    llmJob?: boolean | political_news_crawler_processed_content$llmJobArgs<ExtArgs>\n  }\n\n  export type $political_news_crawler_processed_contentPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_processed_content\"\n    objects: {\n      rawDataStorage: Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>\n      llmJob: Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs> | null\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Foreign key to the raw data storage record,\n       * political_news_crawler_raw_data_storage.id.\n       */\n      raw_data_storage_id: string\n      /**\n       * Foreign key to associated LLM job, political_news_crawler_llm_jobs.id.\n       */\n      llm_job_id: string | null\n      /**\n       * Type of processed content, e.g., summary, highlight, or analysis.\n       */\n      content_type: string\n      /**\n       * Full textual content produced by LLM processing.\n       */\n      content_body: string\n      /**\n       * Timestamp when this content was generated.\n       */\n      generation_timestamp: Date\n      /**\n       * Record creation timestamp, typically same or near generation time.\n       */\n      created_at: Date\n      /**\n       * Last update timestamp record.\n       */\n      updated_at: Date\n    }, ExtArgs[\"result\"][\"political_news_crawler_processed_content\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_processed_contentGetPayload<S extends boolean | null | undefined | political_news_crawler_processed_contentDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload, S>\n\n  type political_news_crawler_processed_contentCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_processed_contentFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_processed_contentCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_processed_contentDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_processed_content'], meta: { name: 'political_news_crawler_processed_content' } }\n    /**\n     * Find zero or one Political_news_crawler_processed_content that matches the filter.\n     * @param {political_news_crawler_processed_contentFindUniqueArgs} args - Arguments to find a Political_news_crawler_processed_content\n     * @example\n     * // Get one Political_news_crawler_processed_content\n     * const political_news_crawler_processed_content = await prisma.political_news_crawler_processed_content.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_processed_contentFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_processed_contentFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_processed_contentClient<$Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_processed_content that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_processed_contentFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_processed_content\n     * @example\n     * // Get one Political_news_crawler_processed_content\n     * const political_news_crawler_processed_content = await prisma.political_news_crawler_processed_content.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_processed_contentFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_processed_contentFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_processed_contentClient<$Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_processed_content that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processed_contentFindFirstArgs} args - Arguments to find a Political_news_crawler_processed_content\n     * @example\n     * // Get one Political_news_crawler_processed_content\n     * const political_news_crawler_processed_content = await prisma.political_news_crawler_processed_content.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_processed_contentFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_processed_contentFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_processed_contentClient<$Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_processed_content that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processed_contentFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_processed_content\n     * @example\n     * // Get one Political_news_crawler_processed_content\n     * const political_news_crawler_processed_content = await prisma.political_news_crawler_processed_content.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_processed_contentFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_processed_contentFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_processed_contentClient<$Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_processed_contents that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processed_contentFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_processed_contents\n     * const political_news_crawler_processed_contents = await prisma.political_news_crawler_processed_content.findMany()\n     * \n     * // Get first 10 Political_news_crawler_processed_contents\n     * const political_news_crawler_processed_contents = await prisma.political_news_crawler_processed_content.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_processed_contentWithIdOnly = await prisma.political_news_crawler_processed_content.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_processed_contentFindManyArgs>(args?: SelectSubset<T, political_news_crawler_processed_contentFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_processed_content.\n     * @param {political_news_crawler_processed_contentCreateArgs} args - Arguments to create a Political_news_crawler_processed_content.\n     * @example\n     * // Create one Political_news_crawler_processed_content\n     * const Political_news_crawler_processed_content = await prisma.political_news_crawler_processed_content.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_processed_content\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_processed_contentCreateArgs>(args: SelectSubset<T, political_news_crawler_processed_contentCreateArgs<ExtArgs>>): Prisma__political_news_crawler_processed_contentClient<$Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_processed_contents.\n     * @param {political_news_crawler_processed_contentCreateManyArgs} args - Arguments to create many Political_news_crawler_processed_contents.\n     * @example\n     * // Create many Political_news_crawler_processed_contents\n     * const political_news_crawler_processed_content = await prisma.political_news_crawler_processed_content.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_processed_contentCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_processed_contentCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_processed_contents and returns the data saved in the database.\n     * @param {political_news_crawler_processed_contentCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_processed_contents.\n     * @example\n     * // Create many Political_news_crawler_processed_contents\n     * const political_news_crawler_processed_content = await prisma.political_news_crawler_processed_content.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_processed_contents and only return the `id`\n     * const political_news_crawler_processed_contentWithIdOnly = await prisma.political_news_crawler_processed_content.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_processed_contentCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_processed_contentCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_processed_content.\n     * @param {political_news_crawler_processed_contentDeleteArgs} args - Arguments to delete one Political_news_crawler_processed_content.\n     * @example\n     * // Delete one Political_news_crawler_processed_content\n     * const Political_news_crawler_processed_content = await prisma.political_news_crawler_processed_content.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_processed_content\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_processed_contentDeleteArgs>(args: SelectSubset<T, political_news_crawler_processed_contentDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_processed_contentClient<$Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_processed_content.\n     * @param {political_news_crawler_processed_contentUpdateArgs} args - Arguments to update one Political_news_crawler_processed_content.\n     * @example\n     * // Update one Political_news_crawler_processed_content\n     * const political_news_crawler_processed_content = await prisma.political_news_crawler_processed_content.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_processed_contentUpdateArgs>(args: SelectSubset<T, political_news_crawler_processed_contentUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_processed_contentClient<$Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_processed_contents.\n     * @param {political_news_crawler_processed_contentDeleteManyArgs} args - Arguments to filter Political_news_crawler_processed_contents to delete.\n     * @example\n     * // Delete a few Political_news_crawler_processed_contents\n     * const { count } = await prisma.political_news_crawler_processed_content.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_processed_contentDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_processed_contentDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_processed_contents.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processed_contentUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_processed_contents\n     * const political_news_crawler_processed_content = await prisma.political_news_crawler_processed_content.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_processed_contentUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_processed_contentUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_processed_contents and returns the data updated in the database.\n     * @param {political_news_crawler_processed_contentUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_processed_contents.\n     * @example\n     * // Update many Political_news_crawler_processed_contents\n     * const political_news_crawler_processed_content = await prisma.political_news_crawler_processed_content.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_processed_contents and only return the `id`\n     * const political_news_crawler_processed_contentWithIdOnly = await prisma.political_news_crawler_processed_content.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_processed_contentUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_processed_contentUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_processed_content.\n     * @param {political_news_crawler_processed_contentUpsertArgs} args - Arguments to update or create a Political_news_crawler_processed_content.\n     * @example\n     * // Update or create a Political_news_crawler_processed_content\n     * const political_news_crawler_processed_content = await prisma.political_news_crawler_processed_content.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_processed_content\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_processed_content we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_processed_contentUpsertArgs>(args: SelectSubset<T, political_news_crawler_processed_contentUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_processed_contentClient<$Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_processed_contents.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processed_contentCountArgs} args - Arguments to filter Political_news_crawler_processed_contents to count.\n     * @example\n     * // Count the number of Political_news_crawler_processed_contents\n     * const count = await prisma.political_news_crawler_processed_content.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_processed_contents we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_processed_contentCountArgs>(\n      args?: Subset<T, political_news_crawler_processed_contentCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_processed_contentCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_processed_content.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_processed_contentAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_processed_contentAggregateArgs>(args: Subset<T, Political_news_crawler_processed_contentAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_processed_contentAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_processed_content.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processed_contentGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_processed_contentGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_processed_contentGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_processed_contentGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_processed_contentGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_processed_contentGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_processed_content model\n   */\n  readonly fields: political_news_crawler_processed_contentFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_processed_content.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_processed_contentClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    rawDataStorage<T extends political_news_crawler_raw_data_storageDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_raw_data_storageDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_raw_data_storageClient<$Result.GetResult<Prisma.$political_news_crawler_raw_data_storagePayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    llmJob<T extends political_news_crawler_processed_content$llmJobArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_processed_content$llmJobArgs<ExtArgs>>): Prisma__political_news_crawler_llm_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_processed_content model\n   */\n  interface political_news_crawler_processed_contentFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_processed_content\", 'String'>\n    readonly raw_data_storage_id: FieldRef<\"political_news_crawler_processed_content\", 'String'>\n    readonly llm_job_id: FieldRef<\"political_news_crawler_processed_content\", 'String'>\n    readonly content_type: FieldRef<\"political_news_crawler_processed_content\", 'String'>\n    readonly content_body: FieldRef<\"political_news_crawler_processed_content\", 'String'>\n    readonly generation_timestamp: FieldRef<\"political_news_crawler_processed_content\", 'DateTime'>\n    readonly created_at: FieldRef<\"political_news_crawler_processed_content\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_processed_content\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_processed_content findUnique\n   */\n  export type political_news_crawler_processed_contentFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processed_content to fetch.\n     */\n    where: political_news_crawler_processed_contentWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_processed_content findUniqueOrThrow\n   */\n  export type political_news_crawler_processed_contentFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processed_content to fetch.\n     */\n    where: political_news_crawler_processed_contentWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_processed_content findFirst\n   */\n  export type political_news_crawler_processed_contentFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processed_content to fetch.\n     */\n    where?: political_news_crawler_processed_contentWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_processed_contents to fetch.\n     */\n    orderBy?: political_news_crawler_processed_contentOrderByWithRelationInput | political_news_crawler_processed_contentOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_processed_contents.\n     */\n    cursor?: political_news_crawler_processed_contentWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_processed_contents from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_processed_contents.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_processed_contents.\n     */\n    distinct?: Political_news_crawler_processed_contentScalarFieldEnum | Political_news_crawler_processed_contentScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_processed_content findFirstOrThrow\n   */\n  export type political_news_crawler_processed_contentFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processed_content to fetch.\n     */\n    where?: political_news_crawler_processed_contentWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_processed_contents to fetch.\n     */\n    orderBy?: political_news_crawler_processed_contentOrderByWithRelationInput | political_news_crawler_processed_contentOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_processed_contents.\n     */\n    cursor?: political_news_crawler_processed_contentWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_processed_contents from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_processed_contents.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_processed_contents.\n     */\n    distinct?: Political_news_crawler_processed_contentScalarFieldEnum | Political_news_crawler_processed_contentScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_processed_content findMany\n   */\n  export type political_news_crawler_processed_contentFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processed_contents to fetch.\n     */\n    where?: political_news_crawler_processed_contentWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_processed_contents to fetch.\n     */\n    orderBy?: political_news_crawler_processed_contentOrderByWithRelationInput | political_news_crawler_processed_contentOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_processed_contents.\n     */\n    cursor?: political_news_crawler_processed_contentWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_processed_contents from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_processed_contents.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_processed_contentScalarFieldEnum | Political_news_crawler_processed_contentScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_processed_content create\n   */\n  export type political_news_crawler_processed_contentCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_processed_content.\n     */\n    data: XOR<political_news_crawler_processed_contentCreateInput, political_news_crawler_processed_contentUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_processed_content createMany\n   */\n  export type political_news_crawler_processed_contentCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_processed_contents.\n     */\n    data: political_news_crawler_processed_contentCreateManyInput | political_news_crawler_processed_contentCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_processed_content createManyAndReturn\n   */\n  export type political_news_crawler_processed_contentCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_processed_contents.\n     */\n    data: political_news_crawler_processed_contentCreateManyInput | political_news_crawler_processed_contentCreateManyInput[]\n    skipDuplicates?: boolean\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentIncludeCreateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_processed_content update\n   */\n  export type political_news_crawler_processed_contentUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_processed_content.\n     */\n    data: XOR<political_news_crawler_processed_contentUpdateInput, political_news_crawler_processed_contentUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_processed_content to update.\n     */\n    where: political_news_crawler_processed_contentWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_processed_content updateMany\n   */\n  export type political_news_crawler_processed_contentUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_processed_contents.\n     */\n    data: XOR<political_news_crawler_processed_contentUpdateManyMutationInput, political_news_crawler_processed_contentUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_processed_contents to update\n     */\n    where?: political_news_crawler_processed_contentWhereInput\n    /**\n     * Limit how many political_news_crawler_processed_contents to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_processed_content updateManyAndReturn\n   */\n  export type political_news_crawler_processed_contentUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_processed_contents.\n     */\n    data: XOR<political_news_crawler_processed_contentUpdateManyMutationInput, political_news_crawler_processed_contentUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_processed_contents to update\n     */\n    where?: political_news_crawler_processed_contentWhereInput\n    /**\n     * Limit how many political_news_crawler_processed_contents to update.\n     */\n    limit?: number\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentIncludeUpdateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_processed_content upsert\n   */\n  export type political_news_crawler_processed_contentUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_processed_content to update in case it exists.\n     */\n    where: political_news_crawler_processed_contentWhereUniqueInput\n    /**\n     * In case the political_news_crawler_processed_content found by the `where` argument doesn't exist, create a new political_news_crawler_processed_content with this data.\n     */\n    create: XOR<political_news_crawler_processed_contentCreateInput, political_news_crawler_processed_contentUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_processed_content was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_processed_contentUpdateInput, political_news_crawler_processed_contentUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_processed_content delete\n   */\n  export type political_news_crawler_processed_contentDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_processed_content to delete.\n     */\n    where: political_news_crawler_processed_contentWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_processed_content deleteMany\n   */\n  export type political_news_crawler_processed_contentDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_processed_contents to delete\n     */\n    where?: political_news_crawler_processed_contentWhereInput\n    /**\n     * Limit how many political_news_crawler_processed_contents to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_processed_content.llmJob\n   */\n  export type political_news_crawler_processed_content$llmJobArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsInclude<ExtArgs> | null\n    where?: political_news_crawler_llm_jobsWhereInput\n  }\n\n  /**\n   * political_news_crawler_processed_content without action\n   */\n  export type political_news_crawler_processed_contentDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_llm_jobs\n   */\n\n  export type AggregatePolitical_news_crawler_llm_jobs = {\n    _count: Political_news_crawler_llm_jobsCountAggregateOutputType | null\n    _min: Political_news_crawler_llm_jobsMinAggregateOutputType | null\n    _max: Political_news_crawler_llm_jobsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_llm_jobsMinAggregateOutputType = {\n    id: string | null\n    crawl_source_id: string | null\n    status: string | null\n    parameters: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_llm_jobsMaxAggregateOutputType = {\n    id: string | null\n    crawl_source_id: string | null\n    status: string | null\n    parameters: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_llm_jobsCountAggregateOutputType = {\n    id: number\n    crawl_source_id: number\n    status: number\n    parameters: number\n    created_at: number\n    updated_at: number\n    deleted_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_llm_jobsMinAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    status?: true\n    parameters?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_llm_jobsMaxAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    status?: true\n    parameters?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_llm_jobsCountAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    status?: true\n    parameters?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_llm_jobsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_llm_jobs to aggregate.\n     */\n    where?: political_news_crawler_llm_jobsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_llm_jobs to fetch.\n     */\n    orderBy?: political_news_crawler_llm_jobsOrderByWithRelationInput | political_news_crawler_llm_jobsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_llm_jobsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_llm_jobs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_llm_jobs.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_llm_jobs\n    **/\n    _count?: true | Political_news_crawler_llm_jobsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_llm_jobsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_llm_jobsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_llm_jobsAggregateType<T extends Political_news_crawler_llm_jobsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_llm_jobs]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_llm_jobs[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_llm_jobs[P]>\n  }\n\n\n\n\n  export type political_news_crawler_llm_jobsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_llm_jobsWhereInput\n    orderBy?: political_news_crawler_llm_jobsOrderByWithAggregationInput | political_news_crawler_llm_jobsOrderByWithAggregationInput[]\n    by: Political_news_crawler_llm_jobsScalarFieldEnum[] | Political_news_crawler_llm_jobsScalarFieldEnum\n    having?: political_news_crawler_llm_jobsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_llm_jobsCountAggregateInputType | true\n    _min?: Political_news_crawler_llm_jobsMinAggregateInputType\n    _max?: Political_news_crawler_llm_jobsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_llm_jobsGroupByOutputType = {\n    id: string\n    crawl_source_id: string\n    status: string\n    parameters: string\n    created_at: Date\n    updated_at: Date\n    deleted_at: Date | null\n    _count: Political_news_crawler_llm_jobsCountAggregateOutputType | null\n    _min: Political_news_crawler_llm_jobsMinAggregateOutputType | null\n    _max: Political_news_crawler_llm_jobsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_llm_jobsGroupByPayload<T extends political_news_crawler_llm_jobsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_llm_jobsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_llm_jobsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_llm_jobsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_llm_jobsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_llm_jobsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    status?: boolean\n    parameters?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    political_news_crawler_processed_content?: boolean | political_news_crawler_llm_jobs$political_news_crawler_processed_contentArgs<ExtArgs>\n    political_news_crawler_llm_results?: boolean | political_news_crawler_llm_jobs$political_news_crawler_llm_resultsArgs<ExtArgs>\n    political_news_crawler_processing_metadata?: boolean | political_news_crawler_llm_jobs$political_news_crawler_processing_metadataArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_llm_jobsCountOutputTypeDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_llm_jobs\"]>\n\n  export type political_news_crawler_llm_jobsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    status?: boolean\n    parameters?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_llm_jobs\"]>\n\n  export type political_news_crawler_llm_jobsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    status?: boolean\n    parameters?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_llm_jobs\"]>\n\n  export type political_news_crawler_llm_jobsSelectScalar = {\n    id?: boolean\n    crawl_source_id?: boolean\n    status?: boolean\n    parameters?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }\n\n  export type political_news_crawler_llm_jobsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"crawl_source_id\" | \"status\" | \"parameters\" | \"created_at\" | \"updated_at\" | \"deleted_at\", ExtArgs[\"result\"][\"political_news_crawler_llm_jobs\"]>\n  export type political_news_crawler_llm_jobsInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n    political_news_crawler_processed_content?: boolean | political_news_crawler_llm_jobs$political_news_crawler_processed_contentArgs<ExtArgs>\n    political_news_crawler_llm_results?: boolean | political_news_crawler_llm_jobs$political_news_crawler_llm_resultsArgs<ExtArgs>\n    political_news_crawler_processing_metadata?: boolean | political_news_crawler_llm_jobs$political_news_crawler_processing_metadataArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_llm_jobsCountOutputTypeDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_llm_jobsIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_llm_jobsIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n  }\n\n  export type $political_news_crawler_llm_jobsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_llm_jobs\"\n    objects: {\n      crawlSource: Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>\n      political_news_crawler_processed_content: Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>[]\n      political_news_crawler_llm_results: Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>[]\n      political_news_crawler_processing_metadata: Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>[]\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * The source channel from which the raw news data originated, referencing\n       * political_news_crawler_crawl_sources.id.\n       */\n      crawl_source_id: string\n      /**\n       * Processing status of the job, e.g., 'pending', 'running', 'completed',\n       * 'failed'.\n       */\n      status: string\n      /**\n       * JSON string of parameters or prompts used for this LLM job.\n       */\n      parameters: string\n      /**\n       * Job creation timestamp.\n       */\n      created_at: Date\n      /**\n       * Job last update timestamp.\n       */\n      updated_at: Date\n      /**\n       * Soft delete timestamp, null if not deleted.\n       */\n      deleted_at: Date | null\n    }, ExtArgs[\"result\"][\"political_news_crawler_llm_jobs\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_llm_jobsGetPayload<S extends boolean | null | undefined | political_news_crawler_llm_jobsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload, S>\n\n  type political_news_crawler_llm_jobsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_llm_jobsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_llm_jobsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_llm_jobsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_llm_jobs'], meta: { name: 'political_news_crawler_llm_jobs' } }\n    /**\n     * Find zero or one Political_news_crawler_llm_jobs that matches the filter.\n     * @param {political_news_crawler_llm_jobsFindUniqueArgs} args - Arguments to find a Political_news_crawler_llm_jobs\n     * @example\n     * // Get one Political_news_crawler_llm_jobs\n     * const political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_llm_jobsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_llm_jobsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_llm_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_llm_jobs that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_llm_jobsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_llm_jobs\n     * @example\n     * // Get one Political_news_crawler_llm_jobs\n     * const political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_llm_jobsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_llm_jobsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_llm_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_llm_jobs that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_llm_jobsFindFirstArgs} args - Arguments to find a Political_news_crawler_llm_jobs\n     * @example\n     * // Get one Political_news_crawler_llm_jobs\n     * const political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_llm_jobsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_llm_jobsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_llm_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_llm_jobs that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_llm_jobsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_llm_jobs\n     * @example\n     * // Get one Political_news_crawler_llm_jobs\n     * const political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_llm_jobsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_llm_jobsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_llm_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_llm_jobs that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_llm_jobsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_llm_jobs\n     * const political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.findMany()\n     * \n     * // Get first 10 Political_news_crawler_llm_jobs\n     * const political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_llm_jobsWithIdOnly = await prisma.political_news_crawler_llm_jobs.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_llm_jobsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_llm_jobsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_llm_jobs.\n     * @param {political_news_crawler_llm_jobsCreateArgs} args - Arguments to create a Political_news_crawler_llm_jobs.\n     * @example\n     * // Create one Political_news_crawler_llm_jobs\n     * const Political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_llm_jobs\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_llm_jobsCreateArgs>(args: SelectSubset<T, political_news_crawler_llm_jobsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_llm_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_llm_jobs.\n     * @param {political_news_crawler_llm_jobsCreateManyArgs} args - Arguments to create many Political_news_crawler_llm_jobs.\n     * @example\n     * // Create many Political_news_crawler_llm_jobs\n     * const political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_llm_jobsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_llm_jobsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_llm_jobs and returns the data saved in the database.\n     * @param {political_news_crawler_llm_jobsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_llm_jobs.\n     * @example\n     * // Create many Political_news_crawler_llm_jobs\n     * const political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_llm_jobs and only return the `id`\n     * const political_news_crawler_llm_jobsWithIdOnly = await prisma.political_news_crawler_llm_jobs.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_llm_jobsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_llm_jobsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_llm_jobs.\n     * @param {political_news_crawler_llm_jobsDeleteArgs} args - Arguments to delete one Political_news_crawler_llm_jobs.\n     * @example\n     * // Delete one Political_news_crawler_llm_jobs\n     * const Political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_llm_jobs\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_llm_jobsDeleteArgs>(args: SelectSubset<T, political_news_crawler_llm_jobsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_llm_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_llm_jobs.\n     * @param {political_news_crawler_llm_jobsUpdateArgs} args - Arguments to update one Political_news_crawler_llm_jobs.\n     * @example\n     * // Update one Political_news_crawler_llm_jobs\n     * const political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_llm_jobsUpdateArgs>(args: SelectSubset<T, political_news_crawler_llm_jobsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_llm_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_llm_jobs.\n     * @param {political_news_crawler_llm_jobsDeleteManyArgs} args - Arguments to filter Political_news_crawler_llm_jobs to delete.\n     * @example\n     * // Delete a few Political_news_crawler_llm_jobs\n     * const { count } = await prisma.political_news_crawler_llm_jobs.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_llm_jobsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_llm_jobsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_llm_jobs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_llm_jobsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_llm_jobs\n     * const political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_llm_jobsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_llm_jobsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_llm_jobs and returns the data updated in the database.\n     * @param {political_news_crawler_llm_jobsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_llm_jobs.\n     * @example\n     * // Update many Political_news_crawler_llm_jobs\n     * const political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_llm_jobs and only return the `id`\n     * const political_news_crawler_llm_jobsWithIdOnly = await prisma.political_news_crawler_llm_jobs.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_llm_jobsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_llm_jobsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_llm_jobs.\n     * @param {political_news_crawler_llm_jobsUpsertArgs} args - Arguments to update or create a Political_news_crawler_llm_jobs.\n     * @example\n     * // Update or create a Political_news_crawler_llm_jobs\n     * const political_news_crawler_llm_jobs = await prisma.political_news_crawler_llm_jobs.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_llm_jobs\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_llm_jobs we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_llm_jobsUpsertArgs>(args: SelectSubset<T, political_news_crawler_llm_jobsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_llm_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_llm_jobs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_llm_jobsCountArgs} args - Arguments to filter Political_news_crawler_llm_jobs to count.\n     * @example\n     * // Count the number of Political_news_crawler_llm_jobs\n     * const count = await prisma.political_news_crawler_llm_jobs.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_llm_jobs we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_llm_jobsCountArgs>(\n      args?: Subset<T, political_news_crawler_llm_jobsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_llm_jobsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_llm_jobs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_llm_jobsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_llm_jobsAggregateArgs>(args: Subset<T, Political_news_crawler_llm_jobsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_llm_jobsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_llm_jobs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_llm_jobsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_llm_jobsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_llm_jobsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_llm_jobsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_llm_jobsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_llm_jobsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_llm_jobs model\n   */\n  readonly fields: political_news_crawler_llm_jobsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_llm_jobs.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_llm_jobsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    crawlSource<T extends political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_sourcesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    political_news_crawler_processed_content<T extends political_news_crawler_llm_jobs$political_news_crawler_processed_contentArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_llm_jobs$political_news_crawler_processed_contentArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_processed_contentPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    political_news_crawler_llm_results<T extends political_news_crawler_llm_jobs$political_news_crawler_llm_resultsArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_llm_jobs$political_news_crawler_llm_resultsArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    political_news_crawler_processing_metadata<T extends political_news_crawler_llm_jobs$political_news_crawler_processing_metadataArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_llm_jobs$political_news_crawler_processing_metadataArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_llm_jobs model\n   */\n  interface political_news_crawler_llm_jobsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_llm_jobs\", 'String'>\n    readonly crawl_source_id: FieldRef<\"political_news_crawler_llm_jobs\", 'String'>\n    readonly status: FieldRef<\"political_news_crawler_llm_jobs\", 'String'>\n    readonly parameters: FieldRef<\"political_news_crawler_llm_jobs\", 'String'>\n    readonly created_at: FieldRef<\"political_news_crawler_llm_jobs\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_llm_jobs\", 'DateTime'>\n    readonly deleted_at: FieldRef<\"political_news_crawler_llm_jobs\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_llm_jobs findUnique\n   */\n  export type political_news_crawler_llm_jobsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_llm_jobs to fetch.\n     */\n    where: political_news_crawler_llm_jobsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_llm_jobs findUniqueOrThrow\n   */\n  export type political_news_crawler_llm_jobsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_llm_jobs to fetch.\n     */\n    where: political_news_crawler_llm_jobsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_llm_jobs findFirst\n   */\n  export type political_news_crawler_llm_jobsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_llm_jobs to fetch.\n     */\n    where?: political_news_crawler_llm_jobsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_llm_jobs to fetch.\n     */\n    orderBy?: political_news_crawler_llm_jobsOrderByWithRelationInput | political_news_crawler_llm_jobsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_llm_jobs.\n     */\n    cursor?: political_news_crawler_llm_jobsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_llm_jobs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_llm_jobs.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_llm_jobs.\n     */\n    distinct?: Political_news_crawler_llm_jobsScalarFieldEnum | Political_news_crawler_llm_jobsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_llm_jobs findFirstOrThrow\n   */\n  export type political_news_crawler_llm_jobsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_llm_jobs to fetch.\n     */\n    where?: political_news_crawler_llm_jobsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_llm_jobs to fetch.\n     */\n    orderBy?: political_news_crawler_llm_jobsOrderByWithRelationInput | political_news_crawler_llm_jobsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_llm_jobs.\n     */\n    cursor?: political_news_crawler_llm_jobsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_llm_jobs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_llm_jobs.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_llm_jobs.\n     */\n    distinct?: Political_news_crawler_llm_jobsScalarFieldEnum | Political_news_crawler_llm_jobsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_llm_jobs findMany\n   */\n  export type political_news_crawler_llm_jobsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_llm_jobs to fetch.\n     */\n    where?: political_news_crawler_llm_jobsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_llm_jobs to fetch.\n     */\n    orderBy?: political_news_crawler_llm_jobsOrderByWithRelationInput | political_news_crawler_llm_jobsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_llm_jobs.\n     */\n    cursor?: political_news_crawler_llm_jobsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_llm_jobs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_llm_jobs.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_llm_jobsScalarFieldEnum | Political_news_crawler_llm_jobsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_llm_jobs create\n   */\n  export type political_news_crawler_llm_jobsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_llm_jobs.\n     */\n    data: XOR<political_news_crawler_llm_jobsCreateInput, political_news_crawler_llm_jobsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_llm_jobs createMany\n   */\n  export type political_news_crawler_llm_jobsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_llm_jobs.\n     */\n    data: political_news_crawler_llm_jobsCreateManyInput | political_news_crawler_llm_jobsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_llm_jobs createManyAndReturn\n   */\n  export type political_news_crawler_llm_jobsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_llm_jobs.\n     */\n    data: political_news_crawler_llm_jobsCreateManyInput | political_news_crawler_llm_jobsCreateManyInput[]\n    skipDuplicates?: boolean\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsIncludeCreateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_llm_jobs update\n   */\n  export type political_news_crawler_llm_jobsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_llm_jobs.\n     */\n    data: XOR<political_news_crawler_llm_jobsUpdateInput, political_news_crawler_llm_jobsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_llm_jobs to update.\n     */\n    where: political_news_crawler_llm_jobsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_llm_jobs updateMany\n   */\n  export type political_news_crawler_llm_jobsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_llm_jobs.\n     */\n    data: XOR<political_news_crawler_llm_jobsUpdateManyMutationInput, political_news_crawler_llm_jobsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_llm_jobs to update\n     */\n    where?: political_news_crawler_llm_jobsWhereInput\n    /**\n     * Limit how many political_news_crawler_llm_jobs to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_llm_jobs updateManyAndReturn\n   */\n  export type political_news_crawler_llm_jobsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_llm_jobs.\n     */\n    data: XOR<political_news_crawler_llm_jobsUpdateManyMutationInput, political_news_crawler_llm_jobsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_llm_jobs to update\n     */\n    where?: political_news_crawler_llm_jobsWhereInput\n    /**\n     * Limit how many political_news_crawler_llm_jobs to update.\n     */\n    limit?: number\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsIncludeUpdateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_llm_jobs upsert\n   */\n  export type political_news_crawler_llm_jobsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_llm_jobs to update in case it exists.\n     */\n    where: political_news_crawler_llm_jobsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_llm_jobs found by the `where` argument doesn't exist, create a new political_news_crawler_llm_jobs with this data.\n     */\n    create: XOR<political_news_crawler_llm_jobsCreateInput, political_news_crawler_llm_jobsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_llm_jobs was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_llm_jobsUpdateInput, political_news_crawler_llm_jobsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_llm_jobs delete\n   */\n  export type political_news_crawler_llm_jobsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_llm_jobs to delete.\n     */\n    where: political_news_crawler_llm_jobsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_llm_jobs deleteMany\n   */\n  export type political_news_crawler_llm_jobsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_llm_jobs to delete\n     */\n    where?: political_news_crawler_llm_jobsWhereInput\n    /**\n     * Limit how many political_news_crawler_llm_jobs to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_llm_jobs.political_news_crawler_processed_content\n   */\n  export type political_news_crawler_llm_jobs$political_news_crawler_processed_contentArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processed_content\n     */\n    select?: political_news_crawler_processed_contentSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processed_content\n     */\n    omit?: political_news_crawler_processed_contentOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processed_contentInclude<ExtArgs> | null\n    where?: political_news_crawler_processed_contentWhereInput\n    orderBy?: political_news_crawler_processed_contentOrderByWithRelationInput | political_news_crawler_processed_contentOrderByWithRelationInput[]\n    cursor?: political_news_crawler_processed_contentWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_processed_contentScalarFieldEnum | Political_news_crawler_processed_contentScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_llm_jobs.political_news_crawler_llm_results\n   */\n  export type political_news_crawler_llm_jobs$political_news_crawler_llm_resultsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_results\n     */\n    select?: political_news_crawler_llm_resultsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_results\n     */\n    omit?: political_news_crawler_llm_resultsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_resultsInclude<ExtArgs> | null\n    where?: political_news_crawler_llm_resultsWhereInput\n    orderBy?: political_news_crawler_llm_resultsOrderByWithRelationInput | political_news_crawler_llm_resultsOrderByWithRelationInput[]\n    cursor?: political_news_crawler_llm_resultsWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_llm_resultsScalarFieldEnum | Political_news_crawler_llm_resultsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_llm_jobs.political_news_crawler_processing_metadata\n   */\n  export type political_news_crawler_llm_jobs$political_news_crawler_processing_metadataArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_metadata\n     */\n    select?: political_news_crawler_processing_metadataSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_metadata\n     */\n    omit?: political_news_crawler_processing_metadataOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processing_metadataInclude<ExtArgs> | null\n    where?: political_news_crawler_processing_metadataWhereInput\n    orderBy?: political_news_crawler_processing_metadataOrderByWithRelationInput | political_news_crawler_processing_metadataOrderByWithRelationInput[]\n    cursor?: political_news_crawler_processing_metadataWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_processing_metadataScalarFieldEnum | Political_news_crawler_processing_metadataScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_llm_jobs without action\n   */\n  export type political_news_crawler_llm_jobsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_jobs\n     */\n    select?: political_news_crawler_llm_jobsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_jobs\n     */\n    omit?: political_news_crawler_llm_jobsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_jobsInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_llm_results\n   */\n\n  export type AggregatePolitical_news_crawler_llm_results = {\n    _count: Political_news_crawler_llm_resultsCountAggregateOutputType | null\n    _min: Political_news_crawler_llm_resultsMinAggregateOutputType | null\n    _max: Political_news_crawler_llm_resultsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_llm_resultsMinAggregateOutputType = {\n    id: string | null\n    llm_job_id: string | null\n    content_type: string | null\n    content_text: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_llm_resultsMaxAggregateOutputType = {\n    id: string | null\n    llm_job_id: string | null\n    content_type: string | null\n    content_text: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_llm_resultsCountAggregateOutputType = {\n    id: number\n    llm_job_id: number\n    content_type: number\n    content_text: number\n    created_at: number\n    updated_at: number\n    deleted_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_llm_resultsMinAggregateInputType = {\n    id?: true\n    llm_job_id?: true\n    content_type?: true\n    content_text?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_llm_resultsMaxAggregateInputType = {\n    id?: true\n    llm_job_id?: true\n    content_type?: true\n    content_text?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_llm_resultsCountAggregateInputType = {\n    id?: true\n    llm_job_id?: true\n    content_type?: true\n    content_text?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_llm_resultsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_llm_results to aggregate.\n     */\n    where?: political_news_crawler_llm_resultsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_llm_results to fetch.\n     */\n    orderBy?: political_news_crawler_llm_resultsOrderByWithRelationInput | political_news_crawler_llm_resultsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_llm_resultsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_llm_results from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_llm_results.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_llm_results\n    **/\n    _count?: true | Political_news_crawler_llm_resultsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_llm_resultsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_llm_resultsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_llm_resultsAggregateType<T extends Political_news_crawler_llm_resultsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_llm_results]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_llm_results[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_llm_results[P]>\n  }\n\n\n\n\n  export type political_news_crawler_llm_resultsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_llm_resultsWhereInput\n    orderBy?: political_news_crawler_llm_resultsOrderByWithAggregationInput | political_news_crawler_llm_resultsOrderByWithAggregationInput[]\n    by: Political_news_crawler_llm_resultsScalarFieldEnum[] | Political_news_crawler_llm_resultsScalarFieldEnum\n    having?: political_news_crawler_llm_resultsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_llm_resultsCountAggregateInputType | true\n    _min?: Political_news_crawler_llm_resultsMinAggregateInputType\n    _max?: Political_news_crawler_llm_resultsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_llm_resultsGroupByOutputType = {\n    id: string\n    llm_job_id: string\n    content_type: string\n    content_text: string\n    created_at: Date\n    updated_at: Date\n    deleted_at: Date | null\n    _count: Political_news_crawler_llm_resultsCountAggregateOutputType | null\n    _min: Political_news_crawler_llm_resultsMinAggregateOutputType | null\n    _max: Political_news_crawler_llm_resultsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_llm_resultsGroupByPayload<T extends political_news_crawler_llm_resultsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_llm_resultsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_llm_resultsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_llm_resultsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_llm_resultsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_llm_resultsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    llm_job_id?: boolean\n    content_type?: boolean\n    content_text?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    llmJob?: boolean | political_news_crawler_llm_jobsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_llm_results\"]>\n\n  export type political_news_crawler_llm_resultsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    llm_job_id?: boolean\n    content_type?: boolean\n    content_text?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    llmJob?: boolean | political_news_crawler_llm_jobsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_llm_results\"]>\n\n  export type political_news_crawler_llm_resultsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    llm_job_id?: boolean\n    content_type?: boolean\n    content_text?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    llmJob?: boolean | political_news_crawler_llm_jobsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_llm_results\"]>\n\n  export type political_news_crawler_llm_resultsSelectScalar = {\n    id?: boolean\n    llm_job_id?: boolean\n    content_type?: boolean\n    content_text?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }\n\n  export type political_news_crawler_llm_resultsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"llm_job_id\" | \"content_type\" | \"content_text\" | \"created_at\" | \"updated_at\" | \"deleted_at\", ExtArgs[\"result\"][\"political_news_crawler_llm_results\"]>\n  export type political_news_crawler_llm_resultsInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    llmJob?: boolean | political_news_crawler_llm_jobsDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_llm_resultsIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    llmJob?: boolean | political_news_crawler_llm_jobsDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_llm_resultsIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    llmJob?: boolean | political_news_crawler_llm_jobsDefaultArgs<ExtArgs>\n  }\n\n  export type $political_news_crawler_llm_resultsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_llm_results\"\n    objects: {\n      llmJob: Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Associated LLM job's political_news_crawler_llm_jobs.id.\n       */\n      llm_job_id: string\n      /**\n       * Type of generated content, e.g., 'summary', 'highlight', 'analysis'.\n       */\n      content_type: string\n      /**\n       * Generated content text by the LLM.\n       */\n      content_text: string\n      /**\n       * Timestamp when the output was created.\n       */\n      created_at: Date\n      /**\n       * Timestamp when the output was last updated.\n       */\n      updated_at: Date\n      /**\n       * Soft delete timestamp, null if not deleted.\n       */\n      deleted_at: Date | null\n    }, ExtArgs[\"result\"][\"political_news_crawler_llm_results\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_llm_resultsGetPayload<S extends boolean | null | undefined | political_news_crawler_llm_resultsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_llm_resultsPayload, S>\n\n  type political_news_crawler_llm_resultsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_llm_resultsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_llm_resultsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_llm_resultsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_llm_results'], meta: { name: 'political_news_crawler_llm_results' } }\n    /**\n     * Find zero or one Political_news_crawler_llm_results that matches the filter.\n     * @param {political_news_crawler_llm_resultsFindUniqueArgs} args - Arguments to find a Political_news_crawler_llm_results\n     * @example\n     * // Get one Political_news_crawler_llm_results\n     * const political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_llm_resultsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_llm_resultsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_llm_resultsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_llm_results that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_llm_resultsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_llm_results\n     * @example\n     * // Get one Political_news_crawler_llm_results\n     * const political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_llm_resultsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_llm_resultsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_llm_resultsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_llm_results that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_llm_resultsFindFirstArgs} args - Arguments to find a Political_news_crawler_llm_results\n     * @example\n     * // Get one Political_news_crawler_llm_results\n     * const political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_llm_resultsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_llm_resultsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_llm_resultsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_llm_results that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_llm_resultsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_llm_results\n     * @example\n     * // Get one Political_news_crawler_llm_results\n     * const political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_llm_resultsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_llm_resultsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_llm_resultsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_llm_results that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_llm_resultsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_llm_results\n     * const political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.findMany()\n     * \n     * // Get first 10 Political_news_crawler_llm_results\n     * const political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_llm_resultsWithIdOnly = await prisma.political_news_crawler_llm_results.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_llm_resultsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_llm_resultsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_llm_results.\n     * @param {political_news_crawler_llm_resultsCreateArgs} args - Arguments to create a Political_news_crawler_llm_results.\n     * @example\n     * // Create one Political_news_crawler_llm_results\n     * const Political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_llm_results\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_llm_resultsCreateArgs>(args: SelectSubset<T, political_news_crawler_llm_resultsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_llm_resultsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_llm_results.\n     * @param {political_news_crawler_llm_resultsCreateManyArgs} args - Arguments to create many Political_news_crawler_llm_results.\n     * @example\n     * // Create many Political_news_crawler_llm_results\n     * const political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_llm_resultsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_llm_resultsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_llm_results and returns the data saved in the database.\n     * @param {political_news_crawler_llm_resultsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_llm_results.\n     * @example\n     * // Create many Political_news_crawler_llm_results\n     * const political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_llm_results and only return the `id`\n     * const political_news_crawler_llm_resultsWithIdOnly = await prisma.political_news_crawler_llm_results.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_llm_resultsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_llm_resultsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_llm_results.\n     * @param {political_news_crawler_llm_resultsDeleteArgs} args - Arguments to delete one Political_news_crawler_llm_results.\n     * @example\n     * // Delete one Political_news_crawler_llm_results\n     * const Political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_llm_results\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_llm_resultsDeleteArgs>(args: SelectSubset<T, political_news_crawler_llm_resultsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_llm_resultsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_llm_results.\n     * @param {political_news_crawler_llm_resultsUpdateArgs} args - Arguments to update one Political_news_crawler_llm_results.\n     * @example\n     * // Update one Political_news_crawler_llm_results\n     * const political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_llm_resultsUpdateArgs>(args: SelectSubset<T, political_news_crawler_llm_resultsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_llm_resultsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_llm_results.\n     * @param {political_news_crawler_llm_resultsDeleteManyArgs} args - Arguments to filter Political_news_crawler_llm_results to delete.\n     * @example\n     * // Delete a few Political_news_crawler_llm_results\n     * const { count } = await prisma.political_news_crawler_llm_results.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_llm_resultsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_llm_resultsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_llm_results.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_llm_resultsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_llm_results\n     * const political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_llm_resultsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_llm_resultsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_llm_results and returns the data updated in the database.\n     * @param {political_news_crawler_llm_resultsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_llm_results.\n     * @example\n     * // Update many Political_news_crawler_llm_results\n     * const political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_llm_results and only return the `id`\n     * const political_news_crawler_llm_resultsWithIdOnly = await prisma.political_news_crawler_llm_results.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_llm_resultsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_llm_resultsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_llm_results.\n     * @param {political_news_crawler_llm_resultsUpsertArgs} args - Arguments to update or create a Political_news_crawler_llm_results.\n     * @example\n     * // Update or create a Political_news_crawler_llm_results\n     * const political_news_crawler_llm_results = await prisma.political_news_crawler_llm_results.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_llm_results\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_llm_results we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_llm_resultsUpsertArgs>(args: SelectSubset<T, political_news_crawler_llm_resultsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_llm_resultsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_resultsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_llm_results.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_llm_resultsCountArgs} args - Arguments to filter Political_news_crawler_llm_results to count.\n     * @example\n     * // Count the number of Political_news_crawler_llm_results\n     * const count = await prisma.political_news_crawler_llm_results.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_llm_results we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_llm_resultsCountArgs>(\n      args?: Subset<T, political_news_crawler_llm_resultsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_llm_resultsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_llm_results.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_llm_resultsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_llm_resultsAggregateArgs>(args: Subset<T, Political_news_crawler_llm_resultsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_llm_resultsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_llm_results.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_llm_resultsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_llm_resultsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_llm_resultsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_llm_resultsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_llm_resultsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_llm_resultsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_llm_results model\n   */\n  readonly fields: political_news_crawler_llm_resultsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_llm_results.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_llm_resultsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    llmJob<T extends political_news_crawler_llm_jobsDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_llm_jobsDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_llm_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_llm_results model\n   */\n  interface political_news_crawler_llm_resultsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_llm_results\", 'String'>\n    readonly llm_job_id: FieldRef<\"political_news_crawler_llm_results\", 'String'>\n    readonly content_type: FieldRef<\"political_news_crawler_llm_results\", 'String'>\n    readonly content_text: FieldRef<\"political_news_crawler_llm_results\", 'String'>\n    readonly created_at: FieldRef<\"political_news_crawler_llm_results\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_llm_results\", 'DateTime'>\n    readonly deleted_at: FieldRef<\"political_news_crawler_llm_results\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_llm_results findUnique\n   */\n  export type political_news_crawler_llm_resultsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_results\n     */\n    select?: political_news_crawler_llm_resultsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_results\n     */\n    omit?: political_news_crawler_llm_resultsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_resultsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_llm_results to fetch.\n     */\n    where: political_news_crawler_llm_resultsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_llm_results findUniqueOrThrow\n   */\n  export type political_news_crawler_llm_resultsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_results\n     */\n    select?: political_news_crawler_llm_resultsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_results\n     */\n    omit?: political_news_crawler_llm_resultsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_resultsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_llm_results to fetch.\n     */\n    where: political_news_crawler_llm_resultsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_llm_results findFirst\n   */\n  export type political_news_crawler_llm_resultsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_results\n     */\n    select?: political_news_crawler_llm_resultsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_results\n     */\n    omit?: political_news_crawler_llm_resultsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_resultsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_llm_results to fetch.\n     */\n    where?: political_news_crawler_llm_resultsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_llm_results to fetch.\n     */\n    orderBy?: political_news_crawler_llm_resultsOrderByWithRelationInput | political_news_crawler_llm_resultsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_llm_results.\n     */\n    cursor?: political_news_crawler_llm_resultsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_llm_results from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_llm_results.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_llm_results.\n     */\n    distinct?: Political_news_crawler_llm_resultsScalarFieldEnum | Political_news_crawler_llm_resultsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_llm_results findFirstOrThrow\n   */\n  export type political_news_crawler_llm_resultsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_results\n     */\n    select?: political_news_crawler_llm_resultsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_results\n     */\n    omit?: political_news_crawler_llm_resultsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_resultsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_llm_results to fetch.\n     */\n    where?: political_news_crawler_llm_resultsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_llm_results to fetch.\n     */\n    orderBy?: political_news_crawler_llm_resultsOrderByWithRelationInput | political_news_crawler_llm_resultsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_llm_results.\n     */\n    cursor?: political_news_crawler_llm_resultsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_llm_results from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_llm_results.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_llm_results.\n     */\n    distinct?: Political_news_crawler_llm_resultsScalarFieldEnum | Political_news_crawler_llm_resultsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_llm_results findMany\n   */\n  export type political_news_crawler_llm_resultsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_results\n     */\n    select?: political_news_crawler_llm_resultsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_results\n     */\n    omit?: political_news_crawler_llm_resultsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_resultsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_llm_results to fetch.\n     */\n    where?: political_news_crawler_llm_resultsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_llm_results to fetch.\n     */\n    orderBy?: political_news_crawler_llm_resultsOrderByWithRelationInput | political_news_crawler_llm_resultsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_llm_results.\n     */\n    cursor?: political_news_crawler_llm_resultsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_llm_results from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_llm_results.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_llm_resultsScalarFieldEnum | Political_news_crawler_llm_resultsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_llm_results create\n   */\n  export type political_news_crawler_llm_resultsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_results\n     */\n    select?: political_news_crawler_llm_resultsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_results\n     */\n    omit?: political_news_crawler_llm_resultsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_resultsInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_llm_results.\n     */\n    data: XOR<political_news_crawler_llm_resultsCreateInput, political_news_crawler_llm_resultsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_llm_results createMany\n   */\n  export type political_news_crawler_llm_resultsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_llm_results.\n     */\n    data: political_news_crawler_llm_resultsCreateManyInput | political_news_crawler_llm_resultsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_llm_results createManyAndReturn\n   */\n  export type political_news_crawler_llm_resultsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_results\n     */\n    select?: political_news_crawler_llm_resultsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_results\n     */\n    omit?: political_news_crawler_llm_resultsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_llm_results.\n     */\n    data: political_news_crawler_llm_resultsCreateManyInput | political_news_crawler_llm_resultsCreateManyInput[]\n    skipDuplicates?: boolean\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_resultsIncludeCreateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_llm_results update\n   */\n  export type political_news_crawler_llm_resultsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_results\n     */\n    select?: political_news_crawler_llm_resultsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_results\n     */\n    omit?: political_news_crawler_llm_resultsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_resultsInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_llm_results.\n     */\n    data: XOR<political_news_crawler_llm_resultsUpdateInput, political_news_crawler_llm_resultsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_llm_results to update.\n     */\n    where: political_news_crawler_llm_resultsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_llm_results updateMany\n   */\n  export type political_news_crawler_llm_resultsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_llm_results.\n     */\n    data: XOR<political_news_crawler_llm_resultsUpdateManyMutationInput, political_news_crawler_llm_resultsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_llm_results to update\n     */\n    where?: political_news_crawler_llm_resultsWhereInput\n    /**\n     * Limit how many political_news_crawler_llm_results to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_llm_results updateManyAndReturn\n   */\n  export type political_news_crawler_llm_resultsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_results\n     */\n    select?: political_news_crawler_llm_resultsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_results\n     */\n    omit?: political_news_crawler_llm_resultsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_llm_results.\n     */\n    data: XOR<political_news_crawler_llm_resultsUpdateManyMutationInput, political_news_crawler_llm_resultsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_llm_results to update\n     */\n    where?: political_news_crawler_llm_resultsWhereInput\n    /**\n     * Limit how many political_news_crawler_llm_results to update.\n     */\n    limit?: number\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_resultsIncludeUpdateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_llm_results upsert\n   */\n  export type political_news_crawler_llm_resultsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_results\n     */\n    select?: political_news_crawler_llm_resultsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_results\n     */\n    omit?: political_news_crawler_llm_resultsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_resultsInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_llm_results to update in case it exists.\n     */\n    where: political_news_crawler_llm_resultsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_llm_results found by the `where` argument doesn't exist, create a new political_news_crawler_llm_results with this data.\n     */\n    create: XOR<political_news_crawler_llm_resultsCreateInput, political_news_crawler_llm_resultsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_llm_results was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_llm_resultsUpdateInput, political_news_crawler_llm_resultsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_llm_results delete\n   */\n  export type political_news_crawler_llm_resultsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_results\n     */\n    select?: political_news_crawler_llm_resultsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_results\n     */\n    omit?: political_news_crawler_llm_resultsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_resultsInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_llm_results to delete.\n     */\n    where: political_news_crawler_llm_resultsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_llm_results deleteMany\n   */\n  export type political_news_crawler_llm_resultsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_llm_results to delete\n     */\n    where?: political_news_crawler_llm_resultsWhereInput\n    /**\n     * Limit how many political_news_crawler_llm_results to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_llm_results without action\n   */\n  export type political_news_crawler_llm_resultsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_llm_results\n     */\n    select?: political_news_crawler_llm_resultsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_llm_results\n     */\n    omit?: political_news_crawler_llm_resultsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_llm_resultsInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_processing_metadata\n   */\n\n  export type AggregatePolitical_news_crawler_processing_metadata = {\n    _count: Political_news_crawler_processing_metadataCountAggregateOutputType | null\n    _min: Political_news_crawler_processing_metadataMinAggregateOutputType | null\n    _max: Political_news_crawler_processing_metadataMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_processing_metadataMinAggregateOutputType = {\n    id: string | null\n    llm_job_id: string | null\n    metadata_key: string | null\n    metadata_value: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_processing_metadataMaxAggregateOutputType = {\n    id: string | null\n    llm_job_id: string | null\n    metadata_key: string | null\n    metadata_value: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_processing_metadataCountAggregateOutputType = {\n    id: number\n    llm_job_id: number\n    metadata_key: number\n    metadata_value: number\n    created_at: number\n    updated_at: number\n    deleted_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_processing_metadataMinAggregateInputType = {\n    id?: true\n    llm_job_id?: true\n    metadata_key?: true\n    metadata_value?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_processing_metadataMaxAggregateInputType = {\n    id?: true\n    llm_job_id?: true\n    metadata_key?: true\n    metadata_value?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_processing_metadataCountAggregateInputType = {\n    id?: true\n    llm_job_id?: true\n    metadata_key?: true\n    metadata_value?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_processing_metadataAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_processing_metadata to aggregate.\n     */\n    where?: political_news_crawler_processing_metadataWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_processing_metadata to fetch.\n     */\n    orderBy?: political_news_crawler_processing_metadataOrderByWithRelationInput | political_news_crawler_processing_metadataOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_processing_metadataWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_processing_metadata from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_processing_metadata.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_processing_metadata\n    **/\n    _count?: true | Political_news_crawler_processing_metadataCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_processing_metadataMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_processing_metadataMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_processing_metadataAggregateType<T extends Political_news_crawler_processing_metadataAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_processing_metadata]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_processing_metadata[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_processing_metadata[P]>\n  }\n\n\n\n\n  export type political_news_crawler_processing_metadataGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_processing_metadataWhereInput\n    orderBy?: political_news_crawler_processing_metadataOrderByWithAggregationInput | political_news_crawler_processing_metadataOrderByWithAggregationInput[]\n    by: Political_news_crawler_processing_metadataScalarFieldEnum[] | Political_news_crawler_processing_metadataScalarFieldEnum\n    having?: political_news_crawler_processing_metadataScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_processing_metadataCountAggregateInputType | true\n    _min?: Political_news_crawler_processing_metadataMinAggregateInputType\n    _max?: Political_news_crawler_processing_metadataMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_processing_metadataGroupByOutputType = {\n    id: string\n    llm_job_id: string\n    metadata_key: string\n    metadata_value: string\n    created_at: Date\n    updated_at: Date\n    deleted_at: Date | null\n    _count: Political_news_crawler_processing_metadataCountAggregateOutputType | null\n    _min: Political_news_crawler_processing_metadataMinAggregateOutputType | null\n    _max: Political_news_crawler_processing_metadataMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_processing_metadataGroupByPayload<T extends political_news_crawler_processing_metadataGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_processing_metadataGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_processing_metadataGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_processing_metadataGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_processing_metadataGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_processing_metadataSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    llm_job_id?: boolean\n    metadata_key?: boolean\n    metadata_value?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    llmJob?: boolean | political_news_crawler_llm_jobsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_processing_metadata\"]>\n\n  export type political_news_crawler_processing_metadataSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    llm_job_id?: boolean\n    metadata_key?: boolean\n    metadata_value?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    llmJob?: boolean | political_news_crawler_llm_jobsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_processing_metadata\"]>\n\n  export type political_news_crawler_processing_metadataSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    llm_job_id?: boolean\n    metadata_key?: boolean\n    metadata_value?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    llmJob?: boolean | political_news_crawler_llm_jobsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_processing_metadata\"]>\n\n  export type political_news_crawler_processing_metadataSelectScalar = {\n    id?: boolean\n    llm_job_id?: boolean\n    metadata_key?: boolean\n    metadata_value?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }\n\n  export type political_news_crawler_processing_metadataOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"llm_job_id\" | \"metadata_key\" | \"metadata_value\" | \"created_at\" | \"updated_at\" | \"deleted_at\", ExtArgs[\"result\"][\"political_news_crawler_processing_metadata\"]>\n  export type political_news_crawler_processing_metadataInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    llmJob?: boolean | political_news_crawler_llm_jobsDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_processing_metadataIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    llmJob?: boolean | political_news_crawler_llm_jobsDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_processing_metadataIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    llmJob?: boolean | political_news_crawler_llm_jobsDefaultArgs<ExtArgs>\n  }\n\n  export type $political_news_crawler_processing_metadataPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_processing_metadata\"\n    objects: {\n      llmJob: Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Associated LLM job's political_news_crawler_llm_jobs.id.\n       */\n      llm_job_id: string\n      /**\n       * Key name of the metadata attribute.\n       */\n      metadata_key: string\n      /**\n       * Value of the metadata attribute.\n       */\n      metadata_value: string\n      /**\n       * Metadata entry creation timestamp.\n       */\n      created_at: Date\n      /**\n       * Metadata entry last update timestamp.\n       */\n      updated_at: Date\n      /**\n       * Soft delete timestamp, null if not deleted.\n       */\n      deleted_at: Date | null\n    }, ExtArgs[\"result\"][\"political_news_crawler_processing_metadata\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_processing_metadataGetPayload<S extends boolean | null | undefined | political_news_crawler_processing_metadataDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_processing_metadataPayload, S>\n\n  type political_news_crawler_processing_metadataCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_processing_metadataFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_processing_metadataCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_processing_metadataDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_processing_metadata'], meta: { name: 'political_news_crawler_processing_metadata' } }\n    /**\n     * Find zero or one Political_news_crawler_processing_metadata that matches the filter.\n     * @param {political_news_crawler_processing_metadataFindUniqueArgs} args - Arguments to find a Political_news_crawler_processing_metadata\n     * @example\n     * // Get one Political_news_crawler_processing_metadata\n     * const political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_processing_metadataFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_processing_metadataFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_processing_metadataClient<$Result.GetResult<Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_processing_metadata that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_processing_metadataFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_processing_metadata\n     * @example\n     * // Get one Political_news_crawler_processing_metadata\n     * const political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_processing_metadataFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_processing_metadataFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_processing_metadataClient<$Result.GetResult<Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_processing_metadata that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processing_metadataFindFirstArgs} args - Arguments to find a Political_news_crawler_processing_metadata\n     * @example\n     * // Get one Political_news_crawler_processing_metadata\n     * const political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_processing_metadataFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_processing_metadataFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_processing_metadataClient<$Result.GetResult<Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_processing_metadata that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processing_metadataFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_processing_metadata\n     * @example\n     * // Get one Political_news_crawler_processing_metadata\n     * const political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_processing_metadataFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_processing_metadataFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_processing_metadataClient<$Result.GetResult<Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_processing_metadata that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processing_metadataFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_processing_metadata\n     * const political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.findMany()\n     * \n     * // Get first 10 Political_news_crawler_processing_metadata\n     * const political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_processing_metadataWithIdOnly = await prisma.political_news_crawler_processing_metadata.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_processing_metadataFindManyArgs>(args?: SelectSubset<T, political_news_crawler_processing_metadataFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_processing_metadata.\n     * @param {political_news_crawler_processing_metadataCreateArgs} args - Arguments to create a Political_news_crawler_processing_metadata.\n     * @example\n     * // Create one Political_news_crawler_processing_metadata\n     * const Political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_processing_metadata\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_processing_metadataCreateArgs>(args: SelectSubset<T, political_news_crawler_processing_metadataCreateArgs<ExtArgs>>): Prisma__political_news_crawler_processing_metadataClient<$Result.GetResult<Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_processing_metadata.\n     * @param {political_news_crawler_processing_metadataCreateManyArgs} args - Arguments to create many Political_news_crawler_processing_metadata.\n     * @example\n     * // Create many Political_news_crawler_processing_metadata\n     * const political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_processing_metadataCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_processing_metadataCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_processing_metadata and returns the data saved in the database.\n     * @param {political_news_crawler_processing_metadataCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_processing_metadata.\n     * @example\n     * // Create many Political_news_crawler_processing_metadata\n     * const political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_processing_metadata and only return the `id`\n     * const political_news_crawler_processing_metadataWithIdOnly = await prisma.political_news_crawler_processing_metadata.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_processing_metadataCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_processing_metadataCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_processing_metadata.\n     * @param {political_news_crawler_processing_metadataDeleteArgs} args - Arguments to delete one Political_news_crawler_processing_metadata.\n     * @example\n     * // Delete one Political_news_crawler_processing_metadata\n     * const Political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_processing_metadata\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_processing_metadataDeleteArgs>(args: SelectSubset<T, political_news_crawler_processing_metadataDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_processing_metadataClient<$Result.GetResult<Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_processing_metadata.\n     * @param {political_news_crawler_processing_metadataUpdateArgs} args - Arguments to update one Political_news_crawler_processing_metadata.\n     * @example\n     * // Update one Political_news_crawler_processing_metadata\n     * const political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_processing_metadataUpdateArgs>(args: SelectSubset<T, political_news_crawler_processing_metadataUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_processing_metadataClient<$Result.GetResult<Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_processing_metadata.\n     * @param {political_news_crawler_processing_metadataDeleteManyArgs} args - Arguments to filter Political_news_crawler_processing_metadata to delete.\n     * @example\n     * // Delete a few Political_news_crawler_processing_metadata\n     * const { count } = await prisma.political_news_crawler_processing_metadata.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_processing_metadataDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_processing_metadataDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_processing_metadata.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processing_metadataUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_processing_metadata\n     * const political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_processing_metadataUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_processing_metadataUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_processing_metadata and returns the data updated in the database.\n     * @param {political_news_crawler_processing_metadataUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_processing_metadata.\n     * @example\n     * // Update many Political_news_crawler_processing_metadata\n     * const political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_processing_metadata and only return the `id`\n     * const political_news_crawler_processing_metadataWithIdOnly = await prisma.political_news_crawler_processing_metadata.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_processing_metadataUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_processing_metadataUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_processing_metadata.\n     * @param {political_news_crawler_processing_metadataUpsertArgs} args - Arguments to update or create a Political_news_crawler_processing_metadata.\n     * @example\n     * // Update or create a Political_news_crawler_processing_metadata\n     * const political_news_crawler_processing_metadata = await prisma.political_news_crawler_processing_metadata.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_processing_metadata\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_processing_metadata we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_processing_metadataUpsertArgs>(args: SelectSubset<T, political_news_crawler_processing_metadataUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_processing_metadataClient<$Result.GetResult<Prisma.$political_news_crawler_processing_metadataPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_processing_metadata.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processing_metadataCountArgs} args - Arguments to filter Political_news_crawler_processing_metadata to count.\n     * @example\n     * // Count the number of Political_news_crawler_processing_metadata\n     * const count = await prisma.political_news_crawler_processing_metadata.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_processing_metadata we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_processing_metadataCountArgs>(\n      args?: Subset<T, political_news_crawler_processing_metadataCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_processing_metadataCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_processing_metadata.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_processing_metadataAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_processing_metadataAggregateArgs>(args: Subset<T, Political_news_crawler_processing_metadataAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_processing_metadataAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_processing_metadata.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processing_metadataGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_processing_metadataGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_processing_metadataGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_processing_metadataGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_processing_metadataGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_processing_metadataGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_processing_metadata model\n   */\n  readonly fields: political_news_crawler_processing_metadataFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_processing_metadata.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_processing_metadataClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    llmJob<T extends political_news_crawler_llm_jobsDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_llm_jobsDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_llm_jobsClient<$Result.GetResult<Prisma.$political_news_crawler_llm_jobsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_processing_metadata model\n   */\n  interface political_news_crawler_processing_metadataFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_processing_metadata\", 'String'>\n    readonly llm_job_id: FieldRef<\"political_news_crawler_processing_metadata\", 'String'>\n    readonly metadata_key: FieldRef<\"political_news_crawler_processing_metadata\", 'String'>\n    readonly metadata_value: FieldRef<\"political_news_crawler_processing_metadata\", 'String'>\n    readonly created_at: FieldRef<\"political_news_crawler_processing_metadata\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_processing_metadata\", 'DateTime'>\n    readonly deleted_at: FieldRef<\"political_news_crawler_processing_metadata\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_processing_metadata findUnique\n   */\n  export type political_news_crawler_processing_metadataFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_metadata\n     */\n    select?: political_news_crawler_processing_metadataSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_metadata\n     */\n    omit?: political_news_crawler_processing_metadataOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processing_metadataInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processing_metadata to fetch.\n     */\n    where: political_news_crawler_processing_metadataWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_processing_metadata findUniqueOrThrow\n   */\n  export type political_news_crawler_processing_metadataFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_metadata\n     */\n    select?: political_news_crawler_processing_metadataSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_metadata\n     */\n    omit?: political_news_crawler_processing_metadataOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processing_metadataInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processing_metadata to fetch.\n     */\n    where: political_news_crawler_processing_metadataWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_processing_metadata findFirst\n   */\n  export type political_news_crawler_processing_metadataFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_metadata\n     */\n    select?: political_news_crawler_processing_metadataSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_metadata\n     */\n    omit?: political_news_crawler_processing_metadataOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processing_metadataInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processing_metadata to fetch.\n     */\n    where?: political_news_crawler_processing_metadataWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_processing_metadata to fetch.\n     */\n    orderBy?: political_news_crawler_processing_metadataOrderByWithRelationInput | political_news_crawler_processing_metadataOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_processing_metadata.\n     */\n    cursor?: political_news_crawler_processing_metadataWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_processing_metadata from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_processing_metadata.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_processing_metadata.\n     */\n    distinct?: Political_news_crawler_processing_metadataScalarFieldEnum | Political_news_crawler_processing_metadataScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_processing_metadata findFirstOrThrow\n   */\n  export type political_news_crawler_processing_metadataFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_metadata\n     */\n    select?: political_news_crawler_processing_metadataSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_metadata\n     */\n    omit?: political_news_crawler_processing_metadataOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processing_metadataInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processing_metadata to fetch.\n     */\n    where?: political_news_crawler_processing_metadataWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_processing_metadata to fetch.\n     */\n    orderBy?: political_news_crawler_processing_metadataOrderByWithRelationInput | political_news_crawler_processing_metadataOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_processing_metadata.\n     */\n    cursor?: political_news_crawler_processing_metadataWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_processing_metadata from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_processing_metadata.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_processing_metadata.\n     */\n    distinct?: Political_news_crawler_processing_metadataScalarFieldEnum | Political_news_crawler_processing_metadataScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_processing_metadata findMany\n   */\n  export type political_news_crawler_processing_metadataFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_metadata\n     */\n    select?: political_news_crawler_processing_metadataSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_metadata\n     */\n    omit?: political_news_crawler_processing_metadataOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processing_metadataInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processing_metadata to fetch.\n     */\n    where?: political_news_crawler_processing_metadataWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_processing_metadata to fetch.\n     */\n    orderBy?: political_news_crawler_processing_metadataOrderByWithRelationInput | political_news_crawler_processing_metadataOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_processing_metadata.\n     */\n    cursor?: political_news_crawler_processing_metadataWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_processing_metadata from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_processing_metadata.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_processing_metadataScalarFieldEnum | Political_news_crawler_processing_metadataScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_processing_metadata create\n   */\n  export type political_news_crawler_processing_metadataCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_metadata\n     */\n    select?: political_news_crawler_processing_metadataSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_metadata\n     */\n    omit?: political_news_crawler_processing_metadataOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processing_metadataInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_processing_metadata.\n     */\n    data: XOR<political_news_crawler_processing_metadataCreateInput, political_news_crawler_processing_metadataUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_processing_metadata createMany\n   */\n  export type political_news_crawler_processing_metadataCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_processing_metadata.\n     */\n    data: political_news_crawler_processing_metadataCreateManyInput | political_news_crawler_processing_metadataCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_processing_metadata createManyAndReturn\n   */\n  export type political_news_crawler_processing_metadataCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_metadata\n     */\n    select?: political_news_crawler_processing_metadataSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_metadata\n     */\n    omit?: political_news_crawler_processing_metadataOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_processing_metadata.\n     */\n    data: political_news_crawler_processing_metadataCreateManyInput | political_news_crawler_processing_metadataCreateManyInput[]\n    skipDuplicates?: boolean\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processing_metadataIncludeCreateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_processing_metadata update\n   */\n  export type political_news_crawler_processing_metadataUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_metadata\n     */\n    select?: political_news_crawler_processing_metadataSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_metadata\n     */\n    omit?: political_news_crawler_processing_metadataOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processing_metadataInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_processing_metadata.\n     */\n    data: XOR<political_news_crawler_processing_metadataUpdateInput, political_news_crawler_processing_metadataUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_processing_metadata to update.\n     */\n    where: political_news_crawler_processing_metadataWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_processing_metadata updateMany\n   */\n  export type political_news_crawler_processing_metadataUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_processing_metadata.\n     */\n    data: XOR<political_news_crawler_processing_metadataUpdateManyMutationInput, political_news_crawler_processing_metadataUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_processing_metadata to update\n     */\n    where?: political_news_crawler_processing_metadataWhereInput\n    /**\n     * Limit how many political_news_crawler_processing_metadata to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_processing_metadata updateManyAndReturn\n   */\n  export type political_news_crawler_processing_metadataUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_metadata\n     */\n    select?: political_news_crawler_processing_metadataSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_metadata\n     */\n    omit?: political_news_crawler_processing_metadataOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_processing_metadata.\n     */\n    data: XOR<political_news_crawler_processing_metadataUpdateManyMutationInput, political_news_crawler_processing_metadataUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_processing_metadata to update\n     */\n    where?: political_news_crawler_processing_metadataWhereInput\n    /**\n     * Limit how many political_news_crawler_processing_metadata to update.\n     */\n    limit?: number\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processing_metadataIncludeUpdateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_processing_metadata upsert\n   */\n  export type political_news_crawler_processing_metadataUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_metadata\n     */\n    select?: political_news_crawler_processing_metadataSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_metadata\n     */\n    omit?: political_news_crawler_processing_metadataOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processing_metadataInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_processing_metadata to update in case it exists.\n     */\n    where: political_news_crawler_processing_metadataWhereUniqueInput\n    /**\n     * In case the political_news_crawler_processing_metadata found by the `where` argument doesn't exist, create a new political_news_crawler_processing_metadata with this data.\n     */\n    create: XOR<political_news_crawler_processing_metadataCreateInput, political_news_crawler_processing_metadataUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_processing_metadata was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_processing_metadataUpdateInput, political_news_crawler_processing_metadataUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_processing_metadata delete\n   */\n  export type political_news_crawler_processing_metadataDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_metadata\n     */\n    select?: political_news_crawler_processing_metadataSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_metadata\n     */\n    omit?: political_news_crawler_processing_metadataOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processing_metadataInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_processing_metadata to delete.\n     */\n    where: political_news_crawler_processing_metadataWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_processing_metadata deleteMany\n   */\n  export type political_news_crawler_processing_metadataDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_processing_metadata to delete\n     */\n    where?: political_news_crawler_processing_metadataWhereInput\n    /**\n     * Limit how many political_news_crawler_processing_metadata to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_processing_metadata without action\n   */\n  export type political_news_crawler_processing_metadataDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_metadata\n     */\n    select?: political_news_crawler_processing_metadataSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_metadata\n     */\n    omit?: political_news_crawler_processing_metadataOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_processing_metadataInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_popularity_scores\n   */\n\n  export type AggregatePolitical_news_crawler_popularity_scores = {\n    _count: Political_news_crawler_popularity_scoresCountAggregateOutputType | null\n    _avg: Political_news_crawler_popularity_scoresAvgAggregateOutputType | null\n    _sum: Political_news_crawler_popularity_scoresSumAggregateOutputType | null\n    _min: Political_news_crawler_popularity_scoresMinAggregateOutputType | null\n    _max: Political_news_crawler_popularity_scoresMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_popularity_scoresAvgAggregateOutputType = {\n    score: number | null\n    decay_factor: number | null\n  }\n\n  export type Political_news_crawler_popularity_scoresSumAggregateOutputType = {\n    score: number | null\n    decay_factor: number | null\n  }\n\n  export type Political_news_crawler_popularity_scoresMinAggregateOutputType = {\n    id: string | null\n    political_news_crawler_popular_topic_id: string | null\n    score: number | null\n    decay_factor: number | null\n    snapshot_at: Date | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_popularity_scoresMaxAggregateOutputType = {\n    id: string | null\n    political_news_crawler_popular_topic_id: string | null\n    score: number | null\n    decay_factor: number | null\n    snapshot_at: Date | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_popularity_scoresCountAggregateOutputType = {\n    id: number\n    political_news_crawler_popular_topic_id: number\n    score: number\n    decay_factor: number\n    snapshot_at: number\n    created_at: number\n    updated_at: number\n    deleted_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_popularity_scoresAvgAggregateInputType = {\n    score?: true\n    decay_factor?: true\n  }\n\n  export type Political_news_crawler_popularity_scoresSumAggregateInputType = {\n    score?: true\n    decay_factor?: true\n  }\n\n  export type Political_news_crawler_popularity_scoresMinAggregateInputType = {\n    id?: true\n    political_news_crawler_popular_topic_id?: true\n    score?: true\n    decay_factor?: true\n    snapshot_at?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_popularity_scoresMaxAggregateInputType = {\n    id?: true\n    political_news_crawler_popular_topic_id?: true\n    score?: true\n    decay_factor?: true\n    snapshot_at?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_popularity_scoresCountAggregateInputType = {\n    id?: true\n    political_news_crawler_popular_topic_id?: true\n    score?: true\n    decay_factor?: true\n    snapshot_at?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_popularity_scoresAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_popularity_scores to aggregate.\n     */\n    where?: political_news_crawler_popularity_scoresWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_popularity_scores to fetch.\n     */\n    orderBy?: political_news_crawler_popularity_scoresOrderByWithRelationInput | political_news_crawler_popularity_scoresOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_popularity_scoresWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_popularity_scores from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_popularity_scores.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_popularity_scores\n    **/\n    _count?: true | Political_news_crawler_popularity_scoresCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to average\n    **/\n    _avg?: Political_news_crawler_popularity_scoresAvgAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to sum\n    **/\n    _sum?: Political_news_crawler_popularity_scoresSumAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_popularity_scoresMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_popularity_scoresMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_popularity_scoresAggregateType<T extends Political_news_crawler_popularity_scoresAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_popularity_scores]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_popularity_scores[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_popularity_scores[P]>\n  }\n\n\n\n\n  export type political_news_crawler_popularity_scoresGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_popularity_scoresWhereInput\n    orderBy?: political_news_crawler_popularity_scoresOrderByWithAggregationInput | political_news_crawler_popularity_scoresOrderByWithAggregationInput[]\n    by: Political_news_crawler_popularity_scoresScalarFieldEnum[] | Political_news_crawler_popularity_scoresScalarFieldEnum\n    having?: political_news_crawler_popularity_scoresScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_popularity_scoresCountAggregateInputType | true\n    _avg?: Political_news_crawler_popularity_scoresAvgAggregateInputType\n    _sum?: Political_news_crawler_popularity_scoresSumAggregateInputType\n    _min?: Political_news_crawler_popularity_scoresMinAggregateInputType\n    _max?: Political_news_crawler_popularity_scoresMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_popularity_scoresGroupByOutputType = {\n    id: string\n    political_news_crawler_popular_topic_id: string\n    score: number\n    decay_factor: number\n    snapshot_at: Date\n    created_at: Date\n    updated_at: Date\n    deleted_at: Date | null\n    _count: Political_news_crawler_popularity_scoresCountAggregateOutputType | null\n    _avg: Political_news_crawler_popularity_scoresAvgAggregateOutputType | null\n    _sum: Political_news_crawler_popularity_scoresSumAggregateOutputType | null\n    _min: Political_news_crawler_popularity_scoresMinAggregateOutputType | null\n    _max: Political_news_crawler_popularity_scoresMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_popularity_scoresGroupByPayload<T extends political_news_crawler_popularity_scoresGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_popularity_scoresGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_popularity_scoresGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_popularity_scoresGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_popularity_scoresGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_popularity_scoresSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    political_news_crawler_popular_topic_id?: boolean\n    score?: boolean\n    decay_factor?: boolean\n    snapshot_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    popularTopic?: boolean | political_news_crawler_popular_topicsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_popularity_scores\"]>\n\n  export type political_news_crawler_popularity_scoresSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    political_news_crawler_popular_topic_id?: boolean\n    score?: boolean\n    decay_factor?: boolean\n    snapshot_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    popularTopic?: boolean | political_news_crawler_popular_topicsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_popularity_scores\"]>\n\n  export type political_news_crawler_popularity_scoresSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    political_news_crawler_popular_topic_id?: boolean\n    score?: boolean\n    decay_factor?: boolean\n    snapshot_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    popularTopic?: boolean | political_news_crawler_popular_topicsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_popularity_scores\"]>\n\n  export type political_news_crawler_popularity_scoresSelectScalar = {\n    id?: boolean\n    political_news_crawler_popular_topic_id?: boolean\n    score?: boolean\n    decay_factor?: boolean\n    snapshot_at?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }\n\n  export type political_news_crawler_popularity_scoresOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"political_news_crawler_popular_topic_id\" | \"score\" | \"decay_factor\" | \"snapshot_at\" | \"created_at\" | \"updated_at\" | \"deleted_at\", ExtArgs[\"result\"][\"political_news_crawler_popularity_scores\"]>\n  export type political_news_crawler_popularity_scoresInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    popularTopic?: boolean | political_news_crawler_popular_topicsDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_popularity_scoresIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    popularTopic?: boolean | political_news_crawler_popular_topicsDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_popularity_scoresIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    popularTopic?: boolean | political_news_crawler_popular_topicsDefaultArgs<ExtArgs>\n  }\n\n  export type $political_news_crawler_popularity_scoresPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_popularity_scores\"\n    objects: {\n      popularTopic: Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Referenced popular topic's {@link\n       * political_news_crawler_popular_topics.id}.\n       */\n      political_news_crawler_popular_topic_id: string\n      /**\n       * Calculated popularity score for the topic at this snapshot.\n       */\n      score: number\n      /**\n       * Decay factor applied to the score based on the age of the topic mention.\n       */\n      decay_factor: number\n      /**\n       * Timestamp when this popularity score snapshot was taken.\n       */\n      snapshot_at: Date\n      /**\n       * Record creation timestamp.\n       */\n      created_at: Date\n      /**\n       * Record last update timestamp.\n       */\n      updated_at: Date\n      /**\n       * Soft deletion timestamp if applicable, otherwise null.\n       */\n      deleted_at: Date | null\n    }, ExtArgs[\"result\"][\"political_news_crawler_popularity_scores\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_popularity_scoresGetPayload<S extends boolean | null | undefined | political_news_crawler_popularity_scoresDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_popularity_scoresPayload, S>\n\n  type political_news_crawler_popularity_scoresCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_popularity_scoresFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_popularity_scoresCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_popularity_scoresDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_popularity_scores'], meta: { name: 'political_news_crawler_popularity_scores' } }\n    /**\n     * Find zero or one Political_news_crawler_popularity_scores that matches the filter.\n     * @param {political_news_crawler_popularity_scoresFindUniqueArgs} args - Arguments to find a Political_news_crawler_popularity_scores\n     * @example\n     * // Get one Political_news_crawler_popularity_scores\n     * const political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_popularity_scoresFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_popularity_scoresFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_popularity_scoresClient<$Result.GetResult<Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_popularity_scores that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_popularity_scoresFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_popularity_scores\n     * @example\n     * // Get one Political_news_crawler_popularity_scores\n     * const political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_popularity_scoresFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_popularity_scoresFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_popularity_scoresClient<$Result.GetResult<Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_popularity_scores that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_popularity_scoresFindFirstArgs} args - Arguments to find a Political_news_crawler_popularity_scores\n     * @example\n     * // Get one Political_news_crawler_popularity_scores\n     * const political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_popularity_scoresFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_popularity_scoresFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_popularity_scoresClient<$Result.GetResult<Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_popularity_scores that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_popularity_scoresFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_popularity_scores\n     * @example\n     * // Get one Political_news_crawler_popularity_scores\n     * const political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_popularity_scoresFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_popularity_scoresFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_popularity_scoresClient<$Result.GetResult<Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_popularity_scores that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_popularity_scoresFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_popularity_scores\n     * const political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.findMany()\n     * \n     * // Get first 10 Political_news_crawler_popularity_scores\n     * const political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_popularity_scoresWithIdOnly = await prisma.political_news_crawler_popularity_scores.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_popularity_scoresFindManyArgs>(args?: SelectSubset<T, political_news_crawler_popularity_scoresFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_popularity_scores.\n     * @param {political_news_crawler_popularity_scoresCreateArgs} args - Arguments to create a Political_news_crawler_popularity_scores.\n     * @example\n     * // Create one Political_news_crawler_popularity_scores\n     * const Political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_popularity_scores\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_popularity_scoresCreateArgs>(args: SelectSubset<T, political_news_crawler_popularity_scoresCreateArgs<ExtArgs>>): Prisma__political_news_crawler_popularity_scoresClient<$Result.GetResult<Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_popularity_scores.\n     * @param {political_news_crawler_popularity_scoresCreateManyArgs} args - Arguments to create many Political_news_crawler_popularity_scores.\n     * @example\n     * // Create many Political_news_crawler_popularity_scores\n     * const political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_popularity_scoresCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_popularity_scoresCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_popularity_scores and returns the data saved in the database.\n     * @param {political_news_crawler_popularity_scoresCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_popularity_scores.\n     * @example\n     * // Create many Political_news_crawler_popularity_scores\n     * const political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_popularity_scores and only return the `id`\n     * const political_news_crawler_popularity_scoresWithIdOnly = await prisma.political_news_crawler_popularity_scores.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_popularity_scoresCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_popularity_scoresCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_popularity_scores.\n     * @param {political_news_crawler_popularity_scoresDeleteArgs} args - Arguments to delete one Political_news_crawler_popularity_scores.\n     * @example\n     * // Delete one Political_news_crawler_popularity_scores\n     * const Political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_popularity_scores\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_popularity_scoresDeleteArgs>(args: SelectSubset<T, political_news_crawler_popularity_scoresDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_popularity_scoresClient<$Result.GetResult<Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_popularity_scores.\n     * @param {political_news_crawler_popularity_scoresUpdateArgs} args - Arguments to update one Political_news_crawler_popularity_scores.\n     * @example\n     * // Update one Political_news_crawler_popularity_scores\n     * const political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_popularity_scoresUpdateArgs>(args: SelectSubset<T, political_news_crawler_popularity_scoresUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_popularity_scoresClient<$Result.GetResult<Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_popularity_scores.\n     * @param {political_news_crawler_popularity_scoresDeleteManyArgs} args - Arguments to filter Political_news_crawler_popularity_scores to delete.\n     * @example\n     * // Delete a few Political_news_crawler_popularity_scores\n     * const { count } = await prisma.political_news_crawler_popularity_scores.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_popularity_scoresDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_popularity_scoresDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_popularity_scores.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_popularity_scoresUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_popularity_scores\n     * const political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_popularity_scoresUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_popularity_scoresUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_popularity_scores and returns the data updated in the database.\n     * @param {political_news_crawler_popularity_scoresUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_popularity_scores.\n     * @example\n     * // Update many Political_news_crawler_popularity_scores\n     * const political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_popularity_scores and only return the `id`\n     * const political_news_crawler_popularity_scoresWithIdOnly = await prisma.political_news_crawler_popularity_scores.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_popularity_scoresUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_popularity_scoresUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_popularity_scores.\n     * @param {political_news_crawler_popularity_scoresUpsertArgs} args - Arguments to update or create a Political_news_crawler_popularity_scores.\n     * @example\n     * // Update or create a Political_news_crawler_popularity_scores\n     * const political_news_crawler_popularity_scores = await prisma.political_news_crawler_popularity_scores.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_popularity_scores\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_popularity_scores we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_popularity_scoresUpsertArgs>(args: SelectSubset<T, political_news_crawler_popularity_scoresUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_popularity_scoresClient<$Result.GetResult<Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_popularity_scores.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_popularity_scoresCountArgs} args - Arguments to filter Political_news_crawler_popularity_scores to count.\n     * @example\n     * // Count the number of Political_news_crawler_popularity_scores\n     * const count = await prisma.political_news_crawler_popularity_scores.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_popularity_scores we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_popularity_scoresCountArgs>(\n      args?: Subset<T, political_news_crawler_popularity_scoresCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_popularity_scoresCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_popularity_scores.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_popularity_scoresAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_popularity_scoresAggregateArgs>(args: Subset<T, Political_news_crawler_popularity_scoresAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_popularity_scoresAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_popularity_scores.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_popularity_scoresGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_popularity_scoresGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_popularity_scoresGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_popularity_scoresGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_popularity_scoresGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_popularity_scoresGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_popularity_scores model\n   */\n  readonly fields: political_news_crawler_popularity_scoresFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_popularity_scores.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_popularity_scoresClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    popularTopic<T extends political_news_crawler_popular_topicsDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_popular_topicsDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_popular_topicsClient<$Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_popularity_scores model\n   */\n  interface political_news_crawler_popularity_scoresFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_popularity_scores\", 'String'>\n    readonly political_news_crawler_popular_topic_id: FieldRef<\"political_news_crawler_popularity_scores\", 'String'>\n    readonly score: FieldRef<\"political_news_crawler_popularity_scores\", 'Float'>\n    readonly decay_factor: FieldRef<\"political_news_crawler_popularity_scores\", 'Float'>\n    readonly snapshot_at: FieldRef<\"political_news_crawler_popularity_scores\", 'DateTime'>\n    readonly created_at: FieldRef<\"political_news_crawler_popularity_scores\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_popularity_scores\", 'DateTime'>\n    readonly deleted_at: FieldRef<\"political_news_crawler_popularity_scores\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_popularity_scores findUnique\n   */\n  export type political_news_crawler_popularity_scoresFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popularity_scores\n     */\n    select?: political_news_crawler_popularity_scoresSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popularity_scores\n     */\n    omit?: political_news_crawler_popularity_scoresOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popularity_scoresInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_popularity_scores to fetch.\n     */\n    where: political_news_crawler_popularity_scoresWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_popularity_scores findUniqueOrThrow\n   */\n  export type political_news_crawler_popularity_scoresFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popularity_scores\n     */\n    select?: political_news_crawler_popularity_scoresSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popularity_scores\n     */\n    omit?: political_news_crawler_popularity_scoresOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popularity_scoresInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_popularity_scores to fetch.\n     */\n    where: political_news_crawler_popularity_scoresWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_popularity_scores findFirst\n   */\n  export type political_news_crawler_popularity_scoresFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popularity_scores\n     */\n    select?: political_news_crawler_popularity_scoresSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popularity_scores\n     */\n    omit?: political_news_crawler_popularity_scoresOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popularity_scoresInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_popularity_scores to fetch.\n     */\n    where?: political_news_crawler_popularity_scoresWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_popularity_scores to fetch.\n     */\n    orderBy?: political_news_crawler_popularity_scoresOrderByWithRelationInput | political_news_crawler_popularity_scoresOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_popularity_scores.\n     */\n    cursor?: political_news_crawler_popularity_scoresWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_popularity_scores from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_popularity_scores.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_popularity_scores.\n     */\n    distinct?: Political_news_crawler_popularity_scoresScalarFieldEnum | Political_news_crawler_popularity_scoresScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_popularity_scores findFirstOrThrow\n   */\n  export type political_news_crawler_popularity_scoresFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popularity_scores\n     */\n    select?: political_news_crawler_popularity_scoresSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popularity_scores\n     */\n    omit?: political_news_crawler_popularity_scoresOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popularity_scoresInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_popularity_scores to fetch.\n     */\n    where?: political_news_crawler_popularity_scoresWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_popularity_scores to fetch.\n     */\n    orderBy?: political_news_crawler_popularity_scoresOrderByWithRelationInput | political_news_crawler_popularity_scoresOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_popularity_scores.\n     */\n    cursor?: political_news_crawler_popularity_scoresWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_popularity_scores from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_popularity_scores.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_popularity_scores.\n     */\n    distinct?: Political_news_crawler_popularity_scoresScalarFieldEnum | Political_news_crawler_popularity_scoresScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_popularity_scores findMany\n   */\n  export type political_news_crawler_popularity_scoresFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popularity_scores\n     */\n    select?: political_news_crawler_popularity_scoresSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popularity_scores\n     */\n    omit?: political_news_crawler_popularity_scoresOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popularity_scoresInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_popularity_scores to fetch.\n     */\n    where?: political_news_crawler_popularity_scoresWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_popularity_scores to fetch.\n     */\n    orderBy?: political_news_crawler_popularity_scoresOrderByWithRelationInput | political_news_crawler_popularity_scoresOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_popularity_scores.\n     */\n    cursor?: political_news_crawler_popularity_scoresWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_popularity_scores from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_popularity_scores.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_popularity_scoresScalarFieldEnum | Political_news_crawler_popularity_scoresScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_popularity_scores create\n   */\n  export type political_news_crawler_popularity_scoresCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popularity_scores\n     */\n    select?: political_news_crawler_popularity_scoresSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popularity_scores\n     */\n    omit?: political_news_crawler_popularity_scoresOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popularity_scoresInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_popularity_scores.\n     */\n    data: XOR<political_news_crawler_popularity_scoresCreateInput, political_news_crawler_popularity_scoresUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_popularity_scores createMany\n   */\n  export type political_news_crawler_popularity_scoresCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_popularity_scores.\n     */\n    data: political_news_crawler_popularity_scoresCreateManyInput | political_news_crawler_popularity_scoresCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_popularity_scores createManyAndReturn\n   */\n  export type political_news_crawler_popularity_scoresCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popularity_scores\n     */\n    select?: political_news_crawler_popularity_scoresSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popularity_scores\n     */\n    omit?: political_news_crawler_popularity_scoresOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_popularity_scores.\n     */\n    data: political_news_crawler_popularity_scoresCreateManyInput | political_news_crawler_popularity_scoresCreateManyInput[]\n    skipDuplicates?: boolean\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popularity_scoresIncludeCreateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_popularity_scores update\n   */\n  export type political_news_crawler_popularity_scoresUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popularity_scores\n     */\n    select?: political_news_crawler_popularity_scoresSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popularity_scores\n     */\n    omit?: political_news_crawler_popularity_scoresOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popularity_scoresInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_popularity_scores.\n     */\n    data: XOR<political_news_crawler_popularity_scoresUpdateInput, political_news_crawler_popularity_scoresUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_popularity_scores to update.\n     */\n    where: political_news_crawler_popularity_scoresWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_popularity_scores updateMany\n   */\n  export type political_news_crawler_popularity_scoresUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_popularity_scores.\n     */\n    data: XOR<political_news_crawler_popularity_scoresUpdateManyMutationInput, political_news_crawler_popularity_scoresUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_popularity_scores to update\n     */\n    where?: political_news_crawler_popularity_scoresWhereInput\n    /**\n     * Limit how many political_news_crawler_popularity_scores to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_popularity_scores updateManyAndReturn\n   */\n  export type political_news_crawler_popularity_scoresUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popularity_scores\n     */\n    select?: political_news_crawler_popularity_scoresSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popularity_scores\n     */\n    omit?: political_news_crawler_popularity_scoresOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_popularity_scores.\n     */\n    data: XOR<political_news_crawler_popularity_scoresUpdateManyMutationInput, political_news_crawler_popularity_scoresUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_popularity_scores to update\n     */\n    where?: political_news_crawler_popularity_scoresWhereInput\n    /**\n     * Limit how many political_news_crawler_popularity_scores to update.\n     */\n    limit?: number\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popularity_scoresIncludeUpdateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_popularity_scores upsert\n   */\n  export type political_news_crawler_popularity_scoresUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popularity_scores\n     */\n    select?: political_news_crawler_popularity_scoresSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popularity_scores\n     */\n    omit?: political_news_crawler_popularity_scoresOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popularity_scoresInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_popularity_scores to update in case it exists.\n     */\n    where: political_news_crawler_popularity_scoresWhereUniqueInput\n    /**\n     * In case the political_news_crawler_popularity_scores found by the `where` argument doesn't exist, create a new political_news_crawler_popularity_scores with this data.\n     */\n    create: XOR<political_news_crawler_popularity_scoresCreateInput, political_news_crawler_popularity_scoresUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_popularity_scores was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_popularity_scoresUpdateInput, political_news_crawler_popularity_scoresUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_popularity_scores delete\n   */\n  export type political_news_crawler_popularity_scoresDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popularity_scores\n     */\n    select?: political_news_crawler_popularity_scoresSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popularity_scores\n     */\n    omit?: political_news_crawler_popularity_scoresOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popularity_scoresInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_popularity_scores to delete.\n     */\n    where: political_news_crawler_popularity_scoresWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_popularity_scores deleteMany\n   */\n  export type political_news_crawler_popularity_scoresDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_popularity_scores to delete\n     */\n    where?: political_news_crawler_popularity_scoresWhereInput\n    /**\n     * Limit how many political_news_crawler_popularity_scores to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_popularity_scores without action\n   */\n  export type political_news_crawler_popularity_scoresDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popularity_scores\n     */\n    select?: political_news_crawler_popularity_scoresSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popularity_scores\n     */\n    omit?: political_news_crawler_popularity_scoresOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popularity_scoresInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_popular_topics\n   */\n\n  export type AggregatePolitical_news_crawler_popular_topics = {\n    _count: Political_news_crawler_popular_topicsCountAggregateOutputType | null\n    _min: Political_news_crawler_popular_topicsMinAggregateOutputType | null\n    _max: Political_news_crawler_popular_topicsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_popular_topicsMinAggregateOutputType = {\n    id: string | null\n    topic_code: string | null\n    title: string | null\n    description: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_popular_topicsMaxAggregateOutputType = {\n    id: string | null\n    topic_code: string | null\n    title: string | null\n    description: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_popular_topicsCountAggregateOutputType = {\n    id: number\n    topic_code: number\n    title: number\n    description: number\n    created_at: number\n    updated_at: number\n    deleted_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_popular_topicsMinAggregateInputType = {\n    id?: true\n    topic_code?: true\n    title?: true\n    description?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_popular_topicsMaxAggregateInputType = {\n    id?: true\n    topic_code?: true\n    title?: true\n    description?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_popular_topicsCountAggregateInputType = {\n    id?: true\n    topic_code?: true\n    title?: true\n    description?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_popular_topicsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_popular_topics to aggregate.\n     */\n    where?: political_news_crawler_popular_topicsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_popular_topics to fetch.\n     */\n    orderBy?: political_news_crawler_popular_topicsOrderByWithRelationInput | political_news_crawler_popular_topicsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_popular_topicsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_popular_topics from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_popular_topics.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_popular_topics\n    **/\n    _count?: true | Political_news_crawler_popular_topicsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_popular_topicsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_popular_topicsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_popular_topicsAggregateType<T extends Political_news_crawler_popular_topicsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_popular_topics]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_popular_topics[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_popular_topics[P]>\n  }\n\n\n\n\n  export type political_news_crawler_popular_topicsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_popular_topicsWhereInput\n    orderBy?: political_news_crawler_popular_topicsOrderByWithAggregationInput | political_news_crawler_popular_topicsOrderByWithAggregationInput[]\n    by: Political_news_crawler_popular_topicsScalarFieldEnum[] | Political_news_crawler_popular_topicsScalarFieldEnum\n    having?: political_news_crawler_popular_topicsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_popular_topicsCountAggregateInputType | true\n    _min?: Political_news_crawler_popular_topicsMinAggregateInputType\n    _max?: Political_news_crawler_popular_topicsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_popular_topicsGroupByOutputType = {\n    id: string\n    topic_code: string\n    title: string\n    description: string | null\n    created_at: Date\n    updated_at: Date\n    deleted_at: Date | null\n    _count: Political_news_crawler_popular_topicsCountAggregateOutputType | null\n    _min: Political_news_crawler_popular_topicsMinAggregateOutputType | null\n    _max: Political_news_crawler_popular_topicsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_popular_topicsGroupByPayload<T extends political_news_crawler_popular_topicsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_popular_topicsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_popular_topicsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_popular_topicsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_popular_topicsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_popular_topicsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    topic_code?: boolean\n    title?: boolean\n    description?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    political_news_crawler_popularity_scores?: boolean | political_news_crawler_popular_topics$political_news_crawler_popularity_scoresArgs<ExtArgs>\n    political_news_crawler_topic_mentions?: boolean | political_news_crawler_popular_topics$political_news_crawler_topic_mentionsArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_popular_topicsCountOutputTypeDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_popular_topics\"]>\n\n  export type political_news_crawler_popular_topicsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    topic_code?: boolean\n    title?: boolean\n    description?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_popular_topics\"]>\n\n  export type political_news_crawler_popular_topicsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    topic_code?: boolean\n    title?: boolean\n    description?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_popular_topics\"]>\n\n  export type political_news_crawler_popular_topicsSelectScalar = {\n    id?: boolean\n    topic_code?: boolean\n    title?: boolean\n    description?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }\n\n  export type political_news_crawler_popular_topicsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"topic_code\" | \"title\" | \"description\" | \"created_at\" | \"updated_at\" | \"deleted_at\", ExtArgs[\"result\"][\"political_news_crawler_popular_topics\"]>\n  export type political_news_crawler_popular_topicsInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    political_news_crawler_popularity_scores?: boolean | political_news_crawler_popular_topics$political_news_crawler_popularity_scoresArgs<ExtArgs>\n    political_news_crawler_topic_mentions?: boolean | political_news_crawler_popular_topics$political_news_crawler_topic_mentionsArgs<ExtArgs>\n    _count?: boolean | Political_news_crawler_popular_topicsCountOutputTypeDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_popular_topicsIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {}\n  export type political_news_crawler_popular_topicsIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {}\n\n  export type $political_news_crawler_popular_topicsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_popular_topics\"\n    objects: {\n      political_news_crawler_popularity_scores: Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>[]\n      political_news_crawler_topic_mentions: Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>[]\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Unique code identifier for the political topic.\n       */\n      topic_code: string\n      /**\n       * Official title or name of the popular topic.\n       */\n      title: string\n      /**\n       * Optional detailed description or context about the popular topic.\n       */\n      description: string | null\n      /**\n       * Record creation timestamp.\n       */\n      created_at: Date\n      /**\n       * Record last update timestamp.\n       */\n      updated_at: Date\n      /**\n       * Soft deletion timestamp if applicable, otherwise null.\n       */\n      deleted_at: Date | null\n    }, ExtArgs[\"result\"][\"political_news_crawler_popular_topics\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_popular_topicsGetPayload<S extends boolean | null | undefined | political_news_crawler_popular_topicsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload, S>\n\n  type political_news_crawler_popular_topicsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_popular_topicsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_popular_topicsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_popular_topicsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_popular_topics'], meta: { name: 'political_news_crawler_popular_topics' } }\n    /**\n     * Find zero or one Political_news_crawler_popular_topics that matches the filter.\n     * @param {political_news_crawler_popular_topicsFindUniqueArgs} args - Arguments to find a Political_news_crawler_popular_topics\n     * @example\n     * // Get one Political_news_crawler_popular_topics\n     * const political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_popular_topicsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_popular_topicsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_popular_topicsClient<$Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_popular_topics that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_popular_topicsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_popular_topics\n     * @example\n     * // Get one Political_news_crawler_popular_topics\n     * const political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_popular_topicsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_popular_topicsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_popular_topicsClient<$Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_popular_topics that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_popular_topicsFindFirstArgs} args - Arguments to find a Political_news_crawler_popular_topics\n     * @example\n     * // Get one Political_news_crawler_popular_topics\n     * const political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_popular_topicsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_popular_topicsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_popular_topicsClient<$Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_popular_topics that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_popular_topicsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_popular_topics\n     * @example\n     * // Get one Political_news_crawler_popular_topics\n     * const political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_popular_topicsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_popular_topicsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_popular_topicsClient<$Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_popular_topics that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_popular_topicsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_popular_topics\n     * const political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.findMany()\n     * \n     * // Get first 10 Political_news_crawler_popular_topics\n     * const political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_popular_topicsWithIdOnly = await prisma.political_news_crawler_popular_topics.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_popular_topicsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_popular_topicsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_popular_topics.\n     * @param {political_news_crawler_popular_topicsCreateArgs} args - Arguments to create a Political_news_crawler_popular_topics.\n     * @example\n     * // Create one Political_news_crawler_popular_topics\n     * const Political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_popular_topics\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_popular_topicsCreateArgs>(args: SelectSubset<T, political_news_crawler_popular_topicsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_popular_topicsClient<$Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_popular_topics.\n     * @param {political_news_crawler_popular_topicsCreateManyArgs} args - Arguments to create many Political_news_crawler_popular_topics.\n     * @example\n     * // Create many Political_news_crawler_popular_topics\n     * const political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_popular_topicsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_popular_topicsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_popular_topics and returns the data saved in the database.\n     * @param {political_news_crawler_popular_topicsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_popular_topics.\n     * @example\n     * // Create many Political_news_crawler_popular_topics\n     * const political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_popular_topics and only return the `id`\n     * const political_news_crawler_popular_topicsWithIdOnly = await prisma.political_news_crawler_popular_topics.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_popular_topicsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_popular_topicsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_popular_topics.\n     * @param {political_news_crawler_popular_topicsDeleteArgs} args - Arguments to delete one Political_news_crawler_popular_topics.\n     * @example\n     * // Delete one Political_news_crawler_popular_topics\n     * const Political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_popular_topics\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_popular_topicsDeleteArgs>(args: SelectSubset<T, political_news_crawler_popular_topicsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_popular_topicsClient<$Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_popular_topics.\n     * @param {political_news_crawler_popular_topicsUpdateArgs} args - Arguments to update one Political_news_crawler_popular_topics.\n     * @example\n     * // Update one Political_news_crawler_popular_topics\n     * const political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_popular_topicsUpdateArgs>(args: SelectSubset<T, political_news_crawler_popular_topicsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_popular_topicsClient<$Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_popular_topics.\n     * @param {political_news_crawler_popular_topicsDeleteManyArgs} args - Arguments to filter Political_news_crawler_popular_topics to delete.\n     * @example\n     * // Delete a few Political_news_crawler_popular_topics\n     * const { count } = await prisma.political_news_crawler_popular_topics.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_popular_topicsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_popular_topicsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_popular_topics.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_popular_topicsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_popular_topics\n     * const political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_popular_topicsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_popular_topicsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_popular_topics and returns the data updated in the database.\n     * @param {political_news_crawler_popular_topicsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_popular_topics.\n     * @example\n     * // Update many Political_news_crawler_popular_topics\n     * const political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_popular_topics and only return the `id`\n     * const political_news_crawler_popular_topicsWithIdOnly = await prisma.political_news_crawler_popular_topics.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_popular_topicsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_popular_topicsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_popular_topics.\n     * @param {political_news_crawler_popular_topicsUpsertArgs} args - Arguments to update or create a Political_news_crawler_popular_topics.\n     * @example\n     * // Update or create a Political_news_crawler_popular_topics\n     * const political_news_crawler_popular_topics = await prisma.political_news_crawler_popular_topics.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_popular_topics\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_popular_topics we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_popular_topicsUpsertArgs>(args: SelectSubset<T, political_news_crawler_popular_topicsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_popular_topicsClient<$Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_popular_topics.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_popular_topicsCountArgs} args - Arguments to filter Political_news_crawler_popular_topics to count.\n     * @example\n     * // Count the number of Political_news_crawler_popular_topics\n     * const count = await prisma.political_news_crawler_popular_topics.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_popular_topics we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_popular_topicsCountArgs>(\n      args?: Subset<T, political_news_crawler_popular_topicsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_popular_topicsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_popular_topics.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_popular_topicsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_popular_topicsAggregateArgs>(args: Subset<T, Political_news_crawler_popular_topicsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_popular_topicsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_popular_topics.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_popular_topicsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_popular_topicsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_popular_topicsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_popular_topicsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_popular_topicsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_popular_topicsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_popular_topics model\n   */\n  readonly fields: political_news_crawler_popular_topicsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_popular_topics.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_popular_topicsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    political_news_crawler_popularity_scores<T extends political_news_crawler_popular_topics$political_news_crawler_popularity_scoresArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_popular_topics$political_news_crawler_popularity_scoresArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_popularity_scoresPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    political_news_crawler_topic_mentions<T extends political_news_crawler_popular_topics$political_news_crawler_topic_mentionsArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_popular_topics$political_news_crawler_topic_mentionsArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions> | Null>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_popular_topics model\n   */\n  interface political_news_crawler_popular_topicsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_popular_topics\", 'String'>\n    readonly topic_code: FieldRef<\"political_news_crawler_popular_topics\", 'String'>\n    readonly title: FieldRef<\"political_news_crawler_popular_topics\", 'String'>\n    readonly description: FieldRef<\"political_news_crawler_popular_topics\", 'String'>\n    readonly created_at: FieldRef<\"political_news_crawler_popular_topics\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_popular_topics\", 'DateTime'>\n    readonly deleted_at: FieldRef<\"political_news_crawler_popular_topics\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_popular_topics findUnique\n   */\n  export type political_news_crawler_popular_topicsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popular_topics\n     */\n    select?: political_news_crawler_popular_topicsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popular_topics\n     */\n    omit?: political_news_crawler_popular_topicsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popular_topicsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_popular_topics to fetch.\n     */\n    where: political_news_crawler_popular_topicsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_popular_topics findUniqueOrThrow\n   */\n  export type political_news_crawler_popular_topicsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popular_topics\n     */\n    select?: political_news_crawler_popular_topicsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popular_topics\n     */\n    omit?: political_news_crawler_popular_topicsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popular_topicsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_popular_topics to fetch.\n     */\n    where: political_news_crawler_popular_topicsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_popular_topics findFirst\n   */\n  export type political_news_crawler_popular_topicsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popular_topics\n     */\n    select?: political_news_crawler_popular_topicsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popular_topics\n     */\n    omit?: political_news_crawler_popular_topicsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popular_topicsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_popular_topics to fetch.\n     */\n    where?: political_news_crawler_popular_topicsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_popular_topics to fetch.\n     */\n    orderBy?: political_news_crawler_popular_topicsOrderByWithRelationInput | political_news_crawler_popular_topicsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_popular_topics.\n     */\n    cursor?: political_news_crawler_popular_topicsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_popular_topics from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_popular_topics.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_popular_topics.\n     */\n    distinct?: Political_news_crawler_popular_topicsScalarFieldEnum | Political_news_crawler_popular_topicsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_popular_topics findFirstOrThrow\n   */\n  export type political_news_crawler_popular_topicsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popular_topics\n     */\n    select?: political_news_crawler_popular_topicsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popular_topics\n     */\n    omit?: political_news_crawler_popular_topicsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popular_topicsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_popular_topics to fetch.\n     */\n    where?: political_news_crawler_popular_topicsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_popular_topics to fetch.\n     */\n    orderBy?: political_news_crawler_popular_topicsOrderByWithRelationInput | political_news_crawler_popular_topicsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_popular_topics.\n     */\n    cursor?: political_news_crawler_popular_topicsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_popular_topics from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_popular_topics.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_popular_topics.\n     */\n    distinct?: Political_news_crawler_popular_topicsScalarFieldEnum | Political_news_crawler_popular_topicsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_popular_topics findMany\n   */\n  export type political_news_crawler_popular_topicsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popular_topics\n     */\n    select?: political_news_crawler_popular_topicsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popular_topics\n     */\n    omit?: political_news_crawler_popular_topicsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popular_topicsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_popular_topics to fetch.\n     */\n    where?: political_news_crawler_popular_topicsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_popular_topics to fetch.\n     */\n    orderBy?: political_news_crawler_popular_topicsOrderByWithRelationInput | political_news_crawler_popular_topicsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_popular_topics.\n     */\n    cursor?: political_news_crawler_popular_topicsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_popular_topics from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_popular_topics.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_popular_topicsScalarFieldEnum | Political_news_crawler_popular_topicsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_popular_topics create\n   */\n  export type political_news_crawler_popular_topicsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popular_topics\n     */\n    select?: political_news_crawler_popular_topicsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popular_topics\n     */\n    omit?: political_news_crawler_popular_topicsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popular_topicsInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_popular_topics.\n     */\n    data: XOR<political_news_crawler_popular_topicsCreateInput, political_news_crawler_popular_topicsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_popular_topics createMany\n   */\n  export type political_news_crawler_popular_topicsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_popular_topics.\n     */\n    data: political_news_crawler_popular_topicsCreateManyInput | political_news_crawler_popular_topicsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_popular_topics createManyAndReturn\n   */\n  export type political_news_crawler_popular_topicsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popular_topics\n     */\n    select?: political_news_crawler_popular_topicsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popular_topics\n     */\n    omit?: political_news_crawler_popular_topicsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_popular_topics.\n     */\n    data: political_news_crawler_popular_topicsCreateManyInput | political_news_crawler_popular_topicsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_popular_topics update\n   */\n  export type political_news_crawler_popular_topicsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popular_topics\n     */\n    select?: political_news_crawler_popular_topicsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popular_topics\n     */\n    omit?: political_news_crawler_popular_topicsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popular_topicsInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_popular_topics.\n     */\n    data: XOR<political_news_crawler_popular_topicsUpdateInput, political_news_crawler_popular_topicsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_popular_topics to update.\n     */\n    where: political_news_crawler_popular_topicsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_popular_topics updateMany\n   */\n  export type political_news_crawler_popular_topicsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_popular_topics.\n     */\n    data: XOR<political_news_crawler_popular_topicsUpdateManyMutationInput, political_news_crawler_popular_topicsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_popular_topics to update\n     */\n    where?: political_news_crawler_popular_topicsWhereInput\n    /**\n     * Limit how many political_news_crawler_popular_topics to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_popular_topics updateManyAndReturn\n   */\n  export type political_news_crawler_popular_topicsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popular_topics\n     */\n    select?: political_news_crawler_popular_topicsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popular_topics\n     */\n    omit?: political_news_crawler_popular_topicsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_popular_topics.\n     */\n    data: XOR<political_news_crawler_popular_topicsUpdateManyMutationInput, political_news_crawler_popular_topicsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_popular_topics to update\n     */\n    where?: political_news_crawler_popular_topicsWhereInput\n    /**\n     * Limit how many political_news_crawler_popular_topics to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_popular_topics upsert\n   */\n  export type political_news_crawler_popular_topicsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popular_topics\n     */\n    select?: political_news_crawler_popular_topicsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popular_topics\n     */\n    omit?: political_news_crawler_popular_topicsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popular_topicsInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_popular_topics to update in case it exists.\n     */\n    where: political_news_crawler_popular_topicsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_popular_topics found by the `where` argument doesn't exist, create a new political_news_crawler_popular_topics with this data.\n     */\n    create: XOR<political_news_crawler_popular_topicsCreateInput, political_news_crawler_popular_topicsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_popular_topics was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_popular_topicsUpdateInput, political_news_crawler_popular_topicsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_popular_topics delete\n   */\n  export type political_news_crawler_popular_topicsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popular_topics\n     */\n    select?: political_news_crawler_popular_topicsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popular_topics\n     */\n    omit?: political_news_crawler_popular_topicsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popular_topicsInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_popular_topics to delete.\n     */\n    where: political_news_crawler_popular_topicsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_popular_topics deleteMany\n   */\n  export type political_news_crawler_popular_topicsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_popular_topics to delete\n     */\n    where?: political_news_crawler_popular_topicsWhereInput\n    /**\n     * Limit how many political_news_crawler_popular_topics to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_popular_topics.political_news_crawler_popularity_scores\n   */\n  export type political_news_crawler_popular_topics$political_news_crawler_popularity_scoresArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popularity_scores\n     */\n    select?: political_news_crawler_popularity_scoresSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popularity_scores\n     */\n    omit?: political_news_crawler_popularity_scoresOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popularity_scoresInclude<ExtArgs> | null\n    where?: political_news_crawler_popularity_scoresWhereInput\n    orderBy?: political_news_crawler_popularity_scoresOrderByWithRelationInput | political_news_crawler_popularity_scoresOrderByWithRelationInput[]\n    cursor?: political_news_crawler_popularity_scoresWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_popularity_scoresScalarFieldEnum | Political_news_crawler_popularity_scoresScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_popular_topics.political_news_crawler_topic_mentions\n   */\n  export type political_news_crawler_popular_topics$political_news_crawler_topic_mentionsArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsInclude<ExtArgs> | null\n    where?: political_news_crawler_topic_mentionsWhereInput\n    orderBy?: political_news_crawler_topic_mentionsOrderByWithRelationInput | political_news_crawler_topic_mentionsOrderByWithRelationInput[]\n    cursor?: political_news_crawler_topic_mentionsWhereUniqueInput\n    take?: number\n    skip?: number\n    distinct?: Political_news_crawler_topic_mentionsScalarFieldEnum | Political_news_crawler_topic_mentionsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_popular_topics without action\n   */\n  export type political_news_crawler_popular_topicsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_popular_topics\n     */\n    select?: political_news_crawler_popular_topicsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_popular_topics\n     */\n    omit?: political_news_crawler_popular_topicsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_popular_topicsInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_topic_mentions\n   */\n\n  export type AggregatePolitical_news_crawler_topic_mentions = {\n    _count: Political_news_crawler_topic_mentionsCountAggregateOutputType | null\n    _min: Political_news_crawler_topic_mentionsMinAggregateOutputType | null\n    _max: Political_news_crawler_topic_mentionsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_topic_mentionsMinAggregateOutputType = {\n    id: string | null\n    political_news_crawler_popular_topic_id: string | null\n    political_news_crawler_crawled_news_id: string | null\n    mention_context: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_topic_mentionsMaxAggregateOutputType = {\n    id: string | null\n    political_news_crawler_popular_topic_id: string | null\n    political_news_crawler_crawled_news_id: string | null\n    mention_context: string | null\n    created_at: Date | null\n    updated_at: Date | null\n    deleted_at: Date | null\n  }\n\n  export type Political_news_crawler_topic_mentionsCountAggregateOutputType = {\n    id: number\n    political_news_crawler_popular_topic_id: number\n    political_news_crawler_crawled_news_id: number\n    mention_context: number\n    created_at: number\n    updated_at: number\n    deleted_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_topic_mentionsMinAggregateInputType = {\n    id?: true\n    political_news_crawler_popular_topic_id?: true\n    political_news_crawler_crawled_news_id?: true\n    mention_context?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_topic_mentionsMaxAggregateInputType = {\n    id?: true\n    political_news_crawler_popular_topic_id?: true\n    political_news_crawler_crawled_news_id?: true\n    mention_context?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n  }\n\n  export type Political_news_crawler_topic_mentionsCountAggregateInputType = {\n    id?: true\n    political_news_crawler_popular_topic_id?: true\n    political_news_crawler_crawled_news_id?: true\n    mention_context?: true\n    created_at?: true\n    updated_at?: true\n    deleted_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_topic_mentionsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_topic_mentions to aggregate.\n     */\n    where?: political_news_crawler_topic_mentionsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_topic_mentions to fetch.\n     */\n    orderBy?: political_news_crawler_topic_mentionsOrderByWithRelationInput | political_news_crawler_topic_mentionsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_topic_mentionsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_topic_mentions from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_topic_mentions.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_topic_mentions\n    **/\n    _count?: true | Political_news_crawler_topic_mentionsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_topic_mentionsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_topic_mentionsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_topic_mentionsAggregateType<T extends Political_news_crawler_topic_mentionsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_topic_mentions]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_topic_mentions[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_topic_mentions[P]>\n  }\n\n\n\n\n  export type political_news_crawler_topic_mentionsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_topic_mentionsWhereInput\n    orderBy?: political_news_crawler_topic_mentionsOrderByWithAggregationInput | political_news_crawler_topic_mentionsOrderByWithAggregationInput[]\n    by: Political_news_crawler_topic_mentionsScalarFieldEnum[] | Political_news_crawler_topic_mentionsScalarFieldEnum\n    having?: political_news_crawler_topic_mentionsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_topic_mentionsCountAggregateInputType | true\n    _min?: Political_news_crawler_topic_mentionsMinAggregateInputType\n    _max?: Political_news_crawler_topic_mentionsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_topic_mentionsGroupByOutputType = {\n    id: string\n    political_news_crawler_popular_topic_id: string\n    political_news_crawler_crawled_news_id: string\n    mention_context: string | null\n    created_at: Date\n    updated_at: Date\n    deleted_at: Date | null\n    _count: Political_news_crawler_topic_mentionsCountAggregateOutputType | null\n    _min: Political_news_crawler_topic_mentionsMinAggregateOutputType | null\n    _max: Political_news_crawler_topic_mentionsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_topic_mentionsGroupByPayload<T extends political_news_crawler_topic_mentionsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_topic_mentionsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_topic_mentionsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_topic_mentionsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_topic_mentionsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_topic_mentionsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    political_news_crawler_popular_topic_id?: boolean\n    political_news_crawler_crawled_news_id?: boolean\n    mention_context?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    popularTopic?: boolean | political_news_crawler_popular_topicsDefaultArgs<ExtArgs>\n    crawledNews?: boolean | political_news_crawler_crawled_newsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_topic_mentions\"]>\n\n  export type political_news_crawler_topic_mentionsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    political_news_crawler_popular_topic_id?: boolean\n    political_news_crawler_crawled_news_id?: boolean\n    mention_context?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    popularTopic?: boolean | political_news_crawler_popular_topicsDefaultArgs<ExtArgs>\n    crawledNews?: boolean | political_news_crawler_crawled_newsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_topic_mentions\"]>\n\n  export type political_news_crawler_topic_mentionsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    political_news_crawler_popular_topic_id?: boolean\n    political_news_crawler_crawled_news_id?: boolean\n    mention_context?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n    popularTopic?: boolean | political_news_crawler_popular_topicsDefaultArgs<ExtArgs>\n    crawledNews?: boolean | political_news_crawler_crawled_newsDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_topic_mentions\"]>\n\n  export type political_news_crawler_topic_mentionsSelectScalar = {\n    id?: boolean\n    political_news_crawler_popular_topic_id?: boolean\n    political_news_crawler_crawled_news_id?: boolean\n    mention_context?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    deleted_at?: boolean\n  }\n\n  export type political_news_crawler_topic_mentionsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"political_news_crawler_popular_topic_id\" | \"political_news_crawler_crawled_news_id\" | \"mention_context\" | \"created_at\" | \"updated_at\" | \"deleted_at\", ExtArgs[\"result\"][\"political_news_crawler_topic_mentions\"]>\n  export type political_news_crawler_topic_mentionsInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    popularTopic?: boolean | political_news_crawler_popular_topicsDefaultArgs<ExtArgs>\n    crawledNews?: boolean | political_news_crawler_crawled_newsDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_topic_mentionsIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    popularTopic?: boolean | political_news_crawler_popular_topicsDefaultArgs<ExtArgs>\n    crawledNews?: boolean | political_news_crawler_crawled_newsDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_topic_mentionsIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    popularTopic?: boolean | political_news_crawler_popular_topicsDefaultArgs<ExtArgs>\n    crawledNews?: boolean | political_news_crawler_crawled_newsDefaultArgs<ExtArgs>\n  }\n\n  export type $political_news_crawler_topic_mentionsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_topic_mentions\"\n    objects: {\n      popularTopic: Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>\n      crawledNews: Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Referenced popular topic's {@link\n       * political_news_crawler_popular_topics.id}.\n       */\n      political_news_crawler_popular_topic_id: string\n      /**\n       * Referenced crawled news item's {@link\n       * political_news_crawler_crawled_news.id}.\n       */\n      political_news_crawler_crawled_news_id: string\n      /**\n       * Optional text snippet or context where the topic is mentioned within the\n       * article.\n       */\n      mention_context: string | null\n      /**\n       * Record creation timestamp.\n       */\n      created_at: Date\n      /**\n       * Record last update timestamp.\n       */\n      updated_at: Date\n      /**\n       * Soft deletion timestamp if applicable, otherwise null.\n       */\n      deleted_at: Date | null\n    }, ExtArgs[\"result\"][\"political_news_crawler_topic_mentions\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_topic_mentionsGetPayload<S extends boolean | null | undefined | political_news_crawler_topic_mentionsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload, S>\n\n  type political_news_crawler_topic_mentionsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_topic_mentionsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_topic_mentionsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_topic_mentionsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_topic_mentions'], meta: { name: 'political_news_crawler_topic_mentions' } }\n    /**\n     * Find zero or one Political_news_crawler_topic_mentions that matches the filter.\n     * @param {political_news_crawler_topic_mentionsFindUniqueArgs} args - Arguments to find a Political_news_crawler_topic_mentions\n     * @example\n     * // Get one Political_news_crawler_topic_mentions\n     * const political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_topic_mentionsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_topic_mentionsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_topic_mentionsClient<$Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_topic_mentions that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_topic_mentionsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_topic_mentions\n     * @example\n     * // Get one Political_news_crawler_topic_mentions\n     * const political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_topic_mentionsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_topic_mentionsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_topic_mentionsClient<$Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_topic_mentions that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_topic_mentionsFindFirstArgs} args - Arguments to find a Political_news_crawler_topic_mentions\n     * @example\n     * // Get one Political_news_crawler_topic_mentions\n     * const political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_topic_mentionsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_topic_mentionsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_topic_mentionsClient<$Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_topic_mentions that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_topic_mentionsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_topic_mentions\n     * @example\n     * // Get one Political_news_crawler_topic_mentions\n     * const political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_topic_mentionsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_topic_mentionsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_topic_mentionsClient<$Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_topic_mentions that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_topic_mentionsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_topic_mentions\n     * const political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.findMany()\n     * \n     * // Get first 10 Political_news_crawler_topic_mentions\n     * const political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_topic_mentionsWithIdOnly = await prisma.political_news_crawler_topic_mentions.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_topic_mentionsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_topic_mentionsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_topic_mentions.\n     * @param {political_news_crawler_topic_mentionsCreateArgs} args - Arguments to create a Political_news_crawler_topic_mentions.\n     * @example\n     * // Create one Political_news_crawler_topic_mentions\n     * const Political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_topic_mentions\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_topic_mentionsCreateArgs>(args: SelectSubset<T, political_news_crawler_topic_mentionsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_topic_mentionsClient<$Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_topic_mentions.\n     * @param {political_news_crawler_topic_mentionsCreateManyArgs} args - Arguments to create many Political_news_crawler_topic_mentions.\n     * @example\n     * // Create many Political_news_crawler_topic_mentions\n     * const political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_topic_mentionsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_topic_mentionsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_topic_mentions and returns the data saved in the database.\n     * @param {political_news_crawler_topic_mentionsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_topic_mentions.\n     * @example\n     * // Create many Political_news_crawler_topic_mentions\n     * const political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_topic_mentions and only return the `id`\n     * const political_news_crawler_topic_mentionsWithIdOnly = await prisma.political_news_crawler_topic_mentions.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_topic_mentionsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_topic_mentionsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_topic_mentions.\n     * @param {political_news_crawler_topic_mentionsDeleteArgs} args - Arguments to delete one Political_news_crawler_topic_mentions.\n     * @example\n     * // Delete one Political_news_crawler_topic_mentions\n     * const Political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_topic_mentions\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_topic_mentionsDeleteArgs>(args: SelectSubset<T, political_news_crawler_topic_mentionsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_topic_mentionsClient<$Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_topic_mentions.\n     * @param {political_news_crawler_topic_mentionsUpdateArgs} args - Arguments to update one Political_news_crawler_topic_mentions.\n     * @example\n     * // Update one Political_news_crawler_topic_mentions\n     * const political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_topic_mentionsUpdateArgs>(args: SelectSubset<T, political_news_crawler_topic_mentionsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_topic_mentionsClient<$Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_topic_mentions.\n     * @param {political_news_crawler_topic_mentionsDeleteManyArgs} args - Arguments to filter Political_news_crawler_topic_mentions to delete.\n     * @example\n     * // Delete a few Political_news_crawler_topic_mentions\n     * const { count } = await prisma.political_news_crawler_topic_mentions.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_topic_mentionsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_topic_mentionsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_topic_mentions.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_topic_mentionsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_topic_mentions\n     * const political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_topic_mentionsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_topic_mentionsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_topic_mentions and returns the data updated in the database.\n     * @param {political_news_crawler_topic_mentionsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_topic_mentions.\n     * @example\n     * // Update many Political_news_crawler_topic_mentions\n     * const political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_topic_mentions and only return the `id`\n     * const political_news_crawler_topic_mentionsWithIdOnly = await prisma.political_news_crawler_topic_mentions.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_topic_mentionsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_topic_mentionsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_topic_mentions.\n     * @param {political_news_crawler_topic_mentionsUpsertArgs} args - Arguments to update or create a Political_news_crawler_topic_mentions.\n     * @example\n     * // Update or create a Political_news_crawler_topic_mentions\n     * const political_news_crawler_topic_mentions = await prisma.political_news_crawler_topic_mentions.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_topic_mentions\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_topic_mentions we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_topic_mentionsUpsertArgs>(args: SelectSubset<T, political_news_crawler_topic_mentionsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_topic_mentionsClient<$Result.GetResult<Prisma.$political_news_crawler_topic_mentionsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_topic_mentions.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_topic_mentionsCountArgs} args - Arguments to filter Political_news_crawler_topic_mentions to count.\n     * @example\n     * // Count the number of Political_news_crawler_topic_mentions\n     * const count = await prisma.political_news_crawler_topic_mentions.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_topic_mentions we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_topic_mentionsCountArgs>(\n      args?: Subset<T, political_news_crawler_topic_mentionsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_topic_mentionsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_topic_mentions.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_topic_mentionsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_topic_mentionsAggregateArgs>(args: Subset<T, Political_news_crawler_topic_mentionsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_topic_mentionsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_topic_mentions.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_topic_mentionsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_topic_mentionsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_topic_mentionsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_topic_mentionsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_topic_mentionsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_topic_mentionsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_topic_mentions model\n   */\n  readonly fields: political_news_crawler_topic_mentionsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_topic_mentions.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_topic_mentionsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    popularTopic<T extends political_news_crawler_popular_topicsDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_popular_topicsDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_popular_topicsClient<$Result.GetResult<Prisma.$political_news_crawler_popular_topicsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    crawledNews<T extends political_news_crawler_crawled_newsDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawled_newsDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_crawled_newsClient<$Result.GetResult<Prisma.$political_news_crawler_crawled_newsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_topic_mentions model\n   */\n  interface political_news_crawler_topic_mentionsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_topic_mentions\", 'String'>\n    readonly political_news_crawler_popular_topic_id: FieldRef<\"political_news_crawler_topic_mentions\", 'String'>\n    readonly political_news_crawler_crawled_news_id: FieldRef<\"political_news_crawler_topic_mentions\", 'String'>\n    readonly mention_context: FieldRef<\"political_news_crawler_topic_mentions\", 'String'>\n    readonly created_at: FieldRef<\"political_news_crawler_topic_mentions\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_topic_mentions\", 'DateTime'>\n    readonly deleted_at: FieldRef<\"political_news_crawler_topic_mentions\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_topic_mentions findUnique\n   */\n  export type political_news_crawler_topic_mentionsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_topic_mentions to fetch.\n     */\n    where: political_news_crawler_topic_mentionsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_topic_mentions findUniqueOrThrow\n   */\n  export type political_news_crawler_topic_mentionsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_topic_mentions to fetch.\n     */\n    where: political_news_crawler_topic_mentionsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_topic_mentions findFirst\n   */\n  export type political_news_crawler_topic_mentionsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_topic_mentions to fetch.\n     */\n    where?: political_news_crawler_topic_mentionsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_topic_mentions to fetch.\n     */\n    orderBy?: political_news_crawler_topic_mentionsOrderByWithRelationInput | political_news_crawler_topic_mentionsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_topic_mentions.\n     */\n    cursor?: political_news_crawler_topic_mentionsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_topic_mentions from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_topic_mentions.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_topic_mentions.\n     */\n    distinct?: Political_news_crawler_topic_mentionsScalarFieldEnum | Political_news_crawler_topic_mentionsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_topic_mentions findFirstOrThrow\n   */\n  export type political_news_crawler_topic_mentionsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_topic_mentions to fetch.\n     */\n    where?: political_news_crawler_topic_mentionsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_topic_mentions to fetch.\n     */\n    orderBy?: political_news_crawler_topic_mentionsOrderByWithRelationInput | political_news_crawler_topic_mentionsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_topic_mentions.\n     */\n    cursor?: political_news_crawler_topic_mentionsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_topic_mentions from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_topic_mentions.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_topic_mentions.\n     */\n    distinct?: Political_news_crawler_topic_mentionsScalarFieldEnum | Political_news_crawler_topic_mentionsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_topic_mentions findMany\n   */\n  export type political_news_crawler_topic_mentionsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_topic_mentions to fetch.\n     */\n    where?: political_news_crawler_topic_mentionsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_topic_mentions to fetch.\n     */\n    orderBy?: political_news_crawler_topic_mentionsOrderByWithRelationInput | political_news_crawler_topic_mentionsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_topic_mentions.\n     */\n    cursor?: political_news_crawler_topic_mentionsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_topic_mentions from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_topic_mentions.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_topic_mentionsScalarFieldEnum | Political_news_crawler_topic_mentionsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_topic_mentions create\n   */\n  export type political_news_crawler_topic_mentionsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_topic_mentions.\n     */\n    data: XOR<political_news_crawler_topic_mentionsCreateInput, political_news_crawler_topic_mentionsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_topic_mentions createMany\n   */\n  export type political_news_crawler_topic_mentionsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_topic_mentions.\n     */\n    data: political_news_crawler_topic_mentionsCreateManyInput | political_news_crawler_topic_mentionsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_topic_mentions createManyAndReturn\n   */\n  export type political_news_crawler_topic_mentionsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_topic_mentions.\n     */\n    data: political_news_crawler_topic_mentionsCreateManyInput | political_news_crawler_topic_mentionsCreateManyInput[]\n    skipDuplicates?: boolean\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsIncludeCreateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_topic_mentions update\n   */\n  export type political_news_crawler_topic_mentionsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_topic_mentions.\n     */\n    data: XOR<political_news_crawler_topic_mentionsUpdateInput, political_news_crawler_topic_mentionsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_topic_mentions to update.\n     */\n    where: political_news_crawler_topic_mentionsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_topic_mentions updateMany\n   */\n  export type political_news_crawler_topic_mentionsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_topic_mentions.\n     */\n    data: XOR<political_news_crawler_topic_mentionsUpdateManyMutationInput, political_news_crawler_topic_mentionsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_topic_mentions to update\n     */\n    where?: political_news_crawler_topic_mentionsWhereInput\n    /**\n     * Limit how many political_news_crawler_topic_mentions to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_topic_mentions updateManyAndReturn\n   */\n  export type political_news_crawler_topic_mentionsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_topic_mentions.\n     */\n    data: XOR<political_news_crawler_topic_mentionsUpdateManyMutationInput, political_news_crawler_topic_mentionsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_topic_mentions to update\n     */\n    where?: political_news_crawler_topic_mentionsWhereInput\n    /**\n     * Limit how many political_news_crawler_topic_mentions to update.\n     */\n    limit?: number\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsIncludeUpdateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_topic_mentions upsert\n   */\n  export type political_news_crawler_topic_mentionsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_topic_mentions to update in case it exists.\n     */\n    where: political_news_crawler_topic_mentionsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_topic_mentions found by the `where` argument doesn't exist, create a new political_news_crawler_topic_mentions with this data.\n     */\n    create: XOR<political_news_crawler_topic_mentionsCreateInput, political_news_crawler_topic_mentionsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_topic_mentions was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_topic_mentionsUpdateInput, political_news_crawler_topic_mentionsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_topic_mentions delete\n   */\n  export type political_news_crawler_topic_mentionsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_topic_mentions to delete.\n     */\n    where: political_news_crawler_topic_mentionsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_topic_mentions deleteMany\n   */\n  export type political_news_crawler_topic_mentionsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_topic_mentions to delete\n     */\n    where?: political_news_crawler_topic_mentionsWhereInput\n    /**\n     * Limit how many political_news_crawler_topic_mentions to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_topic_mentions without action\n   */\n  export type political_news_crawler_topic_mentionsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_topic_mentions\n     */\n    select?: political_news_crawler_topic_mentionsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_topic_mentions\n     */\n    omit?: political_news_crawler_topic_mentionsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_topic_mentionsInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_api_access_logs\n   */\n\n  export type AggregatePolitical_news_crawler_api_access_logs = {\n    _count: Political_news_crawler_api_access_logsCountAggregateOutputType | null\n    _avg: Political_news_crawler_api_access_logsAvgAggregateOutputType | null\n    _sum: Political_news_crawler_api_access_logsSumAggregateOutputType | null\n    _min: Political_news_crawler_api_access_logsMinAggregateOutputType | null\n    _max: Political_news_crawler_api_access_logsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_api_access_logsAvgAggregateOutputType = {\n    status_code: number | null\n    duration_ms: number | null\n  }\n\n  export type Political_news_crawler_api_access_logsSumAggregateOutputType = {\n    status_code: number | null\n    duration_ms: number | null\n  }\n\n  export type Political_news_crawler_api_access_logsMinAggregateOutputType = {\n    id: string | null\n    http_method: string | null\n    path: string | null\n    status_code: number | null\n    client_ip: string | null\n    user_agent: string | null\n    duration_ms: number | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_api_access_logsMaxAggregateOutputType = {\n    id: string | null\n    http_method: string | null\n    path: string | null\n    status_code: number | null\n    client_ip: string | null\n    user_agent: string | null\n    duration_ms: number | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_api_access_logsCountAggregateOutputType = {\n    id: number\n    http_method: number\n    path: number\n    status_code: number\n    client_ip: number\n    user_agent: number\n    duration_ms: number\n    created_at: number\n    updated_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_api_access_logsAvgAggregateInputType = {\n    status_code?: true\n    duration_ms?: true\n  }\n\n  export type Political_news_crawler_api_access_logsSumAggregateInputType = {\n    status_code?: true\n    duration_ms?: true\n  }\n\n  export type Political_news_crawler_api_access_logsMinAggregateInputType = {\n    id?: true\n    http_method?: true\n    path?: true\n    status_code?: true\n    client_ip?: true\n    user_agent?: true\n    duration_ms?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_api_access_logsMaxAggregateInputType = {\n    id?: true\n    http_method?: true\n    path?: true\n    status_code?: true\n    client_ip?: true\n    user_agent?: true\n    duration_ms?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_api_access_logsCountAggregateInputType = {\n    id?: true\n    http_method?: true\n    path?: true\n    status_code?: true\n    client_ip?: true\n    user_agent?: true\n    duration_ms?: true\n    created_at?: true\n    updated_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_api_access_logsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_api_access_logs to aggregate.\n     */\n    where?: political_news_crawler_api_access_logsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_access_logs to fetch.\n     */\n    orderBy?: political_news_crawler_api_access_logsOrderByWithRelationInput | political_news_crawler_api_access_logsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_api_access_logsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_access_logs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_access_logs.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_api_access_logs\n    **/\n    _count?: true | Political_news_crawler_api_access_logsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to average\n    **/\n    _avg?: Political_news_crawler_api_access_logsAvgAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to sum\n    **/\n    _sum?: Political_news_crawler_api_access_logsSumAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_api_access_logsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_api_access_logsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_api_access_logsAggregateType<T extends Political_news_crawler_api_access_logsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_api_access_logs]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_api_access_logs[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_api_access_logs[P]>\n  }\n\n\n\n\n  export type political_news_crawler_api_access_logsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_api_access_logsWhereInput\n    orderBy?: political_news_crawler_api_access_logsOrderByWithAggregationInput | political_news_crawler_api_access_logsOrderByWithAggregationInput[]\n    by: Political_news_crawler_api_access_logsScalarFieldEnum[] | Political_news_crawler_api_access_logsScalarFieldEnum\n    having?: political_news_crawler_api_access_logsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_api_access_logsCountAggregateInputType | true\n    _avg?: Political_news_crawler_api_access_logsAvgAggregateInputType\n    _sum?: Political_news_crawler_api_access_logsSumAggregateInputType\n    _min?: Political_news_crawler_api_access_logsMinAggregateInputType\n    _max?: Political_news_crawler_api_access_logsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_api_access_logsGroupByOutputType = {\n    id: string\n    http_method: string\n    path: string\n    status_code: number\n    client_ip: string\n    user_agent: string\n    duration_ms: number\n    created_at: Date\n    updated_at: Date\n    _count: Political_news_crawler_api_access_logsCountAggregateOutputType | null\n    _avg: Political_news_crawler_api_access_logsAvgAggregateOutputType | null\n    _sum: Political_news_crawler_api_access_logsSumAggregateOutputType | null\n    _min: Political_news_crawler_api_access_logsMinAggregateOutputType | null\n    _max: Political_news_crawler_api_access_logsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_api_access_logsGroupByPayload<T extends political_news_crawler_api_access_logsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_api_access_logsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_api_access_logsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_api_access_logsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_api_access_logsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_api_access_logsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    http_method?: boolean\n    path?: boolean\n    status_code?: boolean\n    client_ip?: boolean\n    user_agent?: boolean\n    duration_ms?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_api_access_logs\"]>\n\n  export type political_news_crawler_api_access_logsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    http_method?: boolean\n    path?: boolean\n    status_code?: boolean\n    client_ip?: boolean\n    user_agent?: boolean\n    duration_ms?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_api_access_logs\"]>\n\n  export type political_news_crawler_api_access_logsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    http_method?: boolean\n    path?: boolean\n    status_code?: boolean\n    client_ip?: boolean\n    user_agent?: boolean\n    duration_ms?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_api_access_logs\"]>\n\n  export type political_news_crawler_api_access_logsSelectScalar = {\n    id?: boolean\n    http_method?: boolean\n    path?: boolean\n    status_code?: boolean\n    client_ip?: boolean\n    user_agent?: boolean\n    duration_ms?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }\n\n  export type political_news_crawler_api_access_logsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"http_method\" | \"path\" | \"status_code\" | \"client_ip\" | \"user_agent\" | \"duration_ms\" | \"created_at\" | \"updated_at\", ExtArgs[\"result\"][\"political_news_crawler_api_access_logs\"]>\n\n  export type $political_news_crawler_api_access_logsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_api_access_logs\"\n    objects: {}\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * HTTP request method used in the API call, e.g., GET, POST, PUT.\n       */\n      http_method: string\n      /**\n       * API endpoint path being accessed, e.g., /api/v1/popular_topics.\n       */\n      path: string\n      /**\n       * HTTP response status code returned to the client.\n       */\n      status_code: number\n      /**\n       * IP address of the client making the API request.\n       */\n      client_ip: string\n      /**\n       * User agent string of the client or application making the request.\n       */\n      user_agent: string\n      /**\n       * Duration of the API request processing in milliseconds.\n       */\n      duration_ms: number\n      /**\n       * Timestamp when the log entry was created.\n       */\n      created_at: Date\n      /**\n       * Timestamp when the log entry was last updated.\n       */\n      updated_at: Date\n    }, ExtArgs[\"result\"][\"political_news_crawler_api_access_logs\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_api_access_logsGetPayload<S extends boolean | null | undefined | political_news_crawler_api_access_logsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_api_access_logsPayload, S>\n\n  type political_news_crawler_api_access_logsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_api_access_logsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_api_access_logsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_api_access_logsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_api_access_logs'], meta: { name: 'political_news_crawler_api_access_logs' } }\n    /**\n     * Find zero or one Political_news_crawler_api_access_logs that matches the filter.\n     * @param {political_news_crawler_api_access_logsFindUniqueArgs} args - Arguments to find a Political_news_crawler_api_access_logs\n     * @example\n     * // Get one Political_news_crawler_api_access_logs\n     * const political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_api_access_logsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_api_access_logsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_api_access_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_access_logsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_api_access_logs that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_api_access_logsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_api_access_logs\n     * @example\n     * // Get one Political_news_crawler_api_access_logs\n     * const political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_api_access_logsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_api_access_logsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_api_access_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_access_logsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_api_access_logs that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_access_logsFindFirstArgs} args - Arguments to find a Political_news_crawler_api_access_logs\n     * @example\n     * // Get one Political_news_crawler_api_access_logs\n     * const political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_api_access_logsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_api_access_logsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_api_access_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_access_logsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_api_access_logs that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_access_logsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_api_access_logs\n     * @example\n     * // Get one Political_news_crawler_api_access_logs\n     * const political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_api_access_logsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_api_access_logsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_api_access_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_access_logsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_api_access_logs that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_access_logsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_api_access_logs\n     * const political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.findMany()\n     * \n     * // Get first 10 Political_news_crawler_api_access_logs\n     * const political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_api_access_logsWithIdOnly = await prisma.political_news_crawler_api_access_logs.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_api_access_logsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_api_access_logsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_api_access_logsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_api_access_logs.\n     * @param {political_news_crawler_api_access_logsCreateArgs} args - Arguments to create a Political_news_crawler_api_access_logs.\n     * @example\n     * // Create one Political_news_crawler_api_access_logs\n     * const Political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_api_access_logs\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_api_access_logsCreateArgs>(args: SelectSubset<T, political_news_crawler_api_access_logsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_api_access_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_access_logsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_api_access_logs.\n     * @param {political_news_crawler_api_access_logsCreateManyArgs} args - Arguments to create many Political_news_crawler_api_access_logs.\n     * @example\n     * // Create many Political_news_crawler_api_access_logs\n     * const political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_api_access_logsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_api_access_logsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_api_access_logs and returns the data saved in the database.\n     * @param {political_news_crawler_api_access_logsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_api_access_logs.\n     * @example\n     * // Create many Political_news_crawler_api_access_logs\n     * const political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_api_access_logs and only return the `id`\n     * const political_news_crawler_api_access_logsWithIdOnly = await prisma.political_news_crawler_api_access_logs.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_api_access_logsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_api_access_logsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_api_access_logsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_api_access_logs.\n     * @param {political_news_crawler_api_access_logsDeleteArgs} args - Arguments to delete one Political_news_crawler_api_access_logs.\n     * @example\n     * // Delete one Political_news_crawler_api_access_logs\n     * const Political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_api_access_logs\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_api_access_logsDeleteArgs>(args: SelectSubset<T, political_news_crawler_api_access_logsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_api_access_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_access_logsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_api_access_logs.\n     * @param {political_news_crawler_api_access_logsUpdateArgs} args - Arguments to update one Political_news_crawler_api_access_logs.\n     * @example\n     * // Update one Political_news_crawler_api_access_logs\n     * const political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_api_access_logsUpdateArgs>(args: SelectSubset<T, political_news_crawler_api_access_logsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_api_access_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_access_logsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_api_access_logs.\n     * @param {political_news_crawler_api_access_logsDeleteManyArgs} args - Arguments to filter Political_news_crawler_api_access_logs to delete.\n     * @example\n     * // Delete a few Political_news_crawler_api_access_logs\n     * const { count } = await prisma.political_news_crawler_api_access_logs.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_api_access_logsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_api_access_logsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_api_access_logs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_access_logsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_api_access_logs\n     * const political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_api_access_logsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_api_access_logsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_api_access_logs and returns the data updated in the database.\n     * @param {political_news_crawler_api_access_logsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_api_access_logs.\n     * @example\n     * // Update many Political_news_crawler_api_access_logs\n     * const political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_api_access_logs and only return the `id`\n     * const political_news_crawler_api_access_logsWithIdOnly = await prisma.political_news_crawler_api_access_logs.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_api_access_logsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_api_access_logsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_api_access_logsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_api_access_logs.\n     * @param {political_news_crawler_api_access_logsUpsertArgs} args - Arguments to update or create a Political_news_crawler_api_access_logs.\n     * @example\n     * // Update or create a Political_news_crawler_api_access_logs\n     * const political_news_crawler_api_access_logs = await prisma.political_news_crawler_api_access_logs.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_api_access_logs\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_api_access_logs we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_api_access_logsUpsertArgs>(args: SelectSubset<T, political_news_crawler_api_access_logsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_api_access_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_access_logsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_api_access_logs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_access_logsCountArgs} args - Arguments to filter Political_news_crawler_api_access_logs to count.\n     * @example\n     * // Count the number of Political_news_crawler_api_access_logs\n     * const count = await prisma.political_news_crawler_api_access_logs.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_api_access_logs we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_api_access_logsCountArgs>(\n      args?: Subset<T, political_news_crawler_api_access_logsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_api_access_logsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_api_access_logs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_api_access_logsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_api_access_logsAggregateArgs>(args: Subset<T, Political_news_crawler_api_access_logsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_api_access_logsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_api_access_logs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_access_logsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_api_access_logsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_api_access_logsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_api_access_logsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_api_access_logsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_api_access_logsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_api_access_logs model\n   */\n  readonly fields: political_news_crawler_api_access_logsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_api_access_logs.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_api_access_logsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_api_access_logs model\n   */\n  interface political_news_crawler_api_access_logsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_api_access_logs\", 'String'>\n    readonly http_method: FieldRef<\"political_news_crawler_api_access_logs\", 'String'>\n    readonly path: FieldRef<\"political_news_crawler_api_access_logs\", 'String'>\n    readonly status_code: FieldRef<\"political_news_crawler_api_access_logs\", 'Int'>\n    readonly client_ip: FieldRef<\"political_news_crawler_api_access_logs\", 'String'>\n    readonly user_agent: FieldRef<\"political_news_crawler_api_access_logs\", 'String'>\n    readonly duration_ms: FieldRef<\"political_news_crawler_api_access_logs\", 'Int'>\n    readonly created_at: FieldRef<\"political_news_crawler_api_access_logs\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_api_access_logs\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_api_access_logs findUnique\n   */\n  export type political_news_crawler_api_access_logsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_access_logs\n     */\n    select?: political_news_crawler_api_access_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_access_logs\n     */\n    omit?: political_news_crawler_api_access_logsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_access_logs to fetch.\n     */\n    where: political_news_crawler_api_access_logsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_access_logs findUniqueOrThrow\n   */\n  export type political_news_crawler_api_access_logsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_access_logs\n     */\n    select?: political_news_crawler_api_access_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_access_logs\n     */\n    omit?: political_news_crawler_api_access_logsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_access_logs to fetch.\n     */\n    where: political_news_crawler_api_access_logsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_access_logs findFirst\n   */\n  export type political_news_crawler_api_access_logsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_access_logs\n     */\n    select?: political_news_crawler_api_access_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_access_logs\n     */\n    omit?: political_news_crawler_api_access_logsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_access_logs to fetch.\n     */\n    where?: political_news_crawler_api_access_logsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_access_logs to fetch.\n     */\n    orderBy?: political_news_crawler_api_access_logsOrderByWithRelationInput | political_news_crawler_api_access_logsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_api_access_logs.\n     */\n    cursor?: political_news_crawler_api_access_logsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_access_logs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_access_logs.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_api_access_logs.\n     */\n    distinct?: Political_news_crawler_api_access_logsScalarFieldEnum | Political_news_crawler_api_access_logsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_api_access_logs findFirstOrThrow\n   */\n  export type political_news_crawler_api_access_logsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_access_logs\n     */\n    select?: political_news_crawler_api_access_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_access_logs\n     */\n    omit?: political_news_crawler_api_access_logsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_access_logs to fetch.\n     */\n    where?: political_news_crawler_api_access_logsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_access_logs to fetch.\n     */\n    orderBy?: political_news_crawler_api_access_logsOrderByWithRelationInput | political_news_crawler_api_access_logsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_api_access_logs.\n     */\n    cursor?: political_news_crawler_api_access_logsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_access_logs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_access_logs.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_api_access_logs.\n     */\n    distinct?: Political_news_crawler_api_access_logsScalarFieldEnum | Political_news_crawler_api_access_logsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_api_access_logs findMany\n   */\n  export type political_news_crawler_api_access_logsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_access_logs\n     */\n    select?: political_news_crawler_api_access_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_access_logs\n     */\n    omit?: political_news_crawler_api_access_logsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_access_logs to fetch.\n     */\n    where?: political_news_crawler_api_access_logsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_access_logs to fetch.\n     */\n    orderBy?: political_news_crawler_api_access_logsOrderByWithRelationInput | political_news_crawler_api_access_logsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_api_access_logs.\n     */\n    cursor?: political_news_crawler_api_access_logsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_access_logs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_access_logs.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_api_access_logsScalarFieldEnum | Political_news_crawler_api_access_logsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_api_access_logs create\n   */\n  export type political_news_crawler_api_access_logsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_access_logs\n     */\n    select?: political_news_crawler_api_access_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_access_logs\n     */\n    omit?: political_news_crawler_api_access_logsOmit<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_api_access_logs.\n     */\n    data: XOR<political_news_crawler_api_access_logsCreateInput, political_news_crawler_api_access_logsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_api_access_logs createMany\n   */\n  export type political_news_crawler_api_access_logsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_api_access_logs.\n     */\n    data: political_news_crawler_api_access_logsCreateManyInput | political_news_crawler_api_access_logsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_api_access_logs createManyAndReturn\n   */\n  export type political_news_crawler_api_access_logsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_access_logs\n     */\n    select?: political_news_crawler_api_access_logsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_access_logs\n     */\n    omit?: political_news_crawler_api_access_logsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_api_access_logs.\n     */\n    data: political_news_crawler_api_access_logsCreateManyInput | political_news_crawler_api_access_logsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_api_access_logs update\n   */\n  export type political_news_crawler_api_access_logsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_access_logs\n     */\n    select?: political_news_crawler_api_access_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_access_logs\n     */\n    omit?: political_news_crawler_api_access_logsOmit<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_api_access_logs.\n     */\n    data: XOR<political_news_crawler_api_access_logsUpdateInput, political_news_crawler_api_access_logsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_api_access_logs to update.\n     */\n    where: political_news_crawler_api_access_logsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_access_logs updateMany\n   */\n  export type political_news_crawler_api_access_logsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_api_access_logs.\n     */\n    data: XOR<political_news_crawler_api_access_logsUpdateManyMutationInput, political_news_crawler_api_access_logsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_api_access_logs to update\n     */\n    where?: political_news_crawler_api_access_logsWhereInput\n    /**\n     * Limit how many political_news_crawler_api_access_logs to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_api_access_logs updateManyAndReturn\n   */\n  export type political_news_crawler_api_access_logsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_access_logs\n     */\n    select?: political_news_crawler_api_access_logsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_access_logs\n     */\n    omit?: political_news_crawler_api_access_logsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_api_access_logs.\n     */\n    data: XOR<political_news_crawler_api_access_logsUpdateManyMutationInput, political_news_crawler_api_access_logsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_api_access_logs to update\n     */\n    where?: political_news_crawler_api_access_logsWhereInput\n    /**\n     * Limit how many political_news_crawler_api_access_logs to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_api_access_logs upsert\n   */\n  export type political_news_crawler_api_access_logsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_access_logs\n     */\n    select?: political_news_crawler_api_access_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_access_logs\n     */\n    omit?: political_news_crawler_api_access_logsOmit<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_api_access_logs to update in case it exists.\n     */\n    where: political_news_crawler_api_access_logsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_api_access_logs found by the `where` argument doesn't exist, create a new political_news_crawler_api_access_logs with this data.\n     */\n    create: XOR<political_news_crawler_api_access_logsCreateInput, political_news_crawler_api_access_logsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_api_access_logs was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_api_access_logsUpdateInput, political_news_crawler_api_access_logsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_api_access_logs delete\n   */\n  export type political_news_crawler_api_access_logsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_access_logs\n     */\n    select?: political_news_crawler_api_access_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_access_logs\n     */\n    omit?: political_news_crawler_api_access_logsOmit<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_api_access_logs to delete.\n     */\n    where: political_news_crawler_api_access_logsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_access_logs deleteMany\n   */\n  export type political_news_crawler_api_access_logsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_api_access_logs to delete\n     */\n    where?: political_news_crawler_api_access_logsWhereInput\n    /**\n     * Limit how many political_news_crawler_api_access_logs to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_api_access_logs without action\n   */\n  export type political_news_crawler_api_access_logsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_access_logs\n     */\n    select?: political_news_crawler_api_access_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_access_logs\n     */\n    omit?: political_news_crawler_api_access_logsOmit<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_api_error_logs\n   */\n\n  export type AggregatePolitical_news_crawler_api_error_logs = {\n    _count: Political_news_crawler_api_error_logsCountAggregateOutputType | null\n    _min: Political_news_crawler_api_error_logsMinAggregateOutputType | null\n    _max: Political_news_crawler_api_error_logsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_api_error_logsMinAggregateOutputType = {\n    id: string | null\n    path: string | null\n    error_code: string | null\n    error_message: string | null\n    client_ip: string | null\n    user_agent: string | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_api_error_logsMaxAggregateOutputType = {\n    id: string | null\n    path: string | null\n    error_code: string | null\n    error_message: string | null\n    client_ip: string | null\n    user_agent: string | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_api_error_logsCountAggregateOutputType = {\n    id: number\n    path: number\n    error_code: number\n    error_message: number\n    client_ip: number\n    user_agent: number\n    created_at: number\n    updated_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_api_error_logsMinAggregateInputType = {\n    id?: true\n    path?: true\n    error_code?: true\n    error_message?: true\n    client_ip?: true\n    user_agent?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_api_error_logsMaxAggregateInputType = {\n    id?: true\n    path?: true\n    error_code?: true\n    error_message?: true\n    client_ip?: true\n    user_agent?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_api_error_logsCountAggregateInputType = {\n    id?: true\n    path?: true\n    error_code?: true\n    error_message?: true\n    client_ip?: true\n    user_agent?: true\n    created_at?: true\n    updated_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_api_error_logsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_api_error_logs to aggregate.\n     */\n    where?: political_news_crawler_api_error_logsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_error_logs to fetch.\n     */\n    orderBy?: political_news_crawler_api_error_logsOrderByWithRelationInput | political_news_crawler_api_error_logsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_api_error_logsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_error_logs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_error_logs.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_api_error_logs\n    **/\n    _count?: true | Political_news_crawler_api_error_logsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_api_error_logsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_api_error_logsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_api_error_logsAggregateType<T extends Political_news_crawler_api_error_logsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_api_error_logs]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_api_error_logs[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_api_error_logs[P]>\n  }\n\n\n\n\n  export type political_news_crawler_api_error_logsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_api_error_logsWhereInput\n    orderBy?: political_news_crawler_api_error_logsOrderByWithAggregationInput | political_news_crawler_api_error_logsOrderByWithAggregationInput[]\n    by: Political_news_crawler_api_error_logsScalarFieldEnum[] | Political_news_crawler_api_error_logsScalarFieldEnum\n    having?: political_news_crawler_api_error_logsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_api_error_logsCountAggregateInputType | true\n    _min?: Political_news_crawler_api_error_logsMinAggregateInputType\n    _max?: Political_news_crawler_api_error_logsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_api_error_logsGroupByOutputType = {\n    id: string\n    path: string\n    error_code: string\n    error_message: string\n    client_ip: string\n    user_agent: string\n    created_at: Date\n    updated_at: Date\n    _count: Political_news_crawler_api_error_logsCountAggregateOutputType | null\n    _min: Political_news_crawler_api_error_logsMinAggregateOutputType | null\n    _max: Political_news_crawler_api_error_logsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_api_error_logsGroupByPayload<T extends political_news_crawler_api_error_logsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_api_error_logsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_api_error_logsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_api_error_logsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_api_error_logsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_api_error_logsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    path?: boolean\n    error_code?: boolean\n    error_message?: boolean\n    client_ip?: boolean\n    user_agent?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_api_error_logs\"]>\n\n  export type political_news_crawler_api_error_logsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    path?: boolean\n    error_code?: boolean\n    error_message?: boolean\n    client_ip?: boolean\n    user_agent?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_api_error_logs\"]>\n\n  export type political_news_crawler_api_error_logsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    path?: boolean\n    error_code?: boolean\n    error_message?: boolean\n    client_ip?: boolean\n    user_agent?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_api_error_logs\"]>\n\n  export type political_news_crawler_api_error_logsSelectScalar = {\n    id?: boolean\n    path?: boolean\n    error_code?: boolean\n    error_message?: boolean\n    client_ip?: boolean\n    user_agent?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }\n\n  export type political_news_crawler_api_error_logsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"path\" | \"error_code\" | \"error_message\" | \"client_ip\" | \"user_agent\" | \"created_at\" | \"updated_at\", ExtArgs[\"result\"][\"political_news_crawler_api_error_logs\"]>\n\n  export type $political_news_crawler_api_error_logsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_api_error_logs\"\n    objects: {}\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * API endpoint path where the error occurred.\n       */\n      path: string\n      /**\n       * Error code identifying the type of API error.\n       */\n      error_code: string\n      /**\n       * Descriptive error message to assist debugging.\n       */\n      error_message: string\n      /**\n       * IP address of the client causing the error.\n       */\n      client_ip: string\n      /**\n       * User agent string of the client application.\n       */\n      user_agent: string\n      /**\n       * Timestamp when the error log was created.\n       */\n      created_at: Date\n      /**\n       * Timestamp when the error log was last updated.\n       */\n      updated_at: Date\n    }, ExtArgs[\"result\"][\"political_news_crawler_api_error_logs\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_api_error_logsGetPayload<S extends boolean | null | undefined | political_news_crawler_api_error_logsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_api_error_logsPayload, S>\n\n  type political_news_crawler_api_error_logsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_api_error_logsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_api_error_logsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_api_error_logsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_api_error_logs'], meta: { name: 'political_news_crawler_api_error_logs' } }\n    /**\n     * Find zero or one Political_news_crawler_api_error_logs that matches the filter.\n     * @param {political_news_crawler_api_error_logsFindUniqueArgs} args - Arguments to find a Political_news_crawler_api_error_logs\n     * @example\n     * // Get one Political_news_crawler_api_error_logs\n     * const political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_api_error_logsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_api_error_logsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_api_error_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_error_logsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_api_error_logs that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_api_error_logsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_api_error_logs\n     * @example\n     * // Get one Political_news_crawler_api_error_logs\n     * const political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_api_error_logsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_api_error_logsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_api_error_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_error_logsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_api_error_logs that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_error_logsFindFirstArgs} args - Arguments to find a Political_news_crawler_api_error_logs\n     * @example\n     * // Get one Political_news_crawler_api_error_logs\n     * const political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_api_error_logsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_api_error_logsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_api_error_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_error_logsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_api_error_logs that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_error_logsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_api_error_logs\n     * @example\n     * // Get one Political_news_crawler_api_error_logs\n     * const political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_api_error_logsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_api_error_logsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_api_error_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_error_logsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_api_error_logs that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_error_logsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_api_error_logs\n     * const political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.findMany()\n     * \n     * // Get first 10 Political_news_crawler_api_error_logs\n     * const political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_api_error_logsWithIdOnly = await prisma.political_news_crawler_api_error_logs.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_api_error_logsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_api_error_logsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_api_error_logsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_api_error_logs.\n     * @param {political_news_crawler_api_error_logsCreateArgs} args - Arguments to create a Political_news_crawler_api_error_logs.\n     * @example\n     * // Create one Political_news_crawler_api_error_logs\n     * const Political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_api_error_logs\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_api_error_logsCreateArgs>(args: SelectSubset<T, political_news_crawler_api_error_logsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_api_error_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_error_logsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_api_error_logs.\n     * @param {political_news_crawler_api_error_logsCreateManyArgs} args - Arguments to create many Political_news_crawler_api_error_logs.\n     * @example\n     * // Create many Political_news_crawler_api_error_logs\n     * const political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_api_error_logsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_api_error_logsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_api_error_logs and returns the data saved in the database.\n     * @param {political_news_crawler_api_error_logsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_api_error_logs.\n     * @example\n     * // Create many Political_news_crawler_api_error_logs\n     * const political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_api_error_logs and only return the `id`\n     * const political_news_crawler_api_error_logsWithIdOnly = await prisma.political_news_crawler_api_error_logs.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_api_error_logsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_api_error_logsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_api_error_logsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_api_error_logs.\n     * @param {political_news_crawler_api_error_logsDeleteArgs} args - Arguments to delete one Political_news_crawler_api_error_logs.\n     * @example\n     * // Delete one Political_news_crawler_api_error_logs\n     * const Political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_api_error_logs\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_api_error_logsDeleteArgs>(args: SelectSubset<T, political_news_crawler_api_error_logsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_api_error_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_error_logsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_api_error_logs.\n     * @param {political_news_crawler_api_error_logsUpdateArgs} args - Arguments to update one Political_news_crawler_api_error_logs.\n     * @example\n     * // Update one Political_news_crawler_api_error_logs\n     * const political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_api_error_logsUpdateArgs>(args: SelectSubset<T, political_news_crawler_api_error_logsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_api_error_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_error_logsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_api_error_logs.\n     * @param {political_news_crawler_api_error_logsDeleteManyArgs} args - Arguments to filter Political_news_crawler_api_error_logs to delete.\n     * @example\n     * // Delete a few Political_news_crawler_api_error_logs\n     * const { count } = await prisma.political_news_crawler_api_error_logs.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_api_error_logsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_api_error_logsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_api_error_logs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_error_logsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_api_error_logs\n     * const political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_api_error_logsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_api_error_logsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_api_error_logs and returns the data updated in the database.\n     * @param {political_news_crawler_api_error_logsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_api_error_logs.\n     * @example\n     * // Update many Political_news_crawler_api_error_logs\n     * const political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_api_error_logs and only return the `id`\n     * const political_news_crawler_api_error_logsWithIdOnly = await prisma.political_news_crawler_api_error_logs.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_api_error_logsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_api_error_logsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_api_error_logsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_api_error_logs.\n     * @param {political_news_crawler_api_error_logsUpsertArgs} args - Arguments to update or create a Political_news_crawler_api_error_logs.\n     * @example\n     * // Update or create a Political_news_crawler_api_error_logs\n     * const political_news_crawler_api_error_logs = await prisma.political_news_crawler_api_error_logs.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_api_error_logs\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_api_error_logs we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_api_error_logsUpsertArgs>(args: SelectSubset<T, political_news_crawler_api_error_logsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_api_error_logsClient<$Result.GetResult<Prisma.$political_news_crawler_api_error_logsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_api_error_logs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_error_logsCountArgs} args - Arguments to filter Political_news_crawler_api_error_logs to count.\n     * @example\n     * // Count the number of Political_news_crawler_api_error_logs\n     * const count = await prisma.political_news_crawler_api_error_logs.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_api_error_logs we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_api_error_logsCountArgs>(\n      args?: Subset<T, political_news_crawler_api_error_logsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_api_error_logsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_api_error_logs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_api_error_logsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_api_error_logsAggregateArgs>(args: Subset<T, Political_news_crawler_api_error_logsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_api_error_logsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_api_error_logs.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_error_logsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_api_error_logsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_api_error_logsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_api_error_logsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_api_error_logsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_api_error_logsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_api_error_logs model\n   */\n  readonly fields: political_news_crawler_api_error_logsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_api_error_logs.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_api_error_logsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_api_error_logs model\n   */\n  interface political_news_crawler_api_error_logsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_api_error_logs\", 'String'>\n    readonly path: FieldRef<\"political_news_crawler_api_error_logs\", 'String'>\n    readonly error_code: FieldRef<\"political_news_crawler_api_error_logs\", 'String'>\n    readonly error_message: FieldRef<\"political_news_crawler_api_error_logs\", 'String'>\n    readonly client_ip: FieldRef<\"political_news_crawler_api_error_logs\", 'String'>\n    readonly user_agent: FieldRef<\"political_news_crawler_api_error_logs\", 'String'>\n    readonly created_at: FieldRef<\"political_news_crawler_api_error_logs\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_api_error_logs\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_api_error_logs findUnique\n   */\n  export type political_news_crawler_api_error_logsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_error_logs\n     */\n    select?: political_news_crawler_api_error_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_error_logs\n     */\n    omit?: political_news_crawler_api_error_logsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_error_logs to fetch.\n     */\n    where: political_news_crawler_api_error_logsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_error_logs findUniqueOrThrow\n   */\n  export type political_news_crawler_api_error_logsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_error_logs\n     */\n    select?: political_news_crawler_api_error_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_error_logs\n     */\n    omit?: political_news_crawler_api_error_logsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_error_logs to fetch.\n     */\n    where: political_news_crawler_api_error_logsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_error_logs findFirst\n   */\n  export type political_news_crawler_api_error_logsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_error_logs\n     */\n    select?: political_news_crawler_api_error_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_error_logs\n     */\n    omit?: political_news_crawler_api_error_logsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_error_logs to fetch.\n     */\n    where?: political_news_crawler_api_error_logsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_error_logs to fetch.\n     */\n    orderBy?: political_news_crawler_api_error_logsOrderByWithRelationInput | political_news_crawler_api_error_logsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_api_error_logs.\n     */\n    cursor?: political_news_crawler_api_error_logsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_error_logs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_error_logs.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_api_error_logs.\n     */\n    distinct?: Political_news_crawler_api_error_logsScalarFieldEnum | Political_news_crawler_api_error_logsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_api_error_logs findFirstOrThrow\n   */\n  export type political_news_crawler_api_error_logsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_error_logs\n     */\n    select?: political_news_crawler_api_error_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_error_logs\n     */\n    omit?: political_news_crawler_api_error_logsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_error_logs to fetch.\n     */\n    where?: political_news_crawler_api_error_logsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_error_logs to fetch.\n     */\n    orderBy?: political_news_crawler_api_error_logsOrderByWithRelationInput | political_news_crawler_api_error_logsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_api_error_logs.\n     */\n    cursor?: political_news_crawler_api_error_logsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_error_logs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_error_logs.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_api_error_logs.\n     */\n    distinct?: Political_news_crawler_api_error_logsScalarFieldEnum | Political_news_crawler_api_error_logsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_api_error_logs findMany\n   */\n  export type political_news_crawler_api_error_logsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_error_logs\n     */\n    select?: political_news_crawler_api_error_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_error_logs\n     */\n    omit?: political_news_crawler_api_error_logsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_error_logs to fetch.\n     */\n    where?: political_news_crawler_api_error_logsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_error_logs to fetch.\n     */\n    orderBy?: political_news_crawler_api_error_logsOrderByWithRelationInput | political_news_crawler_api_error_logsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_api_error_logs.\n     */\n    cursor?: political_news_crawler_api_error_logsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_error_logs from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_error_logs.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_api_error_logsScalarFieldEnum | Political_news_crawler_api_error_logsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_api_error_logs create\n   */\n  export type political_news_crawler_api_error_logsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_error_logs\n     */\n    select?: political_news_crawler_api_error_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_error_logs\n     */\n    omit?: political_news_crawler_api_error_logsOmit<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_api_error_logs.\n     */\n    data: XOR<political_news_crawler_api_error_logsCreateInput, political_news_crawler_api_error_logsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_api_error_logs createMany\n   */\n  export type political_news_crawler_api_error_logsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_api_error_logs.\n     */\n    data: political_news_crawler_api_error_logsCreateManyInput | political_news_crawler_api_error_logsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_api_error_logs createManyAndReturn\n   */\n  export type political_news_crawler_api_error_logsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_error_logs\n     */\n    select?: political_news_crawler_api_error_logsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_error_logs\n     */\n    omit?: political_news_crawler_api_error_logsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_api_error_logs.\n     */\n    data: political_news_crawler_api_error_logsCreateManyInput | political_news_crawler_api_error_logsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_api_error_logs update\n   */\n  export type political_news_crawler_api_error_logsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_error_logs\n     */\n    select?: political_news_crawler_api_error_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_error_logs\n     */\n    omit?: political_news_crawler_api_error_logsOmit<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_api_error_logs.\n     */\n    data: XOR<political_news_crawler_api_error_logsUpdateInput, political_news_crawler_api_error_logsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_api_error_logs to update.\n     */\n    where: political_news_crawler_api_error_logsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_error_logs updateMany\n   */\n  export type political_news_crawler_api_error_logsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_api_error_logs.\n     */\n    data: XOR<political_news_crawler_api_error_logsUpdateManyMutationInput, political_news_crawler_api_error_logsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_api_error_logs to update\n     */\n    where?: political_news_crawler_api_error_logsWhereInput\n    /**\n     * Limit how many political_news_crawler_api_error_logs to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_api_error_logs updateManyAndReturn\n   */\n  export type political_news_crawler_api_error_logsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_error_logs\n     */\n    select?: political_news_crawler_api_error_logsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_error_logs\n     */\n    omit?: political_news_crawler_api_error_logsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_api_error_logs.\n     */\n    data: XOR<political_news_crawler_api_error_logsUpdateManyMutationInput, political_news_crawler_api_error_logsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_api_error_logs to update\n     */\n    where?: political_news_crawler_api_error_logsWhereInput\n    /**\n     * Limit how many political_news_crawler_api_error_logs to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_api_error_logs upsert\n   */\n  export type political_news_crawler_api_error_logsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_error_logs\n     */\n    select?: political_news_crawler_api_error_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_error_logs\n     */\n    omit?: political_news_crawler_api_error_logsOmit<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_api_error_logs to update in case it exists.\n     */\n    where: political_news_crawler_api_error_logsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_api_error_logs found by the `where` argument doesn't exist, create a new political_news_crawler_api_error_logs with this data.\n     */\n    create: XOR<political_news_crawler_api_error_logsCreateInput, political_news_crawler_api_error_logsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_api_error_logs was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_api_error_logsUpdateInput, political_news_crawler_api_error_logsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_api_error_logs delete\n   */\n  export type political_news_crawler_api_error_logsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_error_logs\n     */\n    select?: political_news_crawler_api_error_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_error_logs\n     */\n    omit?: political_news_crawler_api_error_logsOmit<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_api_error_logs to delete.\n     */\n    where: political_news_crawler_api_error_logsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_error_logs deleteMany\n   */\n  export type political_news_crawler_api_error_logsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_api_error_logs to delete\n     */\n    where?: political_news_crawler_api_error_logsWhereInput\n    /**\n     * Limit how many political_news_crawler_api_error_logs to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_api_error_logs without action\n   */\n  export type political_news_crawler_api_error_logsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_error_logs\n     */\n    select?: political_news_crawler_api_error_logsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_error_logs\n     */\n    omit?: political_news_crawler_api_error_logsOmit<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_api_usage_metrics\n   */\n\n  export type AggregatePolitical_news_crawler_api_usage_metrics = {\n    _count: Political_news_crawler_api_usage_metricsCountAggregateOutputType | null\n    _avg: Political_news_crawler_api_usage_metricsAvgAggregateOutputType | null\n    _sum: Political_news_crawler_api_usage_metricsSumAggregateOutputType | null\n    _min: Political_news_crawler_api_usage_metricsMinAggregateOutputType | null\n    _max: Political_news_crawler_api_usage_metricsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_api_usage_metricsAvgAggregateOutputType = {\n    total_calls: number | null\n    max_response_ms: number | null\n    avg_response_ms: number | null\n  }\n\n  export type Political_news_crawler_api_usage_metricsSumAggregateOutputType = {\n    total_calls: number | null\n    max_response_ms: number | null\n    avg_response_ms: number | null\n  }\n\n  export type Political_news_crawler_api_usage_metricsMinAggregateOutputType = {\n    id: string | null\n    http_method: string | null\n    path: string | null\n    period_start: Date | null\n    period_end: Date | null\n    total_calls: number | null\n    max_response_ms: number | null\n    avg_response_ms: number | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_api_usage_metricsMaxAggregateOutputType = {\n    id: string | null\n    http_method: string | null\n    path: string | null\n    period_start: Date | null\n    period_end: Date | null\n    total_calls: number | null\n    max_response_ms: number | null\n    avg_response_ms: number | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_api_usage_metricsCountAggregateOutputType = {\n    id: number\n    http_method: number\n    path: number\n    period_start: number\n    period_end: number\n    total_calls: number\n    max_response_ms: number\n    avg_response_ms: number\n    created_at: number\n    updated_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_api_usage_metricsAvgAggregateInputType = {\n    total_calls?: true\n    max_response_ms?: true\n    avg_response_ms?: true\n  }\n\n  export type Political_news_crawler_api_usage_metricsSumAggregateInputType = {\n    total_calls?: true\n    max_response_ms?: true\n    avg_response_ms?: true\n  }\n\n  export type Political_news_crawler_api_usage_metricsMinAggregateInputType = {\n    id?: true\n    http_method?: true\n    path?: true\n    period_start?: true\n    period_end?: true\n    total_calls?: true\n    max_response_ms?: true\n    avg_response_ms?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_api_usage_metricsMaxAggregateInputType = {\n    id?: true\n    http_method?: true\n    path?: true\n    period_start?: true\n    period_end?: true\n    total_calls?: true\n    max_response_ms?: true\n    avg_response_ms?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_api_usage_metricsCountAggregateInputType = {\n    id?: true\n    http_method?: true\n    path?: true\n    period_start?: true\n    period_end?: true\n    total_calls?: true\n    max_response_ms?: true\n    avg_response_ms?: true\n    created_at?: true\n    updated_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_api_usage_metricsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_api_usage_metrics to aggregate.\n     */\n    where?: political_news_crawler_api_usage_metricsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_usage_metrics to fetch.\n     */\n    orderBy?: political_news_crawler_api_usage_metricsOrderByWithRelationInput | political_news_crawler_api_usage_metricsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_api_usage_metricsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_usage_metrics from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_usage_metrics.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_api_usage_metrics\n    **/\n    _count?: true | Political_news_crawler_api_usage_metricsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to average\n    **/\n    _avg?: Political_news_crawler_api_usage_metricsAvgAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to sum\n    **/\n    _sum?: Political_news_crawler_api_usage_metricsSumAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_api_usage_metricsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_api_usage_metricsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_api_usage_metricsAggregateType<T extends Political_news_crawler_api_usage_metricsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_api_usage_metrics]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_api_usage_metrics[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_api_usage_metrics[P]>\n  }\n\n\n\n\n  export type political_news_crawler_api_usage_metricsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_api_usage_metricsWhereInput\n    orderBy?: political_news_crawler_api_usage_metricsOrderByWithAggregationInput | political_news_crawler_api_usage_metricsOrderByWithAggregationInput[]\n    by: Political_news_crawler_api_usage_metricsScalarFieldEnum[] | Political_news_crawler_api_usage_metricsScalarFieldEnum\n    having?: political_news_crawler_api_usage_metricsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_api_usage_metricsCountAggregateInputType | true\n    _avg?: Political_news_crawler_api_usage_metricsAvgAggregateInputType\n    _sum?: Political_news_crawler_api_usage_metricsSumAggregateInputType\n    _min?: Political_news_crawler_api_usage_metricsMinAggregateInputType\n    _max?: Political_news_crawler_api_usage_metricsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_api_usage_metricsGroupByOutputType = {\n    id: string\n    http_method: string\n    path: string\n    period_start: Date\n    period_end: Date\n    total_calls: number\n    max_response_ms: number\n    avg_response_ms: number\n    created_at: Date\n    updated_at: Date\n    _count: Political_news_crawler_api_usage_metricsCountAggregateOutputType | null\n    _avg: Political_news_crawler_api_usage_metricsAvgAggregateOutputType | null\n    _sum: Political_news_crawler_api_usage_metricsSumAggregateOutputType | null\n    _min: Political_news_crawler_api_usage_metricsMinAggregateOutputType | null\n    _max: Political_news_crawler_api_usage_metricsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_api_usage_metricsGroupByPayload<T extends political_news_crawler_api_usage_metricsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_api_usage_metricsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_api_usage_metricsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_api_usage_metricsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_api_usage_metricsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_api_usage_metricsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    http_method?: boolean\n    path?: boolean\n    period_start?: boolean\n    period_end?: boolean\n    total_calls?: boolean\n    max_response_ms?: boolean\n    avg_response_ms?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_api_usage_metrics\"]>\n\n  export type political_news_crawler_api_usage_metricsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    http_method?: boolean\n    path?: boolean\n    period_start?: boolean\n    period_end?: boolean\n    total_calls?: boolean\n    max_response_ms?: boolean\n    avg_response_ms?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_api_usage_metrics\"]>\n\n  export type political_news_crawler_api_usage_metricsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    http_method?: boolean\n    path?: boolean\n    period_start?: boolean\n    period_end?: boolean\n    total_calls?: boolean\n    max_response_ms?: boolean\n    avg_response_ms?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_api_usage_metrics\"]>\n\n  export type political_news_crawler_api_usage_metricsSelectScalar = {\n    id?: boolean\n    http_method?: boolean\n    path?: boolean\n    period_start?: boolean\n    period_end?: boolean\n    total_calls?: boolean\n    max_response_ms?: boolean\n    avg_response_ms?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }\n\n  export type political_news_crawler_api_usage_metricsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"http_method\" | \"path\" | \"period_start\" | \"period_end\" | \"total_calls\" | \"max_response_ms\" | \"avg_response_ms\" | \"created_at\" | \"updated_at\", ExtArgs[\"result\"][\"political_news_crawler_api_usage_metrics\"]>\n\n  export type $political_news_crawler_api_usage_metricsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_api_usage_metrics\"\n    objects: {}\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * HTTP method for which metrics are aggregated.\n       */\n      http_method: string\n      /**\n       * API endpoint path for which metrics are aggregated.\n       */\n      path: string\n      /**\n       * Start timestamp of the aggregation period.\n       */\n      period_start: Date\n      /**\n       * End timestamp of the aggregation period.\n       */\n      period_end: Date\n      /**\n       * Total number of API calls observed in the aggregation period.\n       */\n      total_calls: number\n      /**\n       * Maximum response time in milliseconds recorded during the period.\n       */\n      max_response_ms: number\n      /**\n       * Average response time in milliseconds over the period.\n       */\n      avg_response_ms: number\n      /**\n       * Timestamp when this aggregated record was created.\n       */\n      created_at: Date\n      /**\n       * Timestamp when this aggregated record was last updated.\n       */\n      updated_at: Date\n    }, ExtArgs[\"result\"][\"political_news_crawler_api_usage_metrics\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_api_usage_metricsGetPayload<S extends boolean | null | undefined | political_news_crawler_api_usage_metricsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_api_usage_metricsPayload, S>\n\n  type political_news_crawler_api_usage_metricsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_api_usage_metricsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_api_usage_metricsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_api_usage_metricsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_api_usage_metrics'], meta: { name: 'political_news_crawler_api_usage_metrics' } }\n    /**\n     * Find zero or one Political_news_crawler_api_usage_metrics that matches the filter.\n     * @param {political_news_crawler_api_usage_metricsFindUniqueArgs} args - Arguments to find a Political_news_crawler_api_usage_metrics\n     * @example\n     * // Get one Political_news_crawler_api_usage_metrics\n     * const political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_api_usage_metricsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_api_usage_metricsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_api_usage_metricsClient<$Result.GetResult<Prisma.$political_news_crawler_api_usage_metricsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_api_usage_metrics that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_api_usage_metricsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_api_usage_metrics\n     * @example\n     * // Get one Political_news_crawler_api_usage_metrics\n     * const political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_api_usage_metricsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_api_usage_metricsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_api_usage_metricsClient<$Result.GetResult<Prisma.$political_news_crawler_api_usage_metricsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_api_usage_metrics that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_usage_metricsFindFirstArgs} args - Arguments to find a Political_news_crawler_api_usage_metrics\n     * @example\n     * // Get one Political_news_crawler_api_usage_metrics\n     * const political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_api_usage_metricsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_api_usage_metricsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_api_usage_metricsClient<$Result.GetResult<Prisma.$political_news_crawler_api_usage_metricsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_api_usage_metrics that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_usage_metricsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_api_usage_metrics\n     * @example\n     * // Get one Political_news_crawler_api_usage_metrics\n     * const political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_api_usage_metricsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_api_usage_metricsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_api_usage_metricsClient<$Result.GetResult<Prisma.$political_news_crawler_api_usage_metricsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_api_usage_metrics that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_usage_metricsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_api_usage_metrics\n     * const political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.findMany()\n     * \n     * // Get first 10 Political_news_crawler_api_usage_metrics\n     * const political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_api_usage_metricsWithIdOnly = await prisma.political_news_crawler_api_usage_metrics.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_api_usage_metricsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_api_usage_metricsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_api_usage_metricsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_api_usage_metrics.\n     * @param {political_news_crawler_api_usage_metricsCreateArgs} args - Arguments to create a Political_news_crawler_api_usage_metrics.\n     * @example\n     * // Create one Political_news_crawler_api_usage_metrics\n     * const Political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_api_usage_metrics\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_api_usage_metricsCreateArgs>(args: SelectSubset<T, political_news_crawler_api_usage_metricsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_api_usage_metricsClient<$Result.GetResult<Prisma.$political_news_crawler_api_usage_metricsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_api_usage_metrics.\n     * @param {political_news_crawler_api_usage_metricsCreateManyArgs} args - Arguments to create many Political_news_crawler_api_usage_metrics.\n     * @example\n     * // Create many Political_news_crawler_api_usage_metrics\n     * const political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_api_usage_metricsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_api_usage_metricsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_api_usage_metrics and returns the data saved in the database.\n     * @param {political_news_crawler_api_usage_metricsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_api_usage_metrics.\n     * @example\n     * // Create many Political_news_crawler_api_usage_metrics\n     * const political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_api_usage_metrics and only return the `id`\n     * const political_news_crawler_api_usage_metricsWithIdOnly = await prisma.political_news_crawler_api_usage_metrics.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_api_usage_metricsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_api_usage_metricsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_api_usage_metricsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_api_usage_metrics.\n     * @param {political_news_crawler_api_usage_metricsDeleteArgs} args - Arguments to delete one Political_news_crawler_api_usage_metrics.\n     * @example\n     * // Delete one Political_news_crawler_api_usage_metrics\n     * const Political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_api_usage_metrics\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_api_usage_metricsDeleteArgs>(args: SelectSubset<T, political_news_crawler_api_usage_metricsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_api_usage_metricsClient<$Result.GetResult<Prisma.$political_news_crawler_api_usage_metricsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_api_usage_metrics.\n     * @param {political_news_crawler_api_usage_metricsUpdateArgs} args - Arguments to update one Political_news_crawler_api_usage_metrics.\n     * @example\n     * // Update one Political_news_crawler_api_usage_metrics\n     * const political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_api_usage_metricsUpdateArgs>(args: SelectSubset<T, political_news_crawler_api_usage_metricsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_api_usage_metricsClient<$Result.GetResult<Prisma.$political_news_crawler_api_usage_metricsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_api_usage_metrics.\n     * @param {political_news_crawler_api_usage_metricsDeleteManyArgs} args - Arguments to filter Political_news_crawler_api_usage_metrics to delete.\n     * @example\n     * // Delete a few Political_news_crawler_api_usage_metrics\n     * const { count } = await prisma.political_news_crawler_api_usage_metrics.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_api_usage_metricsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_api_usage_metricsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_api_usage_metrics.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_usage_metricsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_api_usage_metrics\n     * const political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_api_usage_metricsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_api_usage_metricsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_api_usage_metrics and returns the data updated in the database.\n     * @param {political_news_crawler_api_usage_metricsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_api_usage_metrics.\n     * @example\n     * // Update many Political_news_crawler_api_usage_metrics\n     * const political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_api_usage_metrics and only return the `id`\n     * const political_news_crawler_api_usage_metricsWithIdOnly = await prisma.political_news_crawler_api_usage_metrics.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_api_usage_metricsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_api_usage_metricsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_api_usage_metricsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_api_usage_metrics.\n     * @param {political_news_crawler_api_usage_metricsUpsertArgs} args - Arguments to update or create a Political_news_crawler_api_usage_metrics.\n     * @example\n     * // Update or create a Political_news_crawler_api_usage_metrics\n     * const political_news_crawler_api_usage_metrics = await prisma.political_news_crawler_api_usage_metrics.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_api_usage_metrics\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_api_usage_metrics we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_api_usage_metricsUpsertArgs>(args: SelectSubset<T, political_news_crawler_api_usage_metricsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_api_usage_metricsClient<$Result.GetResult<Prisma.$political_news_crawler_api_usage_metricsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_api_usage_metrics.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_usage_metricsCountArgs} args - Arguments to filter Political_news_crawler_api_usage_metrics to count.\n     * @example\n     * // Count the number of Political_news_crawler_api_usage_metrics\n     * const count = await prisma.political_news_crawler_api_usage_metrics.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_api_usage_metrics we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_api_usage_metricsCountArgs>(\n      args?: Subset<T, political_news_crawler_api_usage_metricsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_api_usage_metricsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_api_usage_metrics.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_api_usage_metricsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_api_usage_metricsAggregateArgs>(args: Subset<T, Political_news_crawler_api_usage_metricsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_api_usage_metricsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_api_usage_metrics.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_usage_metricsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_api_usage_metricsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_api_usage_metricsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_api_usage_metricsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_api_usage_metricsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_api_usage_metricsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_api_usage_metrics model\n   */\n  readonly fields: political_news_crawler_api_usage_metricsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_api_usage_metrics.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_api_usage_metricsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_api_usage_metrics model\n   */\n  interface political_news_crawler_api_usage_metricsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_api_usage_metrics\", 'String'>\n    readonly http_method: FieldRef<\"political_news_crawler_api_usage_metrics\", 'String'>\n    readonly path: FieldRef<\"political_news_crawler_api_usage_metrics\", 'String'>\n    readonly period_start: FieldRef<\"political_news_crawler_api_usage_metrics\", 'DateTime'>\n    readonly period_end: FieldRef<\"political_news_crawler_api_usage_metrics\", 'DateTime'>\n    readonly total_calls: FieldRef<\"political_news_crawler_api_usage_metrics\", 'Int'>\n    readonly max_response_ms: FieldRef<\"political_news_crawler_api_usage_metrics\", 'Int'>\n    readonly avg_response_ms: FieldRef<\"political_news_crawler_api_usage_metrics\", 'Int'>\n    readonly created_at: FieldRef<\"political_news_crawler_api_usage_metrics\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_api_usage_metrics\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_api_usage_metrics findUnique\n   */\n  export type political_news_crawler_api_usage_metricsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_usage_metrics\n     */\n    select?: political_news_crawler_api_usage_metricsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_usage_metrics\n     */\n    omit?: political_news_crawler_api_usage_metricsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_usage_metrics to fetch.\n     */\n    where: political_news_crawler_api_usage_metricsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics findUniqueOrThrow\n   */\n  export type political_news_crawler_api_usage_metricsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_usage_metrics\n     */\n    select?: political_news_crawler_api_usage_metricsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_usage_metrics\n     */\n    omit?: political_news_crawler_api_usage_metricsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_usage_metrics to fetch.\n     */\n    where: political_news_crawler_api_usage_metricsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics findFirst\n   */\n  export type political_news_crawler_api_usage_metricsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_usage_metrics\n     */\n    select?: political_news_crawler_api_usage_metricsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_usage_metrics\n     */\n    omit?: political_news_crawler_api_usage_metricsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_usage_metrics to fetch.\n     */\n    where?: political_news_crawler_api_usage_metricsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_usage_metrics to fetch.\n     */\n    orderBy?: political_news_crawler_api_usage_metricsOrderByWithRelationInput | political_news_crawler_api_usage_metricsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_api_usage_metrics.\n     */\n    cursor?: political_news_crawler_api_usage_metricsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_usage_metrics from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_usage_metrics.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_api_usage_metrics.\n     */\n    distinct?: Political_news_crawler_api_usage_metricsScalarFieldEnum | Political_news_crawler_api_usage_metricsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics findFirstOrThrow\n   */\n  export type political_news_crawler_api_usage_metricsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_usage_metrics\n     */\n    select?: political_news_crawler_api_usage_metricsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_usage_metrics\n     */\n    omit?: political_news_crawler_api_usage_metricsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_usage_metrics to fetch.\n     */\n    where?: political_news_crawler_api_usage_metricsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_usage_metrics to fetch.\n     */\n    orderBy?: political_news_crawler_api_usage_metricsOrderByWithRelationInput | political_news_crawler_api_usage_metricsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_api_usage_metrics.\n     */\n    cursor?: political_news_crawler_api_usage_metricsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_usage_metrics from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_usage_metrics.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_api_usage_metrics.\n     */\n    distinct?: Political_news_crawler_api_usage_metricsScalarFieldEnum | Political_news_crawler_api_usage_metricsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics findMany\n   */\n  export type political_news_crawler_api_usage_metricsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_usage_metrics\n     */\n    select?: political_news_crawler_api_usage_metricsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_usage_metrics\n     */\n    omit?: political_news_crawler_api_usage_metricsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_usage_metrics to fetch.\n     */\n    where?: political_news_crawler_api_usage_metricsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_usage_metrics to fetch.\n     */\n    orderBy?: political_news_crawler_api_usage_metricsOrderByWithRelationInput | political_news_crawler_api_usage_metricsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_api_usage_metrics.\n     */\n    cursor?: political_news_crawler_api_usage_metricsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_usage_metrics from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_usage_metrics.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_api_usage_metricsScalarFieldEnum | Political_news_crawler_api_usage_metricsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics create\n   */\n  export type political_news_crawler_api_usage_metricsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_usage_metrics\n     */\n    select?: political_news_crawler_api_usage_metricsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_usage_metrics\n     */\n    omit?: political_news_crawler_api_usage_metricsOmit<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_api_usage_metrics.\n     */\n    data: XOR<political_news_crawler_api_usage_metricsCreateInput, political_news_crawler_api_usage_metricsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics createMany\n   */\n  export type political_news_crawler_api_usage_metricsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_api_usage_metrics.\n     */\n    data: political_news_crawler_api_usage_metricsCreateManyInput | political_news_crawler_api_usage_metricsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics createManyAndReturn\n   */\n  export type political_news_crawler_api_usage_metricsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_usage_metrics\n     */\n    select?: political_news_crawler_api_usage_metricsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_usage_metrics\n     */\n    omit?: political_news_crawler_api_usage_metricsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_api_usage_metrics.\n     */\n    data: political_news_crawler_api_usage_metricsCreateManyInput | political_news_crawler_api_usage_metricsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics update\n   */\n  export type political_news_crawler_api_usage_metricsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_usage_metrics\n     */\n    select?: political_news_crawler_api_usage_metricsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_usage_metrics\n     */\n    omit?: political_news_crawler_api_usage_metricsOmit<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_api_usage_metrics.\n     */\n    data: XOR<political_news_crawler_api_usage_metricsUpdateInput, political_news_crawler_api_usage_metricsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_api_usage_metrics to update.\n     */\n    where: political_news_crawler_api_usage_metricsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics updateMany\n   */\n  export type political_news_crawler_api_usage_metricsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_api_usage_metrics.\n     */\n    data: XOR<political_news_crawler_api_usage_metricsUpdateManyMutationInput, political_news_crawler_api_usage_metricsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_api_usage_metrics to update\n     */\n    where?: political_news_crawler_api_usage_metricsWhereInput\n    /**\n     * Limit how many political_news_crawler_api_usage_metrics to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics updateManyAndReturn\n   */\n  export type political_news_crawler_api_usage_metricsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_usage_metrics\n     */\n    select?: political_news_crawler_api_usage_metricsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_usage_metrics\n     */\n    omit?: political_news_crawler_api_usage_metricsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_api_usage_metrics.\n     */\n    data: XOR<political_news_crawler_api_usage_metricsUpdateManyMutationInput, political_news_crawler_api_usage_metricsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_api_usage_metrics to update\n     */\n    where?: political_news_crawler_api_usage_metricsWhereInput\n    /**\n     * Limit how many political_news_crawler_api_usage_metrics to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics upsert\n   */\n  export type political_news_crawler_api_usage_metricsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_usage_metrics\n     */\n    select?: political_news_crawler_api_usage_metricsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_usage_metrics\n     */\n    omit?: political_news_crawler_api_usage_metricsOmit<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_api_usage_metrics to update in case it exists.\n     */\n    where: political_news_crawler_api_usage_metricsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_api_usage_metrics found by the `where` argument doesn't exist, create a new political_news_crawler_api_usage_metrics with this data.\n     */\n    create: XOR<political_news_crawler_api_usage_metricsCreateInput, political_news_crawler_api_usage_metricsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_api_usage_metrics was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_api_usage_metricsUpdateInput, political_news_crawler_api_usage_metricsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics delete\n   */\n  export type political_news_crawler_api_usage_metricsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_usage_metrics\n     */\n    select?: political_news_crawler_api_usage_metricsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_usage_metrics\n     */\n    omit?: political_news_crawler_api_usage_metricsOmit<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_api_usage_metrics to delete.\n     */\n    where: political_news_crawler_api_usage_metricsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics deleteMany\n   */\n  export type political_news_crawler_api_usage_metricsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_api_usage_metrics to delete\n     */\n    where?: political_news_crawler_api_usage_metricsWhereInput\n    /**\n     * Limit how many political_news_crawler_api_usage_metrics to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_api_usage_metrics without action\n   */\n  export type political_news_crawler_api_usage_metricsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_usage_metrics\n     */\n    select?: political_news_crawler_api_usage_metricsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_usage_metrics\n     */\n    omit?: political_news_crawler_api_usage_metricsOmit<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_crawl_alerts\n   */\n\n  export type AggregatePolitical_news_crawler_crawl_alerts = {\n    _count: Political_news_crawler_crawl_alertsCountAggregateOutputType | null\n    _min: Political_news_crawler_crawl_alertsMinAggregateOutputType | null\n    _max: Political_news_crawler_crawl_alertsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_crawl_alertsMinAggregateOutputType = {\n    id: string | null\n    crawl_source_id: string | null\n    alert_type: string | null\n    message: string | null\n    severity: string | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_crawl_alertsMaxAggregateOutputType = {\n    id: string | null\n    crawl_source_id: string | null\n    alert_type: string | null\n    message: string | null\n    severity: string | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_crawl_alertsCountAggregateOutputType = {\n    id: number\n    crawl_source_id: number\n    alert_type: number\n    message: number\n    severity: number\n    created_at: number\n    updated_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_crawl_alertsMinAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    alert_type?: true\n    message?: true\n    severity?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_crawl_alertsMaxAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    alert_type?: true\n    message?: true\n    severity?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_crawl_alertsCountAggregateInputType = {\n    id?: true\n    crawl_source_id?: true\n    alert_type?: true\n    message?: true\n    severity?: true\n    created_at?: true\n    updated_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_crawl_alertsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawl_alerts to aggregate.\n     */\n    where?: political_news_crawler_crawl_alertsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_alerts to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_alertsOrderByWithRelationInput | political_news_crawler_crawl_alertsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_crawl_alertsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_alerts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_alerts.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_crawl_alerts\n    **/\n    _count?: true | Political_news_crawler_crawl_alertsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_crawl_alertsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_crawl_alertsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_crawl_alertsAggregateType<T extends Political_news_crawler_crawl_alertsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_crawl_alerts]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_crawl_alerts[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_crawl_alerts[P]>\n  }\n\n\n\n\n  export type political_news_crawler_crawl_alertsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_crawl_alertsWhereInput\n    orderBy?: political_news_crawler_crawl_alertsOrderByWithAggregationInput | political_news_crawler_crawl_alertsOrderByWithAggregationInput[]\n    by: Political_news_crawler_crawl_alertsScalarFieldEnum[] | Political_news_crawler_crawl_alertsScalarFieldEnum\n    having?: political_news_crawler_crawl_alertsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_crawl_alertsCountAggregateInputType | true\n    _min?: Political_news_crawler_crawl_alertsMinAggregateInputType\n    _max?: Political_news_crawler_crawl_alertsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_crawl_alertsGroupByOutputType = {\n    id: string\n    crawl_source_id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date\n    updated_at: Date\n    _count: Political_news_crawler_crawl_alertsCountAggregateOutputType | null\n    _min: Political_news_crawler_crawl_alertsMinAggregateOutputType | null\n    _max: Political_news_crawler_crawl_alertsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_crawl_alertsGroupByPayload<T extends political_news_crawler_crawl_alertsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_crawl_alertsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_crawl_alertsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_crawl_alertsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_crawl_alertsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_crawl_alertsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    alert_type?: boolean\n    message?: boolean\n    severity?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_alerts\"]>\n\n  export type political_news_crawler_crawl_alertsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    alert_type?: boolean\n    message?: boolean\n    severity?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_alerts\"]>\n\n  export type political_news_crawler_crawl_alertsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    crawl_source_id?: boolean\n    alert_type?: boolean\n    message?: boolean\n    severity?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n  }, ExtArgs[\"result\"][\"political_news_crawler_crawl_alerts\"]>\n\n  export type political_news_crawler_crawl_alertsSelectScalar = {\n    id?: boolean\n    crawl_source_id?: boolean\n    alert_type?: boolean\n    message?: boolean\n    severity?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }\n\n  export type political_news_crawler_crawl_alertsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"crawl_source_id\" | \"alert_type\" | \"message\" | \"severity\" | \"created_at\" | \"updated_at\", ExtArgs[\"result\"][\"political_news_crawler_crawl_alerts\"]>\n  export type political_news_crawler_crawl_alertsInclude<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_crawl_alertsIncludeCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n  }\n  export type political_news_crawler_crawl_alertsIncludeUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    crawlSource?: boolean | political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>\n  }\n\n  export type $political_news_crawler_crawl_alertsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_crawl_alerts\"\n    objects: {\n      crawlSource: Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>\n    }\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Referenced crawl source's {@link political_news_crawler_crawl_sources.id}\n       * which triggered the alert.\n       */\n      crawl_source_id: string\n      /**\n       * Type of alert event indicating the category, e.g., 'ban_detected',\n       * 'network_error', 'throttle_warning'.\n       */\n      alert_type: string\n      /**\n       * Detailed description of the alert event and context for operational\n       * understanding.\n       */\n      message: string\n      /**\n       * Severity level of the alert such as 'info', 'warning', 'critical'.\n       */\n      severity: string\n      /**\n       * Timestamp when the alert was created.\n       */\n      created_at: Date\n      /**\n       * Timestamp when the alert was last updated.\n       */\n      updated_at: Date\n    }, ExtArgs[\"result\"][\"political_news_crawler_crawl_alerts\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_crawl_alertsGetPayload<S extends boolean | null | undefined | political_news_crawler_crawl_alertsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_crawl_alertsPayload, S>\n\n  type political_news_crawler_crawl_alertsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_crawl_alertsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_crawl_alertsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_crawl_alertsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_crawl_alerts'], meta: { name: 'political_news_crawler_crawl_alerts' } }\n    /**\n     * Find zero or one Political_news_crawler_crawl_alerts that matches the filter.\n     * @param {political_news_crawler_crawl_alertsFindUniqueArgs} args - Arguments to find a Political_news_crawler_crawl_alerts\n     * @example\n     * // Get one Political_news_crawler_crawl_alerts\n     * const political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_crawl_alertsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_crawl_alertsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_crawl_alerts that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_crawl_alertsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_crawl_alerts\n     * @example\n     * // Get one Political_news_crawler_crawl_alerts\n     * const political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_crawl_alertsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_crawl_alertsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawl_alerts that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_alertsFindFirstArgs} args - Arguments to find a Political_news_crawler_crawl_alerts\n     * @example\n     * // Get one Political_news_crawler_crawl_alerts\n     * const political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_crawl_alertsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_crawl_alertsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_crawl_alerts that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_alertsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_crawl_alerts\n     * @example\n     * // Get one Political_news_crawler_crawl_alerts\n     * const political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_crawl_alertsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_crawl_alertsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_crawl_alerts that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_alertsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_crawl_alerts\n     * const political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.findMany()\n     * \n     * // Get first 10 Political_news_crawler_crawl_alerts\n     * const political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_crawl_alertsWithIdOnly = await prisma.political_news_crawler_crawl_alerts.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_crawl_alertsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_alertsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_crawl_alerts.\n     * @param {political_news_crawler_crawl_alertsCreateArgs} args - Arguments to create a Political_news_crawler_crawl_alerts.\n     * @example\n     * // Create one Political_news_crawler_crawl_alerts\n     * const Political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_crawl_alerts\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_crawl_alertsCreateArgs>(args: SelectSubset<T, political_news_crawler_crawl_alertsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_crawl_alerts.\n     * @param {political_news_crawler_crawl_alertsCreateManyArgs} args - Arguments to create many Political_news_crawler_crawl_alerts.\n     * @example\n     * // Create many Political_news_crawler_crawl_alerts\n     * const political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_crawl_alertsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_alertsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_crawl_alerts and returns the data saved in the database.\n     * @param {political_news_crawler_crawl_alertsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_crawl_alerts.\n     * @example\n     * // Create many Political_news_crawler_crawl_alerts\n     * const political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_crawl_alerts and only return the `id`\n     * const political_news_crawler_crawl_alertsWithIdOnly = await prisma.political_news_crawler_crawl_alerts.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_crawl_alertsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_crawl_alertsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_crawl_alerts.\n     * @param {political_news_crawler_crawl_alertsDeleteArgs} args - Arguments to delete one Political_news_crawler_crawl_alerts.\n     * @example\n     * // Delete one Political_news_crawler_crawl_alerts\n     * const Political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_crawl_alerts\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_crawl_alertsDeleteArgs>(args: SelectSubset<T, political_news_crawler_crawl_alertsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_crawl_alerts.\n     * @param {political_news_crawler_crawl_alertsUpdateArgs} args - Arguments to update one Political_news_crawler_crawl_alerts.\n     * @example\n     * // Update one Political_news_crawler_crawl_alerts\n     * const political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_crawl_alertsUpdateArgs>(args: SelectSubset<T, political_news_crawler_crawl_alertsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_crawl_alerts.\n     * @param {political_news_crawler_crawl_alertsDeleteManyArgs} args - Arguments to filter Political_news_crawler_crawl_alerts to delete.\n     * @example\n     * // Delete a few Political_news_crawler_crawl_alerts\n     * const { count } = await prisma.political_news_crawler_crawl_alerts.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_crawl_alertsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_crawl_alertsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawl_alerts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_alertsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_crawl_alerts\n     * const political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_crawl_alertsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_crawl_alertsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_crawl_alerts and returns the data updated in the database.\n     * @param {political_news_crawler_crawl_alertsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_crawl_alerts.\n     * @example\n     * // Update many Political_news_crawler_crawl_alerts\n     * const political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_crawl_alerts and only return the `id`\n     * const political_news_crawler_crawl_alertsWithIdOnly = await prisma.political_news_crawler_crawl_alerts.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_crawl_alertsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_crawl_alertsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_crawl_alerts.\n     * @param {political_news_crawler_crawl_alertsUpsertArgs} args - Arguments to update or create a Political_news_crawler_crawl_alerts.\n     * @example\n     * // Update or create a Political_news_crawler_crawl_alerts\n     * const political_news_crawler_crawl_alerts = await prisma.political_news_crawler_crawl_alerts.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_crawl_alerts\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawl_alerts we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_crawl_alertsUpsertArgs>(args: SelectSubset<T, political_news_crawler_crawl_alertsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_alertsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_crawl_alerts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_alertsCountArgs} args - Arguments to filter Political_news_crawler_crawl_alerts to count.\n     * @example\n     * // Count the number of Political_news_crawler_crawl_alerts\n     * const count = await prisma.political_news_crawler_crawl_alerts.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_crawl_alerts we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_crawl_alertsCountArgs>(\n      args?: Subset<T, political_news_crawler_crawl_alertsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_crawl_alertsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_crawl_alerts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_crawl_alertsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_crawl_alertsAggregateArgs>(args: Subset<T, Political_news_crawler_crawl_alertsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_crawl_alertsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_crawl_alerts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_crawl_alertsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_crawl_alertsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_crawl_alertsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_crawl_alertsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_crawl_alertsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_crawl_alertsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_crawl_alerts model\n   */\n  readonly fields: political_news_crawler_crawl_alertsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_crawl_alerts.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_crawl_alertsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    crawlSource<T extends political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs> = {}>(args?: Subset<T, political_news_crawler_crawl_sourcesDefaultArgs<ExtArgs>>): Prisma__political_news_crawler_crawl_sourcesClient<$Result.GetResult<Prisma.$political_news_crawler_crawl_sourcesPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions> | Null, Null, ExtArgs, GlobalOmitOptions>\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_crawl_alerts model\n   */\n  interface political_news_crawler_crawl_alertsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_crawl_alerts\", 'String'>\n    readonly crawl_source_id: FieldRef<\"political_news_crawler_crawl_alerts\", 'String'>\n    readonly alert_type: FieldRef<\"political_news_crawler_crawl_alerts\", 'String'>\n    readonly message: FieldRef<\"political_news_crawler_crawl_alerts\", 'String'>\n    readonly severity: FieldRef<\"political_news_crawler_crawl_alerts\", 'String'>\n    readonly created_at: FieldRef<\"political_news_crawler_crawl_alerts\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_crawl_alerts\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_crawl_alerts findUnique\n   */\n  export type political_news_crawler_crawl_alertsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_alerts\n     */\n    select?: political_news_crawler_crawl_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_alerts\n     */\n    omit?: political_news_crawler_crawl_alertsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_alertsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_alerts to fetch.\n     */\n    where: political_news_crawler_crawl_alertsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts findUniqueOrThrow\n   */\n  export type political_news_crawler_crawl_alertsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_alerts\n     */\n    select?: political_news_crawler_crawl_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_alerts\n     */\n    omit?: political_news_crawler_crawl_alertsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_alertsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_alerts to fetch.\n     */\n    where: political_news_crawler_crawl_alertsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts findFirst\n   */\n  export type political_news_crawler_crawl_alertsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_alerts\n     */\n    select?: political_news_crawler_crawl_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_alerts\n     */\n    omit?: political_news_crawler_crawl_alertsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_alertsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_alerts to fetch.\n     */\n    where?: political_news_crawler_crawl_alertsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_alerts to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_alertsOrderByWithRelationInput | political_news_crawler_crawl_alertsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawl_alerts.\n     */\n    cursor?: political_news_crawler_crawl_alertsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_alerts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_alerts.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawl_alerts.\n     */\n    distinct?: Political_news_crawler_crawl_alertsScalarFieldEnum | Political_news_crawler_crawl_alertsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts findFirstOrThrow\n   */\n  export type political_news_crawler_crawl_alertsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_alerts\n     */\n    select?: political_news_crawler_crawl_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_alerts\n     */\n    omit?: political_news_crawler_crawl_alertsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_alertsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_alerts to fetch.\n     */\n    where?: political_news_crawler_crawl_alertsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_alerts to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_alertsOrderByWithRelationInput | political_news_crawler_crawl_alertsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_crawl_alerts.\n     */\n    cursor?: political_news_crawler_crawl_alertsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_alerts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_alerts.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_crawl_alerts.\n     */\n    distinct?: Political_news_crawler_crawl_alertsScalarFieldEnum | Political_news_crawler_crawl_alertsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts findMany\n   */\n  export type political_news_crawler_crawl_alertsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_alerts\n     */\n    select?: political_news_crawler_crawl_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_alerts\n     */\n    omit?: political_news_crawler_crawl_alertsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_alertsInclude<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_crawl_alerts to fetch.\n     */\n    where?: political_news_crawler_crawl_alertsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_crawl_alerts to fetch.\n     */\n    orderBy?: political_news_crawler_crawl_alertsOrderByWithRelationInput | political_news_crawler_crawl_alertsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_crawl_alerts.\n     */\n    cursor?: political_news_crawler_crawl_alertsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_crawl_alerts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_crawl_alerts.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_crawl_alertsScalarFieldEnum | Political_news_crawler_crawl_alertsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts create\n   */\n  export type political_news_crawler_crawl_alertsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_alerts\n     */\n    select?: political_news_crawler_crawl_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_alerts\n     */\n    omit?: political_news_crawler_crawl_alertsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_alertsInclude<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_crawl_alerts.\n     */\n    data: XOR<political_news_crawler_crawl_alertsCreateInput, political_news_crawler_crawl_alertsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts createMany\n   */\n  export type political_news_crawler_crawl_alertsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_crawl_alerts.\n     */\n    data: political_news_crawler_crawl_alertsCreateManyInput | political_news_crawler_crawl_alertsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts createManyAndReturn\n   */\n  export type political_news_crawler_crawl_alertsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_alerts\n     */\n    select?: political_news_crawler_crawl_alertsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_alerts\n     */\n    omit?: political_news_crawler_crawl_alertsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_crawl_alerts.\n     */\n    data: political_news_crawler_crawl_alertsCreateManyInput | political_news_crawler_crawl_alertsCreateManyInput[]\n    skipDuplicates?: boolean\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_alertsIncludeCreateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts update\n   */\n  export type political_news_crawler_crawl_alertsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_alerts\n     */\n    select?: political_news_crawler_crawl_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_alerts\n     */\n    omit?: political_news_crawler_crawl_alertsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_alertsInclude<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_crawl_alerts.\n     */\n    data: XOR<political_news_crawler_crawl_alertsUpdateInput, political_news_crawler_crawl_alertsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_crawl_alerts to update.\n     */\n    where: political_news_crawler_crawl_alertsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts updateMany\n   */\n  export type political_news_crawler_crawl_alertsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_crawl_alerts.\n     */\n    data: XOR<political_news_crawler_crawl_alertsUpdateManyMutationInput, political_news_crawler_crawl_alertsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawl_alerts to update\n     */\n    where?: political_news_crawler_crawl_alertsWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_alerts to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts updateManyAndReturn\n   */\n  export type political_news_crawler_crawl_alertsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_alerts\n     */\n    select?: political_news_crawler_crawl_alertsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_alerts\n     */\n    omit?: political_news_crawler_crawl_alertsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_crawl_alerts.\n     */\n    data: XOR<political_news_crawler_crawl_alertsUpdateManyMutationInput, political_news_crawler_crawl_alertsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_crawl_alerts to update\n     */\n    where?: political_news_crawler_crawl_alertsWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_alerts to update.\n     */\n    limit?: number\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_alertsIncludeUpdateManyAndReturn<ExtArgs> | null\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts upsert\n   */\n  export type political_news_crawler_crawl_alertsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_alerts\n     */\n    select?: political_news_crawler_crawl_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_alerts\n     */\n    omit?: political_news_crawler_crawl_alertsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_alertsInclude<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_crawl_alerts to update in case it exists.\n     */\n    where: political_news_crawler_crawl_alertsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_crawl_alerts found by the `where` argument doesn't exist, create a new political_news_crawler_crawl_alerts with this data.\n     */\n    create: XOR<political_news_crawler_crawl_alertsCreateInput, political_news_crawler_crawl_alertsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_crawl_alerts was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_crawl_alertsUpdateInput, political_news_crawler_crawl_alertsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts delete\n   */\n  export type political_news_crawler_crawl_alertsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_alerts\n     */\n    select?: political_news_crawler_crawl_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_alerts\n     */\n    omit?: political_news_crawler_crawl_alertsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_alertsInclude<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_crawl_alerts to delete.\n     */\n    where: political_news_crawler_crawl_alertsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts deleteMany\n   */\n  export type political_news_crawler_crawl_alertsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_crawl_alerts to delete\n     */\n    where?: political_news_crawler_crawl_alertsWhereInput\n    /**\n     * Limit how many political_news_crawler_crawl_alerts to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_crawl_alerts without action\n   */\n  export type political_news_crawler_crawl_alertsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_crawl_alerts\n     */\n    select?: political_news_crawler_crawl_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_crawl_alerts\n     */\n    omit?: political_news_crawler_crawl_alertsOmit<ExtArgs> | null\n    /**\n     * Choose, which related nodes to fetch as well\n     */\n    include?: political_news_crawler_crawl_alertsInclude<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_processing_alerts\n   */\n\n  export type AggregatePolitical_news_crawler_processing_alerts = {\n    _count: Political_news_crawler_processing_alertsCountAggregateOutputType | null\n    _min: Political_news_crawler_processing_alertsMinAggregateOutputType | null\n    _max: Political_news_crawler_processing_alertsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_processing_alertsMinAggregateOutputType = {\n    id: string | null\n    alert_type: string | null\n    message: string | null\n    severity: string | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_processing_alertsMaxAggregateOutputType = {\n    id: string | null\n    alert_type: string | null\n    message: string | null\n    severity: string | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_processing_alertsCountAggregateOutputType = {\n    id: number\n    alert_type: number\n    message: number\n    severity: number\n    created_at: number\n    updated_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_processing_alertsMinAggregateInputType = {\n    id?: true\n    alert_type?: true\n    message?: true\n    severity?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_processing_alertsMaxAggregateInputType = {\n    id?: true\n    alert_type?: true\n    message?: true\n    severity?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_processing_alertsCountAggregateInputType = {\n    id?: true\n    alert_type?: true\n    message?: true\n    severity?: true\n    created_at?: true\n    updated_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_processing_alertsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_processing_alerts to aggregate.\n     */\n    where?: political_news_crawler_processing_alertsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_processing_alerts to fetch.\n     */\n    orderBy?: political_news_crawler_processing_alertsOrderByWithRelationInput | political_news_crawler_processing_alertsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_processing_alertsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_processing_alerts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_processing_alerts.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_processing_alerts\n    **/\n    _count?: true | Political_news_crawler_processing_alertsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_processing_alertsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_processing_alertsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_processing_alertsAggregateType<T extends Political_news_crawler_processing_alertsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_processing_alerts]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_processing_alerts[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_processing_alerts[P]>\n  }\n\n\n\n\n  export type political_news_crawler_processing_alertsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_processing_alertsWhereInput\n    orderBy?: political_news_crawler_processing_alertsOrderByWithAggregationInput | political_news_crawler_processing_alertsOrderByWithAggregationInput[]\n    by: Political_news_crawler_processing_alertsScalarFieldEnum[] | Political_news_crawler_processing_alertsScalarFieldEnum\n    having?: political_news_crawler_processing_alertsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_processing_alertsCountAggregateInputType | true\n    _min?: Political_news_crawler_processing_alertsMinAggregateInputType\n    _max?: Political_news_crawler_processing_alertsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_processing_alertsGroupByOutputType = {\n    id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date\n    updated_at: Date\n    _count: Political_news_crawler_processing_alertsCountAggregateOutputType | null\n    _min: Political_news_crawler_processing_alertsMinAggregateOutputType | null\n    _max: Political_news_crawler_processing_alertsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_processing_alertsGroupByPayload<T extends political_news_crawler_processing_alertsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_processing_alertsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_processing_alertsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_processing_alertsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_processing_alertsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_processing_alertsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    alert_type?: boolean\n    message?: boolean\n    severity?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_processing_alerts\"]>\n\n  export type political_news_crawler_processing_alertsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    alert_type?: boolean\n    message?: boolean\n    severity?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_processing_alerts\"]>\n\n  export type political_news_crawler_processing_alertsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    alert_type?: boolean\n    message?: boolean\n    severity?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_processing_alerts\"]>\n\n  export type political_news_crawler_processing_alertsSelectScalar = {\n    id?: boolean\n    alert_type?: boolean\n    message?: boolean\n    severity?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }\n\n  export type political_news_crawler_processing_alertsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"alert_type\" | \"message\" | \"severity\" | \"created_at\" | \"updated_at\", ExtArgs[\"result\"][\"political_news_crawler_processing_alerts\"]>\n\n  export type $political_news_crawler_processing_alertsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_processing_alerts\"\n    objects: {}\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Category of processing alert such as 'llm_failure', 'queue_overflow',\n       * 'retry_limit_reached'.\n       */\n      alert_type: string\n      /**\n       * Detailed description of the processing alert event for operational use.\n       */\n      message: string\n      /**\n       * Severity level of the alert (e.g., 'info', 'warning', 'critical').\n       */\n      severity: string\n      /**\n       * Timestamp when the alert was created.\n       */\n      created_at: Date\n      /**\n       * Timestamp for last update of the alert.\n       */\n      updated_at: Date\n    }, ExtArgs[\"result\"][\"political_news_crawler_processing_alerts\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_processing_alertsGetPayload<S extends boolean | null | undefined | political_news_crawler_processing_alertsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_processing_alertsPayload, S>\n\n  type political_news_crawler_processing_alertsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_processing_alertsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_processing_alertsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_processing_alertsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_processing_alerts'], meta: { name: 'political_news_crawler_processing_alerts' } }\n    /**\n     * Find zero or one Political_news_crawler_processing_alerts that matches the filter.\n     * @param {political_news_crawler_processing_alertsFindUniqueArgs} args - Arguments to find a Political_news_crawler_processing_alerts\n     * @example\n     * // Get one Political_news_crawler_processing_alerts\n     * const political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_processing_alertsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_processing_alertsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_processing_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_processing_alertsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_processing_alerts that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_processing_alertsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_processing_alerts\n     * @example\n     * // Get one Political_news_crawler_processing_alerts\n     * const political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_processing_alertsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_processing_alertsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_processing_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_processing_alertsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_processing_alerts that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processing_alertsFindFirstArgs} args - Arguments to find a Political_news_crawler_processing_alerts\n     * @example\n     * // Get one Political_news_crawler_processing_alerts\n     * const political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_processing_alertsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_processing_alertsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_processing_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_processing_alertsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_processing_alerts that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processing_alertsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_processing_alerts\n     * @example\n     * // Get one Political_news_crawler_processing_alerts\n     * const political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_processing_alertsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_processing_alertsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_processing_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_processing_alertsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_processing_alerts that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processing_alertsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_processing_alerts\n     * const political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.findMany()\n     * \n     * // Get first 10 Political_news_crawler_processing_alerts\n     * const political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_processing_alertsWithIdOnly = await prisma.political_news_crawler_processing_alerts.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_processing_alertsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_processing_alertsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_processing_alertsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_processing_alerts.\n     * @param {political_news_crawler_processing_alertsCreateArgs} args - Arguments to create a Political_news_crawler_processing_alerts.\n     * @example\n     * // Create one Political_news_crawler_processing_alerts\n     * const Political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_processing_alerts\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_processing_alertsCreateArgs>(args: SelectSubset<T, political_news_crawler_processing_alertsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_processing_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_processing_alertsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_processing_alerts.\n     * @param {political_news_crawler_processing_alertsCreateManyArgs} args - Arguments to create many Political_news_crawler_processing_alerts.\n     * @example\n     * // Create many Political_news_crawler_processing_alerts\n     * const political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_processing_alertsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_processing_alertsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_processing_alerts and returns the data saved in the database.\n     * @param {political_news_crawler_processing_alertsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_processing_alerts.\n     * @example\n     * // Create many Political_news_crawler_processing_alerts\n     * const political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_processing_alerts and only return the `id`\n     * const political_news_crawler_processing_alertsWithIdOnly = await prisma.political_news_crawler_processing_alerts.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_processing_alertsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_processing_alertsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_processing_alertsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_processing_alerts.\n     * @param {political_news_crawler_processing_alertsDeleteArgs} args - Arguments to delete one Political_news_crawler_processing_alerts.\n     * @example\n     * // Delete one Political_news_crawler_processing_alerts\n     * const Political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_processing_alerts\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_processing_alertsDeleteArgs>(args: SelectSubset<T, political_news_crawler_processing_alertsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_processing_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_processing_alertsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_processing_alerts.\n     * @param {political_news_crawler_processing_alertsUpdateArgs} args - Arguments to update one Political_news_crawler_processing_alerts.\n     * @example\n     * // Update one Political_news_crawler_processing_alerts\n     * const political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_processing_alertsUpdateArgs>(args: SelectSubset<T, political_news_crawler_processing_alertsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_processing_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_processing_alertsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_processing_alerts.\n     * @param {political_news_crawler_processing_alertsDeleteManyArgs} args - Arguments to filter Political_news_crawler_processing_alerts to delete.\n     * @example\n     * // Delete a few Political_news_crawler_processing_alerts\n     * const { count } = await prisma.political_news_crawler_processing_alerts.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_processing_alertsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_processing_alertsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_processing_alerts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processing_alertsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_processing_alerts\n     * const political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_processing_alertsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_processing_alertsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_processing_alerts and returns the data updated in the database.\n     * @param {political_news_crawler_processing_alertsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_processing_alerts.\n     * @example\n     * // Update many Political_news_crawler_processing_alerts\n     * const political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_processing_alerts and only return the `id`\n     * const political_news_crawler_processing_alertsWithIdOnly = await prisma.political_news_crawler_processing_alerts.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_processing_alertsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_processing_alertsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_processing_alertsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_processing_alerts.\n     * @param {political_news_crawler_processing_alertsUpsertArgs} args - Arguments to update or create a Political_news_crawler_processing_alerts.\n     * @example\n     * // Update or create a Political_news_crawler_processing_alerts\n     * const political_news_crawler_processing_alerts = await prisma.political_news_crawler_processing_alerts.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_processing_alerts\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_processing_alerts we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_processing_alertsUpsertArgs>(args: SelectSubset<T, political_news_crawler_processing_alertsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_processing_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_processing_alertsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_processing_alerts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processing_alertsCountArgs} args - Arguments to filter Political_news_crawler_processing_alerts to count.\n     * @example\n     * // Count the number of Political_news_crawler_processing_alerts\n     * const count = await prisma.political_news_crawler_processing_alerts.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_processing_alerts we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_processing_alertsCountArgs>(\n      args?: Subset<T, political_news_crawler_processing_alertsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_processing_alertsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_processing_alerts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_processing_alertsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_processing_alertsAggregateArgs>(args: Subset<T, Political_news_crawler_processing_alertsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_processing_alertsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_processing_alerts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_processing_alertsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_processing_alertsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_processing_alertsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_processing_alertsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_processing_alertsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_processing_alertsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_processing_alerts model\n   */\n  readonly fields: political_news_crawler_processing_alertsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_processing_alerts.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_processing_alertsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_processing_alerts model\n   */\n  interface political_news_crawler_processing_alertsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_processing_alerts\", 'String'>\n    readonly alert_type: FieldRef<\"political_news_crawler_processing_alerts\", 'String'>\n    readonly message: FieldRef<\"political_news_crawler_processing_alerts\", 'String'>\n    readonly severity: FieldRef<\"political_news_crawler_processing_alerts\", 'String'>\n    readonly created_at: FieldRef<\"political_news_crawler_processing_alerts\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_processing_alerts\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_processing_alerts findUnique\n   */\n  export type political_news_crawler_processing_alertsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_alerts\n     */\n    select?: political_news_crawler_processing_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_alerts\n     */\n    omit?: political_news_crawler_processing_alertsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processing_alerts to fetch.\n     */\n    where: political_news_crawler_processing_alertsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_processing_alerts findUniqueOrThrow\n   */\n  export type political_news_crawler_processing_alertsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_alerts\n     */\n    select?: political_news_crawler_processing_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_alerts\n     */\n    omit?: political_news_crawler_processing_alertsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processing_alerts to fetch.\n     */\n    where: political_news_crawler_processing_alertsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_processing_alerts findFirst\n   */\n  export type political_news_crawler_processing_alertsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_alerts\n     */\n    select?: political_news_crawler_processing_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_alerts\n     */\n    omit?: political_news_crawler_processing_alertsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processing_alerts to fetch.\n     */\n    where?: political_news_crawler_processing_alertsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_processing_alerts to fetch.\n     */\n    orderBy?: political_news_crawler_processing_alertsOrderByWithRelationInput | political_news_crawler_processing_alertsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_processing_alerts.\n     */\n    cursor?: political_news_crawler_processing_alertsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_processing_alerts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_processing_alerts.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_processing_alerts.\n     */\n    distinct?: Political_news_crawler_processing_alertsScalarFieldEnum | Political_news_crawler_processing_alertsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_processing_alerts findFirstOrThrow\n   */\n  export type political_news_crawler_processing_alertsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_alerts\n     */\n    select?: political_news_crawler_processing_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_alerts\n     */\n    omit?: political_news_crawler_processing_alertsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processing_alerts to fetch.\n     */\n    where?: political_news_crawler_processing_alertsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_processing_alerts to fetch.\n     */\n    orderBy?: political_news_crawler_processing_alertsOrderByWithRelationInput | political_news_crawler_processing_alertsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_processing_alerts.\n     */\n    cursor?: political_news_crawler_processing_alertsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_processing_alerts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_processing_alerts.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_processing_alerts.\n     */\n    distinct?: Political_news_crawler_processing_alertsScalarFieldEnum | Political_news_crawler_processing_alertsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_processing_alerts findMany\n   */\n  export type political_news_crawler_processing_alertsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_alerts\n     */\n    select?: political_news_crawler_processing_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_alerts\n     */\n    omit?: political_news_crawler_processing_alertsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_processing_alerts to fetch.\n     */\n    where?: political_news_crawler_processing_alertsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_processing_alerts to fetch.\n     */\n    orderBy?: political_news_crawler_processing_alertsOrderByWithRelationInput | political_news_crawler_processing_alertsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_processing_alerts.\n     */\n    cursor?: political_news_crawler_processing_alertsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_processing_alerts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_processing_alerts.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_processing_alertsScalarFieldEnum | Political_news_crawler_processing_alertsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_processing_alerts create\n   */\n  export type political_news_crawler_processing_alertsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_alerts\n     */\n    select?: political_news_crawler_processing_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_alerts\n     */\n    omit?: political_news_crawler_processing_alertsOmit<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_processing_alerts.\n     */\n    data: XOR<political_news_crawler_processing_alertsCreateInput, political_news_crawler_processing_alertsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_processing_alerts createMany\n   */\n  export type political_news_crawler_processing_alertsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_processing_alerts.\n     */\n    data: political_news_crawler_processing_alertsCreateManyInput | political_news_crawler_processing_alertsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_processing_alerts createManyAndReturn\n   */\n  export type political_news_crawler_processing_alertsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_alerts\n     */\n    select?: political_news_crawler_processing_alertsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_alerts\n     */\n    omit?: political_news_crawler_processing_alertsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_processing_alerts.\n     */\n    data: political_news_crawler_processing_alertsCreateManyInput | political_news_crawler_processing_alertsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_processing_alerts update\n   */\n  export type political_news_crawler_processing_alertsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_alerts\n     */\n    select?: political_news_crawler_processing_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_alerts\n     */\n    omit?: political_news_crawler_processing_alertsOmit<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_processing_alerts.\n     */\n    data: XOR<political_news_crawler_processing_alertsUpdateInput, political_news_crawler_processing_alertsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_processing_alerts to update.\n     */\n    where: political_news_crawler_processing_alertsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_processing_alerts updateMany\n   */\n  export type political_news_crawler_processing_alertsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_processing_alerts.\n     */\n    data: XOR<political_news_crawler_processing_alertsUpdateManyMutationInput, political_news_crawler_processing_alertsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_processing_alerts to update\n     */\n    where?: political_news_crawler_processing_alertsWhereInput\n    /**\n     * Limit how many political_news_crawler_processing_alerts to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_processing_alerts updateManyAndReturn\n   */\n  export type political_news_crawler_processing_alertsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_alerts\n     */\n    select?: political_news_crawler_processing_alertsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_alerts\n     */\n    omit?: political_news_crawler_processing_alertsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_processing_alerts.\n     */\n    data: XOR<political_news_crawler_processing_alertsUpdateManyMutationInput, political_news_crawler_processing_alertsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_processing_alerts to update\n     */\n    where?: political_news_crawler_processing_alertsWhereInput\n    /**\n     * Limit how many political_news_crawler_processing_alerts to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_processing_alerts upsert\n   */\n  export type political_news_crawler_processing_alertsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_alerts\n     */\n    select?: political_news_crawler_processing_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_alerts\n     */\n    omit?: political_news_crawler_processing_alertsOmit<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_processing_alerts to update in case it exists.\n     */\n    where: political_news_crawler_processing_alertsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_processing_alerts found by the `where` argument doesn't exist, create a new political_news_crawler_processing_alerts with this data.\n     */\n    create: XOR<political_news_crawler_processing_alertsCreateInput, political_news_crawler_processing_alertsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_processing_alerts was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_processing_alertsUpdateInput, political_news_crawler_processing_alertsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_processing_alerts delete\n   */\n  export type political_news_crawler_processing_alertsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_alerts\n     */\n    select?: political_news_crawler_processing_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_alerts\n     */\n    omit?: political_news_crawler_processing_alertsOmit<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_processing_alerts to delete.\n     */\n    where: political_news_crawler_processing_alertsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_processing_alerts deleteMany\n   */\n  export type political_news_crawler_processing_alertsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_processing_alerts to delete\n     */\n    where?: political_news_crawler_processing_alertsWhereInput\n    /**\n     * Limit how many political_news_crawler_processing_alerts to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_processing_alerts without action\n   */\n  export type political_news_crawler_processing_alertsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_processing_alerts\n     */\n    select?: political_news_crawler_processing_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_processing_alerts\n     */\n    omit?: political_news_crawler_processing_alertsOmit<ExtArgs> | null\n  }\n\n\n  /**\n   * Model political_news_crawler_api_alerts\n   */\n\n  export type AggregatePolitical_news_crawler_api_alerts = {\n    _count: Political_news_crawler_api_alertsCountAggregateOutputType | null\n    _min: Political_news_crawler_api_alertsMinAggregateOutputType | null\n    _max: Political_news_crawler_api_alertsMaxAggregateOutputType | null\n  }\n\n  export type Political_news_crawler_api_alertsMinAggregateOutputType = {\n    id: string | null\n    alert_type: string | null\n    message: string | null\n    severity: string | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_api_alertsMaxAggregateOutputType = {\n    id: string | null\n    alert_type: string | null\n    message: string | null\n    severity: string | null\n    created_at: Date | null\n    updated_at: Date | null\n  }\n\n  export type Political_news_crawler_api_alertsCountAggregateOutputType = {\n    id: number\n    alert_type: number\n    message: number\n    severity: number\n    created_at: number\n    updated_at: number\n    _all: number\n  }\n\n\n  export type Political_news_crawler_api_alertsMinAggregateInputType = {\n    id?: true\n    alert_type?: true\n    message?: true\n    severity?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_api_alertsMaxAggregateInputType = {\n    id?: true\n    alert_type?: true\n    message?: true\n    severity?: true\n    created_at?: true\n    updated_at?: true\n  }\n\n  export type Political_news_crawler_api_alertsCountAggregateInputType = {\n    id?: true\n    alert_type?: true\n    message?: true\n    severity?: true\n    created_at?: true\n    updated_at?: true\n    _all?: true\n  }\n\n  export type Political_news_crawler_api_alertsAggregateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_api_alerts to aggregate.\n     */\n    where?: political_news_crawler_api_alertsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_alerts to fetch.\n     */\n    orderBy?: political_news_crawler_api_alertsOrderByWithRelationInput | political_news_crawler_api_alertsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the start position\n     */\n    cursor?: political_news_crawler_api_alertsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_alerts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_alerts.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Count returned political_news_crawler_api_alerts\n    **/\n    _count?: true | Political_news_crawler_api_alertsCountAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the minimum value\n    **/\n    _min?: Political_news_crawler_api_alertsMinAggregateInputType\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/aggregations Aggregation Docs}\n     * \n     * Select which fields to find the maximum value\n    **/\n    _max?: Political_news_crawler_api_alertsMaxAggregateInputType\n  }\n\n  export type GetPolitical_news_crawler_api_alertsAggregateType<T extends Political_news_crawler_api_alertsAggregateArgs> = {\n        [P in keyof T & keyof AggregatePolitical_news_crawler_api_alerts]: P extends '_count' | 'count'\n      ? T[P] extends true\n        ? number\n        : GetScalarType<T[P], AggregatePolitical_news_crawler_api_alerts[P]>\n      : GetScalarType<T[P], AggregatePolitical_news_crawler_api_alerts[P]>\n  }\n\n\n\n\n  export type political_news_crawler_api_alertsGroupByArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    where?: political_news_crawler_api_alertsWhereInput\n    orderBy?: political_news_crawler_api_alertsOrderByWithAggregationInput | political_news_crawler_api_alertsOrderByWithAggregationInput[]\n    by: Political_news_crawler_api_alertsScalarFieldEnum[] | Political_news_crawler_api_alertsScalarFieldEnum\n    having?: political_news_crawler_api_alertsScalarWhereWithAggregatesInput\n    take?: number\n    skip?: number\n    _count?: Political_news_crawler_api_alertsCountAggregateInputType | true\n    _min?: Political_news_crawler_api_alertsMinAggregateInputType\n    _max?: Political_news_crawler_api_alertsMaxAggregateInputType\n  }\n\n  export type Political_news_crawler_api_alertsGroupByOutputType = {\n    id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date\n    updated_at: Date\n    _count: Political_news_crawler_api_alertsCountAggregateOutputType | null\n    _min: Political_news_crawler_api_alertsMinAggregateOutputType | null\n    _max: Political_news_crawler_api_alertsMaxAggregateOutputType | null\n  }\n\n  type GetPolitical_news_crawler_api_alertsGroupByPayload<T extends political_news_crawler_api_alertsGroupByArgs> = Prisma.PrismaPromise<\n    Array<\n      PickEnumerable<Political_news_crawler_api_alertsGroupByOutputType, T['by']> &\n        {\n          [P in ((keyof T) & (keyof Political_news_crawler_api_alertsGroupByOutputType))]: P extends '_count'\n            ? T[P] extends boolean\n              ? number\n              : GetScalarType<T[P], Political_news_crawler_api_alertsGroupByOutputType[P]>\n            : GetScalarType<T[P], Political_news_crawler_api_alertsGroupByOutputType[P]>\n        }\n      >\n    >\n\n\n  export type political_news_crawler_api_alertsSelect<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    alert_type?: boolean\n    message?: boolean\n    severity?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_api_alerts\"]>\n\n  export type political_news_crawler_api_alertsSelectCreateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    alert_type?: boolean\n    message?: boolean\n    severity?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_api_alerts\"]>\n\n  export type political_news_crawler_api_alertsSelectUpdateManyAndReturn<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetSelect<{\n    id?: boolean\n    alert_type?: boolean\n    message?: boolean\n    severity?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }, ExtArgs[\"result\"][\"political_news_crawler_api_alerts\"]>\n\n  export type political_news_crawler_api_alertsSelectScalar = {\n    id?: boolean\n    alert_type?: boolean\n    message?: boolean\n    severity?: boolean\n    created_at?: boolean\n    updated_at?: boolean\n  }\n\n  export type political_news_crawler_api_alertsOmit<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = $Extensions.GetOmit<\"id\" | \"alert_type\" | \"message\" | \"severity\" | \"created_at\" | \"updated_at\", ExtArgs[\"result\"][\"political_news_crawler_api_alerts\"]>\n\n  export type $political_news_crawler_api_alertsPayload<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    name: \"political_news_crawler_api_alerts\"\n    objects: {}\n    scalars: $Extensions.GetPayloadResult<{\n      /**\n       * Primary Key.\n       */\n      id: string\n      /**\n       * Type of API alert event such as 'rate_limit_exceeded', 'endpoint_error',\n       * 'error_spike'.\n       */\n      alert_type: string\n      /**\n       * Detailed message describing the API alert context.\n       */\n      message: string\n      /**\n       * Severity level of the alert such as 'info', 'warning', 'critical'.\n       */\n      severity: string\n      /**\n       * Timestamp when the alert was created.\n       */\n      created_at: Date\n      /**\n       * Timestamp when the alert was last updated.\n       */\n      updated_at: Date\n    }, ExtArgs[\"result\"][\"political_news_crawler_api_alerts\"]>\n    composites: {}\n  }\n\n  type political_news_crawler_api_alertsGetPayload<S extends boolean | null | undefined | political_news_crawler_api_alertsDefaultArgs> = $Result.GetResult<Prisma.$political_news_crawler_api_alertsPayload, S>\n\n  type political_news_crawler_api_alertsCountArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> =\n    Omit<political_news_crawler_api_alertsFindManyArgs, 'select' | 'include' | 'distinct' | 'omit'> & {\n      select?: Political_news_crawler_api_alertsCountAggregateInputType | true\n    }\n\n  export interface political_news_crawler_api_alertsDelegate<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> {\n    [K: symbol]: { types: Prisma.TypeMap<ExtArgs>['model']['political_news_crawler_api_alerts'], meta: { name: 'political_news_crawler_api_alerts' } }\n    /**\n     * Find zero or one Political_news_crawler_api_alerts that matches the filter.\n     * @param {political_news_crawler_api_alertsFindUniqueArgs} args - Arguments to find a Political_news_crawler_api_alerts\n     * @example\n     * // Get one Political_news_crawler_api_alerts\n     * const political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.findUnique({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUnique<T extends political_news_crawler_api_alertsFindUniqueArgs>(args: SelectSubset<T, political_news_crawler_api_alertsFindUniqueArgs<ExtArgs>>): Prisma__political_news_crawler_api_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_api_alertsPayload<ExtArgs>, T, \"findUnique\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find one Political_news_crawler_api_alerts that matches the filter or throw an error with `error.code='P2025'`\n     * if no matches were found.\n     * @param {political_news_crawler_api_alertsFindUniqueOrThrowArgs} args - Arguments to find a Political_news_crawler_api_alerts\n     * @example\n     * // Get one Political_news_crawler_api_alerts\n     * const political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.findUniqueOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findUniqueOrThrow<T extends political_news_crawler_api_alertsFindUniqueOrThrowArgs>(args: SelectSubset<T, political_news_crawler_api_alertsFindUniqueOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_api_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_api_alertsPayload<ExtArgs>, T, \"findUniqueOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_api_alerts that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_alertsFindFirstArgs} args - Arguments to find a Political_news_crawler_api_alerts\n     * @example\n     * // Get one Political_news_crawler_api_alerts\n     * const political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.findFirst({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirst<T extends political_news_crawler_api_alertsFindFirstArgs>(args?: SelectSubset<T, political_news_crawler_api_alertsFindFirstArgs<ExtArgs>>): Prisma__political_news_crawler_api_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_api_alertsPayload<ExtArgs>, T, \"findFirst\", GlobalOmitOptions> | null, null, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find the first Political_news_crawler_api_alerts that matches the filter or\n     * throw `PrismaKnownClientError` with `P2025` code if no matches were found.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_alertsFindFirstOrThrowArgs} args - Arguments to find a Political_news_crawler_api_alerts\n     * @example\n     * // Get one Political_news_crawler_api_alerts\n     * const political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.findFirstOrThrow({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     */\n    findFirstOrThrow<T extends political_news_crawler_api_alertsFindFirstOrThrowArgs>(args?: SelectSubset<T, political_news_crawler_api_alertsFindFirstOrThrowArgs<ExtArgs>>): Prisma__political_news_crawler_api_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_api_alertsPayload<ExtArgs>, T, \"findFirstOrThrow\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Find zero or more Political_news_crawler_api_alerts that matches the filter.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_alertsFindManyArgs} args - Arguments to filter and select certain fields only.\n     * @example\n     * // Get all Political_news_crawler_api_alerts\n     * const political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.findMany()\n     * \n     * // Get first 10 Political_news_crawler_api_alerts\n     * const political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.findMany({ take: 10 })\n     * \n     * // Only select the `id`\n     * const political_news_crawler_api_alertsWithIdOnly = await prisma.political_news_crawler_api_alerts.findMany({ select: { id: true } })\n     * \n     */\n    findMany<T extends political_news_crawler_api_alertsFindManyArgs>(args?: SelectSubset<T, political_news_crawler_api_alertsFindManyArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_api_alertsPayload<ExtArgs>, T, \"findMany\", GlobalOmitOptions>>\n\n    /**\n     * Create a Political_news_crawler_api_alerts.\n     * @param {political_news_crawler_api_alertsCreateArgs} args - Arguments to create a Political_news_crawler_api_alerts.\n     * @example\n     * // Create one Political_news_crawler_api_alerts\n     * const Political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.create({\n     *   data: {\n     *     // ... data to create a Political_news_crawler_api_alerts\n     *   }\n     * })\n     * \n     */\n    create<T extends political_news_crawler_api_alertsCreateArgs>(args: SelectSubset<T, political_news_crawler_api_alertsCreateArgs<ExtArgs>>): Prisma__political_news_crawler_api_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_api_alertsPayload<ExtArgs>, T, \"create\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Create many Political_news_crawler_api_alerts.\n     * @param {political_news_crawler_api_alertsCreateManyArgs} args - Arguments to create many Political_news_crawler_api_alerts.\n     * @example\n     * // Create many Political_news_crawler_api_alerts\n     * const political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.createMany({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     *     \n     */\n    createMany<T extends political_news_crawler_api_alertsCreateManyArgs>(args?: SelectSubset<T, political_news_crawler_api_alertsCreateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Create many Political_news_crawler_api_alerts and returns the data saved in the database.\n     * @param {political_news_crawler_api_alertsCreateManyAndReturnArgs} args - Arguments to create many Political_news_crawler_api_alerts.\n     * @example\n     * // Create many Political_news_crawler_api_alerts\n     * const political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.createManyAndReturn({\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Create many Political_news_crawler_api_alerts and only return the `id`\n     * const political_news_crawler_api_alertsWithIdOnly = await prisma.political_news_crawler_api_alerts.createManyAndReturn({\n     *   select: { id: true },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    createManyAndReturn<T extends political_news_crawler_api_alertsCreateManyAndReturnArgs>(args?: SelectSubset<T, political_news_crawler_api_alertsCreateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_api_alertsPayload<ExtArgs>, T, \"createManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Delete a Political_news_crawler_api_alerts.\n     * @param {political_news_crawler_api_alertsDeleteArgs} args - Arguments to delete one Political_news_crawler_api_alerts.\n     * @example\n     * // Delete one Political_news_crawler_api_alerts\n     * const Political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.delete({\n     *   where: {\n     *     // ... filter to delete one Political_news_crawler_api_alerts\n     *   }\n     * })\n     * \n     */\n    delete<T extends political_news_crawler_api_alertsDeleteArgs>(args: SelectSubset<T, political_news_crawler_api_alertsDeleteArgs<ExtArgs>>): Prisma__political_news_crawler_api_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_api_alertsPayload<ExtArgs>, T, \"delete\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Update one Political_news_crawler_api_alerts.\n     * @param {political_news_crawler_api_alertsUpdateArgs} args - Arguments to update one Political_news_crawler_api_alerts.\n     * @example\n     * // Update one Political_news_crawler_api_alerts\n     * const political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.update({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    update<T extends political_news_crawler_api_alertsUpdateArgs>(args: SelectSubset<T, political_news_crawler_api_alertsUpdateArgs<ExtArgs>>): Prisma__political_news_crawler_api_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_api_alertsPayload<ExtArgs>, T, \"update\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n    /**\n     * Delete zero or more Political_news_crawler_api_alerts.\n     * @param {political_news_crawler_api_alertsDeleteManyArgs} args - Arguments to filter Political_news_crawler_api_alerts to delete.\n     * @example\n     * // Delete a few Political_news_crawler_api_alerts\n     * const { count } = await prisma.political_news_crawler_api_alerts.deleteMany({\n     *   where: {\n     *     // ... provide filter here\n     *   }\n     * })\n     * \n     */\n    deleteMany<T extends political_news_crawler_api_alertsDeleteManyArgs>(args?: SelectSubset<T, political_news_crawler_api_alertsDeleteManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_api_alerts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_alertsUpdateManyArgs} args - Arguments to update one or more rows.\n     * @example\n     * // Update many Political_news_crawler_api_alerts\n     * const political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.updateMany({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: {\n     *     // ... provide data here\n     *   }\n     * })\n     * \n     */\n    updateMany<T extends political_news_crawler_api_alertsUpdateManyArgs>(args: SelectSubset<T, political_news_crawler_api_alertsUpdateManyArgs<ExtArgs>>): Prisma.PrismaPromise<BatchPayload>\n\n    /**\n     * Update zero or more Political_news_crawler_api_alerts and returns the data updated in the database.\n     * @param {political_news_crawler_api_alertsUpdateManyAndReturnArgs} args - Arguments to update many Political_news_crawler_api_alerts.\n     * @example\n     * // Update many Political_news_crawler_api_alerts\n     * const political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.updateManyAndReturn({\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * \n     * // Update zero or more Political_news_crawler_api_alerts and only return the `id`\n     * const political_news_crawler_api_alertsWithIdOnly = await prisma.political_news_crawler_api_alerts.updateManyAndReturn({\n     *   select: { id: true },\n     *   where: {\n     *     // ... provide filter here\n     *   },\n     *   data: [\n     *     // ... provide data here\n     *   ]\n     * })\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * \n     */\n    updateManyAndReturn<T extends political_news_crawler_api_alertsUpdateManyAndReturnArgs>(args: SelectSubset<T, political_news_crawler_api_alertsUpdateManyAndReturnArgs<ExtArgs>>): Prisma.PrismaPromise<$Result.GetResult<Prisma.$political_news_crawler_api_alertsPayload<ExtArgs>, T, \"updateManyAndReturn\", GlobalOmitOptions>>\n\n    /**\n     * Create or update one Political_news_crawler_api_alerts.\n     * @param {political_news_crawler_api_alertsUpsertArgs} args - Arguments to update or create a Political_news_crawler_api_alerts.\n     * @example\n     * // Update or create a Political_news_crawler_api_alerts\n     * const political_news_crawler_api_alerts = await prisma.political_news_crawler_api_alerts.upsert({\n     *   create: {\n     *     // ... data to create a Political_news_crawler_api_alerts\n     *   },\n     *   update: {\n     *     // ... in case it already exists, update\n     *   },\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_api_alerts we want to update\n     *   }\n     * })\n     */\n    upsert<T extends political_news_crawler_api_alertsUpsertArgs>(args: SelectSubset<T, political_news_crawler_api_alertsUpsertArgs<ExtArgs>>): Prisma__political_news_crawler_api_alertsClient<$Result.GetResult<Prisma.$political_news_crawler_api_alertsPayload<ExtArgs>, T, \"upsert\", GlobalOmitOptions>, never, ExtArgs, GlobalOmitOptions>\n\n\n    /**\n     * Count the number of Political_news_crawler_api_alerts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_alertsCountArgs} args - Arguments to filter Political_news_crawler_api_alerts to count.\n     * @example\n     * // Count the number of Political_news_crawler_api_alerts\n     * const count = await prisma.political_news_crawler_api_alerts.count({\n     *   where: {\n     *     // ... the filter for the Political_news_crawler_api_alerts we want to count\n     *   }\n     * })\n    **/\n    count<T extends political_news_crawler_api_alertsCountArgs>(\n      args?: Subset<T, political_news_crawler_api_alertsCountArgs>,\n    ): Prisma.PrismaPromise<\n      T extends $Utils.Record<'select', any>\n        ? T['select'] extends true\n          ? number\n          : GetScalarType<T['select'], Political_news_crawler_api_alertsCountAggregateOutputType>\n        : number\n    >\n\n    /**\n     * Allows you to perform aggregations operations on a Political_news_crawler_api_alerts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {Political_news_crawler_api_alertsAggregateArgs} args - Select which aggregations you would like to apply and on what fields.\n     * @example\n     * // Ordered by age ascending\n     * // Where email contains prisma.io\n     * // Limited to the 10 users\n     * const aggregations = await prisma.user.aggregate({\n     *   _avg: {\n     *     age: true,\n     *   },\n     *   where: {\n     *     email: {\n     *       contains: \"prisma.io\",\n     *     },\n     *   },\n     *   orderBy: {\n     *     age: \"asc\",\n     *   },\n     *   take: 10,\n     * })\n    **/\n    aggregate<T extends Political_news_crawler_api_alertsAggregateArgs>(args: Subset<T, Political_news_crawler_api_alertsAggregateArgs>): Prisma.PrismaPromise<GetPolitical_news_crawler_api_alertsAggregateType<T>>\n\n    /**\n     * Group by Political_news_crawler_api_alerts.\n     * Note, that providing `undefined` is treated as the value not being there.\n     * Read more here: https://pris.ly/d/null-undefined\n     * @param {political_news_crawler_api_alertsGroupByArgs} args - Group by arguments.\n     * @example\n     * // Group by city, order by createdAt, get count\n     * const result = await prisma.user.groupBy({\n     *   by: ['city', 'createdAt'],\n     *   orderBy: {\n     *     createdAt: true\n     *   },\n     *   _count: {\n     *     _all: true\n     *   },\n     * })\n     * \n    **/\n    groupBy<\n      T extends political_news_crawler_api_alertsGroupByArgs,\n      HasSelectOrTake extends Or<\n        Extends<'skip', Keys<T>>,\n        Extends<'take', Keys<T>>\n      >,\n      OrderByArg extends True extends HasSelectOrTake\n        ? { orderBy: political_news_crawler_api_alertsGroupByArgs['orderBy'] }\n        : { orderBy?: political_news_crawler_api_alertsGroupByArgs['orderBy'] },\n      OrderFields extends ExcludeUnderscoreKeys<Keys<MaybeTupleToUnion<T['orderBy']>>>,\n      ByFields extends MaybeTupleToUnion<T['by']>,\n      ByValid extends Has<ByFields, OrderFields>,\n      HavingFields extends GetHavingFields<T['having']>,\n      HavingValid extends Has<ByFields, HavingFields>,\n      ByEmpty extends T['by'] extends never[] ? True : False,\n      InputErrors extends ByEmpty extends True\n      ? `Error: \"by\" must not be empty.`\n      : HavingValid extends False\n      ? {\n          [P in HavingFields]: P extends ByFields\n            ? never\n            : P extends string\n            ? `Error: Field \"${P}\" used in \"having\" needs to be provided in \"by\".`\n            : [\n                Error,\n                'Field ',\n                P,\n                ` in \"having\" needs to be provided in \"by\"`,\n              ]\n        }[HavingFields]\n      : 'take' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"take\", you also need to provide \"orderBy\"'\n      : 'skip' extends Keys<T>\n      ? 'orderBy' extends Keys<T>\n        ? ByValid extends True\n          ? {}\n          : {\n              [P in OrderFields]: P extends ByFields\n                ? never\n                : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n            }[OrderFields]\n        : 'Error: If you provide \"skip\", you also need to provide \"orderBy\"'\n      : ByValid extends True\n      ? {}\n      : {\n          [P in OrderFields]: P extends ByFields\n            ? never\n            : `Error: Field \"${P}\" in \"orderBy\" needs to be provided in \"by\"`\n        }[OrderFields]\n    >(args: SubsetIntersection<T, political_news_crawler_api_alertsGroupByArgs, OrderByArg> & InputErrors): {} extends InputErrors ? GetPolitical_news_crawler_api_alertsGroupByPayload<T> : Prisma.PrismaPromise<InputErrors>\n  /**\n   * Fields of the political_news_crawler_api_alerts model\n   */\n  readonly fields: political_news_crawler_api_alertsFieldRefs;\n  }\n\n  /**\n   * The delegate class that acts as a \"Promise-like\" for political_news_crawler_api_alerts.\n   * Why is this prefixed with `Prisma__`?\n   * Because we want to prevent naming conflicts as mentioned in\n   * https://github.com/prisma/prisma-client-js/issues/707\n   */\n  export interface Prisma__political_news_crawler_api_alertsClient<T, Null = never, ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs, GlobalOmitOptions = {}> extends Prisma.PrismaPromise<T> {\n    readonly [Symbol.toStringTag]: \"PrismaPromise\"\n    /**\n     * Attaches callbacks for the resolution and/or rejection of the Promise.\n     * @param onfulfilled The callback to execute when the Promise is resolved.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of which ever callback is executed.\n     */\n    then<TResult1 = T, TResult2 = never>(onfulfilled?: ((value: T) => TResult1 | PromiseLike<TResult1>) | undefined | null, onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null): $Utils.JsPromise<TResult1 | TResult2>\n    /**\n     * Attaches a callback for only the rejection of the Promise.\n     * @param onrejected The callback to execute when the Promise is rejected.\n     * @returns A Promise for the completion of the callback.\n     */\n    catch<TResult = never>(onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null): $Utils.JsPromise<T | TResult>\n    /**\n     * Attaches a callback that is invoked when the Promise is settled (fulfilled or rejected). The\n     * resolved value cannot be modified from the callback.\n     * @param onfinally The callback to execute when the Promise is settled (fulfilled or rejected).\n     * @returns A Promise for the completion of the callback.\n     */\n    finally(onfinally?: (() => void) | undefined | null): $Utils.JsPromise<T>\n  }\n\n\n\n\n  /**\n   * Fields of the political_news_crawler_api_alerts model\n   */\n  interface political_news_crawler_api_alertsFieldRefs {\n    readonly id: FieldRef<\"political_news_crawler_api_alerts\", 'String'>\n    readonly alert_type: FieldRef<\"political_news_crawler_api_alerts\", 'String'>\n    readonly message: FieldRef<\"political_news_crawler_api_alerts\", 'String'>\n    readonly severity: FieldRef<\"political_news_crawler_api_alerts\", 'String'>\n    readonly created_at: FieldRef<\"political_news_crawler_api_alerts\", 'DateTime'>\n    readonly updated_at: FieldRef<\"political_news_crawler_api_alerts\", 'DateTime'>\n  }\n    \n\n  // Custom InputTypes\n  /**\n   * political_news_crawler_api_alerts findUnique\n   */\n  export type political_news_crawler_api_alertsFindUniqueArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_alerts\n     */\n    select?: political_news_crawler_api_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_alerts\n     */\n    omit?: political_news_crawler_api_alertsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_alerts to fetch.\n     */\n    where: political_news_crawler_api_alertsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_alerts findUniqueOrThrow\n   */\n  export type political_news_crawler_api_alertsFindUniqueOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_alerts\n     */\n    select?: political_news_crawler_api_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_alerts\n     */\n    omit?: political_news_crawler_api_alertsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_alerts to fetch.\n     */\n    where: political_news_crawler_api_alertsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_alerts findFirst\n   */\n  export type political_news_crawler_api_alertsFindFirstArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_alerts\n     */\n    select?: political_news_crawler_api_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_alerts\n     */\n    omit?: political_news_crawler_api_alertsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_alerts to fetch.\n     */\n    where?: political_news_crawler_api_alertsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_alerts to fetch.\n     */\n    orderBy?: political_news_crawler_api_alertsOrderByWithRelationInput | political_news_crawler_api_alertsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_api_alerts.\n     */\n    cursor?: political_news_crawler_api_alertsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_alerts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_alerts.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_api_alerts.\n     */\n    distinct?: Political_news_crawler_api_alertsScalarFieldEnum | Political_news_crawler_api_alertsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_api_alerts findFirstOrThrow\n   */\n  export type political_news_crawler_api_alertsFindFirstOrThrowArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_alerts\n     */\n    select?: political_news_crawler_api_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_alerts\n     */\n    omit?: political_news_crawler_api_alertsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_alerts to fetch.\n     */\n    where?: political_news_crawler_api_alertsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_alerts to fetch.\n     */\n    orderBy?: political_news_crawler_api_alertsOrderByWithRelationInput | political_news_crawler_api_alertsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for searching for political_news_crawler_api_alerts.\n     */\n    cursor?: political_news_crawler_api_alertsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_alerts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_alerts.\n     */\n    skip?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/distinct Distinct Docs}\n     * \n     * Filter by unique combinations of political_news_crawler_api_alerts.\n     */\n    distinct?: Political_news_crawler_api_alertsScalarFieldEnum | Political_news_crawler_api_alertsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_api_alerts findMany\n   */\n  export type political_news_crawler_api_alertsFindManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_alerts\n     */\n    select?: political_news_crawler_api_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_alerts\n     */\n    omit?: political_news_crawler_api_alertsOmit<ExtArgs> | null\n    /**\n     * Filter, which political_news_crawler_api_alerts to fetch.\n     */\n    where?: political_news_crawler_api_alertsWhereInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/sorting Sorting Docs}\n     * \n     * Determine the order of political_news_crawler_api_alerts to fetch.\n     */\n    orderBy?: political_news_crawler_api_alertsOrderByWithRelationInput | political_news_crawler_api_alertsOrderByWithRelationInput[]\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination#cursor-based-pagination Cursor Docs}\n     * \n     * Sets the position for listing political_news_crawler_api_alerts.\n     */\n    cursor?: political_news_crawler_api_alertsWhereUniqueInput\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Take `±n` political_news_crawler_api_alerts from the position of the cursor.\n     */\n    take?: number\n    /**\n     * {@link https://www.prisma.io/docs/concepts/components/prisma-client/pagination Pagination Docs}\n     * \n     * Skip the first `n` political_news_crawler_api_alerts.\n     */\n    skip?: number\n    distinct?: Political_news_crawler_api_alertsScalarFieldEnum | Political_news_crawler_api_alertsScalarFieldEnum[]\n  }\n\n  /**\n   * political_news_crawler_api_alerts create\n   */\n  export type political_news_crawler_api_alertsCreateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_alerts\n     */\n    select?: political_news_crawler_api_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_alerts\n     */\n    omit?: political_news_crawler_api_alertsOmit<ExtArgs> | null\n    /**\n     * The data needed to create a political_news_crawler_api_alerts.\n     */\n    data: XOR<political_news_crawler_api_alertsCreateInput, political_news_crawler_api_alertsUncheckedCreateInput>\n  }\n\n  /**\n   * political_news_crawler_api_alerts createMany\n   */\n  export type political_news_crawler_api_alertsCreateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to create many political_news_crawler_api_alerts.\n     */\n    data: political_news_crawler_api_alertsCreateManyInput | political_news_crawler_api_alertsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_api_alerts createManyAndReturn\n   */\n  export type political_news_crawler_api_alertsCreateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_alerts\n     */\n    select?: political_news_crawler_api_alertsSelectCreateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_alerts\n     */\n    omit?: political_news_crawler_api_alertsOmit<ExtArgs> | null\n    /**\n     * The data used to create many political_news_crawler_api_alerts.\n     */\n    data: political_news_crawler_api_alertsCreateManyInput | political_news_crawler_api_alertsCreateManyInput[]\n    skipDuplicates?: boolean\n  }\n\n  /**\n   * political_news_crawler_api_alerts update\n   */\n  export type political_news_crawler_api_alertsUpdateArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_alerts\n     */\n    select?: political_news_crawler_api_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_alerts\n     */\n    omit?: political_news_crawler_api_alertsOmit<ExtArgs> | null\n    /**\n     * The data needed to update a political_news_crawler_api_alerts.\n     */\n    data: XOR<political_news_crawler_api_alertsUpdateInput, political_news_crawler_api_alertsUncheckedUpdateInput>\n    /**\n     * Choose, which political_news_crawler_api_alerts to update.\n     */\n    where: political_news_crawler_api_alertsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_alerts updateMany\n   */\n  export type political_news_crawler_api_alertsUpdateManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * The data used to update political_news_crawler_api_alerts.\n     */\n    data: XOR<political_news_crawler_api_alertsUpdateManyMutationInput, political_news_crawler_api_alertsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_api_alerts to update\n     */\n    where?: political_news_crawler_api_alertsWhereInput\n    /**\n     * Limit how many political_news_crawler_api_alerts to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_api_alerts updateManyAndReturn\n   */\n  export type political_news_crawler_api_alertsUpdateManyAndReturnArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_alerts\n     */\n    select?: political_news_crawler_api_alertsSelectUpdateManyAndReturn<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_alerts\n     */\n    omit?: political_news_crawler_api_alertsOmit<ExtArgs> | null\n    /**\n     * The data used to update political_news_crawler_api_alerts.\n     */\n    data: XOR<political_news_crawler_api_alertsUpdateManyMutationInput, political_news_crawler_api_alertsUncheckedUpdateManyInput>\n    /**\n     * Filter which political_news_crawler_api_alerts to update\n     */\n    where?: political_news_crawler_api_alertsWhereInput\n    /**\n     * Limit how many political_news_crawler_api_alerts to update.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_api_alerts upsert\n   */\n  export type political_news_crawler_api_alertsUpsertArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_alerts\n     */\n    select?: political_news_crawler_api_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_alerts\n     */\n    omit?: political_news_crawler_api_alertsOmit<ExtArgs> | null\n    /**\n     * The filter to search for the political_news_crawler_api_alerts to update in case it exists.\n     */\n    where: political_news_crawler_api_alertsWhereUniqueInput\n    /**\n     * In case the political_news_crawler_api_alerts found by the `where` argument doesn't exist, create a new political_news_crawler_api_alerts with this data.\n     */\n    create: XOR<political_news_crawler_api_alertsCreateInput, political_news_crawler_api_alertsUncheckedCreateInput>\n    /**\n     * In case the political_news_crawler_api_alerts was found with the provided `where` argument, update it with this data.\n     */\n    update: XOR<political_news_crawler_api_alertsUpdateInput, political_news_crawler_api_alertsUncheckedUpdateInput>\n  }\n\n  /**\n   * political_news_crawler_api_alerts delete\n   */\n  export type political_news_crawler_api_alertsDeleteArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_alerts\n     */\n    select?: political_news_crawler_api_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_alerts\n     */\n    omit?: political_news_crawler_api_alertsOmit<ExtArgs> | null\n    /**\n     * Filter which political_news_crawler_api_alerts to delete.\n     */\n    where: political_news_crawler_api_alertsWhereUniqueInput\n  }\n\n  /**\n   * political_news_crawler_api_alerts deleteMany\n   */\n  export type political_news_crawler_api_alertsDeleteManyArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Filter which political_news_crawler_api_alerts to delete\n     */\n    where?: political_news_crawler_api_alertsWhereInput\n    /**\n     * Limit how many political_news_crawler_api_alerts to delete.\n     */\n    limit?: number\n  }\n\n  /**\n   * political_news_crawler_api_alerts without action\n   */\n  export type political_news_crawler_api_alertsDefaultArgs<ExtArgs extends $Extensions.InternalArgs = $Extensions.DefaultArgs> = {\n    /**\n     * Select specific fields to fetch from the political_news_crawler_api_alerts\n     */\n    select?: political_news_crawler_api_alertsSelect<ExtArgs> | null\n    /**\n     * Omit specific fields from the political_news_crawler_api_alerts\n     */\n    omit?: political_news_crawler_api_alertsOmit<ExtArgs> | null\n  }\n\n\n  /**\n   * Enums\n   */\n\n  export const TransactionIsolationLevel: {\n    ReadUncommitted: 'ReadUncommitted',\n    ReadCommitted: 'ReadCommitted',\n    RepeatableRead: 'RepeatableRead',\n    Serializable: 'Serializable'\n  };\n\n  export type TransactionIsolationLevel = (typeof TransactionIsolationLevel)[keyof typeof TransactionIsolationLevel]\n\n\n  export const Political_news_crawler_crawl_sourcesScalarFieldEnum: {\n    id: 'id',\n    source_code: 'source_code',\n    source_url: 'source_url',\n    is_active: 'is_active',\n    description: 'description',\n    created_at: 'created_at',\n    updated_at: 'updated_at',\n    deleted_at: 'deleted_at'\n  };\n\n  export type Political_news_crawler_crawl_sourcesScalarFieldEnum = (typeof Political_news_crawler_crawl_sourcesScalarFieldEnum)[keyof typeof Political_news_crawler_crawl_sourcesScalarFieldEnum]\n\n\n  export const Political_news_crawler_crawl_policiesScalarFieldEnum: {\n    id: 'id',\n    policy_name: 'policy_name',\n    max_crawl_frequency_minutes: 'max_crawl_frequency_minutes',\n    max_retry_attempts: 'max_retry_attempts',\n    backoff_multiplier: 'backoff_multiplier',\n    ban_detection_enabled: 'ban_detection_enabled',\n    created_at: 'created_at',\n    updated_at: 'updated_at',\n    deleted_at: 'deleted_at'\n  };\n\n  export type Political_news_crawler_crawl_policiesScalarFieldEnum = (typeof Political_news_crawler_crawl_policiesScalarFieldEnum)[keyof typeof Political_news_crawler_crawl_policiesScalarFieldEnum]\n\n\n  export const Political_news_crawler_crawl_schedulesScalarFieldEnum: {\n    id: 'id',\n    crawl_source_id: 'crawl_source_id',\n    crawl_policy_id: 'crawl_policy_id',\n    schedule_expression: 'schedule_expression',\n    last_crawled_at: 'last_crawled_at',\n    next_crawl_at: 'next_crawl_at',\n    is_enabled: 'is_enabled',\n    created_at: 'created_at',\n    updated_at: 'updated_at',\n    deleted_at: 'deleted_at'\n  };\n\n  export type Political_news_crawler_crawl_schedulesScalarFieldEnum = (typeof Political_news_crawler_crawl_schedulesScalarFieldEnum)[keyof typeof Political_news_crawler_crawl_schedulesScalarFieldEnum]\n\n\n  export const Political_news_crawler_guestsScalarFieldEnum: {\n    id: 'id',\n    ip_address: 'ip_address',\n    user_agent: 'user_agent',\n    created_at: 'created_at',\n    updated_at: 'updated_at',\n    deleted_at: 'deleted_at'\n  };\n\n  export type Political_news_crawler_guestsScalarFieldEnum = (typeof Political_news_crawler_guestsScalarFieldEnum)[keyof typeof Political_news_crawler_guestsScalarFieldEnum]\n\n\n  export const Political_news_crawler_crawl_jobsScalarFieldEnum: {\n    id: 'id',\n    crawl_source_id: 'crawl_source_id',\n    crawl_schedule_id: 'crawl_schedule_id',\n    active: 'active',\n    last_run_started_at: 'last_run_started_at',\n    last_run_completed_at: 'last_run_completed_at',\n    created_at: 'created_at',\n    updated_at: 'updated_at',\n    deleted_at: 'deleted_at'\n  };\n\n  export type Political_news_crawler_crawl_jobsScalarFieldEnum = (typeof Political_news_crawler_crawl_jobsScalarFieldEnum)[keyof typeof Political_news_crawler_crawl_jobsScalarFieldEnum]\n\n\n  export const Political_news_crawler_crawl_attemptsScalarFieldEnum: {\n    id: 'id',\n    crawl_job_id: 'crawl_job_id',\n    raw_data_storage_id: 'raw_data_storage_id',\n    started_at: 'started_at',\n    completed_at: 'completed_at',\n    success: 'success',\n    error_message: 'error_message',\n    created_at: 'created_at',\n    updated_at: 'updated_at'\n  };\n\n  export type Political_news_crawler_crawl_attemptsScalarFieldEnum = (typeof Political_news_crawler_crawl_attemptsScalarFieldEnum)[keyof typeof Political_news_crawler_crawl_attemptsScalarFieldEnum]\n\n\n  export const Political_news_crawler_crawled_newsScalarFieldEnum: {\n    id: 'id',\n    crawl_attempt_id: 'crawl_attempt_id',\n    url: 'url',\n    title: 'title',\n    published_at: 'published_at',\n    created_at: 'created_at',\n    updated_at: 'updated_at'\n  };\n\n  export type Political_news_crawler_crawled_newsScalarFieldEnum = (typeof Political_news_crawler_crawled_newsScalarFieldEnum)[keyof typeof Political_news_crawler_crawled_newsScalarFieldEnum]\n\n\n  export const Political_news_crawler_raw_data_storageScalarFieldEnum: {\n    id: 'id',\n    crawl_source_id: 'crawl_source_id',\n    crawl_job_id: 'crawl_job_id',\n    storage_key: 'storage_key',\n    file_format: 'file_format',\n    file_size_bytes: 'file_size_bytes',\n    checksum: 'checksum',\n    crawl_timestamp: 'crawl_timestamp',\n    created_at: 'created_at',\n    updated_at: 'updated_at'\n  };\n\n  export type Political_news_crawler_raw_data_storageScalarFieldEnum = (typeof Political_news_crawler_raw_data_storageScalarFieldEnum)[keyof typeof Political_news_crawler_raw_data_storageScalarFieldEnum]\n\n\n  export const Political_news_crawler_local_cache_filesScalarFieldEnum: {\n    id: 'id',\n    raw_data_storage_id: 'raw_data_storage_id',\n    local_file_path: 'local_file_path',\n    file_size_bytes: 'file_size_bytes',\n    ttl_expiration_at: 'ttl_expiration_at',\n    deleted_at: 'deleted_at',\n    created_at: 'created_at',\n    updated_at: 'updated_at'\n  };\n\n  export type Political_news_crawler_local_cache_filesScalarFieldEnum = (typeof Political_news_crawler_local_cache_filesScalarFieldEnum)[keyof typeof Political_news_crawler_local_cache_filesScalarFieldEnum]\n\n\n  export const Political_news_crawler_processed_contentScalarFieldEnum: {\n    id: 'id',\n    raw_data_storage_id: 'raw_data_storage_id',\n    llm_job_id: 'llm_job_id',\n    content_type: 'content_type',\n    content_body: 'content_body',\n    generation_timestamp: 'generation_timestamp',\n    created_at: 'created_at',\n    updated_at: 'updated_at'\n  };\n\n  export type Political_news_crawler_processed_contentScalarFieldEnum = (typeof Political_news_crawler_processed_contentScalarFieldEnum)[keyof typeof Political_news_crawler_processed_contentScalarFieldEnum]\n\n\n  export const Political_news_crawler_llm_jobsScalarFieldEnum: {\n    id: 'id',\n    crawl_source_id: 'crawl_source_id',\n    status: 'status',\n    parameters: 'parameters',\n    created_at: 'created_at',\n    updated_at: 'updated_at',\n    deleted_at: 'deleted_at'\n  };\n\n  export type Political_news_crawler_llm_jobsScalarFieldEnum = (typeof Political_news_crawler_llm_jobsScalarFieldEnum)[keyof typeof Political_news_crawler_llm_jobsScalarFieldEnum]\n\n\n  export const Political_news_crawler_llm_resultsScalarFieldEnum: {\n    id: 'id',\n    llm_job_id: 'llm_job_id',\n    content_type: 'content_type',\n    content_text: 'content_text',\n    created_at: 'created_at',\n    updated_at: 'updated_at',\n    deleted_at: 'deleted_at'\n  };\n\n  export type Political_news_crawler_llm_resultsScalarFieldEnum = (typeof Political_news_crawler_llm_resultsScalarFieldEnum)[keyof typeof Political_news_crawler_llm_resultsScalarFieldEnum]\n\n\n  export const Political_news_crawler_processing_metadataScalarFieldEnum: {\n    id: 'id',\n    llm_job_id: 'llm_job_id',\n    metadata_key: 'metadata_key',\n    metadata_value: 'metadata_value',\n    created_at: 'created_at',\n    updated_at: 'updated_at',\n    deleted_at: 'deleted_at'\n  };\n\n  export type Political_news_crawler_processing_metadataScalarFieldEnum = (typeof Political_news_crawler_processing_metadataScalarFieldEnum)[keyof typeof Political_news_crawler_processing_metadataScalarFieldEnum]\n\n\n  export const Political_news_crawler_popularity_scoresScalarFieldEnum: {\n    id: 'id',\n    political_news_crawler_popular_topic_id: 'political_news_crawler_popular_topic_id',\n    score: 'score',\n    decay_factor: 'decay_factor',\n    snapshot_at: 'snapshot_at',\n    created_at: 'created_at',\n    updated_at: 'updated_at',\n    deleted_at: 'deleted_at'\n  };\n\n  export type Political_news_crawler_popularity_scoresScalarFieldEnum = (typeof Political_news_crawler_popularity_scoresScalarFieldEnum)[keyof typeof Political_news_crawler_popularity_scoresScalarFieldEnum]\n\n\n  export const Political_news_crawler_popular_topicsScalarFieldEnum: {\n    id: 'id',\n    topic_code: 'topic_code',\n    title: 'title',\n    description: 'description',\n    created_at: 'created_at',\n    updated_at: 'updated_at',\n    deleted_at: 'deleted_at'\n  };\n\n  export type Political_news_crawler_popular_topicsScalarFieldEnum = (typeof Political_news_crawler_popular_topicsScalarFieldEnum)[keyof typeof Political_news_crawler_popular_topicsScalarFieldEnum]\n\n\n  export const Political_news_crawler_topic_mentionsScalarFieldEnum: {\n    id: 'id',\n    political_news_crawler_popular_topic_id: 'political_news_crawler_popular_topic_id',\n    political_news_crawler_crawled_news_id: 'political_news_crawler_crawled_news_id',\n    mention_context: 'mention_context',\n    created_at: 'created_at',\n    updated_at: 'updated_at',\n    deleted_at: 'deleted_at'\n  };\n\n  export type Political_news_crawler_topic_mentionsScalarFieldEnum = (typeof Political_news_crawler_topic_mentionsScalarFieldEnum)[keyof typeof Political_news_crawler_topic_mentionsScalarFieldEnum]\n\n\n  export const Political_news_crawler_api_access_logsScalarFieldEnum: {\n    id: 'id',\n    http_method: 'http_method',\n    path: 'path',\n    status_code: 'status_code',\n    client_ip: 'client_ip',\n    user_agent: 'user_agent',\n    duration_ms: 'duration_ms',\n    created_at: 'created_at',\n    updated_at: 'updated_at'\n  };\n\n  export type Political_news_crawler_api_access_logsScalarFieldEnum = (typeof Political_news_crawler_api_access_logsScalarFieldEnum)[keyof typeof Political_news_crawler_api_access_logsScalarFieldEnum]\n\n\n  export const Political_news_crawler_api_error_logsScalarFieldEnum: {\n    id: 'id',\n    path: 'path',\n    error_code: 'error_code',\n    error_message: 'error_message',\n    client_ip: 'client_ip',\n    user_agent: 'user_agent',\n    created_at: 'created_at',\n    updated_at: 'updated_at'\n  };\n\n  export type Political_news_crawler_api_error_logsScalarFieldEnum = (typeof Political_news_crawler_api_error_logsScalarFieldEnum)[keyof typeof Political_news_crawler_api_error_logsScalarFieldEnum]\n\n\n  export const Political_news_crawler_api_usage_metricsScalarFieldEnum: {\n    id: 'id',\n    http_method: 'http_method',\n    path: 'path',\n    period_start: 'period_start',\n    period_end: 'period_end',\n    total_calls: 'total_calls',\n    max_response_ms: 'max_response_ms',\n    avg_response_ms: 'avg_response_ms',\n    created_at: 'created_at',\n    updated_at: 'updated_at'\n  };\n\n  export type Political_news_crawler_api_usage_metricsScalarFieldEnum = (typeof Political_news_crawler_api_usage_metricsScalarFieldEnum)[keyof typeof Political_news_crawler_api_usage_metricsScalarFieldEnum]\n\n\n  export const Political_news_crawler_crawl_alertsScalarFieldEnum: {\n    id: 'id',\n    crawl_source_id: 'crawl_source_id',\n    alert_type: 'alert_type',\n    message: 'message',\n    severity: 'severity',\n    created_at: 'created_at',\n    updated_at: 'updated_at'\n  };\n\n  export type Political_news_crawler_crawl_alertsScalarFieldEnum = (typeof Political_news_crawler_crawl_alertsScalarFieldEnum)[keyof typeof Political_news_crawler_crawl_alertsScalarFieldEnum]\n\n\n  export const Political_news_crawler_processing_alertsScalarFieldEnum: {\n    id: 'id',\n    alert_type: 'alert_type',\n    message: 'message',\n    severity: 'severity',\n    created_at: 'created_at',\n    updated_at: 'updated_at'\n  };\n\n  export type Political_news_crawler_processing_alertsScalarFieldEnum = (typeof Political_news_crawler_processing_alertsScalarFieldEnum)[keyof typeof Political_news_crawler_processing_alertsScalarFieldEnum]\n\n\n  export const Political_news_crawler_api_alertsScalarFieldEnum: {\n    id: 'id',\n    alert_type: 'alert_type',\n    message: 'message',\n    severity: 'severity',\n    created_at: 'created_at',\n    updated_at: 'updated_at'\n  };\n\n  export type Political_news_crawler_api_alertsScalarFieldEnum = (typeof Political_news_crawler_api_alertsScalarFieldEnum)[keyof typeof Political_news_crawler_api_alertsScalarFieldEnum]\n\n\n  export const SortOrder: {\n    asc: 'asc',\n    desc: 'desc'\n  };\n\n  export type SortOrder = (typeof SortOrder)[keyof typeof SortOrder]\n\n\n  export const QueryMode: {\n    default: 'default',\n    insensitive: 'insensitive'\n  };\n\n  export type QueryMode = (typeof QueryMode)[keyof typeof QueryMode]\n\n\n  export const NullsOrder: {\n    first: 'first',\n    last: 'last'\n  };\n\n  export type NullsOrder = (typeof NullsOrder)[keyof typeof NullsOrder]\n\n\n  /**\n   * Field references\n   */\n\n\n  /**\n   * Reference to a field of type 'String'\n   */\n  export type StringFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'String'>\n    \n\n\n  /**\n   * Reference to a field of type 'String[]'\n   */\n  export type ListStringFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'String[]'>\n    \n\n\n  /**\n   * Reference to a field of type 'Boolean'\n   */\n  export type BooleanFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'Boolean'>\n    \n\n\n  /**\n   * Reference to a field of type 'DateTime'\n   */\n  export type DateTimeFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'DateTime'>\n    \n\n\n  /**\n   * Reference to a field of type 'DateTime[]'\n   */\n  export type ListDateTimeFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'DateTime[]'>\n    \n\n\n  /**\n   * Reference to a field of type 'Int'\n   */\n  export type IntFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'Int'>\n    \n\n\n  /**\n   * Reference to a field of type 'Int[]'\n   */\n  export type ListIntFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'Int[]'>\n    \n\n\n  /**\n   * Reference to a field of type 'Float'\n   */\n  export type FloatFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'Float'>\n    \n\n\n  /**\n   * Reference to a field of type 'Float[]'\n   */\n  export type ListFloatFieldRefInput<$PrismaModel> = FieldRefInputType<$PrismaModel, 'Float[]'>\n    \n  /**\n   * Deep Input Types\n   */\n\n\n  export type political_news_crawler_crawl_sourcesWhereInput = {\n    AND?: political_news_crawler_crawl_sourcesWhereInput | political_news_crawler_crawl_sourcesWhereInput[]\n    OR?: political_news_crawler_crawl_sourcesWhereInput[]\n    NOT?: political_news_crawler_crawl_sourcesWhereInput | political_news_crawler_crawl_sourcesWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_crawl_sources\"> | string\n    source_code?: StringFilter<\"political_news_crawler_crawl_sources\"> | string\n    source_url?: StringFilter<\"political_news_crawler_crawl_sources\"> | string\n    is_active?: BoolFilter<\"political_news_crawler_crawl_sources\"> | boolean\n    description?: StringNullableFilter<\"political_news_crawler_crawl_sources\"> | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_sources\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_sources\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_sources\"> | Date | string | null\n    political_news_crawler_crawl_schedules?: Political_news_crawler_crawl_schedulesListRelationFilter\n    political_news_crawler_crawl_jobs?: Political_news_crawler_crawl_jobsListRelationFilter\n    political_news_crawler_raw_data_storage?: Political_news_crawler_raw_data_storageListRelationFilter\n    political_news_crawler_llm_jobs?: Political_news_crawler_llm_jobsListRelationFilter\n    political_news_crawler_crawl_alerts?: Political_news_crawler_crawl_alertsListRelationFilter\n  }\n\n  export type political_news_crawler_crawl_sourcesOrderByWithRelationInput = {\n    id?: SortOrder\n    source_code?: SortOrder\n    source_url?: SortOrder\n    is_active?: SortOrder\n    description?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesOrderByRelationAggregateInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsOrderByRelationAggregateInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageOrderByRelationAggregateInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsOrderByRelationAggregateInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsOrderByRelationAggregateInput\n  }\n\n  export type political_news_crawler_crawl_sourcesWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    source_code?: string\n    source_url?: string\n    AND?: political_news_crawler_crawl_sourcesWhereInput | political_news_crawler_crawl_sourcesWhereInput[]\n    OR?: political_news_crawler_crawl_sourcesWhereInput[]\n    NOT?: political_news_crawler_crawl_sourcesWhereInput | political_news_crawler_crawl_sourcesWhereInput[]\n    is_active?: BoolFilter<\"political_news_crawler_crawl_sources\"> | boolean\n    description?: StringNullableFilter<\"political_news_crawler_crawl_sources\"> | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_sources\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_sources\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_sources\"> | Date | string | null\n    political_news_crawler_crawl_schedules?: Political_news_crawler_crawl_schedulesListRelationFilter\n    political_news_crawler_crawl_jobs?: Political_news_crawler_crawl_jobsListRelationFilter\n    political_news_crawler_raw_data_storage?: Political_news_crawler_raw_data_storageListRelationFilter\n    political_news_crawler_llm_jobs?: Political_news_crawler_llm_jobsListRelationFilter\n    political_news_crawler_crawl_alerts?: Political_news_crawler_crawl_alertsListRelationFilter\n  }, \"id\" | \"source_code\" | \"source_url\">\n\n  export type political_news_crawler_crawl_sourcesOrderByWithAggregationInput = {\n    id?: SortOrder\n    source_code?: SortOrder\n    source_url?: SortOrder\n    is_active?: SortOrder\n    description?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    _count?: political_news_crawler_crawl_sourcesCountOrderByAggregateInput\n    _max?: political_news_crawler_crawl_sourcesMaxOrderByAggregateInput\n    _min?: political_news_crawler_crawl_sourcesMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_crawl_sourcesScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_crawl_sourcesScalarWhereWithAggregatesInput | political_news_crawler_crawl_sourcesScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_crawl_sourcesScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_crawl_sourcesScalarWhereWithAggregatesInput | political_news_crawler_crawl_sourcesScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_crawl_sources\"> | string\n    source_code?: StringWithAggregatesFilter<\"political_news_crawler_crawl_sources\"> | string\n    source_url?: StringWithAggregatesFilter<\"political_news_crawler_crawl_sources\"> | string\n    is_active?: BoolWithAggregatesFilter<\"political_news_crawler_crawl_sources\"> | boolean\n    description?: StringNullableWithAggregatesFilter<\"political_news_crawler_crawl_sources\"> | string | null\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawl_sources\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawl_sources\"> | Date | string\n    deleted_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_crawl_sources\"> | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_policiesWhereInput = {\n    AND?: political_news_crawler_crawl_policiesWhereInput | political_news_crawler_crawl_policiesWhereInput[]\n    OR?: political_news_crawler_crawl_policiesWhereInput[]\n    NOT?: political_news_crawler_crawl_policiesWhereInput | political_news_crawler_crawl_policiesWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_crawl_policies\"> | string\n    policy_name?: StringFilter<\"political_news_crawler_crawl_policies\"> | string\n    max_crawl_frequency_minutes?: IntFilter<\"political_news_crawler_crawl_policies\"> | number\n    max_retry_attempts?: IntFilter<\"political_news_crawler_crawl_policies\"> | number\n    backoff_multiplier?: FloatFilter<\"political_news_crawler_crawl_policies\"> | number\n    ban_detection_enabled?: BoolFilter<\"political_news_crawler_crawl_policies\"> | boolean\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_policies\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_policies\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_policies\"> | Date | string | null\n    political_news_crawler_crawl_schedules?: Political_news_crawler_crawl_schedulesListRelationFilter\n  }\n\n  export type political_news_crawler_crawl_policiesOrderByWithRelationInput = {\n    id?: SortOrder\n    policy_name?: SortOrder\n    max_crawl_frequency_minutes?: SortOrder\n    max_retry_attempts?: SortOrder\n    backoff_multiplier?: SortOrder\n    ban_detection_enabled?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesOrderByRelationAggregateInput\n  }\n\n  export type political_news_crawler_crawl_policiesWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    policy_name?: string\n    AND?: political_news_crawler_crawl_policiesWhereInput | political_news_crawler_crawl_policiesWhereInput[]\n    OR?: political_news_crawler_crawl_policiesWhereInput[]\n    NOT?: political_news_crawler_crawl_policiesWhereInput | political_news_crawler_crawl_policiesWhereInput[]\n    max_crawl_frequency_minutes?: IntFilter<\"political_news_crawler_crawl_policies\"> | number\n    max_retry_attempts?: IntFilter<\"political_news_crawler_crawl_policies\"> | number\n    backoff_multiplier?: FloatFilter<\"political_news_crawler_crawl_policies\"> | number\n    ban_detection_enabled?: BoolFilter<\"political_news_crawler_crawl_policies\"> | boolean\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_policies\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_policies\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_policies\"> | Date | string | null\n    political_news_crawler_crawl_schedules?: Political_news_crawler_crawl_schedulesListRelationFilter\n  }, \"id\" | \"policy_name\">\n\n  export type political_news_crawler_crawl_policiesOrderByWithAggregationInput = {\n    id?: SortOrder\n    policy_name?: SortOrder\n    max_crawl_frequency_minutes?: SortOrder\n    max_retry_attempts?: SortOrder\n    backoff_multiplier?: SortOrder\n    ban_detection_enabled?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    _count?: political_news_crawler_crawl_policiesCountOrderByAggregateInput\n    _avg?: political_news_crawler_crawl_policiesAvgOrderByAggregateInput\n    _max?: political_news_crawler_crawl_policiesMaxOrderByAggregateInput\n    _min?: political_news_crawler_crawl_policiesMinOrderByAggregateInput\n    _sum?: political_news_crawler_crawl_policiesSumOrderByAggregateInput\n  }\n\n  export type political_news_crawler_crawl_policiesScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_crawl_policiesScalarWhereWithAggregatesInput | political_news_crawler_crawl_policiesScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_crawl_policiesScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_crawl_policiesScalarWhereWithAggregatesInput | political_news_crawler_crawl_policiesScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_crawl_policies\"> | string\n    policy_name?: StringWithAggregatesFilter<\"political_news_crawler_crawl_policies\"> | string\n    max_crawl_frequency_minutes?: IntWithAggregatesFilter<\"political_news_crawler_crawl_policies\"> | number\n    max_retry_attempts?: IntWithAggregatesFilter<\"political_news_crawler_crawl_policies\"> | number\n    backoff_multiplier?: FloatWithAggregatesFilter<\"political_news_crawler_crawl_policies\"> | number\n    ban_detection_enabled?: BoolWithAggregatesFilter<\"political_news_crawler_crawl_policies\"> | boolean\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawl_policies\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawl_policies\"> | Date | string\n    deleted_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_crawl_policies\"> | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_schedulesWhereInput = {\n    AND?: political_news_crawler_crawl_schedulesWhereInput | political_news_crawler_crawl_schedulesWhereInput[]\n    OR?: political_news_crawler_crawl_schedulesWhereInput[]\n    NOT?: political_news_crawler_crawl_schedulesWhereInput | political_news_crawler_crawl_schedulesWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_crawl_schedules\"> | string\n    crawl_source_id?: UuidFilter<\"political_news_crawler_crawl_schedules\"> | string\n    crawl_policy_id?: UuidFilter<\"political_news_crawler_crawl_schedules\"> | string\n    schedule_expression?: StringFilter<\"political_news_crawler_crawl_schedules\"> | string\n    last_crawled_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_schedules\"> | Date | string | null\n    next_crawl_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_schedules\"> | Date | string | null\n    is_enabled?: BoolFilter<\"political_news_crawler_crawl_schedules\"> | boolean\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_schedules\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_schedules\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_schedules\"> | Date | string | null\n    crawlSource?: XOR<Political_news_crawler_crawl_sourcesScalarRelationFilter, political_news_crawler_crawl_sourcesWhereInput>\n    crawlPolicy?: XOR<Political_news_crawler_crawl_policiesScalarRelationFilter, political_news_crawler_crawl_policiesWhereInput>\n    political_news_crawler_crawl_jobs?: Political_news_crawler_crawl_jobsListRelationFilter\n  }\n\n  export type political_news_crawler_crawl_schedulesOrderByWithRelationInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_policy_id?: SortOrder\n    schedule_expression?: SortOrder\n    last_crawled_at?: SortOrderInput | SortOrder\n    next_crawl_at?: SortOrderInput | SortOrder\n    is_enabled?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    crawlSource?: political_news_crawler_crawl_sourcesOrderByWithRelationInput\n    crawlPolicy?: political_news_crawler_crawl_policiesOrderByWithRelationInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsOrderByRelationAggregateInput\n  }\n\n  export type political_news_crawler_crawl_schedulesWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    AND?: political_news_crawler_crawl_schedulesWhereInput | political_news_crawler_crawl_schedulesWhereInput[]\n    OR?: political_news_crawler_crawl_schedulesWhereInput[]\n    NOT?: political_news_crawler_crawl_schedulesWhereInput | political_news_crawler_crawl_schedulesWhereInput[]\n    crawl_source_id?: UuidFilter<\"political_news_crawler_crawl_schedules\"> | string\n    crawl_policy_id?: UuidFilter<\"political_news_crawler_crawl_schedules\"> | string\n    schedule_expression?: StringFilter<\"political_news_crawler_crawl_schedules\"> | string\n    last_crawled_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_schedules\"> | Date | string | null\n    next_crawl_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_schedules\"> | Date | string | null\n    is_enabled?: BoolFilter<\"political_news_crawler_crawl_schedules\"> | boolean\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_schedules\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_schedules\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_schedules\"> | Date | string | null\n    crawlSource?: XOR<Political_news_crawler_crawl_sourcesScalarRelationFilter, political_news_crawler_crawl_sourcesWhereInput>\n    crawlPolicy?: XOR<Political_news_crawler_crawl_policiesScalarRelationFilter, political_news_crawler_crawl_policiesWhereInput>\n    political_news_crawler_crawl_jobs?: Political_news_crawler_crawl_jobsListRelationFilter\n  }, \"id\">\n\n  export type political_news_crawler_crawl_schedulesOrderByWithAggregationInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_policy_id?: SortOrder\n    schedule_expression?: SortOrder\n    last_crawled_at?: SortOrderInput | SortOrder\n    next_crawl_at?: SortOrderInput | SortOrder\n    is_enabled?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    _count?: political_news_crawler_crawl_schedulesCountOrderByAggregateInput\n    _max?: political_news_crawler_crawl_schedulesMaxOrderByAggregateInput\n    _min?: political_news_crawler_crawl_schedulesMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_crawl_schedulesScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_crawl_schedulesScalarWhereWithAggregatesInput | political_news_crawler_crawl_schedulesScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_crawl_schedulesScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_crawl_schedulesScalarWhereWithAggregatesInput | political_news_crawler_crawl_schedulesScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_crawl_schedules\"> | string\n    crawl_source_id?: UuidWithAggregatesFilter<\"political_news_crawler_crawl_schedules\"> | string\n    crawl_policy_id?: UuidWithAggregatesFilter<\"political_news_crawler_crawl_schedules\"> | string\n    schedule_expression?: StringWithAggregatesFilter<\"political_news_crawler_crawl_schedules\"> | string\n    last_crawled_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_crawl_schedules\"> | Date | string | null\n    next_crawl_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_crawl_schedules\"> | Date | string | null\n    is_enabled?: BoolWithAggregatesFilter<\"political_news_crawler_crawl_schedules\"> | boolean\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawl_schedules\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawl_schedules\"> | Date | string\n    deleted_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_crawl_schedules\"> | Date | string | null\n  }\n\n  export type political_news_crawler_guestsWhereInput = {\n    AND?: political_news_crawler_guestsWhereInput | political_news_crawler_guestsWhereInput[]\n    OR?: political_news_crawler_guestsWhereInput[]\n    NOT?: political_news_crawler_guestsWhereInput | political_news_crawler_guestsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_guests\"> | string\n    ip_address?: StringFilter<\"political_news_crawler_guests\"> | string\n    user_agent?: StringNullableFilter<\"political_news_crawler_guests\"> | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_guests\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_guests\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_guests\"> | Date | string | null\n  }\n\n  export type political_news_crawler_guestsOrderByWithRelationInput = {\n    id?: SortOrder\n    ip_address?: SortOrder\n    user_agent?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n  }\n\n  export type political_news_crawler_guestsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    ip_address_user_agent?: political_news_crawler_guestsIp_addressUser_agentCompoundUniqueInput\n    AND?: political_news_crawler_guestsWhereInput | political_news_crawler_guestsWhereInput[]\n    OR?: political_news_crawler_guestsWhereInput[]\n    NOT?: political_news_crawler_guestsWhereInput | political_news_crawler_guestsWhereInput[]\n    ip_address?: StringFilter<\"political_news_crawler_guests\"> | string\n    user_agent?: StringNullableFilter<\"political_news_crawler_guests\"> | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_guests\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_guests\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_guests\"> | Date | string | null\n  }, \"id\" | \"ip_address_user_agent\">\n\n  export type political_news_crawler_guestsOrderByWithAggregationInput = {\n    id?: SortOrder\n    ip_address?: SortOrder\n    user_agent?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    _count?: political_news_crawler_guestsCountOrderByAggregateInput\n    _max?: political_news_crawler_guestsMaxOrderByAggregateInput\n    _min?: political_news_crawler_guestsMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_guestsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_guestsScalarWhereWithAggregatesInput | political_news_crawler_guestsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_guestsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_guestsScalarWhereWithAggregatesInput | political_news_crawler_guestsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_guests\"> | string\n    ip_address?: StringWithAggregatesFilter<\"political_news_crawler_guests\"> | string\n    user_agent?: StringNullableWithAggregatesFilter<\"political_news_crawler_guests\"> | string | null\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_guests\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_guests\"> | Date | string\n    deleted_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_guests\"> | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_jobsWhereInput = {\n    AND?: political_news_crawler_crawl_jobsWhereInput | political_news_crawler_crawl_jobsWhereInput[]\n    OR?: political_news_crawler_crawl_jobsWhereInput[]\n    NOT?: political_news_crawler_crawl_jobsWhereInput | political_news_crawler_crawl_jobsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_crawl_jobs\"> | string\n    crawl_source_id?: UuidFilter<\"political_news_crawler_crawl_jobs\"> | string\n    crawl_schedule_id?: UuidFilter<\"political_news_crawler_crawl_jobs\"> | string\n    active?: BoolFilter<\"political_news_crawler_crawl_jobs\"> | boolean\n    last_run_started_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_jobs\"> | Date | string | null\n    last_run_completed_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_jobs\"> | Date | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_jobs\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_jobs\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_jobs\"> | Date | string | null\n    crawlSource?: XOR<Political_news_crawler_crawl_sourcesScalarRelationFilter, political_news_crawler_crawl_sourcesWhereInput>\n    crawlSchedule?: XOR<Political_news_crawler_crawl_schedulesScalarRelationFilter, political_news_crawler_crawl_schedulesWhereInput>\n    political_news_crawler_crawl_attempts?: Political_news_crawler_crawl_attemptsListRelationFilter\n    political_news_crawler_raw_data_storage?: Political_news_crawler_raw_data_storageListRelationFilter\n  }\n\n  export type political_news_crawler_crawl_jobsOrderByWithRelationInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_schedule_id?: SortOrder\n    active?: SortOrder\n    last_run_started_at?: SortOrderInput | SortOrder\n    last_run_completed_at?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    crawlSource?: political_news_crawler_crawl_sourcesOrderByWithRelationInput\n    crawlSchedule?: political_news_crawler_crawl_schedulesOrderByWithRelationInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsOrderByRelationAggregateInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageOrderByRelationAggregateInput\n  }\n\n  export type political_news_crawler_crawl_jobsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    crawl_source_id_crawl_schedule_id?: political_news_crawler_crawl_jobsCrawl_source_idCrawl_schedule_idCompoundUniqueInput\n    AND?: political_news_crawler_crawl_jobsWhereInput | political_news_crawler_crawl_jobsWhereInput[]\n    OR?: political_news_crawler_crawl_jobsWhereInput[]\n    NOT?: political_news_crawler_crawl_jobsWhereInput | political_news_crawler_crawl_jobsWhereInput[]\n    crawl_source_id?: UuidFilter<\"political_news_crawler_crawl_jobs\"> | string\n    crawl_schedule_id?: UuidFilter<\"political_news_crawler_crawl_jobs\"> | string\n    active?: BoolFilter<\"political_news_crawler_crawl_jobs\"> | boolean\n    last_run_started_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_jobs\"> | Date | string | null\n    last_run_completed_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_jobs\"> | Date | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_jobs\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_jobs\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_jobs\"> | Date | string | null\n    crawlSource?: XOR<Political_news_crawler_crawl_sourcesScalarRelationFilter, political_news_crawler_crawl_sourcesWhereInput>\n    crawlSchedule?: XOR<Political_news_crawler_crawl_schedulesScalarRelationFilter, political_news_crawler_crawl_schedulesWhereInput>\n    political_news_crawler_crawl_attempts?: Political_news_crawler_crawl_attemptsListRelationFilter\n    political_news_crawler_raw_data_storage?: Political_news_crawler_raw_data_storageListRelationFilter\n  }, \"id\" | \"crawl_source_id_crawl_schedule_id\">\n\n  export type political_news_crawler_crawl_jobsOrderByWithAggregationInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_schedule_id?: SortOrder\n    active?: SortOrder\n    last_run_started_at?: SortOrderInput | SortOrder\n    last_run_completed_at?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    _count?: political_news_crawler_crawl_jobsCountOrderByAggregateInput\n    _max?: political_news_crawler_crawl_jobsMaxOrderByAggregateInput\n    _min?: political_news_crawler_crawl_jobsMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_crawl_jobsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_crawl_jobsScalarWhereWithAggregatesInput | political_news_crawler_crawl_jobsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_crawl_jobsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_crawl_jobsScalarWhereWithAggregatesInput | political_news_crawler_crawl_jobsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_crawl_jobs\"> | string\n    crawl_source_id?: UuidWithAggregatesFilter<\"political_news_crawler_crawl_jobs\"> | string\n    crawl_schedule_id?: UuidWithAggregatesFilter<\"political_news_crawler_crawl_jobs\"> | string\n    active?: BoolWithAggregatesFilter<\"political_news_crawler_crawl_jobs\"> | boolean\n    last_run_started_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_crawl_jobs\"> | Date | string | null\n    last_run_completed_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_crawl_jobs\"> | Date | string | null\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawl_jobs\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawl_jobs\"> | Date | string\n    deleted_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_crawl_jobs\"> | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_attemptsWhereInput = {\n    AND?: political_news_crawler_crawl_attemptsWhereInput | political_news_crawler_crawl_attemptsWhereInput[]\n    OR?: political_news_crawler_crawl_attemptsWhereInput[]\n    NOT?: political_news_crawler_crawl_attemptsWhereInput | political_news_crawler_crawl_attemptsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_crawl_attempts\"> | string\n    crawl_job_id?: UuidFilter<\"political_news_crawler_crawl_attempts\"> | string\n    raw_data_storage_id?: UuidNullableFilter<\"political_news_crawler_crawl_attempts\"> | string | null\n    started_at?: DateTimeFilter<\"political_news_crawler_crawl_attempts\"> | Date | string\n    completed_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_attempts\"> | Date | string | null\n    success?: BoolFilter<\"political_news_crawler_crawl_attempts\"> | boolean\n    error_message?: StringNullableFilter<\"political_news_crawler_crawl_attempts\"> | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_attempts\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_attempts\"> | Date | string\n    crawlJob?: XOR<Political_news_crawler_crawl_jobsScalarRelationFilter, political_news_crawler_crawl_jobsWhereInput>\n    rawDataStorage?: XOR<Political_news_crawler_raw_data_storageNullableScalarRelationFilter, political_news_crawler_raw_data_storageWhereInput> | null\n    political_news_crawler_crawled_news?: Political_news_crawler_crawled_newsListRelationFilter\n  }\n\n  export type political_news_crawler_crawl_attemptsOrderByWithRelationInput = {\n    id?: SortOrder\n    crawl_job_id?: SortOrder\n    raw_data_storage_id?: SortOrderInput | SortOrder\n    started_at?: SortOrder\n    completed_at?: SortOrderInput | SortOrder\n    success?: SortOrder\n    error_message?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    crawlJob?: political_news_crawler_crawl_jobsOrderByWithRelationInput\n    rawDataStorage?: political_news_crawler_raw_data_storageOrderByWithRelationInput\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsOrderByRelationAggregateInput\n  }\n\n  export type political_news_crawler_crawl_attemptsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    AND?: political_news_crawler_crawl_attemptsWhereInput | political_news_crawler_crawl_attemptsWhereInput[]\n    OR?: political_news_crawler_crawl_attemptsWhereInput[]\n    NOT?: political_news_crawler_crawl_attemptsWhereInput | political_news_crawler_crawl_attemptsWhereInput[]\n    crawl_job_id?: UuidFilter<\"political_news_crawler_crawl_attempts\"> | string\n    raw_data_storage_id?: UuidNullableFilter<\"political_news_crawler_crawl_attempts\"> | string | null\n    started_at?: DateTimeFilter<\"political_news_crawler_crawl_attempts\"> | Date | string\n    completed_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_attempts\"> | Date | string | null\n    success?: BoolFilter<\"political_news_crawler_crawl_attempts\"> | boolean\n    error_message?: StringNullableFilter<\"political_news_crawler_crawl_attempts\"> | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_attempts\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_attempts\"> | Date | string\n    crawlJob?: XOR<Political_news_crawler_crawl_jobsScalarRelationFilter, political_news_crawler_crawl_jobsWhereInput>\n    rawDataStorage?: XOR<Political_news_crawler_raw_data_storageNullableScalarRelationFilter, political_news_crawler_raw_data_storageWhereInput> | null\n    political_news_crawler_crawled_news?: Political_news_crawler_crawled_newsListRelationFilter\n  }, \"id\">\n\n  export type political_news_crawler_crawl_attemptsOrderByWithAggregationInput = {\n    id?: SortOrder\n    crawl_job_id?: SortOrder\n    raw_data_storage_id?: SortOrderInput | SortOrder\n    started_at?: SortOrder\n    completed_at?: SortOrderInput | SortOrder\n    success?: SortOrder\n    error_message?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    _count?: political_news_crawler_crawl_attemptsCountOrderByAggregateInput\n    _max?: political_news_crawler_crawl_attemptsMaxOrderByAggregateInput\n    _min?: political_news_crawler_crawl_attemptsMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_crawl_attemptsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_crawl_attemptsScalarWhereWithAggregatesInput | political_news_crawler_crawl_attemptsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_crawl_attemptsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_crawl_attemptsScalarWhereWithAggregatesInput | political_news_crawler_crawl_attemptsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_crawl_attempts\"> | string\n    crawl_job_id?: UuidWithAggregatesFilter<\"political_news_crawler_crawl_attempts\"> | string\n    raw_data_storage_id?: UuidNullableWithAggregatesFilter<\"political_news_crawler_crawl_attempts\"> | string | null\n    started_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawl_attempts\"> | Date | string\n    completed_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_crawl_attempts\"> | Date | string | null\n    success?: BoolWithAggregatesFilter<\"political_news_crawler_crawl_attempts\"> | boolean\n    error_message?: StringNullableWithAggregatesFilter<\"political_news_crawler_crawl_attempts\"> | string | null\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawl_attempts\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawl_attempts\"> | Date | string\n  }\n\n  export type political_news_crawler_crawled_newsWhereInput = {\n    AND?: political_news_crawler_crawled_newsWhereInput | political_news_crawler_crawled_newsWhereInput[]\n    OR?: political_news_crawler_crawled_newsWhereInput[]\n    NOT?: political_news_crawler_crawled_newsWhereInput | political_news_crawler_crawled_newsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_crawled_news\"> | string\n    crawl_attempt_id?: UuidFilter<\"political_news_crawler_crawled_news\"> | string\n    url?: StringFilter<\"political_news_crawler_crawled_news\"> | string\n    title?: StringNullableFilter<\"political_news_crawler_crawled_news\"> | string | null\n    published_at?: DateTimeNullableFilter<\"political_news_crawler_crawled_news\"> | Date | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_crawled_news\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawled_news\"> | Date | string\n    crawlAttempt?: XOR<Political_news_crawler_crawl_attemptsScalarRelationFilter, political_news_crawler_crawl_attemptsWhereInput>\n    political_news_crawler_topic_mentions?: Political_news_crawler_topic_mentionsListRelationFilter\n  }\n\n  export type political_news_crawler_crawled_newsOrderByWithRelationInput = {\n    id?: SortOrder\n    crawl_attempt_id?: SortOrder\n    url?: SortOrder\n    title?: SortOrderInput | SortOrder\n    published_at?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    crawlAttempt?: political_news_crawler_crawl_attemptsOrderByWithRelationInput\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsOrderByRelationAggregateInput\n  }\n\n  export type political_news_crawler_crawled_newsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    url?: string\n    AND?: political_news_crawler_crawled_newsWhereInput | political_news_crawler_crawled_newsWhereInput[]\n    OR?: political_news_crawler_crawled_newsWhereInput[]\n    NOT?: political_news_crawler_crawled_newsWhereInput | political_news_crawler_crawled_newsWhereInput[]\n    crawl_attempt_id?: UuidFilter<\"political_news_crawler_crawled_news\"> | string\n    title?: StringNullableFilter<\"political_news_crawler_crawled_news\"> | string | null\n    published_at?: DateTimeNullableFilter<\"political_news_crawler_crawled_news\"> | Date | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_crawled_news\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawled_news\"> | Date | string\n    crawlAttempt?: XOR<Political_news_crawler_crawl_attemptsScalarRelationFilter, political_news_crawler_crawl_attemptsWhereInput>\n    political_news_crawler_topic_mentions?: Political_news_crawler_topic_mentionsListRelationFilter\n  }, \"id\" | \"url\">\n\n  export type political_news_crawler_crawled_newsOrderByWithAggregationInput = {\n    id?: SortOrder\n    crawl_attempt_id?: SortOrder\n    url?: SortOrder\n    title?: SortOrderInput | SortOrder\n    published_at?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    _count?: political_news_crawler_crawled_newsCountOrderByAggregateInput\n    _max?: political_news_crawler_crawled_newsMaxOrderByAggregateInput\n    _min?: political_news_crawler_crawled_newsMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_crawled_newsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_crawled_newsScalarWhereWithAggregatesInput | political_news_crawler_crawled_newsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_crawled_newsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_crawled_newsScalarWhereWithAggregatesInput | political_news_crawler_crawled_newsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_crawled_news\"> | string\n    crawl_attempt_id?: UuidWithAggregatesFilter<\"political_news_crawler_crawled_news\"> | string\n    url?: StringWithAggregatesFilter<\"political_news_crawler_crawled_news\"> | string\n    title?: StringNullableWithAggregatesFilter<\"political_news_crawler_crawled_news\"> | string | null\n    published_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_crawled_news\"> | Date | string | null\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawled_news\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawled_news\"> | Date | string\n  }\n\n  export type political_news_crawler_raw_data_storageWhereInput = {\n    AND?: political_news_crawler_raw_data_storageWhereInput | political_news_crawler_raw_data_storageWhereInput[]\n    OR?: political_news_crawler_raw_data_storageWhereInput[]\n    NOT?: political_news_crawler_raw_data_storageWhereInput | political_news_crawler_raw_data_storageWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_raw_data_storage\"> | string\n    crawl_source_id?: UuidFilter<\"political_news_crawler_raw_data_storage\"> | string\n    crawl_job_id?: UuidNullableFilter<\"political_news_crawler_raw_data_storage\"> | string | null\n    storage_key?: StringFilter<\"political_news_crawler_raw_data_storage\"> | string\n    file_format?: StringFilter<\"political_news_crawler_raw_data_storage\"> | string\n    file_size_bytes?: IntFilter<\"political_news_crawler_raw_data_storage\"> | number\n    checksum?: StringNullableFilter<\"political_news_crawler_raw_data_storage\"> | string | null\n    crawl_timestamp?: DateTimeFilter<\"political_news_crawler_raw_data_storage\"> | Date | string\n    created_at?: DateTimeFilter<\"political_news_crawler_raw_data_storage\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_raw_data_storage\"> | Date | string\n    crawlSource?: XOR<Political_news_crawler_crawl_sourcesScalarRelationFilter, political_news_crawler_crawl_sourcesWhereInput>\n    crawlJob?: XOR<Political_news_crawler_crawl_jobsNullableScalarRelationFilter, political_news_crawler_crawl_jobsWhereInput> | null\n    political_news_crawler_crawl_attempts?: Political_news_crawler_crawl_attemptsListRelationFilter\n    political_news_crawler_local_cache_files?: Political_news_crawler_local_cache_filesListRelationFilter\n    political_news_crawler_processed_content?: Political_news_crawler_processed_contentListRelationFilter\n  }\n\n  export type political_news_crawler_raw_data_storageOrderByWithRelationInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_job_id?: SortOrderInput | SortOrder\n    storage_key?: SortOrder\n    file_format?: SortOrder\n    file_size_bytes?: SortOrder\n    checksum?: SortOrderInput | SortOrder\n    crawl_timestamp?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    crawlSource?: political_news_crawler_crawl_sourcesOrderByWithRelationInput\n    crawlJob?: political_news_crawler_crawl_jobsOrderByWithRelationInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsOrderByRelationAggregateInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesOrderByRelationAggregateInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentOrderByRelationAggregateInput\n  }\n\n  export type political_news_crawler_raw_data_storageWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    storage_key?: string\n    AND?: political_news_crawler_raw_data_storageWhereInput | political_news_crawler_raw_data_storageWhereInput[]\n    OR?: political_news_crawler_raw_data_storageWhereInput[]\n    NOT?: political_news_crawler_raw_data_storageWhereInput | political_news_crawler_raw_data_storageWhereInput[]\n    crawl_source_id?: UuidFilter<\"political_news_crawler_raw_data_storage\"> | string\n    crawl_job_id?: UuidNullableFilter<\"political_news_crawler_raw_data_storage\"> | string | null\n    file_format?: StringFilter<\"political_news_crawler_raw_data_storage\"> | string\n    file_size_bytes?: IntFilter<\"political_news_crawler_raw_data_storage\"> | number\n    checksum?: StringNullableFilter<\"political_news_crawler_raw_data_storage\"> | string | null\n    crawl_timestamp?: DateTimeFilter<\"political_news_crawler_raw_data_storage\"> | Date | string\n    created_at?: DateTimeFilter<\"political_news_crawler_raw_data_storage\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_raw_data_storage\"> | Date | string\n    crawlSource?: XOR<Political_news_crawler_crawl_sourcesScalarRelationFilter, political_news_crawler_crawl_sourcesWhereInput>\n    crawlJob?: XOR<Political_news_crawler_crawl_jobsNullableScalarRelationFilter, political_news_crawler_crawl_jobsWhereInput> | null\n    political_news_crawler_crawl_attempts?: Political_news_crawler_crawl_attemptsListRelationFilter\n    political_news_crawler_local_cache_files?: Political_news_crawler_local_cache_filesListRelationFilter\n    political_news_crawler_processed_content?: Political_news_crawler_processed_contentListRelationFilter\n  }, \"id\" | \"storage_key\">\n\n  export type political_news_crawler_raw_data_storageOrderByWithAggregationInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_job_id?: SortOrderInput | SortOrder\n    storage_key?: SortOrder\n    file_format?: SortOrder\n    file_size_bytes?: SortOrder\n    checksum?: SortOrderInput | SortOrder\n    crawl_timestamp?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    _count?: political_news_crawler_raw_data_storageCountOrderByAggregateInput\n    _avg?: political_news_crawler_raw_data_storageAvgOrderByAggregateInput\n    _max?: political_news_crawler_raw_data_storageMaxOrderByAggregateInput\n    _min?: political_news_crawler_raw_data_storageMinOrderByAggregateInput\n    _sum?: political_news_crawler_raw_data_storageSumOrderByAggregateInput\n  }\n\n  export type political_news_crawler_raw_data_storageScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_raw_data_storageScalarWhereWithAggregatesInput | political_news_crawler_raw_data_storageScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_raw_data_storageScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_raw_data_storageScalarWhereWithAggregatesInput | political_news_crawler_raw_data_storageScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_raw_data_storage\"> | string\n    crawl_source_id?: UuidWithAggregatesFilter<\"political_news_crawler_raw_data_storage\"> | string\n    crawl_job_id?: UuidNullableWithAggregatesFilter<\"political_news_crawler_raw_data_storage\"> | string | null\n    storage_key?: StringWithAggregatesFilter<\"political_news_crawler_raw_data_storage\"> | string\n    file_format?: StringWithAggregatesFilter<\"political_news_crawler_raw_data_storage\"> | string\n    file_size_bytes?: IntWithAggregatesFilter<\"political_news_crawler_raw_data_storage\"> | number\n    checksum?: StringNullableWithAggregatesFilter<\"political_news_crawler_raw_data_storage\"> | string | null\n    crawl_timestamp?: DateTimeWithAggregatesFilter<\"political_news_crawler_raw_data_storage\"> | Date | string\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_raw_data_storage\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_raw_data_storage\"> | Date | string\n  }\n\n  export type political_news_crawler_local_cache_filesWhereInput = {\n    AND?: political_news_crawler_local_cache_filesWhereInput | political_news_crawler_local_cache_filesWhereInput[]\n    OR?: political_news_crawler_local_cache_filesWhereInput[]\n    NOT?: political_news_crawler_local_cache_filesWhereInput | political_news_crawler_local_cache_filesWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_local_cache_files\"> | string\n    raw_data_storage_id?: UuidFilter<\"political_news_crawler_local_cache_files\"> | string\n    local_file_path?: StringFilter<\"political_news_crawler_local_cache_files\"> | string\n    file_size_bytes?: IntFilter<\"political_news_crawler_local_cache_files\"> | number\n    ttl_expiration_at?: DateTimeFilter<\"political_news_crawler_local_cache_files\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_local_cache_files\"> | Date | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_local_cache_files\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_local_cache_files\"> | Date | string\n    rawDataStorage?: XOR<Political_news_crawler_raw_data_storageScalarRelationFilter, political_news_crawler_raw_data_storageWhereInput>\n  }\n\n  export type political_news_crawler_local_cache_filesOrderByWithRelationInput = {\n    id?: SortOrder\n    raw_data_storage_id?: SortOrder\n    local_file_path?: SortOrder\n    file_size_bytes?: SortOrder\n    ttl_expiration_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    rawDataStorage?: political_news_crawler_raw_data_storageOrderByWithRelationInput\n  }\n\n  export type political_news_crawler_local_cache_filesWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    local_file_path?: string\n    AND?: political_news_crawler_local_cache_filesWhereInput | political_news_crawler_local_cache_filesWhereInput[]\n    OR?: political_news_crawler_local_cache_filesWhereInput[]\n    NOT?: political_news_crawler_local_cache_filesWhereInput | political_news_crawler_local_cache_filesWhereInput[]\n    raw_data_storage_id?: UuidFilter<\"political_news_crawler_local_cache_files\"> | string\n    file_size_bytes?: IntFilter<\"political_news_crawler_local_cache_files\"> | number\n    ttl_expiration_at?: DateTimeFilter<\"political_news_crawler_local_cache_files\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_local_cache_files\"> | Date | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_local_cache_files\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_local_cache_files\"> | Date | string\n    rawDataStorage?: XOR<Political_news_crawler_raw_data_storageScalarRelationFilter, political_news_crawler_raw_data_storageWhereInput>\n  }, \"id\" | \"local_file_path\">\n\n  export type political_news_crawler_local_cache_filesOrderByWithAggregationInput = {\n    id?: SortOrder\n    raw_data_storage_id?: SortOrder\n    local_file_path?: SortOrder\n    file_size_bytes?: SortOrder\n    ttl_expiration_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    _count?: political_news_crawler_local_cache_filesCountOrderByAggregateInput\n    _avg?: political_news_crawler_local_cache_filesAvgOrderByAggregateInput\n    _max?: political_news_crawler_local_cache_filesMaxOrderByAggregateInput\n    _min?: political_news_crawler_local_cache_filesMinOrderByAggregateInput\n    _sum?: political_news_crawler_local_cache_filesSumOrderByAggregateInput\n  }\n\n  export type political_news_crawler_local_cache_filesScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_local_cache_filesScalarWhereWithAggregatesInput | political_news_crawler_local_cache_filesScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_local_cache_filesScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_local_cache_filesScalarWhereWithAggregatesInput | political_news_crawler_local_cache_filesScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_local_cache_files\"> | string\n    raw_data_storage_id?: UuidWithAggregatesFilter<\"political_news_crawler_local_cache_files\"> | string\n    local_file_path?: StringWithAggregatesFilter<\"political_news_crawler_local_cache_files\"> | string\n    file_size_bytes?: IntWithAggregatesFilter<\"political_news_crawler_local_cache_files\"> | number\n    ttl_expiration_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_local_cache_files\"> | Date | string\n    deleted_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_local_cache_files\"> | Date | string | null\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_local_cache_files\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_local_cache_files\"> | Date | string\n  }\n\n  export type political_news_crawler_processed_contentWhereInput = {\n    AND?: political_news_crawler_processed_contentWhereInput | political_news_crawler_processed_contentWhereInput[]\n    OR?: political_news_crawler_processed_contentWhereInput[]\n    NOT?: political_news_crawler_processed_contentWhereInput | political_news_crawler_processed_contentWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_processed_content\"> | string\n    raw_data_storage_id?: UuidFilter<\"political_news_crawler_processed_content\"> | string\n    llm_job_id?: UuidNullableFilter<\"political_news_crawler_processed_content\"> | string | null\n    content_type?: StringFilter<\"political_news_crawler_processed_content\"> | string\n    content_body?: StringFilter<\"political_news_crawler_processed_content\"> | string\n    generation_timestamp?: DateTimeFilter<\"political_news_crawler_processed_content\"> | Date | string\n    created_at?: DateTimeFilter<\"political_news_crawler_processed_content\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_processed_content\"> | Date | string\n    rawDataStorage?: XOR<Political_news_crawler_raw_data_storageScalarRelationFilter, political_news_crawler_raw_data_storageWhereInput>\n    llmJob?: XOR<Political_news_crawler_llm_jobsNullableScalarRelationFilter, political_news_crawler_llm_jobsWhereInput> | null\n  }\n\n  export type political_news_crawler_processed_contentOrderByWithRelationInput = {\n    id?: SortOrder\n    raw_data_storage_id?: SortOrder\n    llm_job_id?: SortOrderInput | SortOrder\n    content_type?: SortOrder\n    content_body?: SortOrder\n    generation_timestamp?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    rawDataStorage?: political_news_crawler_raw_data_storageOrderByWithRelationInput\n    llmJob?: political_news_crawler_llm_jobsOrderByWithRelationInput\n  }\n\n  export type political_news_crawler_processed_contentWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    raw_data_storage_id_content_type?: political_news_crawler_processed_contentRaw_data_storage_idContent_typeCompoundUniqueInput\n    AND?: political_news_crawler_processed_contentWhereInput | political_news_crawler_processed_contentWhereInput[]\n    OR?: political_news_crawler_processed_contentWhereInput[]\n    NOT?: political_news_crawler_processed_contentWhereInput | political_news_crawler_processed_contentWhereInput[]\n    raw_data_storage_id?: UuidFilter<\"political_news_crawler_processed_content\"> | string\n    llm_job_id?: UuidNullableFilter<\"political_news_crawler_processed_content\"> | string | null\n    content_type?: StringFilter<\"political_news_crawler_processed_content\"> | string\n    content_body?: StringFilter<\"political_news_crawler_processed_content\"> | string\n    generation_timestamp?: DateTimeFilter<\"political_news_crawler_processed_content\"> | Date | string\n    created_at?: DateTimeFilter<\"political_news_crawler_processed_content\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_processed_content\"> | Date | string\n    rawDataStorage?: XOR<Political_news_crawler_raw_data_storageScalarRelationFilter, political_news_crawler_raw_data_storageWhereInput>\n    llmJob?: XOR<Political_news_crawler_llm_jobsNullableScalarRelationFilter, political_news_crawler_llm_jobsWhereInput> | null\n  }, \"id\" | \"raw_data_storage_id_content_type\">\n\n  export type political_news_crawler_processed_contentOrderByWithAggregationInput = {\n    id?: SortOrder\n    raw_data_storage_id?: SortOrder\n    llm_job_id?: SortOrderInput | SortOrder\n    content_type?: SortOrder\n    content_body?: SortOrder\n    generation_timestamp?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    _count?: political_news_crawler_processed_contentCountOrderByAggregateInput\n    _max?: political_news_crawler_processed_contentMaxOrderByAggregateInput\n    _min?: political_news_crawler_processed_contentMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_processed_contentScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_processed_contentScalarWhereWithAggregatesInput | political_news_crawler_processed_contentScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_processed_contentScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_processed_contentScalarWhereWithAggregatesInput | political_news_crawler_processed_contentScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_processed_content\"> | string\n    raw_data_storage_id?: UuidWithAggregatesFilter<\"political_news_crawler_processed_content\"> | string\n    llm_job_id?: UuidNullableWithAggregatesFilter<\"political_news_crawler_processed_content\"> | string | null\n    content_type?: StringWithAggregatesFilter<\"political_news_crawler_processed_content\"> | string\n    content_body?: StringWithAggregatesFilter<\"political_news_crawler_processed_content\"> | string\n    generation_timestamp?: DateTimeWithAggregatesFilter<\"political_news_crawler_processed_content\"> | Date | string\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_processed_content\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_processed_content\"> | Date | string\n  }\n\n  export type political_news_crawler_llm_jobsWhereInput = {\n    AND?: political_news_crawler_llm_jobsWhereInput | political_news_crawler_llm_jobsWhereInput[]\n    OR?: political_news_crawler_llm_jobsWhereInput[]\n    NOT?: political_news_crawler_llm_jobsWhereInput | political_news_crawler_llm_jobsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_llm_jobs\"> | string\n    crawl_source_id?: UuidFilter<\"political_news_crawler_llm_jobs\"> | string\n    status?: StringFilter<\"political_news_crawler_llm_jobs\"> | string\n    parameters?: StringFilter<\"political_news_crawler_llm_jobs\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_llm_jobs\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_llm_jobs\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_llm_jobs\"> | Date | string | null\n    crawlSource?: XOR<Political_news_crawler_crawl_sourcesScalarRelationFilter, political_news_crawler_crawl_sourcesWhereInput>\n    political_news_crawler_processed_content?: Political_news_crawler_processed_contentListRelationFilter\n    political_news_crawler_llm_results?: Political_news_crawler_llm_resultsListRelationFilter\n    political_news_crawler_processing_metadata?: Political_news_crawler_processing_metadataListRelationFilter\n  }\n\n  export type political_news_crawler_llm_jobsOrderByWithRelationInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    status?: SortOrder\n    parameters?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    crawlSource?: political_news_crawler_crawl_sourcesOrderByWithRelationInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentOrderByRelationAggregateInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsOrderByRelationAggregateInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataOrderByRelationAggregateInput\n  }\n\n  export type political_news_crawler_llm_jobsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    AND?: political_news_crawler_llm_jobsWhereInput | political_news_crawler_llm_jobsWhereInput[]\n    OR?: political_news_crawler_llm_jobsWhereInput[]\n    NOT?: political_news_crawler_llm_jobsWhereInput | political_news_crawler_llm_jobsWhereInput[]\n    crawl_source_id?: UuidFilter<\"political_news_crawler_llm_jobs\"> | string\n    status?: StringFilter<\"political_news_crawler_llm_jobs\"> | string\n    parameters?: StringFilter<\"political_news_crawler_llm_jobs\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_llm_jobs\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_llm_jobs\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_llm_jobs\"> | Date | string | null\n    crawlSource?: XOR<Political_news_crawler_crawl_sourcesScalarRelationFilter, political_news_crawler_crawl_sourcesWhereInput>\n    political_news_crawler_processed_content?: Political_news_crawler_processed_contentListRelationFilter\n    political_news_crawler_llm_results?: Political_news_crawler_llm_resultsListRelationFilter\n    political_news_crawler_processing_metadata?: Political_news_crawler_processing_metadataListRelationFilter\n  }, \"id\">\n\n  export type political_news_crawler_llm_jobsOrderByWithAggregationInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    status?: SortOrder\n    parameters?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    _count?: political_news_crawler_llm_jobsCountOrderByAggregateInput\n    _max?: political_news_crawler_llm_jobsMaxOrderByAggregateInput\n    _min?: political_news_crawler_llm_jobsMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_llm_jobsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_llm_jobsScalarWhereWithAggregatesInput | political_news_crawler_llm_jobsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_llm_jobsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_llm_jobsScalarWhereWithAggregatesInput | political_news_crawler_llm_jobsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_llm_jobs\"> | string\n    crawl_source_id?: UuidWithAggregatesFilter<\"political_news_crawler_llm_jobs\"> | string\n    status?: StringWithAggregatesFilter<\"political_news_crawler_llm_jobs\"> | string\n    parameters?: StringWithAggregatesFilter<\"political_news_crawler_llm_jobs\"> | string\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_llm_jobs\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_llm_jobs\"> | Date | string\n    deleted_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_llm_jobs\"> | Date | string | null\n  }\n\n  export type political_news_crawler_llm_resultsWhereInput = {\n    AND?: political_news_crawler_llm_resultsWhereInput | political_news_crawler_llm_resultsWhereInput[]\n    OR?: political_news_crawler_llm_resultsWhereInput[]\n    NOT?: political_news_crawler_llm_resultsWhereInput | political_news_crawler_llm_resultsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_llm_results\"> | string\n    llm_job_id?: UuidFilter<\"political_news_crawler_llm_results\"> | string\n    content_type?: StringFilter<\"political_news_crawler_llm_results\"> | string\n    content_text?: StringFilter<\"political_news_crawler_llm_results\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_llm_results\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_llm_results\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_llm_results\"> | Date | string | null\n    llmJob?: XOR<Political_news_crawler_llm_jobsScalarRelationFilter, political_news_crawler_llm_jobsWhereInput>\n  }\n\n  export type political_news_crawler_llm_resultsOrderByWithRelationInput = {\n    id?: SortOrder\n    llm_job_id?: SortOrder\n    content_type?: SortOrder\n    content_text?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    llmJob?: political_news_crawler_llm_jobsOrderByWithRelationInput\n  }\n\n  export type political_news_crawler_llm_resultsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    AND?: political_news_crawler_llm_resultsWhereInput | political_news_crawler_llm_resultsWhereInput[]\n    OR?: political_news_crawler_llm_resultsWhereInput[]\n    NOT?: political_news_crawler_llm_resultsWhereInput | political_news_crawler_llm_resultsWhereInput[]\n    llm_job_id?: UuidFilter<\"political_news_crawler_llm_results\"> | string\n    content_type?: StringFilter<\"political_news_crawler_llm_results\"> | string\n    content_text?: StringFilter<\"political_news_crawler_llm_results\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_llm_results\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_llm_results\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_llm_results\"> | Date | string | null\n    llmJob?: XOR<Political_news_crawler_llm_jobsScalarRelationFilter, political_news_crawler_llm_jobsWhereInput>\n  }, \"id\">\n\n  export type political_news_crawler_llm_resultsOrderByWithAggregationInput = {\n    id?: SortOrder\n    llm_job_id?: SortOrder\n    content_type?: SortOrder\n    content_text?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    _count?: political_news_crawler_llm_resultsCountOrderByAggregateInput\n    _max?: political_news_crawler_llm_resultsMaxOrderByAggregateInput\n    _min?: political_news_crawler_llm_resultsMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_llm_resultsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_llm_resultsScalarWhereWithAggregatesInput | political_news_crawler_llm_resultsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_llm_resultsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_llm_resultsScalarWhereWithAggregatesInput | political_news_crawler_llm_resultsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_llm_results\"> | string\n    llm_job_id?: UuidWithAggregatesFilter<\"political_news_crawler_llm_results\"> | string\n    content_type?: StringWithAggregatesFilter<\"political_news_crawler_llm_results\"> | string\n    content_text?: StringWithAggregatesFilter<\"political_news_crawler_llm_results\"> | string\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_llm_results\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_llm_results\"> | Date | string\n    deleted_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_llm_results\"> | Date | string | null\n  }\n\n  export type political_news_crawler_processing_metadataWhereInput = {\n    AND?: political_news_crawler_processing_metadataWhereInput | political_news_crawler_processing_metadataWhereInput[]\n    OR?: political_news_crawler_processing_metadataWhereInput[]\n    NOT?: political_news_crawler_processing_metadataWhereInput | political_news_crawler_processing_metadataWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_processing_metadata\"> | string\n    llm_job_id?: UuidFilter<\"political_news_crawler_processing_metadata\"> | string\n    metadata_key?: StringFilter<\"political_news_crawler_processing_metadata\"> | string\n    metadata_value?: StringFilter<\"political_news_crawler_processing_metadata\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_processing_metadata\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_processing_metadata\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_processing_metadata\"> | Date | string | null\n    llmJob?: XOR<Political_news_crawler_llm_jobsScalarRelationFilter, political_news_crawler_llm_jobsWhereInput>\n  }\n\n  export type political_news_crawler_processing_metadataOrderByWithRelationInput = {\n    id?: SortOrder\n    llm_job_id?: SortOrder\n    metadata_key?: SortOrder\n    metadata_value?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    llmJob?: political_news_crawler_llm_jobsOrderByWithRelationInput\n  }\n\n  export type political_news_crawler_processing_metadataWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    AND?: political_news_crawler_processing_metadataWhereInput | political_news_crawler_processing_metadataWhereInput[]\n    OR?: political_news_crawler_processing_metadataWhereInput[]\n    NOT?: political_news_crawler_processing_metadataWhereInput | political_news_crawler_processing_metadataWhereInput[]\n    llm_job_id?: UuidFilter<\"political_news_crawler_processing_metadata\"> | string\n    metadata_key?: StringFilter<\"political_news_crawler_processing_metadata\"> | string\n    metadata_value?: StringFilter<\"political_news_crawler_processing_metadata\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_processing_metadata\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_processing_metadata\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_processing_metadata\"> | Date | string | null\n    llmJob?: XOR<Political_news_crawler_llm_jobsScalarRelationFilter, political_news_crawler_llm_jobsWhereInput>\n  }, \"id\">\n\n  export type political_news_crawler_processing_metadataOrderByWithAggregationInput = {\n    id?: SortOrder\n    llm_job_id?: SortOrder\n    metadata_key?: SortOrder\n    metadata_value?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    _count?: political_news_crawler_processing_metadataCountOrderByAggregateInput\n    _max?: political_news_crawler_processing_metadataMaxOrderByAggregateInput\n    _min?: political_news_crawler_processing_metadataMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_processing_metadataScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_processing_metadataScalarWhereWithAggregatesInput | political_news_crawler_processing_metadataScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_processing_metadataScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_processing_metadataScalarWhereWithAggregatesInput | political_news_crawler_processing_metadataScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_processing_metadata\"> | string\n    llm_job_id?: UuidWithAggregatesFilter<\"political_news_crawler_processing_metadata\"> | string\n    metadata_key?: StringWithAggregatesFilter<\"political_news_crawler_processing_metadata\"> | string\n    metadata_value?: StringWithAggregatesFilter<\"political_news_crawler_processing_metadata\"> | string\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_processing_metadata\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_processing_metadata\"> | Date | string\n    deleted_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_processing_metadata\"> | Date | string | null\n  }\n\n  export type political_news_crawler_popularity_scoresWhereInput = {\n    AND?: political_news_crawler_popularity_scoresWhereInput | political_news_crawler_popularity_scoresWhereInput[]\n    OR?: political_news_crawler_popularity_scoresWhereInput[]\n    NOT?: political_news_crawler_popularity_scoresWhereInput | political_news_crawler_popularity_scoresWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_popularity_scores\"> | string\n    political_news_crawler_popular_topic_id?: UuidFilter<\"political_news_crawler_popularity_scores\"> | string\n    score?: FloatFilter<\"political_news_crawler_popularity_scores\"> | number\n    decay_factor?: FloatFilter<\"political_news_crawler_popularity_scores\"> | number\n    snapshot_at?: DateTimeFilter<\"political_news_crawler_popularity_scores\"> | Date | string\n    created_at?: DateTimeFilter<\"political_news_crawler_popularity_scores\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_popularity_scores\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_popularity_scores\"> | Date | string | null\n    popularTopic?: XOR<Political_news_crawler_popular_topicsScalarRelationFilter, political_news_crawler_popular_topicsWhereInput>\n  }\n\n  export type political_news_crawler_popularity_scoresOrderByWithRelationInput = {\n    id?: SortOrder\n    political_news_crawler_popular_topic_id?: SortOrder\n    score?: SortOrder\n    decay_factor?: SortOrder\n    snapshot_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    popularTopic?: political_news_crawler_popular_topicsOrderByWithRelationInput\n  }\n\n  export type political_news_crawler_popularity_scoresWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    AND?: political_news_crawler_popularity_scoresWhereInput | political_news_crawler_popularity_scoresWhereInput[]\n    OR?: political_news_crawler_popularity_scoresWhereInput[]\n    NOT?: political_news_crawler_popularity_scoresWhereInput | political_news_crawler_popularity_scoresWhereInput[]\n    political_news_crawler_popular_topic_id?: UuidFilter<\"political_news_crawler_popularity_scores\"> | string\n    score?: FloatFilter<\"political_news_crawler_popularity_scores\"> | number\n    decay_factor?: FloatFilter<\"political_news_crawler_popularity_scores\"> | number\n    snapshot_at?: DateTimeFilter<\"political_news_crawler_popularity_scores\"> | Date | string\n    created_at?: DateTimeFilter<\"political_news_crawler_popularity_scores\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_popularity_scores\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_popularity_scores\"> | Date | string | null\n    popularTopic?: XOR<Political_news_crawler_popular_topicsScalarRelationFilter, political_news_crawler_popular_topicsWhereInput>\n  }, \"id\">\n\n  export type political_news_crawler_popularity_scoresOrderByWithAggregationInput = {\n    id?: SortOrder\n    political_news_crawler_popular_topic_id?: SortOrder\n    score?: SortOrder\n    decay_factor?: SortOrder\n    snapshot_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    _count?: political_news_crawler_popularity_scoresCountOrderByAggregateInput\n    _avg?: political_news_crawler_popularity_scoresAvgOrderByAggregateInput\n    _max?: political_news_crawler_popularity_scoresMaxOrderByAggregateInput\n    _min?: political_news_crawler_popularity_scoresMinOrderByAggregateInput\n    _sum?: political_news_crawler_popularity_scoresSumOrderByAggregateInput\n  }\n\n  export type political_news_crawler_popularity_scoresScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_popularity_scoresScalarWhereWithAggregatesInput | political_news_crawler_popularity_scoresScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_popularity_scoresScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_popularity_scoresScalarWhereWithAggregatesInput | political_news_crawler_popularity_scoresScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_popularity_scores\"> | string\n    political_news_crawler_popular_topic_id?: UuidWithAggregatesFilter<\"political_news_crawler_popularity_scores\"> | string\n    score?: FloatWithAggregatesFilter<\"political_news_crawler_popularity_scores\"> | number\n    decay_factor?: FloatWithAggregatesFilter<\"political_news_crawler_popularity_scores\"> | number\n    snapshot_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_popularity_scores\"> | Date | string\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_popularity_scores\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_popularity_scores\"> | Date | string\n    deleted_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_popularity_scores\"> | Date | string | null\n  }\n\n  export type political_news_crawler_popular_topicsWhereInput = {\n    AND?: political_news_crawler_popular_topicsWhereInput | political_news_crawler_popular_topicsWhereInput[]\n    OR?: political_news_crawler_popular_topicsWhereInput[]\n    NOT?: political_news_crawler_popular_topicsWhereInput | political_news_crawler_popular_topicsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_popular_topics\"> | string\n    topic_code?: StringFilter<\"political_news_crawler_popular_topics\"> | string\n    title?: StringFilter<\"political_news_crawler_popular_topics\"> | string\n    description?: StringNullableFilter<\"political_news_crawler_popular_topics\"> | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_popular_topics\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_popular_topics\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_popular_topics\"> | Date | string | null\n    political_news_crawler_popularity_scores?: Political_news_crawler_popularity_scoresListRelationFilter\n    political_news_crawler_topic_mentions?: Political_news_crawler_topic_mentionsListRelationFilter\n  }\n\n  export type political_news_crawler_popular_topicsOrderByWithRelationInput = {\n    id?: SortOrder\n    topic_code?: SortOrder\n    title?: SortOrder\n    description?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    political_news_crawler_popularity_scores?: political_news_crawler_popularity_scoresOrderByRelationAggregateInput\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsOrderByRelationAggregateInput\n  }\n\n  export type political_news_crawler_popular_topicsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    topic_code?: string\n    AND?: political_news_crawler_popular_topicsWhereInput | political_news_crawler_popular_topicsWhereInput[]\n    OR?: political_news_crawler_popular_topicsWhereInput[]\n    NOT?: political_news_crawler_popular_topicsWhereInput | political_news_crawler_popular_topicsWhereInput[]\n    title?: StringFilter<\"political_news_crawler_popular_topics\"> | string\n    description?: StringNullableFilter<\"political_news_crawler_popular_topics\"> | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_popular_topics\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_popular_topics\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_popular_topics\"> | Date | string | null\n    political_news_crawler_popularity_scores?: Political_news_crawler_popularity_scoresListRelationFilter\n    political_news_crawler_topic_mentions?: Political_news_crawler_topic_mentionsListRelationFilter\n  }, \"id\" | \"topic_code\">\n\n  export type political_news_crawler_popular_topicsOrderByWithAggregationInput = {\n    id?: SortOrder\n    topic_code?: SortOrder\n    title?: SortOrder\n    description?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    _count?: political_news_crawler_popular_topicsCountOrderByAggregateInput\n    _max?: political_news_crawler_popular_topicsMaxOrderByAggregateInput\n    _min?: political_news_crawler_popular_topicsMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_popular_topicsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_popular_topicsScalarWhereWithAggregatesInput | political_news_crawler_popular_topicsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_popular_topicsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_popular_topicsScalarWhereWithAggregatesInput | political_news_crawler_popular_topicsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_popular_topics\"> | string\n    topic_code?: StringWithAggregatesFilter<\"political_news_crawler_popular_topics\"> | string\n    title?: StringWithAggregatesFilter<\"political_news_crawler_popular_topics\"> | string\n    description?: StringNullableWithAggregatesFilter<\"political_news_crawler_popular_topics\"> | string | null\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_popular_topics\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_popular_topics\"> | Date | string\n    deleted_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_popular_topics\"> | Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsWhereInput = {\n    AND?: political_news_crawler_topic_mentionsWhereInput | political_news_crawler_topic_mentionsWhereInput[]\n    OR?: political_news_crawler_topic_mentionsWhereInput[]\n    NOT?: political_news_crawler_topic_mentionsWhereInput | political_news_crawler_topic_mentionsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_topic_mentions\"> | string\n    political_news_crawler_popular_topic_id?: UuidFilter<\"political_news_crawler_topic_mentions\"> | string\n    political_news_crawler_crawled_news_id?: UuidFilter<\"political_news_crawler_topic_mentions\"> | string\n    mention_context?: StringNullableFilter<\"political_news_crawler_topic_mentions\"> | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_topic_mentions\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_topic_mentions\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_topic_mentions\"> | Date | string | null\n    popularTopic?: XOR<Political_news_crawler_popular_topicsScalarRelationFilter, political_news_crawler_popular_topicsWhereInput>\n    crawledNews?: XOR<Political_news_crawler_crawled_newsScalarRelationFilter, political_news_crawler_crawled_newsWhereInput>\n  }\n\n  export type political_news_crawler_topic_mentionsOrderByWithRelationInput = {\n    id?: SortOrder\n    political_news_crawler_popular_topic_id?: SortOrder\n    political_news_crawler_crawled_news_id?: SortOrder\n    mention_context?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    popularTopic?: political_news_crawler_popular_topicsOrderByWithRelationInput\n    crawledNews?: political_news_crawler_crawled_newsOrderByWithRelationInput\n  }\n\n  export type political_news_crawler_topic_mentionsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    AND?: political_news_crawler_topic_mentionsWhereInput | political_news_crawler_topic_mentionsWhereInput[]\n    OR?: political_news_crawler_topic_mentionsWhereInput[]\n    NOT?: political_news_crawler_topic_mentionsWhereInput | political_news_crawler_topic_mentionsWhereInput[]\n    political_news_crawler_popular_topic_id?: UuidFilter<\"political_news_crawler_topic_mentions\"> | string\n    political_news_crawler_crawled_news_id?: UuidFilter<\"political_news_crawler_topic_mentions\"> | string\n    mention_context?: StringNullableFilter<\"political_news_crawler_topic_mentions\"> | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_topic_mentions\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_topic_mentions\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_topic_mentions\"> | Date | string | null\n    popularTopic?: XOR<Political_news_crawler_popular_topicsScalarRelationFilter, political_news_crawler_popular_topicsWhereInput>\n    crawledNews?: XOR<Political_news_crawler_crawled_newsScalarRelationFilter, political_news_crawler_crawled_newsWhereInput>\n  }, \"id\">\n\n  export type political_news_crawler_topic_mentionsOrderByWithAggregationInput = {\n    id?: SortOrder\n    political_news_crawler_popular_topic_id?: SortOrder\n    political_news_crawler_crawled_news_id?: SortOrder\n    mention_context?: SortOrderInput | SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrderInput | SortOrder\n    _count?: political_news_crawler_topic_mentionsCountOrderByAggregateInput\n    _max?: political_news_crawler_topic_mentionsMaxOrderByAggregateInput\n    _min?: political_news_crawler_topic_mentionsMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_topic_mentionsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_topic_mentionsScalarWhereWithAggregatesInput | political_news_crawler_topic_mentionsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_topic_mentionsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_topic_mentionsScalarWhereWithAggregatesInput | political_news_crawler_topic_mentionsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_topic_mentions\"> | string\n    political_news_crawler_popular_topic_id?: UuidWithAggregatesFilter<\"political_news_crawler_topic_mentions\"> | string\n    political_news_crawler_crawled_news_id?: UuidWithAggregatesFilter<\"political_news_crawler_topic_mentions\"> | string\n    mention_context?: StringNullableWithAggregatesFilter<\"political_news_crawler_topic_mentions\"> | string | null\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_topic_mentions\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_topic_mentions\"> | Date | string\n    deleted_at?: DateTimeNullableWithAggregatesFilter<\"political_news_crawler_topic_mentions\"> | Date | string | null\n  }\n\n  export type political_news_crawler_api_access_logsWhereInput = {\n    AND?: political_news_crawler_api_access_logsWhereInput | political_news_crawler_api_access_logsWhereInput[]\n    OR?: political_news_crawler_api_access_logsWhereInput[]\n    NOT?: political_news_crawler_api_access_logsWhereInput | political_news_crawler_api_access_logsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_api_access_logs\"> | string\n    http_method?: StringFilter<\"political_news_crawler_api_access_logs\"> | string\n    path?: StringFilter<\"political_news_crawler_api_access_logs\"> | string\n    status_code?: IntFilter<\"political_news_crawler_api_access_logs\"> | number\n    client_ip?: StringFilter<\"political_news_crawler_api_access_logs\"> | string\n    user_agent?: StringFilter<\"political_news_crawler_api_access_logs\"> | string\n    duration_ms?: IntFilter<\"political_news_crawler_api_access_logs\"> | number\n    created_at?: DateTimeFilter<\"political_news_crawler_api_access_logs\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_api_access_logs\"> | Date | string\n  }\n\n  export type political_news_crawler_api_access_logsOrderByWithRelationInput = {\n    id?: SortOrder\n    http_method?: SortOrder\n    path?: SortOrder\n    status_code?: SortOrder\n    client_ip?: SortOrder\n    user_agent?: SortOrder\n    duration_ms?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_access_logsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    AND?: political_news_crawler_api_access_logsWhereInput | political_news_crawler_api_access_logsWhereInput[]\n    OR?: political_news_crawler_api_access_logsWhereInput[]\n    NOT?: political_news_crawler_api_access_logsWhereInput | political_news_crawler_api_access_logsWhereInput[]\n    http_method?: StringFilter<\"political_news_crawler_api_access_logs\"> | string\n    path?: StringFilter<\"political_news_crawler_api_access_logs\"> | string\n    status_code?: IntFilter<\"political_news_crawler_api_access_logs\"> | number\n    client_ip?: StringFilter<\"political_news_crawler_api_access_logs\"> | string\n    user_agent?: StringFilter<\"political_news_crawler_api_access_logs\"> | string\n    duration_ms?: IntFilter<\"political_news_crawler_api_access_logs\"> | number\n    created_at?: DateTimeFilter<\"political_news_crawler_api_access_logs\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_api_access_logs\"> | Date | string\n  }, \"id\">\n\n  export type political_news_crawler_api_access_logsOrderByWithAggregationInput = {\n    id?: SortOrder\n    http_method?: SortOrder\n    path?: SortOrder\n    status_code?: SortOrder\n    client_ip?: SortOrder\n    user_agent?: SortOrder\n    duration_ms?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    _count?: political_news_crawler_api_access_logsCountOrderByAggregateInput\n    _avg?: political_news_crawler_api_access_logsAvgOrderByAggregateInput\n    _max?: political_news_crawler_api_access_logsMaxOrderByAggregateInput\n    _min?: political_news_crawler_api_access_logsMinOrderByAggregateInput\n    _sum?: political_news_crawler_api_access_logsSumOrderByAggregateInput\n  }\n\n  export type political_news_crawler_api_access_logsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_api_access_logsScalarWhereWithAggregatesInput | political_news_crawler_api_access_logsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_api_access_logsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_api_access_logsScalarWhereWithAggregatesInput | political_news_crawler_api_access_logsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_api_access_logs\"> | string\n    http_method?: StringWithAggregatesFilter<\"political_news_crawler_api_access_logs\"> | string\n    path?: StringWithAggregatesFilter<\"political_news_crawler_api_access_logs\"> | string\n    status_code?: IntWithAggregatesFilter<\"political_news_crawler_api_access_logs\"> | number\n    client_ip?: StringWithAggregatesFilter<\"political_news_crawler_api_access_logs\"> | string\n    user_agent?: StringWithAggregatesFilter<\"political_news_crawler_api_access_logs\"> | string\n    duration_ms?: IntWithAggregatesFilter<\"political_news_crawler_api_access_logs\"> | number\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_api_access_logs\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_api_access_logs\"> | Date | string\n  }\n\n  export type political_news_crawler_api_error_logsWhereInput = {\n    AND?: political_news_crawler_api_error_logsWhereInput | political_news_crawler_api_error_logsWhereInput[]\n    OR?: political_news_crawler_api_error_logsWhereInput[]\n    NOT?: political_news_crawler_api_error_logsWhereInput | political_news_crawler_api_error_logsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_api_error_logs\"> | string\n    path?: StringFilter<\"political_news_crawler_api_error_logs\"> | string\n    error_code?: StringFilter<\"political_news_crawler_api_error_logs\"> | string\n    error_message?: StringFilter<\"political_news_crawler_api_error_logs\"> | string\n    client_ip?: StringFilter<\"political_news_crawler_api_error_logs\"> | string\n    user_agent?: StringFilter<\"political_news_crawler_api_error_logs\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_api_error_logs\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_api_error_logs\"> | Date | string\n  }\n\n  export type political_news_crawler_api_error_logsOrderByWithRelationInput = {\n    id?: SortOrder\n    path?: SortOrder\n    error_code?: SortOrder\n    error_message?: SortOrder\n    client_ip?: SortOrder\n    user_agent?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_error_logsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    AND?: political_news_crawler_api_error_logsWhereInput | political_news_crawler_api_error_logsWhereInput[]\n    OR?: political_news_crawler_api_error_logsWhereInput[]\n    NOT?: political_news_crawler_api_error_logsWhereInput | political_news_crawler_api_error_logsWhereInput[]\n    path?: StringFilter<\"political_news_crawler_api_error_logs\"> | string\n    error_code?: StringFilter<\"political_news_crawler_api_error_logs\"> | string\n    error_message?: StringFilter<\"political_news_crawler_api_error_logs\"> | string\n    client_ip?: StringFilter<\"political_news_crawler_api_error_logs\"> | string\n    user_agent?: StringFilter<\"political_news_crawler_api_error_logs\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_api_error_logs\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_api_error_logs\"> | Date | string\n  }, \"id\">\n\n  export type political_news_crawler_api_error_logsOrderByWithAggregationInput = {\n    id?: SortOrder\n    path?: SortOrder\n    error_code?: SortOrder\n    error_message?: SortOrder\n    client_ip?: SortOrder\n    user_agent?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    _count?: political_news_crawler_api_error_logsCountOrderByAggregateInput\n    _max?: political_news_crawler_api_error_logsMaxOrderByAggregateInput\n    _min?: political_news_crawler_api_error_logsMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_api_error_logsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_api_error_logsScalarWhereWithAggregatesInput | political_news_crawler_api_error_logsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_api_error_logsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_api_error_logsScalarWhereWithAggregatesInput | political_news_crawler_api_error_logsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_api_error_logs\"> | string\n    path?: StringWithAggregatesFilter<\"political_news_crawler_api_error_logs\"> | string\n    error_code?: StringWithAggregatesFilter<\"political_news_crawler_api_error_logs\"> | string\n    error_message?: StringWithAggregatesFilter<\"political_news_crawler_api_error_logs\"> | string\n    client_ip?: StringWithAggregatesFilter<\"political_news_crawler_api_error_logs\"> | string\n    user_agent?: StringWithAggregatesFilter<\"political_news_crawler_api_error_logs\"> | string\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_api_error_logs\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_api_error_logs\"> | Date | string\n  }\n\n  export type political_news_crawler_api_usage_metricsWhereInput = {\n    AND?: political_news_crawler_api_usage_metricsWhereInput | political_news_crawler_api_usage_metricsWhereInput[]\n    OR?: political_news_crawler_api_usage_metricsWhereInput[]\n    NOT?: political_news_crawler_api_usage_metricsWhereInput | political_news_crawler_api_usage_metricsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_api_usage_metrics\"> | string\n    http_method?: StringFilter<\"political_news_crawler_api_usage_metrics\"> | string\n    path?: StringFilter<\"political_news_crawler_api_usage_metrics\"> | string\n    period_start?: DateTimeFilter<\"political_news_crawler_api_usage_metrics\"> | Date | string\n    period_end?: DateTimeFilter<\"political_news_crawler_api_usage_metrics\"> | Date | string\n    total_calls?: IntFilter<\"political_news_crawler_api_usage_metrics\"> | number\n    max_response_ms?: IntFilter<\"political_news_crawler_api_usage_metrics\"> | number\n    avg_response_ms?: IntFilter<\"political_news_crawler_api_usage_metrics\"> | number\n    created_at?: DateTimeFilter<\"political_news_crawler_api_usage_metrics\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_api_usage_metrics\"> | Date | string\n  }\n\n  export type political_news_crawler_api_usage_metricsOrderByWithRelationInput = {\n    id?: SortOrder\n    http_method?: SortOrder\n    path?: SortOrder\n    period_start?: SortOrder\n    period_end?: SortOrder\n    total_calls?: SortOrder\n    max_response_ms?: SortOrder\n    avg_response_ms?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_usage_metricsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    http_method_path_period_start?: political_news_crawler_api_usage_metricsHttp_methodPathPeriod_startCompoundUniqueInput\n    AND?: political_news_crawler_api_usage_metricsWhereInput | political_news_crawler_api_usage_metricsWhereInput[]\n    OR?: political_news_crawler_api_usage_metricsWhereInput[]\n    NOT?: political_news_crawler_api_usage_metricsWhereInput | political_news_crawler_api_usage_metricsWhereInput[]\n    http_method?: StringFilter<\"political_news_crawler_api_usage_metrics\"> | string\n    path?: StringFilter<\"political_news_crawler_api_usage_metrics\"> | string\n    period_start?: DateTimeFilter<\"political_news_crawler_api_usage_metrics\"> | Date | string\n    period_end?: DateTimeFilter<\"political_news_crawler_api_usage_metrics\"> | Date | string\n    total_calls?: IntFilter<\"political_news_crawler_api_usage_metrics\"> | number\n    max_response_ms?: IntFilter<\"political_news_crawler_api_usage_metrics\"> | number\n    avg_response_ms?: IntFilter<\"political_news_crawler_api_usage_metrics\"> | number\n    created_at?: DateTimeFilter<\"political_news_crawler_api_usage_metrics\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_api_usage_metrics\"> | Date | string\n  }, \"id\" | \"http_method_path_period_start\">\n\n  export type political_news_crawler_api_usage_metricsOrderByWithAggregationInput = {\n    id?: SortOrder\n    http_method?: SortOrder\n    path?: SortOrder\n    period_start?: SortOrder\n    period_end?: SortOrder\n    total_calls?: SortOrder\n    max_response_ms?: SortOrder\n    avg_response_ms?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    _count?: political_news_crawler_api_usage_metricsCountOrderByAggregateInput\n    _avg?: political_news_crawler_api_usage_metricsAvgOrderByAggregateInput\n    _max?: political_news_crawler_api_usage_metricsMaxOrderByAggregateInput\n    _min?: political_news_crawler_api_usage_metricsMinOrderByAggregateInput\n    _sum?: political_news_crawler_api_usage_metricsSumOrderByAggregateInput\n  }\n\n  export type political_news_crawler_api_usage_metricsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_api_usage_metricsScalarWhereWithAggregatesInput | political_news_crawler_api_usage_metricsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_api_usage_metricsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_api_usage_metricsScalarWhereWithAggregatesInput | political_news_crawler_api_usage_metricsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_api_usage_metrics\"> | string\n    http_method?: StringWithAggregatesFilter<\"political_news_crawler_api_usage_metrics\"> | string\n    path?: StringWithAggregatesFilter<\"political_news_crawler_api_usage_metrics\"> | string\n    period_start?: DateTimeWithAggregatesFilter<\"political_news_crawler_api_usage_metrics\"> | Date | string\n    period_end?: DateTimeWithAggregatesFilter<\"political_news_crawler_api_usage_metrics\"> | Date | string\n    total_calls?: IntWithAggregatesFilter<\"political_news_crawler_api_usage_metrics\"> | number\n    max_response_ms?: IntWithAggregatesFilter<\"political_news_crawler_api_usage_metrics\"> | number\n    avg_response_ms?: IntWithAggregatesFilter<\"political_news_crawler_api_usage_metrics\"> | number\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_api_usage_metrics\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_api_usage_metrics\"> | Date | string\n  }\n\n  export type political_news_crawler_crawl_alertsWhereInput = {\n    AND?: political_news_crawler_crawl_alertsWhereInput | political_news_crawler_crawl_alertsWhereInput[]\n    OR?: political_news_crawler_crawl_alertsWhereInput[]\n    NOT?: political_news_crawler_crawl_alertsWhereInput | political_news_crawler_crawl_alertsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_crawl_alerts\"> | string\n    crawl_source_id?: UuidFilter<\"political_news_crawler_crawl_alerts\"> | string\n    alert_type?: StringFilter<\"political_news_crawler_crawl_alerts\"> | string\n    message?: StringFilter<\"political_news_crawler_crawl_alerts\"> | string\n    severity?: StringFilter<\"political_news_crawler_crawl_alerts\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_alerts\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_alerts\"> | Date | string\n    crawlSource?: XOR<Political_news_crawler_crawl_sourcesScalarRelationFilter, political_news_crawler_crawl_sourcesWhereInput>\n  }\n\n  export type political_news_crawler_crawl_alertsOrderByWithRelationInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    crawlSource?: political_news_crawler_crawl_sourcesOrderByWithRelationInput\n  }\n\n  export type political_news_crawler_crawl_alertsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    crawl_source_id_alert_type_created_at?: political_news_crawler_crawl_alertsCrawl_source_idAlert_typeCreated_atCompoundUniqueInput\n    AND?: political_news_crawler_crawl_alertsWhereInput | political_news_crawler_crawl_alertsWhereInput[]\n    OR?: political_news_crawler_crawl_alertsWhereInput[]\n    NOT?: political_news_crawler_crawl_alertsWhereInput | political_news_crawler_crawl_alertsWhereInput[]\n    crawl_source_id?: UuidFilter<\"political_news_crawler_crawl_alerts\"> | string\n    alert_type?: StringFilter<\"political_news_crawler_crawl_alerts\"> | string\n    message?: StringFilter<\"political_news_crawler_crawl_alerts\"> | string\n    severity?: StringFilter<\"political_news_crawler_crawl_alerts\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_alerts\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_alerts\"> | Date | string\n    crawlSource?: XOR<Political_news_crawler_crawl_sourcesScalarRelationFilter, political_news_crawler_crawl_sourcesWhereInput>\n  }, \"id\" | \"crawl_source_id_alert_type_created_at\">\n\n  export type political_news_crawler_crawl_alertsOrderByWithAggregationInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    _count?: political_news_crawler_crawl_alertsCountOrderByAggregateInput\n    _max?: political_news_crawler_crawl_alertsMaxOrderByAggregateInput\n    _min?: political_news_crawler_crawl_alertsMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_crawl_alertsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_crawl_alertsScalarWhereWithAggregatesInput | political_news_crawler_crawl_alertsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_crawl_alertsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_crawl_alertsScalarWhereWithAggregatesInput | political_news_crawler_crawl_alertsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_crawl_alerts\"> | string\n    crawl_source_id?: UuidWithAggregatesFilter<\"political_news_crawler_crawl_alerts\"> | string\n    alert_type?: StringWithAggregatesFilter<\"political_news_crawler_crawl_alerts\"> | string\n    message?: StringWithAggregatesFilter<\"political_news_crawler_crawl_alerts\"> | string\n    severity?: StringWithAggregatesFilter<\"political_news_crawler_crawl_alerts\"> | string\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawl_alerts\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_crawl_alerts\"> | Date | string\n  }\n\n  export type political_news_crawler_processing_alertsWhereInput = {\n    AND?: political_news_crawler_processing_alertsWhereInput | political_news_crawler_processing_alertsWhereInput[]\n    OR?: political_news_crawler_processing_alertsWhereInput[]\n    NOT?: political_news_crawler_processing_alertsWhereInput | political_news_crawler_processing_alertsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_processing_alerts\"> | string\n    alert_type?: StringFilter<\"political_news_crawler_processing_alerts\"> | string\n    message?: StringFilter<\"political_news_crawler_processing_alerts\"> | string\n    severity?: StringFilter<\"political_news_crawler_processing_alerts\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_processing_alerts\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_processing_alerts\"> | Date | string\n  }\n\n  export type political_news_crawler_processing_alertsOrderByWithRelationInput = {\n    id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_processing_alertsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    alert_type_created_at?: political_news_crawler_processing_alertsAlert_typeCreated_atCompoundUniqueInput\n    AND?: political_news_crawler_processing_alertsWhereInput | political_news_crawler_processing_alertsWhereInput[]\n    OR?: political_news_crawler_processing_alertsWhereInput[]\n    NOT?: political_news_crawler_processing_alertsWhereInput | political_news_crawler_processing_alertsWhereInput[]\n    alert_type?: StringFilter<\"political_news_crawler_processing_alerts\"> | string\n    message?: StringFilter<\"political_news_crawler_processing_alerts\"> | string\n    severity?: StringFilter<\"political_news_crawler_processing_alerts\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_processing_alerts\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_processing_alerts\"> | Date | string\n  }, \"id\" | \"alert_type_created_at\">\n\n  export type political_news_crawler_processing_alertsOrderByWithAggregationInput = {\n    id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    _count?: political_news_crawler_processing_alertsCountOrderByAggregateInput\n    _max?: political_news_crawler_processing_alertsMaxOrderByAggregateInput\n    _min?: political_news_crawler_processing_alertsMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_processing_alertsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_processing_alertsScalarWhereWithAggregatesInput | political_news_crawler_processing_alertsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_processing_alertsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_processing_alertsScalarWhereWithAggregatesInput | political_news_crawler_processing_alertsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_processing_alerts\"> | string\n    alert_type?: StringWithAggregatesFilter<\"political_news_crawler_processing_alerts\"> | string\n    message?: StringWithAggregatesFilter<\"political_news_crawler_processing_alerts\"> | string\n    severity?: StringWithAggregatesFilter<\"political_news_crawler_processing_alerts\"> | string\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_processing_alerts\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_processing_alerts\"> | Date | string\n  }\n\n  export type political_news_crawler_api_alertsWhereInput = {\n    AND?: political_news_crawler_api_alertsWhereInput | political_news_crawler_api_alertsWhereInput[]\n    OR?: political_news_crawler_api_alertsWhereInput[]\n    NOT?: political_news_crawler_api_alertsWhereInput | political_news_crawler_api_alertsWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_api_alerts\"> | string\n    alert_type?: StringFilter<\"political_news_crawler_api_alerts\"> | string\n    message?: StringFilter<\"political_news_crawler_api_alerts\"> | string\n    severity?: StringFilter<\"political_news_crawler_api_alerts\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_api_alerts\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_api_alerts\"> | Date | string\n  }\n\n  export type political_news_crawler_api_alertsOrderByWithRelationInput = {\n    id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_alertsWhereUniqueInput = Prisma.AtLeast<{\n    id?: string\n    alert_type_created_at?: political_news_crawler_api_alertsAlert_typeCreated_atCompoundUniqueInput\n    AND?: political_news_crawler_api_alertsWhereInput | political_news_crawler_api_alertsWhereInput[]\n    OR?: political_news_crawler_api_alertsWhereInput[]\n    NOT?: political_news_crawler_api_alertsWhereInput | political_news_crawler_api_alertsWhereInput[]\n    alert_type?: StringFilter<\"political_news_crawler_api_alerts\"> | string\n    message?: StringFilter<\"political_news_crawler_api_alerts\"> | string\n    severity?: StringFilter<\"political_news_crawler_api_alerts\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_api_alerts\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_api_alerts\"> | Date | string\n  }, \"id\" | \"alert_type_created_at\">\n\n  export type political_news_crawler_api_alertsOrderByWithAggregationInput = {\n    id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    _count?: political_news_crawler_api_alertsCountOrderByAggregateInput\n    _max?: political_news_crawler_api_alertsMaxOrderByAggregateInput\n    _min?: political_news_crawler_api_alertsMinOrderByAggregateInput\n  }\n\n  export type political_news_crawler_api_alertsScalarWhereWithAggregatesInput = {\n    AND?: political_news_crawler_api_alertsScalarWhereWithAggregatesInput | political_news_crawler_api_alertsScalarWhereWithAggregatesInput[]\n    OR?: political_news_crawler_api_alertsScalarWhereWithAggregatesInput[]\n    NOT?: political_news_crawler_api_alertsScalarWhereWithAggregatesInput | political_news_crawler_api_alertsScalarWhereWithAggregatesInput[]\n    id?: UuidWithAggregatesFilter<\"political_news_crawler_api_alerts\"> | string\n    alert_type?: StringWithAggregatesFilter<\"political_news_crawler_api_alerts\"> | string\n    message?: StringWithAggregatesFilter<\"political_news_crawler_api_alerts\"> | string\n    severity?: StringWithAggregatesFilter<\"political_news_crawler_api_alerts\"> | string\n    created_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_api_alerts\"> | Date | string\n    updated_at?: DateTimeWithAggregatesFilter<\"political_news_crawler_api_alerts\"> | Date | string\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateInput = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsCreateNestedManyWithoutCrawlSourceInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUncheckedCreateInput = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUncheckedCreateNestedManyWithoutCrawlSourceInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUpdateManyWithoutCrawlSourceNestedInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateManyInput = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_sourcesUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_policiesCreateInput = {\n    id: string\n    policy_name: string\n    max_crawl_frequency_minutes: number\n    max_retry_attempts: number\n    backoff_multiplier: number\n    ban_detection_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesCreateNestedManyWithoutCrawlPolicyInput\n  }\n\n  export type political_news_crawler_crawl_policiesUncheckedCreateInput = {\n    id: string\n    policy_name: string\n    max_crawl_frequency_minutes: number\n    max_retry_attempts: number\n    backoff_multiplier: number\n    ban_detection_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUncheckedCreateNestedManyWithoutCrawlPolicyInput\n  }\n\n  export type political_news_crawler_crawl_policiesUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    policy_name?: StringFieldUpdateOperationsInput | string\n    max_crawl_frequency_minutes?: IntFieldUpdateOperationsInput | number\n    max_retry_attempts?: IntFieldUpdateOperationsInput | number\n    backoff_multiplier?: FloatFieldUpdateOperationsInput | number\n    ban_detection_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUpdateManyWithoutCrawlPolicyNestedInput\n  }\n\n  export type political_news_crawler_crawl_policiesUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    policy_name?: StringFieldUpdateOperationsInput | string\n    max_crawl_frequency_minutes?: IntFieldUpdateOperationsInput | number\n    max_retry_attempts?: IntFieldUpdateOperationsInput | number\n    backoff_multiplier?: FloatFieldUpdateOperationsInput | number\n    ban_detection_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUncheckedUpdateManyWithoutCrawlPolicyNestedInput\n  }\n\n  export type political_news_crawler_crawl_policiesCreateManyInput = {\n    id: string\n    policy_name: string\n    max_crawl_frequency_minutes: number\n    max_retry_attempts: number\n    backoff_multiplier: number\n    ban_detection_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_crawl_policiesUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    policy_name?: StringFieldUpdateOperationsInput | string\n    max_crawl_frequency_minutes?: IntFieldUpdateOperationsInput | number\n    max_retry_attempts?: IntFieldUpdateOperationsInput | number\n    backoff_multiplier?: FloatFieldUpdateOperationsInput | number\n    ban_detection_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_policiesUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    policy_name?: StringFieldUpdateOperationsInput | string\n    max_crawl_frequency_minutes?: IntFieldUpdateOperationsInput | number\n    max_retry_attempts?: IntFieldUpdateOperationsInput | number\n    backoff_multiplier?: FloatFieldUpdateOperationsInput | number\n    ban_detection_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateInput = {\n    id: string\n    schedule_expression: string\n    last_crawled_at?: Date | string | null\n    next_crawl_at?: Date | string | null\n    is_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_crawl_schedulesInput\n    crawlPolicy: political_news_crawler_crawl_policiesCreateNestedOneWithoutPolitical_news_crawler_crawl_schedulesInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsCreateNestedManyWithoutCrawlScheduleInput\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedCreateInput = {\n    id: string\n    crawl_source_id: string\n    crawl_policy_id: string\n    schedule_expression: string\n    last_crawled_at?: Date | string | null\n    next_crawl_at?: Date | string | null\n    is_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedCreateNestedManyWithoutCrawlScheduleInput\n  }\n\n  export type political_news_crawler_crawl_schedulesUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    schedule_expression?: StringFieldUpdateOperationsInput | string\n    last_crawled_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    next_crawl_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    is_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_schedulesNestedInput\n    crawlPolicy?: political_news_crawler_crawl_policiesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_schedulesNestedInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUpdateManyWithoutCrawlScheduleNestedInput\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    crawl_policy_id?: StringFieldUpdateOperationsInput | string\n    schedule_expression?: StringFieldUpdateOperationsInput | string\n    last_crawled_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    next_crawl_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    is_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlScheduleNestedInput\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateManyInput = {\n    id: string\n    crawl_source_id: string\n    crawl_policy_id: string\n    schedule_expression: string\n    last_crawled_at?: Date | string | null\n    next_crawl_at?: Date | string | null\n    is_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_crawl_schedulesUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    schedule_expression?: StringFieldUpdateOperationsInput | string\n    last_crawled_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    next_crawl_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    is_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    crawl_policy_id?: StringFieldUpdateOperationsInput | string\n    schedule_expression?: StringFieldUpdateOperationsInput | string\n    last_crawled_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    next_crawl_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    is_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_guestsCreateInput = {\n    id: string\n    ip_address: string\n    user_agent?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_guestsUncheckedCreateInput = {\n    id: string\n    ip_address: string\n    user_agent?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_guestsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    ip_address?: StringFieldUpdateOperationsInput | string\n    user_agent?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_guestsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    ip_address?: StringFieldUpdateOperationsInput | string\n    user_agent?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_guestsCreateManyInput = {\n    id: string\n    ip_address: string\n    user_agent?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_guestsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    ip_address?: StringFieldUpdateOperationsInput | string\n    user_agent?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_guestsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    ip_address?: StringFieldUpdateOperationsInput | string\n    user_agent?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_jobsCreateInput = {\n    id: string\n    active: boolean\n    last_run_started_at?: Date | string | null\n    last_run_completed_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_crawl_jobsInput\n    crawlSchedule: political_news_crawler_crawl_schedulesCreateNestedOneWithoutPolitical_news_crawler_crawl_jobsInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsCreateNestedManyWithoutCrawlJobInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageCreateNestedManyWithoutCrawlJobInput\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedCreateInput = {\n    id: string\n    crawl_source_id: string\n    crawl_schedule_id: string\n    active: boolean\n    last_run_started_at?: Date | string | null\n    last_run_completed_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedCreateNestedManyWithoutCrawlJobInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedCreateNestedManyWithoutCrawlJobInput\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_jobsNestedInput\n    crawlSchedule?: political_news_crawler_crawl_schedulesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_jobsNestedInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUpdateManyWithoutCrawlJobNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUpdateManyWithoutCrawlJobNestedInput\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    crawl_schedule_id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutCrawlJobNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlJobNestedInput\n  }\n\n  export type political_news_crawler_crawl_jobsCreateManyInput = {\n    id: string\n    crawl_source_id: string\n    crawl_schedule_id: string\n    active: boolean\n    last_run_started_at?: Date | string | null\n    last_run_completed_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    crawl_schedule_id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateInput = {\n    id: string\n    started_at: Date | string\n    completed_at?: Date | string | null\n    success: boolean\n    error_message?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    crawlJob: political_news_crawler_crawl_jobsCreateNestedOneWithoutPolitical_news_crawler_crawl_attemptsInput\n    rawDataStorage?: political_news_crawler_raw_data_storageCreateNestedOneWithoutPolitical_news_crawler_crawl_attemptsInput\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsCreateNestedManyWithoutCrawlAttemptInput\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedCreateInput = {\n    id: string\n    crawl_job_id: string\n    raw_data_storage_id?: string | null\n    started_at: Date | string\n    completed_at?: Date | string | null\n    success: boolean\n    error_message?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsUncheckedCreateNestedManyWithoutCrawlAttemptInput\n  }\n\n  export type political_news_crawler_crawl_attemptsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    started_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    success?: BoolFieldUpdateOperationsInput | boolean\n    error_message?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    crawlJob?: political_news_crawler_crawl_jobsUpdateOneRequiredWithoutPolitical_news_crawler_crawl_attemptsNestedInput\n    rawDataStorage?: political_news_crawler_raw_data_storageUpdateOneWithoutPolitical_news_crawler_crawl_attemptsNestedInput\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsUpdateManyWithoutCrawlAttemptNestedInput\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_job_id?: StringFieldUpdateOperationsInput | string\n    raw_data_storage_id?: NullableStringFieldUpdateOperationsInput | string | null\n    started_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    success?: BoolFieldUpdateOperationsInput | boolean\n    error_message?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsUncheckedUpdateManyWithoutCrawlAttemptNestedInput\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateManyInput = {\n    id: string\n    crawl_job_id: string\n    raw_data_storage_id?: string | null\n    started_at: Date | string\n    completed_at?: Date | string | null\n    success: boolean\n    error_message?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_crawl_attemptsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    started_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    success?: BoolFieldUpdateOperationsInput | boolean\n    error_message?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_job_id?: StringFieldUpdateOperationsInput | string\n    raw_data_storage_id?: NullableStringFieldUpdateOperationsInput | string | null\n    started_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    success?: BoolFieldUpdateOperationsInput | boolean\n    error_message?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_crawled_newsCreateInput = {\n    id: string\n    url: string\n    title?: string | null\n    published_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    crawlAttempt: political_news_crawler_crawl_attemptsCreateNestedOneWithoutPolitical_news_crawler_crawled_newsInput\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsCreateNestedManyWithoutCrawledNewsInput\n  }\n\n  export type political_news_crawler_crawled_newsUncheckedCreateInput = {\n    id: string\n    crawl_attempt_id: string\n    url: string\n    title?: string | null\n    published_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsUncheckedCreateNestedManyWithoutCrawledNewsInput\n  }\n\n  export type political_news_crawler_crawled_newsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    url?: StringFieldUpdateOperationsInput | string\n    title?: NullableStringFieldUpdateOperationsInput | string | null\n    published_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    crawlAttempt?: political_news_crawler_crawl_attemptsUpdateOneRequiredWithoutPolitical_news_crawler_crawled_newsNestedInput\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsUpdateManyWithoutCrawledNewsNestedInput\n  }\n\n  export type political_news_crawler_crawled_newsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_attempt_id?: StringFieldUpdateOperationsInput | string\n    url?: StringFieldUpdateOperationsInput | string\n    title?: NullableStringFieldUpdateOperationsInput | string | null\n    published_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsUncheckedUpdateManyWithoutCrawledNewsNestedInput\n  }\n\n  export type political_news_crawler_crawled_newsCreateManyInput = {\n    id: string\n    crawl_attempt_id: string\n    url: string\n    title?: string | null\n    published_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_crawled_newsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    url?: StringFieldUpdateOperationsInput | string\n    title?: NullableStringFieldUpdateOperationsInput | string | null\n    published_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_crawled_newsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_attempt_id?: StringFieldUpdateOperationsInput | string\n    url?: StringFieldUpdateOperationsInput | string\n    title?: NullableStringFieldUpdateOperationsInput | string | null\n    published_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_raw_data_storageCreateInput = {\n    id: string\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_raw_data_storageInput\n    crawlJob?: political_news_crawler_crawl_jobsCreateNestedOneWithoutPolitical_news_crawler_raw_data_storageInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentCreateNestedManyWithoutRawDataStorageInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedCreateInput = {\n    id: string\n    crawl_source_id: string\n    crawl_job_id?: string | null\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUncheckedCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedCreateNestedManyWithoutRawDataStorageInput\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_raw_data_storageNestedInput\n    crawlJob?: political_news_crawler_crawl_jobsUpdateOneWithoutPolitical_news_crawler_raw_data_storageNestedInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUpdateManyWithoutRawDataStorageNestedInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    crawl_job_id?: NullableStringFieldUpdateOperationsInput | string | null\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUncheckedUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedUpdateManyWithoutRawDataStorageNestedInput\n  }\n\n  export type political_news_crawler_raw_data_storageCreateManyInput = {\n    id: string\n    crawl_source_id: string\n    crawl_job_id?: string | null\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    crawl_job_id?: NullableStringFieldUpdateOperationsInput | string | null\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_local_cache_filesCreateInput = {\n    id: string\n    local_file_path: string\n    file_size_bytes: number\n    ttl_expiration_at: Date | string\n    deleted_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    rawDataStorage: political_news_crawler_raw_data_storageCreateNestedOneWithoutPolitical_news_crawler_local_cache_filesInput\n  }\n\n  export type political_news_crawler_local_cache_filesUncheckedCreateInput = {\n    id: string\n    raw_data_storage_id: string\n    local_file_path: string\n    file_size_bytes: number\n    ttl_expiration_at: Date | string\n    deleted_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_local_cache_filesUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    local_file_path?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    ttl_expiration_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    rawDataStorage?: political_news_crawler_raw_data_storageUpdateOneRequiredWithoutPolitical_news_crawler_local_cache_filesNestedInput\n  }\n\n  export type political_news_crawler_local_cache_filesUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    raw_data_storage_id?: StringFieldUpdateOperationsInput | string\n    local_file_path?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    ttl_expiration_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_local_cache_filesCreateManyInput = {\n    id: string\n    raw_data_storage_id: string\n    local_file_path: string\n    file_size_bytes: number\n    ttl_expiration_at: Date | string\n    deleted_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_local_cache_filesUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    local_file_path?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    ttl_expiration_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_local_cache_filesUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    raw_data_storage_id?: StringFieldUpdateOperationsInput | string\n    local_file_path?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    ttl_expiration_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_processed_contentCreateInput = {\n    id: string\n    content_type: string\n    content_body: string\n    generation_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    rawDataStorage: political_news_crawler_raw_data_storageCreateNestedOneWithoutPolitical_news_crawler_processed_contentInput\n    llmJob?: political_news_crawler_llm_jobsCreateNestedOneWithoutPolitical_news_crawler_processed_contentInput\n  }\n\n  export type political_news_crawler_processed_contentUncheckedCreateInput = {\n    id: string\n    raw_data_storage_id: string\n    llm_job_id?: string | null\n    content_type: string\n    content_body: string\n    generation_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_processed_contentUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_body?: StringFieldUpdateOperationsInput | string\n    generation_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    rawDataStorage?: political_news_crawler_raw_data_storageUpdateOneRequiredWithoutPolitical_news_crawler_processed_contentNestedInput\n    llmJob?: political_news_crawler_llm_jobsUpdateOneWithoutPolitical_news_crawler_processed_contentNestedInput\n  }\n\n  export type political_news_crawler_processed_contentUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    raw_data_storage_id?: StringFieldUpdateOperationsInput | string\n    llm_job_id?: NullableStringFieldUpdateOperationsInput | string | null\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_body?: StringFieldUpdateOperationsInput | string\n    generation_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_processed_contentCreateManyInput = {\n    id: string\n    raw_data_storage_id: string\n    llm_job_id?: string | null\n    content_type: string\n    content_body: string\n    generation_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_processed_contentUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_body?: StringFieldUpdateOperationsInput | string\n    generation_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_processed_contentUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    raw_data_storage_id?: StringFieldUpdateOperationsInput | string\n    llm_job_id?: NullableStringFieldUpdateOperationsInput | string | null\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_body?: StringFieldUpdateOperationsInput | string\n    generation_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_llm_jobsCreateInput = {\n    id: string\n    status: string\n    parameters: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_llm_jobsInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataCreateNestedManyWithoutLlmJobInput\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedCreateInput = {\n    id: string\n    crawl_source_id: string\n    status: string\n    parameters: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsUncheckedCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataUncheckedCreateNestedManyWithoutLlmJobInput\n  }\n\n  export type political_news_crawler_llm_jobsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    status?: StringFieldUpdateOperationsInput | string\n    parameters?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_llm_jobsNestedInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataUpdateManyWithoutLlmJobNestedInput\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    status?: StringFieldUpdateOperationsInput | string\n    parameters?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsUncheckedUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataUncheckedUpdateManyWithoutLlmJobNestedInput\n  }\n\n  export type political_news_crawler_llm_jobsCreateManyInput = {\n    id: string\n    crawl_source_id: string\n    status: string\n    parameters: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_llm_jobsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    status?: StringFieldUpdateOperationsInput | string\n    parameters?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    status?: StringFieldUpdateOperationsInput | string\n    parameters?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_llm_resultsCreateInput = {\n    id: string\n    content_type: string\n    content_text: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    llmJob: political_news_crawler_llm_jobsCreateNestedOneWithoutPolitical_news_crawler_llm_resultsInput\n  }\n\n  export type political_news_crawler_llm_resultsUncheckedCreateInput = {\n    id: string\n    llm_job_id: string\n    content_type: string\n    content_text: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_llm_resultsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_text?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    llmJob?: political_news_crawler_llm_jobsUpdateOneRequiredWithoutPolitical_news_crawler_llm_resultsNestedInput\n  }\n\n  export type political_news_crawler_llm_resultsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    llm_job_id?: StringFieldUpdateOperationsInput | string\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_text?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_llm_resultsCreateManyInput = {\n    id: string\n    llm_job_id: string\n    content_type: string\n    content_text: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_llm_resultsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_text?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_llm_resultsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    llm_job_id?: StringFieldUpdateOperationsInput | string\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_text?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_processing_metadataCreateInput = {\n    id: string\n    metadata_key: string\n    metadata_value: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    llmJob: political_news_crawler_llm_jobsCreateNestedOneWithoutPolitical_news_crawler_processing_metadataInput\n  }\n\n  export type political_news_crawler_processing_metadataUncheckedCreateInput = {\n    id: string\n    llm_job_id: string\n    metadata_key: string\n    metadata_value: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_processing_metadataUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    metadata_key?: StringFieldUpdateOperationsInput | string\n    metadata_value?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    llmJob?: political_news_crawler_llm_jobsUpdateOneRequiredWithoutPolitical_news_crawler_processing_metadataNestedInput\n  }\n\n  export type political_news_crawler_processing_metadataUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    llm_job_id?: StringFieldUpdateOperationsInput | string\n    metadata_key?: StringFieldUpdateOperationsInput | string\n    metadata_value?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_processing_metadataCreateManyInput = {\n    id: string\n    llm_job_id: string\n    metadata_key: string\n    metadata_value: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_processing_metadataUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    metadata_key?: StringFieldUpdateOperationsInput | string\n    metadata_value?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_processing_metadataUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    llm_job_id?: StringFieldUpdateOperationsInput | string\n    metadata_key?: StringFieldUpdateOperationsInput | string\n    metadata_value?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_popularity_scoresCreateInput = {\n    id: string\n    score: number\n    decay_factor: number\n    snapshot_at: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    popularTopic: political_news_crawler_popular_topicsCreateNestedOneWithoutPolitical_news_crawler_popularity_scoresInput\n  }\n\n  export type political_news_crawler_popularity_scoresUncheckedCreateInput = {\n    id: string\n    political_news_crawler_popular_topic_id: string\n    score: number\n    decay_factor: number\n    snapshot_at: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_popularity_scoresUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    score?: FloatFieldUpdateOperationsInput | number\n    decay_factor?: FloatFieldUpdateOperationsInput | number\n    snapshot_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    popularTopic?: political_news_crawler_popular_topicsUpdateOneRequiredWithoutPolitical_news_crawler_popularity_scoresNestedInput\n  }\n\n  export type political_news_crawler_popularity_scoresUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    political_news_crawler_popular_topic_id?: StringFieldUpdateOperationsInput | string\n    score?: FloatFieldUpdateOperationsInput | number\n    decay_factor?: FloatFieldUpdateOperationsInput | number\n    snapshot_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_popularity_scoresCreateManyInput = {\n    id: string\n    political_news_crawler_popular_topic_id: string\n    score: number\n    decay_factor: number\n    snapshot_at: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_popularity_scoresUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    score?: FloatFieldUpdateOperationsInput | number\n    decay_factor?: FloatFieldUpdateOperationsInput | number\n    snapshot_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_popularity_scoresUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    political_news_crawler_popular_topic_id?: StringFieldUpdateOperationsInput | string\n    score?: FloatFieldUpdateOperationsInput | number\n    decay_factor?: FloatFieldUpdateOperationsInput | number\n    snapshot_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_popular_topicsCreateInput = {\n    id: string\n    topic_code: string\n    title: string\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_popularity_scores?: political_news_crawler_popularity_scoresCreateNestedManyWithoutPopularTopicInput\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsCreateNestedManyWithoutPopularTopicInput\n  }\n\n  export type political_news_crawler_popular_topicsUncheckedCreateInput = {\n    id: string\n    topic_code: string\n    title: string\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_popularity_scores?: political_news_crawler_popularity_scoresUncheckedCreateNestedManyWithoutPopularTopicInput\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsUncheckedCreateNestedManyWithoutPopularTopicInput\n  }\n\n  export type political_news_crawler_popular_topicsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    topic_code?: StringFieldUpdateOperationsInput | string\n    title?: StringFieldUpdateOperationsInput | string\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_popularity_scores?: political_news_crawler_popularity_scoresUpdateManyWithoutPopularTopicNestedInput\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsUpdateManyWithoutPopularTopicNestedInput\n  }\n\n  export type political_news_crawler_popular_topicsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    topic_code?: StringFieldUpdateOperationsInput | string\n    title?: StringFieldUpdateOperationsInput | string\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_popularity_scores?: political_news_crawler_popularity_scoresUncheckedUpdateManyWithoutPopularTopicNestedInput\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsUncheckedUpdateManyWithoutPopularTopicNestedInput\n  }\n\n  export type political_news_crawler_popular_topicsCreateManyInput = {\n    id: string\n    topic_code: string\n    title: string\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_popular_topicsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    topic_code?: StringFieldUpdateOperationsInput | string\n    title?: StringFieldUpdateOperationsInput | string\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_popular_topicsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    topic_code?: StringFieldUpdateOperationsInput | string\n    title?: StringFieldUpdateOperationsInput | string\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsCreateInput = {\n    id: string\n    mention_context?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    popularTopic: political_news_crawler_popular_topicsCreateNestedOneWithoutPolitical_news_crawler_topic_mentionsInput\n    crawledNews: political_news_crawler_crawled_newsCreateNestedOneWithoutPolitical_news_crawler_topic_mentionsInput\n  }\n\n  export type political_news_crawler_topic_mentionsUncheckedCreateInput = {\n    id: string\n    political_news_crawler_popular_topic_id: string\n    political_news_crawler_crawled_news_id: string\n    mention_context?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    mention_context?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    popularTopic?: political_news_crawler_popular_topicsUpdateOneRequiredWithoutPolitical_news_crawler_topic_mentionsNestedInput\n    crawledNews?: political_news_crawler_crawled_newsUpdateOneRequiredWithoutPolitical_news_crawler_topic_mentionsNestedInput\n  }\n\n  export type political_news_crawler_topic_mentionsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    political_news_crawler_popular_topic_id?: StringFieldUpdateOperationsInput | string\n    political_news_crawler_crawled_news_id?: StringFieldUpdateOperationsInput | string\n    mention_context?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsCreateManyInput = {\n    id: string\n    political_news_crawler_popular_topic_id: string\n    political_news_crawler_crawled_news_id: string\n    mention_context?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    mention_context?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    political_news_crawler_popular_topic_id?: StringFieldUpdateOperationsInput | string\n    political_news_crawler_crawled_news_id?: StringFieldUpdateOperationsInput | string\n    mention_context?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_api_access_logsCreateInput = {\n    id: string\n    http_method: string\n    path: string\n    status_code: number\n    client_ip: string\n    user_agent: string\n    duration_ms: number\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_api_access_logsUncheckedCreateInput = {\n    id: string\n    http_method: string\n    path: string\n    status_code: number\n    client_ip: string\n    user_agent: string\n    duration_ms: number\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_api_access_logsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    http_method?: StringFieldUpdateOperationsInput | string\n    path?: StringFieldUpdateOperationsInput | string\n    status_code?: IntFieldUpdateOperationsInput | number\n    client_ip?: StringFieldUpdateOperationsInput | string\n    user_agent?: StringFieldUpdateOperationsInput | string\n    duration_ms?: IntFieldUpdateOperationsInput | number\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_access_logsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    http_method?: StringFieldUpdateOperationsInput | string\n    path?: StringFieldUpdateOperationsInput | string\n    status_code?: IntFieldUpdateOperationsInput | number\n    client_ip?: StringFieldUpdateOperationsInput | string\n    user_agent?: StringFieldUpdateOperationsInput | string\n    duration_ms?: IntFieldUpdateOperationsInput | number\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_access_logsCreateManyInput = {\n    id: string\n    http_method: string\n    path: string\n    status_code: number\n    client_ip: string\n    user_agent: string\n    duration_ms: number\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_api_access_logsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    http_method?: StringFieldUpdateOperationsInput | string\n    path?: StringFieldUpdateOperationsInput | string\n    status_code?: IntFieldUpdateOperationsInput | number\n    client_ip?: StringFieldUpdateOperationsInput | string\n    user_agent?: StringFieldUpdateOperationsInput | string\n    duration_ms?: IntFieldUpdateOperationsInput | number\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_access_logsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    http_method?: StringFieldUpdateOperationsInput | string\n    path?: StringFieldUpdateOperationsInput | string\n    status_code?: IntFieldUpdateOperationsInput | number\n    client_ip?: StringFieldUpdateOperationsInput | string\n    user_agent?: StringFieldUpdateOperationsInput | string\n    duration_ms?: IntFieldUpdateOperationsInput | number\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_error_logsCreateInput = {\n    id: string\n    path: string\n    error_code: string\n    error_message: string\n    client_ip: string\n    user_agent: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_api_error_logsUncheckedCreateInput = {\n    id: string\n    path: string\n    error_code: string\n    error_message: string\n    client_ip: string\n    user_agent: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_api_error_logsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    path?: StringFieldUpdateOperationsInput | string\n    error_code?: StringFieldUpdateOperationsInput | string\n    error_message?: StringFieldUpdateOperationsInput | string\n    client_ip?: StringFieldUpdateOperationsInput | string\n    user_agent?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_error_logsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    path?: StringFieldUpdateOperationsInput | string\n    error_code?: StringFieldUpdateOperationsInput | string\n    error_message?: StringFieldUpdateOperationsInput | string\n    client_ip?: StringFieldUpdateOperationsInput | string\n    user_agent?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_error_logsCreateManyInput = {\n    id: string\n    path: string\n    error_code: string\n    error_message: string\n    client_ip: string\n    user_agent: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_api_error_logsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    path?: StringFieldUpdateOperationsInput | string\n    error_code?: StringFieldUpdateOperationsInput | string\n    error_message?: StringFieldUpdateOperationsInput | string\n    client_ip?: StringFieldUpdateOperationsInput | string\n    user_agent?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_error_logsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    path?: StringFieldUpdateOperationsInput | string\n    error_code?: StringFieldUpdateOperationsInput | string\n    error_message?: StringFieldUpdateOperationsInput | string\n    client_ip?: StringFieldUpdateOperationsInput | string\n    user_agent?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_usage_metricsCreateInput = {\n    id: string\n    http_method: string\n    path: string\n    period_start: Date | string\n    period_end: Date | string\n    total_calls: number\n    max_response_ms: number\n    avg_response_ms: number\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_api_usage_metricsUncheckedCreateInput = {\n    id: string\n    http_method: string\n    path: string\n    period_start: Date | string\n    period_end: Date | string\n    total_calls: number\n    max_response_ms: number\n    avg_response_ms: number\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_api_usage_metricsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    http_method?: StringFieldUpdateOperationsInput | string\n    path?: StringFieldUpdateOperationsInput | string\n    period_start?: DateTimeFieldUpdateOperationsInput | Date | string\n    period_end?: DateTimeFieldUpdateOperationsInput | Date | string\n    total_calls?: IntFieldUpdateOperationsInput | number\n    max_response_ms?: IntFieldUpdateOperationsInput | number\n    avg_response_ms?: IntFieldUpdateOperationsInput | number\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_usage_metricsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    http_method?: StringFieldUpdateOperationsInput | string\n    path?: StringFieldUpdateOperationsInput | string\n    period_start?: DateTimeFieldUpdateOperationsInput | Date | string\n    period_end?: DateTimeFieldUpdateOperationsInput | Date | string\n    total_calls?: IntFieldUpdateOperationsInput | number\n    max_response_ms?: IntFieldUpdateOperationsInput | number\n    avg_response_ms?: IntFieldUpdateOperationsInput | number\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_usage_metricsCreateManyInput = {\n    id: string\n    http_method: string\n    path: string\n    period_start: Date | string\n    period_end: Date | string\n    total_calls: number\n    max_response_ms: number\n    avg_response_ms: number\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_api_usage_metricsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    http_method?: StringFieldUpdateOperationsInput | string\n    path?: StringFieldUpdateOperationsInput | string\n    period_start?: DateTimeFieldUpdateOperationsInput | Date | string\n    period_end?: DateTimeFieldUpdateOperationsInput | Date | string\n    total_calls?: IntFieldUpdateOperationsInput | number\n    max_response_ms?: IntFieldUpdateOperationsInput | number\n    avg_response_ms?: IntFieldUpdateOperationsInput | number\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_usage_metricsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    http_method?: StringFieldUpdateOperationsInput | string\n    path?: StringFieldUpdateOperationsInput | string\n    period_start?: DateTimeFieldUpdateOperationsInput | Date | string\n    period_end?: DateTimeFieldUpdateOperationsInput | Date | string\n    total_calls?: IntFieldUpdateOperationsInput | number\n    max_response_ms?: IntFieldUpdateOperationsInput | number\n    avg_response_ms?: IntFieldUpdateOperationsInput | number\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_crawl_alertsCreateInput = {\n    id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date | string\n    updated_at: Date | string\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_crawl_alertsInput\n  }\n\n  export type political_news_crawler_crawl_alertsUncheckedCreateInput = {\n    id: string\n    crawl_source_id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_crawl_alertsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_alertsNestedInput\n  }\n\n  export type political_news_crawler_crawl_alertsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_crawl_alertsCreateManyInput = {\n    id: string\n    crawl_source_id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_crawl_alertsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_crawl_alertsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_processing_alertsCreateInput = {\n    id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_processing_alertsUncheckedCreateInput = {\n    id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_processing_alertsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_processing_alertsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_processing_alertsCreateManyInput = {\n    id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_processing_alertsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_processing_alertsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_alertsCreateInput = {\n    id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_api_alertsUncheckedCreateInput = {\n    id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_api_alertsUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_alertsUncheckedUpdateInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_alertsCreateManyInput = {\n    id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_api_alertsUpdateManyMutationInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_api_alertsUncheckedUpdateManyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type UuidFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel>\n    in?: string[] | ListStringFieldRefInput<$PrismaModel>\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel>\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    mode?: QueryMode\n    not?: NestedUuidFilter<$PrismaModel> | string\n  }\n\n  export type StringFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel>\n    in?: string[] | ListStringFieldRefInput<$PrismaModel>\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel>\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    contains?: string | StringFieldRefInput<$PrismaModel>\n    startsWith?: string | StringFieldRefInput<$PrismaModel>\n    endsWith?: string | StringFieldRefInput<$PrismaModel>\n    mode?: QueryMode\n    not?: NestedStringFilter<$PrismaModel> | string\n  }\n\n  export type BoolFilter<$PrismaModel = never> = {\n    equals?: boolean | BooleanFieldRefInput<$PrismaModel>\n    not?: NestedBoolFilter<$PrismaModel> | boolean\n  }\n\n  export type StringNullableFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel> | null\n    in?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    contains?: string | StringFieldRefInput<$PrismaModel>\n    startsWith?: string | StringFieldRefInput<$PrismaModel>\n    endsWith?: string | StringFieldRefInput<$PrismaModel>\n    mode?: QueryMode\n    not?: NestedStringNullableFilter<$PrismaModel> | string | null\n  }\n\n  export type DateTimeFilter<$PrismaModel = never> = {\n    equals?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    in?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel>\n    notIn?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel>\n    lt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    lte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    not?: NestedDateTimeFilter<$PrismaModel> | Date | string\n  }\n\n  export type DateTimeNullableFilter<$PrismaModel = never> = {\n    equals?: Date | string | DateTimeFieldRefInput<$PrismaModel> | null\n    in?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel> | null\n    notIn?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel> | null\n    lt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    lte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    not?: NestedDateTimeNullableFilter<$PrismaModel> | Date | string | null\n  }\n\n  export type Political_news_crawler_crawl_schedulesListRelationFilter = {\n    every?: political_news_crawler_crawl_schedulesWhereInput\n    some?: political_news_crawler_crawl_schedulesWhereInput\n    none?: political_news_crawler_crawl_schedulesWhereInput\n  }\n\n  export type Political_news_crawler_crawl_jobsListRelationFilter = {\n    every?: political_news_crawler_crawl_jobsWhereInput\n    some?: political_news_crawler_crawl_jobsWhereInput\n    none?: political_news_crawler_crawl_jobsWhereInput\n  }\n\n  export type Political_news_crawler_raw_data_storageListRelationFilter = {\n    every?: political_news_crawler_raw_data_storageWhereInput\n    some?: political_news_crawler_raw_data_storageWhereInput\n    none?: political_news_crawler_raw_data_storageWhereInput\n  }\n\n  export type Political_news_crawler_llm_jobsListRelationFilter = {\n    every?: political_news_crawler_llm_jobsWhereInput\n    some?: political_news_crawler_llm_jobsWhereInput\n    none?: political_news_crawler_llm_jobsWhereInput\n  }\n\n  export type Political_news_crawler_crawl_alertsListRelationFilter = {\n    every?: political_news_crawler_crawl_alertsWhereInput\n    some?: political_news_crawler_crawl_alertsWhereInput\n    none?: political_news_crawler_crawl_alertsWhereInput\n  }\n\n  export type SortOrderInput = {\n    sort: SortOrder\n    nulls?: NullsOrder\n  }\n\n  export type political_news_crawler_crawl_schedulesOrderByRelationAggregateInput = {\n    _count?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_jobsOrderByRelationAggregateInput = {\n    _count?: SortOrder\n  }\n\n  export type political_news_crawler_raw_data_storageOrderByRelationAggregateInput = {\n    _count?: SortOrder\n  }\n\n  export type political_news_crawler_llm_jobsOrderByRelationAggregateInput = {\n    _count?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_alertsOrderByRelationAggregateInput = {\n    _count?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_sourcesCountOrderByAggregateInput = {\n    id?: SortOrder\n    source_code?: SortOrder\n    source_url?: SortOrder\n    is_active?: SortOrder\n    description?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_sourcesMaxOrderByAggregateInput = {\n    id?: SortOrder\n    source_code?: SortOrder\n    source_url?: SortOrder\n    is_active?: SortOrder\n    description?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_sourcesMinOrderByAggregateInput = {\n    id?: SortOrder\n    source_code?: SortOrder\n    source_url?: SortOrder\n    is_active?: SortOrder\n    description?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type UuidWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel>\n    in?: string[] | ListStringFieldRefInput<$PrismaModel>\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel>\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    mode?: QueryMode\n    not?: NestedUuidWithAggregatesFilter<$PrismaModel> | string\n    _count?: NestedIntFilter<$PrismaModel>\n    _min?: NestedStringFilter<$PrismaModel>\n    _max?: NestedStringFilter<$PrismaModel>\n  }\n\n  export type StringWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel>\n    in?: string[] | ListStringFieldRefInput<$PrismaModel>\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel>\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    contains?: string | StringFieldRefInput<$PrismaModel>\n    startsWith?: string | StringFieldRefInput<$PrismaModel>\n    endsWith?: string | StringFieldRefInput<$PrismaModel>\n    mode?: QueryMode\n    not?: NestedStringWithAggregatesFilter<$PrismaModel> | string\n    _count?: NestedIntFilter<$PrismaModel>\n    _min?: NestedStringFilter<$PrismaModel>\n    _max?: NestedStringFilter<$PrismaModel>\n  }\n\n  export type BoolWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: boolean | BooleanFieldRefInput<$PrismaModel>\n    not?: NestedBoolWithAggregatesFilter<$PrismaModel> | boolean\n    _count?: NestedIntFilter<$PrismaModel>\n    _min?: NestedBoolFilter<$PrismaModel>\n    _max?: NestedBoolFilter<$PrismaModel>\n  }\n\n  export type StringNullableWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel> | null\n    in?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    contains?: string | StringFieldRefInput<$PrismaModel>\n    startsWith?: string | StringFieldRefInput<$PrismaModel>\n    endsWith?: string | StringFieldRefInput<$PrismaModel>\n    mode?: QueryMode\n    not?: NestedStringNullableWithAggregatesFilter<$PrismaModel> | string | null\n    _count?: NestedIntNullableFilter<$PrismaModel>\n    _min?: NestedStringNullableFilter<$PrismaModel>\n    _max?: NestedStringNullableFilter<$PrismaModel>\n  }\n\n  export type DateTimeWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    in?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel>\n    notIn?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel>\n    lt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    lte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    not?: NestedDateTimeWithAggregatesFilter<$PrismaModel> | Date | string\n    _count?: NestedIntFilter<$PrismaModel>\n    _min?: NestedDateTimeFilter<$PrismaModel>\n    _max?: NestedDateTimeFilter<$PrismaModel>\n  }\n\n  export type DateTimeNullableWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: Date | string | DateTimeFieldRefInput<$PrismaModel> | null\n    in?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel> | null\n    notIn?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel> | null\n    lt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    lte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    not?: NestedDateTimeNullableWithAggregatesFilter<$PrismaModel> | Date | string | null\n    _count?: NestedIntNullableFilter<$PrismaModel>\n    _min?: NestedDateTimeNullableFilter<$PrismaModel>\n    _max?: NestedDateTimeNullableFilter<$PrismaModel>\n  }\n\n  export type IntFilter<$PrismaModel = never> = {\n    equals?: number | IntFieldRefInput<$PrismaModel>\n    in?: number[] | ListIntFieldRefInput<$PrismaModel>\n    notIn?: number[] | ListIntFieldRefInput<$PrismaModel>\n    lt?: number | IntFieldRefInput<$PrismaModel>\n    lte?: number | IntFieldRefInput<$PrismaModel>\n    gt?: number | IntFieldRefInput<$PrismaModel>\n    gte?: number | IntFieldRefInput<$PrismaModel>\n    not?: NestedIntFilter<$PrismaModel> | number\n  }\n\n  export type FloatFilter<$PrismaModel = never> = {\n    equals?: number | FloatFieldRefInput<$PrismaModel>\n    in?: number[] | ListFloatFieldRefInput<$PrismaModel>\n    notIn?: number[] | ListFloatFieldRefInput<$PrismaModel>\n    lt?: number | FloatFieldRefInput<$PrismaModel>\n    lte?: number | FloatFieldRefInput<$PrismaModel>\n    gt?: number | FloatFieldRefInput<$PrismaModel>\n    gte?: number | FloatFieldRefInput<$PrismaModel>\n    not?: NestedFloatFilter<$PrismaModel> | number\n  }\n\n  export type political_news_crawler_crawl_policiesCountOrderByAggregateInput = {\n    id?: SortOrder\n    policy_name?: SortOrder\n    max_crawl_frequency_minutes?: SortOrder\n    max_retry_attempts?: SortOrder\n    backoff_multiplier?: SortOrder\n    ban_detection_enabled?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_policiesAvgOrderByAggregateInput = {\n    max_crawl_frequency_minutes?: SortOrder\n    max_retry_attempts?: SortOrder\n    backoff_multiplier?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_policiesMaxOrderByAggregateInput = {\n    id?: SortOrder\n    policy_name?: SortOrder\n    max_crawl_frequency_minutes?: SortOrder\n    max_retry_attempts?: SortOrder\n    backoff_multiplier?: SortOrder\n    ban_detection_enabled?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_policiesMinOrderByAggregateInput = {\n    id?: SortOrder\n    policy_name?: SortOrder\n    max_crawl_frequency_minutes?: SortOrder\n    max_retry_attempts?: SortOrder\n    backoff_multiplier?: SortOrder\n    ban_detection_enabled?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_policiesSumOrderByAggregateInput = {\n    max_crawl_frequency_minutes?: SortOrder\n    max_retry_attempts?: SortOrder\n    backoff_multiplier?: SortOrder\n  }\n\n  export type IntWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: number | IntFieldRefInput<$PrismaModel>\n    in?: number[] | ListIntFieldRefInput<$PrismaModel>\n    notIn?: number[] | ListIntFieldRefInput<$PrismaModel>\n    lt?: number | IntFieldRefInput<$PrismaModel>\n    lte?: number | IntFieldRefInput<$PrismaModel>\n    gt?: number | IntFieldRefInput<$PrismaModel>\n    gte?: number | IntFieldRefInput<$PrismaModel>\n    not?: NestedIntWithAggregatesFilter<$PrismaModel> | number\n    _count?: NestedIntFilter<$PrismaModel>\n    _avg?: NestedFloatFilter<$PrismaModel>\n    _sum?: NestedIntFilter<$PrismaModel>\n    _min?: NestedIntFilter<$PrismaModel>\n    _max?: NestedIntFilter<$PrismaModel>\n  }\n\n  export type FloatWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: number | FloatFieldRefInput<$PrismaModel>\n    in?: number[] | ListFloatFieldRefInput<$PrismaModel>\n    notIn?: number[] | ListFloatFieldRefInput<$PrismaModel>\n    lt?: number | FloatFieldRefInput<$PrismaModel>\n    lte?: number | FloatFieldRefInput<$PrismaModel>\n    gt?: number | FloatFieldRefInput<$PrismaModel>\n    gte?: number | FloatFieldRefInput<$PrismaModel>\n    not?: NestedFloatWithAggregatesFilter<$PrismaModel> | number\n    _count?: NestedIntFilter<$PrismaModel>\n    _avg?: NestedFloatFilter<$PrismaModel>\n    _sum?: NestedFloatFilter<$PrismaModel>\n    _min?: NestedFloatFilter<$PrismaModel>\n    _max?: NestedFloatFilter<$PrismaModel>\n  }\n\n  export type Political_news_crawler_crawl_sourcesScalarRelationFilter = {\n    is?: political_news_crawler_crawl_sourcesWhereInput\n    isNot?: political_news_crawler_crawl_sourcesWhereInput\n  }\n\n  export type Political_news_crawler_crawl_policiesScalarRelationFilter = {\n    is?: political_news_crawler_crawl_policiesWhereInput\n    isNot?: political_news_crawler_crawl_policiesWhereInput\n  }\n\n  export type political_news_crawler_crawl_schedulesCountOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_policy_id?: SortOrder\n    schedule_expression?: SortOrder\n    last_crawled_at?: SortOrder\n    next_crawl_at?: SortOrder\n    is_enabled?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_schedulesMaxOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_policy_id?: SortOrder\n    schedule_expression?: SortOrder\n    last_crawled_at?: SortOrder\n    next_crawl_at?: SortOrder\n    is_enabled?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_schedulesMinOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_policy_id?: SortOrder\n    schedule_expression?: SortOrder\n    last_crawled_at?: SortOrder\n    next_crawl_at?: SortOrder\n    is_enabled?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_guestsIp_addressUser_agentCompoundUniqueInput = {\n    ip_address: string\n    user_agent: string\n  }\n\n  export type political_news_crawler_guestsCountOrderByAggregateInput = {\n    id?: SortOrder\n    ip_address?: SortOrder\n    user_agent?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_guestsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    ip_address?: SortOrder\n    user_agent?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_guestsMinOrderByAggregateInput = {\n    id?: SortOrder\n    ip_address?: SortOrder\n    user_agent?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type Political_news_crawler_crawl_schedulesScalarRelationFilter = {\n    is?: political_news_crawler_crawl_schedulesWhereInput\n    isNot?: political_news_crawler_crawl_schedulesWhereInput\n  }\n\n  export type Political_news_crawler_crawl_attemptsListRelationFilter = {\n    every?: political_news_crawler_crawl_attemptsWhereInput\n    some?: political_news_crawler_crawl_attemptsWhereInput\n    none?: political_news_crawler_crawl_attemptsWhereInput\n  }\n\n  export type political_news_crawler_crawl_attemptsOrderByRelationAggregateInput = {\n    _count?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_jobsCrawl_source_idCrawl_schedule_idCompoundUniqueInput = {\n    crawl_source_id: string\n    crawl_schedule_id: string\n  }\n\n  export type political_news_crawler_crawl_jobsCountOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_schedule_id?: SortOrder\n    active?: SortOrder\n    last_run_started_at?: SortOrder\n    last_run_completed_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_jobsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_schedule_id?: SortOrder\n    active?: SortOrder\n    last_run_started_at?: SortOrder\n    last_run_completed_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_jobsMinOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_schedule_id?: SortOrder\n    active?: SortOrder\n    last_run_started_at?: SortOrder\n    last_run_completed_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type UuidNullableFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel> | null\n    in?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    mode?: QueryMode\n    not?: NestedUuidNullableFilter<$PrismaModel> | string | null\n  }\n\n  export type Political_news_crawler_crawl_jobsScalarRelationFilter = {\n    is?: political_news_crawler_crawl_jobsWhereInput\n    isNot?: political_news_crawler_crawl_jobsWhereInput\n  }\n\n  export type Political_news_crawler_raw_data_storageNullableScalarRelationFilter = {\n    is?: political_news_crawler_raw_data_storageWhereInput | null\n    isNot?: political_news_crawler_raw_data_storageWhereInput | null\n  }\n\n  export type Political_news_crawler_crawled_newsListRelationFilter = {\n    every?: political_news_crawler_crawled_newsWhereInput\n    some?: political_news_crawler_crawled_newsWhereInput\n    none?: political_news_crawler_crawled_newsWhereInput\n  }\n\n  export type political_news_crawler_crawled_newsOrderByRelationAggregateInput = {\n    _count?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_attemptsCountOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_job_id?: SortOrder\n    raw_data_storage_id?: SortOrder\n    started_at?: SortOrder\n    completed_at?: SortOrder\n    success?: SortOrder\n    error_message?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_attemptsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_job_id?: SortOrder\n    raw_data_storage_id?: SortOrder\n    started_at?: SortOrder\n    completed_at?: SortOrder\n    success?: SortOrder\n    error_message?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_attemptsMinOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_job_id?: SortOrder\n    raw_data_storage_id?: SortOrder\n    started_at?: SortOrder\n    completed_at?: SortOrder\n    success?: SortOrder\n    error_message?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type UuidNullableWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel> | null\n    in?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    mode?: QueryMode\n    not?: NestedUuidNullableWithAggregatesFilter<$PrismaModel> | string | null\n    _count?: NestedIntNullableFilter<$PrismaModel>\n    _min?: NestedStringNullableFilter<$PrismaModel>\n    _max?: NestedStringNullableFilter<$PrismaModel>\n  }\n\n  export type Political_news_crawler_crawl_attemptsScalarRelationFilter = {\n    is?: political_news_crawler_crawl_attemptsWhereInput\n    isNot?: political_news_crawler_crawl_attemptsWhereInput\n  }\n\n  export type Political_news_crawler_topic_mentionsListRelationFilter = {\n    every?: political_news_crawler_topic_mentionsWhereInput\n    some?: political_news_crawler_topic_mentionsWhereInput\n    none?: political_news_crawler_topic_mentionsWhereInput\n  }\n\n  export type political_news_crawler_topic_mentionsOrderByRelationAggregateInput = {\n    _count?: SortOrder\n  }\n\n  export type political_news_crawler_crawled_newsCountOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_attempt_id?: SortOrder\n    url?: SortOrder\n    title?: SortOrder\n    published_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawled_newsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_attempt_id?: SortOrder\n    url?: SortOrder\n    title?: SortOrder\n    published_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawled_newsMinOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_attempt_id?: SortOrder\n    url?: SortOrder\n    title?: SortOrder\n    published_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type Political_news_crawler_crawl_jobsNullableScalarRelationFilter = {\n    is?: political_news_crawler_crawl_jobsWhereInput | null\n    isNot?: political_news_crawler_crawl_jobsWhereInput | null\n  }\n\n  export type Political_news_crawler_local_cache_filesListRelationFilter = {\n    every?: political_news_crawler_local_cache_filesWhereInput\n    some?: political_news_crawler_local_cache_filesWhereInput\n    none?: political_news_crawler_local_cache_filesWhereInput\n  }\n\n  export type Political_news_crawler_processed_contentListRelationFilter = {\n    every?: political_news_crawler_processed_contentWhereInput\n    some?: political_news_crawler_processed_contentWhereInput\n    none?: political_news_crawler_processed_contentWhereInput\n  }\n\n  export type political_news_crawler_local_cache_filesOrderByRelationAggregateInput = {\n    _count?: SortOrder\n  }\n\n  export type political_news_crawler_processed_contentOrderByRelationAggregateInput = {\n    _count?: SortOrder\n  }\n\n  export type political_news_crawler_raw_data_storageCountOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_job_id?: SortOrder\n    storage_key?: SortOrder\n    file_format?: SortOrder\n    file_size_bytes?: SortOrder\n    checksum?: SortOrder\n    crawl_timestamp?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_raw_data_storageAvgOrderByAggregateInput = {\n    file_size_bytes?: SortOrder\n  }\n\n  export type political_news_crawler_raw_data_storageMaxOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_job_id?: SortOrder\n    storage_key?: SortOrder\n    file_format?: SortOrder\n    file_size_bytes?: SortOrder\n    checksum?: SortOrder\n    crawl_timestamp?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_raw_data_storageMinOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    crawl_job_id?: SortOrder\n    storage_key?: SortOrder\n    file_format?: SortOrder\n    file_size_bytes?: SortOrder\n    checksum?: SortOrder\n    crawl_timestamp?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_raw_data_storageSumOrderByAggregateInput = {\n    file_size_bytes?: SortOrder\n  }\n\n  export type Political_news_crawler_raw_data_storageScalarRelationFilter = {\n    is?: political_news_crawler_raw_data_storageWhereInput\n    isNot?: political_news_crawler_raw_data_storageWhereInput\n  }\n\n  export type political_news_crawler_local_cache_filesCountOrderByAggregateInput = {\n    id?: SortOrder\n    raw_data_storage_id?: SortOrder\n    local_file_path?: SortOrder\n    file_size_bytes?: SortOrder\n    ttl_expiration_at?: SortOrder\n    deleted_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_local_cache_filesAvgOrderByAggregateInput = {\n    file_size_bytes?: SortOrder\n  }\n\n  export type political_news_crawler_local_cache_filesMaxOrderByAggregateInput = {\n    id?: SortOrder\n    raw_data_storage_id?: SortOrder\n    local_file_path?: SortOrder\n    file_size_bytes?: SortOrder\n    ttl_expiration_at?: SortOrder\n    deleted_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_local_cache_filesMinOrderByAggregateInput = {\n    id?: SortOrder\n    raw_data_storage_id?: SortOrder\n    local_file_path?: SortOrder\n    file_size_bytes?: SortOrder\n    ttl_expiration_at?: SortOrder\n    deleted_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_local_cache_filesSumOrderByAggregateInput = {\n    file_size_bytes?: SortOrder\n  }\n\n  export type Political_news_crawler_llm_jobsNullableScalarRelationFilter = {\n    is?: political_news_crawler_llm_jobsWhereInput | null\n    isNot?: political_news_crawler_llm_jobsWhereInput | null\n  }\n\n  export type political_news_crawler_processed_contentRaw_data_storage_idContent_typeCompoundUniqueInput = {\n    raw_data_storage_id: string\n    content_type: string\n  }\n\n  export type political_news_crawler_processed_contentCountOrderByAggregateInput = {\n    id?: SortOrder\n    raw_data_storage_id?: SortOrder\n    llm_job_id?: SortOrder\n    content_type?: SortOrder\n    content_body?: SortOrder\n    generation_timestamp?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_processed_contentMaxOrderByAggregateInput = {\n    id?: SortOrder\n    raw_data_storage_id?: SortOrder\n    llm_job_id?: SortOrder\n    content_type?: SortOrder\n    content_body?: SortOrder\n    generation_timestamp?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_processed_contentMinOrderByAggregateInput = {\n    id?: SortOrder\n    raw_data_storage_id?: SortOrder\n    llm_job_id?: SortOrder\n    content_type?: SortOrder\n    content_body?: SortOrder\n    generation_timestamp?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type Political_news_crawler_llm_resultsListRelationFilter = {\n    every?: political_news_crawler_llm_resultsWhereInput\n    some?: political_news_crawler_llm_resultsWhereInput\n    none?: political_news_crawler_llm_resultsWhereInput\n  }\n\n  export type Political_news_crawler_processing_metadataListRelationFilter = {\n    every?: political_news_crawler_processing_metadataWhereInput\n    some?: political_news_crawler_processing_metadataWhereInput\n    none?: political_news_crawler_processing_metadataWhereInput\n  }\n\n  export type political_news_crawler_llm_resultsOrderByRelationAggregateInput = {\n    _count?: SortOrder\n  }\n\n  export type political_news_crawler_processing_metadataOrderByRelationAggregateInput = {\n    _count?: SortOrder\n  }\n\n  export type political_news_crawler_llm_jobsCountOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    status?: SortOrder\n    parameters?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_llm_jobsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    status?: SortOrder\n    parameters?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_llm_jobsMinOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    status?: SortOrder\n    parameters?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type Political_news_crawler_llm_jobsScalarRelationFilter = {\n    is?: political_news_crawler_llm_jobsWhereInput\n    isNot?: political_news_crawler_llm_jobsWhereInput\n  }\n\n  export type political_news_crawler_llm_resultsCountOrderByAggregateInput = {\n    id?: SortOrder\n    llm_job_id?: SortOrder\n    content_type?: SortOrder\n    content_text?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_llm_resultsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    llm_job_id?: SortOrder\n    content_type?: SortOrder\n    content_text?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_llm_resultsMinOrderByAggregateInput = {\n    id?: SortOrder\n    llm_job_id?: SortOrder\n    content_type?: SortOrder\n    content_text?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_processing_metadataCountOrderByAggregateInput = {\n    id?: SortOrder\n    llm_job_id?: SortOrder\n    metadata_key?: SortOrder\n    metadata_value?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_processing_metadataMaxOrderByAggregateInput = {\n    id?: SortOrder\n    llm_job_id?: SortOrder\n    metadata_key?: SortOrder\n    metadata_value?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_processing_metadataMinOrderByAggregateInput = {\n    id?: SortOrder\n    llm_job_id?: SortOrder\n    metadata_key?: SortOrder\n    metadata_value?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type Political_news_crawler_popular_topicsScalarRelationFilter = {\n    is?: political_news_crawler_popular_topicsWhereInput\n    isNot?: political_news_crawler_popular_topicsWhereInput\n  }\n\n  export type political_news_crawler_popularity_scoresCountOrderByAggregateInput = {\n    id?: SortOrder\n    political_news_crawler_popular_topic_id?: SortOrder\n    score?: SortOrder\n    decay_factor?: SortOrder\n    snapshot_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_popularity_scoresAvgOrderByAggregateInput = {\n    score?: SortOrder\n    decay_factor?: SortOrder\n  }\n\n  export type political_news_crawler_popularity_scoresMaxOrderByAggregateInput = {\n    id?: SortOrder\n    political_news_crawler_popular_topic_id?: SortOrder\n    score?: SortOrder\n    decay_factor?: SortOrder\n    snapshot_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_popularity_scoresMinOrderByAggregateInput = {\n    id?: SortOrder\n    political_news_crawler_popular_topic_id?: SortOrder\n    score?: SortOrder\n    decay_factor?: SortOrder\n    snapshot_at?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_popularity_scoresSumOrderByAggregateInput = {\n    score?: SortOrder\n    decay_factor?: SortOrder\n  }\n\n  export type Political_news_crawler_popularity_scoresListRelationFilter = {\n    every?: political_news_crawler_popularity_scoresWhereInput\n    some?: political_news_crawler_popularity_scoresWhereInput\n    none?: political_news_crawler_popularity_scoresWhereInput\n  }\n\n  export type political_news_crawler_popularity_scoresOrderByRelationAggregateInput = {\n    _count?: SortOrder\n  }\n\n  export type political_news_crawler_popular_topicsCountOrderByAggregateInput = {\n    id?: SortOrder\n    topic_code?: SortOrder\n    title?: SortOrder\n    description?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_popular_topicsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    topic_code?: SortOrder\n    title?: SortOrder\n    description?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_popular_topicsMinOrderByAggregateInput = {\n    id?: SortOrder\n    topic_code?: SortOrder\n    title?: SortOrder\n    description?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type Political_news_crawler_crawled_newsScalarRelationFilter = {\n    is?: political_news_crawler_crawled_newsWhereInput\n    isNot?: political_news_crawler_crawled_newsWhereInput\n  }\n\n  export type political_news_crawler_topic_mentionsCountOrderByAggregateInput = {\n    id?: SortOrder\n    political_news_crawler_popular_topic_id?: SortOrder\n    political_news_crawler_crawled_news_id?: SortOrder\n    mention_context?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_topic_mentionsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    political_news_crawler_popular_topic_id?: SortOrder\n    political_news_crawler_crawled_news_id?: SortOrder\n    mention_context?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_topic_mentionsMinOrderByAggregateInput = {\n    id?: SortOrder\n    political_news_crawler_popular_topic_id?: SortOrder\n    political_news_crawler_crawled_news_id?: SortOrder\n    mention_context?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n    deleted_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_access_logsCountOrderByAggregateInput = {\n    id?: SortOrder\n    http_method?: SortOrder\n    path?: SortOrder\n    status_code?: SortOrder\n    client_ip?: SortOrder\n    user_agent?: SortOrder\n    duration_ms?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_access_logsAvgOrderByAggregateInput = {\n    status_code?: SortOrder\n    duration_ms?: SortOrder\n  }\n\n  export type political_news_crawler_api_access_logsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    http_method?: SortOrder\n    path?: SortOrder\n    status_code?: SortOrder\n    client_ip?: SortOrder\n    user_agent?: SortOrder\n    duration_ms?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_access_logsMinOrderByAggregateInput = {\n    id?: SortOrder\n    http_method?: SortOrder\n    path?: SortOrder\n    status_code?: SortOrder\n    client_ip?: SortOrder\n    user_agent?: SortOrder\n    duration_ms?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_access_logsSumOrderByAggregateInput = {\n    status_code?: SortOrder\n    duration_ms?: SortOrder\n  }\n\n  export type political_news_crawler_api_error_logsCountOrderByAggregateInput = {\n    id?: SortOrder\n    path?: SortOrder\n    error_code?: SortOrder\n    error_message?: SortOrder\n    client_ip?: SortOrder\n    user_agent?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_error_logsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    path?: SortOrder\n    error_code?: SortOrder\n    error_message?: SortOrder\n    client_ip?: SortOrder\n    user_agent?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_error_logsMinOrderByAggregateInput = {\n    id?: SortOrder\n    path?: SortOrder\n    error_code?: SortOrder\n    error_message?: SortOrder\n    client_ip?: SortOrder\n    user_agent?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_usage_metricsHttp_methodPathPeriod_startCompoundUniqueInput = {\n    http_method: string\n    path: string\n    period_start: Date | string\n  }\n\n  export type political_news_crawler_api_usage_metricsCountOrderByAggregateInput = {\n    id?: SortOrder\n    http_method?: SortOrder\n    path?: SortOrder\n    period_start?: SortOrder\n    period_end?: SortOrder\n    total_calls?: SortOrder\n    max_response_ms?: SortOrder\n    avg_response_ms?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_usage_metricsAvgOrderByAggregateInput = {\n    total_calls?: SortOrder\n    max_response_ms?: SortOrder\n    avg_response_ms?: SortOrder\n  }\n\n  export type political_news_crawler_api_usage_metricsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    http_method?: SortOrder\n    path?: SortOrder\n    period_start?: SortOrder\n    period_end?: SortOrder\n    total_calls?: SortOrder\n    max_response_ms?: SortOrder\n    avg_response_ms?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_usage_metricsMinOrderByAggregateInput = {\n    id?: SortOrder\n    http_method?: SortOrder\n    path?: SortOrder\n    period_start?: SortOrder\n    period_end?: SortOrder\n    total_calls?: SortOrder\n    max_response_ms?: SortOrder\n    avg_response_ms?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_usage_metricsSumOrderByAggregateInput = {\n    total_calls?: SortOrder\n    max_response_ms?: SortOrder\n    avg_response_ms?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_alertsCrawl_source_idAlert_typeCreated_atCompoundUniqueInput = {\n    crawl_source_id: string\n    alert_type: string\n    created_at: Date | string\n  }\n\n  export type political_news_crawler_crawl_alertsCountOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_alertsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_alertsMinOrderByAggregateInput = {\n    id?: SortOrder\n    crawl_source_id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_processing_alertsAlert_typeCreated_atCompoundUniqueInput = {\n    alert_type: string\n    created_at: Date | string\n  }\n\n  export type political_news_crawler_processing_alertsCountOrderByAggregateInput = {\n    id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_processing_alertsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_processing_alertsMinOrderByAggregateInput = {\n    id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_alertsAlert_typeCreated_atCompoundUniqueInput = {\n    alert_type: string\n    created_at: Date | string\n  }\n\n  export type political_news_crawler_api_alertsCountOrderByAggregateInput = {\n    id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_alertsMaxOrderByAggregateInput = {\n    id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_api_alertsMinOrderByAggregateInput = {\n    id?: SortOrder\n    alert_type?: SortOrder\n    message?: SortOrder\n    severity?: SortOrder\n    created_at?: SortOrder\n    updated_at?: SortOrder\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateNestedManyWithoutCrawlSourceInput = {\n    create?: XOR<political_news_crawler_crawl_schedulesCreateWithoutCrawlSourceInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_crawl_schedulesCreateWithoutCrawlSourceInput[] | political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_crawl_schedulesCreateManyCrawlSourceInputEnvelope\n    connect?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_jobsCreateNestedManyWithoutCrawlSourceInput = {\n    create?: XOR<political_news_crawler_crawl_jobsCreateWithoutCrawlSourceInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_crawl_jobsCreateWithoutCrawlSourceInput[] | political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_crawl_jobsCreateManyCrawlSourceInputEnvelope\n    connect?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_raw_data_storageCreateNestedManyWithoutCrawlSourceInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutCrawlSourceInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_raw_data_storageCreateWithoutCrawlSourceInput[] | political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_raw_data_storageCreateManyCrawlSourceInputEnvelope\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_llm_jobsCreateNestedManyWithoutCrawlSourceInput = {\n    create?: XOR<political_news_crawler_llm_jobsCreateWithoutCrawlSourceInput, political_news_crawler_llm_jobsUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_llm_jobsCreateWithoutCrawlSourceInput[] | political_news_crawler_llm_jobsUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_llm_jobsCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_llm_jobsCreateOrConnectWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_llm_jobsCreateManyCrawlSourceInputEnvelope\n    connect?: political_news_crawler_llm_jobsWhereUniqueInput | political_news_crawler_llm_jobsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_alertsCreateNestedManyWithoutCrawlSourceInput = {\n    create?: XOR<political_news_crawler_crawl_alertsCreateWithoutCrawlSourceInput, political_news_crawler_crawl_alertsUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_crawl_alertsCreateWithoutCrawlSourceInput[] | political_news_crawler_crawl_alertsUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_crawl_alertsCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_crawl_alertsCreateOrConnectWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_crawl_alertsCreateManyCrawlSourceInputEnvelope\n    connect?: political_news_crawler_crawl_alertsWhereUniqueInput | political_news_crawler_crawl_alertsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedCreateNestedManyWithoutCrawlSourceInput = {\n    create?: XOR<political_news_crawler_crawl_schedulesCreateWithoutCrawlSourceInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_crawl_schedulesCreateWithoutCrawlSourceInput[] | political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_crawl_schedulesCreateManyCrawlSourceInputEnvelope\n    connect?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedCreateNestedManyWithoutCrawlSourceInput = {\n    create?: XOR<political_news_crawler_crawl_jobsCreateWithoutCrawlSourceInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_crawl_jobsCreateWithoutCrawlSourceInput[] | political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_crawl_jobsCreateManyCrawlSourceInputEnvelope\n    connect?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedCreateNestedManyWithoutCrawlSourceInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutCrawlSourceInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_raw_data_storageCreateWithoutCrawlSourceInput[] | political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_raw_data_storageCreateManyCrawlSourceInputEnvelope\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedCreateNestedManyWithoutCrawlSourceInput = {\n    create?: XOR<political_news_crawler_llm_jobsCreateWithoutCrawlSourceInput, political_news_crawler_llm_jobsUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_llm_jobsCreateWithoutCrawlSourceInput[] | political_news_crawler_llm_jobsUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_llm_jobsCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_llm_jobsCreateOrConnectWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_llm_jobsCreateManyCrawlSourceInputEnvelope\n    connect?: political_news_crawler_llm_jobsWhereUniqueInput | political_news_crawler_llm_jobsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_alertsUncheckedCreateNestedManyWithoutCrawlSourceInput = {\n    create?: XOR<political_news_crawler_crawl_alertsCreateWithoutCrawlSourceInput, political_news_crawler_crawl_alertsUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_crawl_alertsCreateWithoutCrawlSourceInput[] | political_news_crawler_crawl_alertsUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_crawl_alertsCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_crawl_alertsCreateOrConnectWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_crawl_alertsCreateManyCrawlSourceInputEnvelope\n    connect?: political_news_crawler_crawl_alertsWhereUniqueInput | political_news_crawler_crawl_alertsWhereUniqueInput[]\n  }\n\n  export type StringFieldUpdateOperationsInput = {\n    set?: string\n  }\n\n  export type BoolFieldUpdateOperationsInput = {\n    set?: boolean\n  }\n\n  export type NullableStringFieldUpdateOperationsInput = {\n    set?: string | null\n  }\n\n  export type DateTimeFieldUpdateOperationsInput = {\n    set?: Date | string\n  }\n\n  export type NullableDateTimeFieldUpdateOperationsInput = {\n    set?: Date | string | null\n  }\n\n  export type political_news_crawler_crawl_schedulesUpdateManyWithoutCrawlSourceNestedInput = {\n    create?: XOR<political_news_crawler_crawl_schedulesCreateWithoutCrawlSourceInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_crawl_schedulesCreateWithoutCrawlSourceInput[] | political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlSourceInput[]\n    upsert?: political_news_crawler_crawl_schedulesUpsertWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_crawl_schedulesUpsertWithWhereUniqueWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_crawl_schedulesCreateManyCrawlSourceInputEnvelope\n    set?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    update?: political_news_crawler_crawl_schedulesUpdateWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_crawl_schedulesUpdateWithWhereUniqueWithoutCrawlSourceInput[]\n    updateMany?: political_news_crawler_crawl_schedulesUpdateManyWithWhereWithoutCrawlSourceInput | political_news_crawler_crawl_schedulesUpdateManyWithWhereWithoutCrawlSourceInput[]\n    deleteMany?: political_news_crawler_crawl_schedulesScalarWhereInput | political_news_crawler_crawl_schedulesScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateManyWithoutCrawlSourceNestedInput = {\n    create?: XOR<political_news_crawler_crawl_jobsCreateWithoutCrawlSourceInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_crawl_jobsCreateWithoutCrawlSourceInput[] | political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlSourceInput[]\n    upsert?: political_news_crawler_crawl_jobsUpsertWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_crawl_jobsUpsertWithWhereUniqueWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_crawl_jobsCreateManyCrawlSourceInputEnvelope\n    set?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    update?: political_news_crawler_crawl_jobsUpdateWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_crawl_jobsUpdateWithWhereUniqueWithoutCrawlSourceInput[]\n    updateMany?: political_news_crawler_crawl_jobsUpdateManyWithWhereWithoutCrawlSourceInput | political_news_crawler_crawl_jobsUpdateManyWithWhereWithoutCrawlSourceInput[]\n    deleteMany?: political_news_crawler_crawl_jobsScalarWhereInput | political_news_crawler_crawl_jobsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateManyWithoutCrawlSourceNestedInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutCrawlSourceInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_raw_data_storageCreateWithoutCrawlSourceInput[] | political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlSourceInput[]\n    upsert?: political_news_crawler_raw_data_storageUpsertWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_raw_data_storageUpsertWithWhereUniqueWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_raw_data_storageCreateManyCrawlSourceInputEnvelope\n    set?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    disconnect?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    delete?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    update?: political_news_crawler_raw_data_storageUpdateWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_raw_data_storageUpdateWithWhereUniqueWithoutCrawlSourceInput[]\n    updateMany?: political_news_crawler_raw_data_storageUpdateManyWithWhereWithoutCrawlSourceInput | political_news_crawler_raw_data_storageUpdateManyWithWhereWithoutCrawlSourceInput[]\n    deleteMany?: political_news_crawler_raw_data_storageScalarWhereInput | political_news_crawler_raw_data_storageScalarWhereInput[]\n  }\n\n  export type political_news_crawler_llm_jobsUpdateManyWithoutCrawlSourceNestedInput = {\n    create?: XOR<political_news_crawler_llm_jobsCreateWithoutCrawlSourceInput, political_news_crawler_llm_jobsUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_llm_jobsCreateWithoutCrawlSourceInput[] | political_news_crawler_llm_jobsUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_llm_jobsCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_llm_jobsCreateOrConnectWithoutCrawlSourceInput[]\n    upsert?: political_news_crawler_llm_jobsUpsertWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_llm_jobsUpsertWithWhereUniqueWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_llm_jobsCreateManyCrawlSourceInputEnvelope\n    set?: political_news_crawler_llm_jobsWhereUniqueInput | political_news_crawler_llm_jobsWhereUniqueInput[]\n    disconnect?: political_news_crawler_llm_jobsWhereUniqueInput | political_news_crawler_llm_jobsWhereUniqueInput[]\n    delete?: political_news_crawler_llm_jobsWhereUniqueInput | political_news_crawler_llm_jobsWhereUniqueInput[]\n    connect?: political_news_crawler_llm_jobsWhereUniqueInput | political_news_crawler_llm_jobsWhereUniqueInput[]\n    update?: political_news_crawler_llm_jobsUpdateWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_llm_jobsUpdateWithWhereUniqueWithoutCrawlSourceInput[]\n    updateMany?: political_news_crawler_llm_jobsUpdateManyWithWhereWithoutCrawlSourceInput | political_news_crawler_llm_jobsUpdateManyWithWhereWithoutCrawlSourceInput[]\n    deleteMany?: political_news_crawler_llm_jobsScalarWhereInput | political_news_crawler_llm_jobsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_alertsUpdateManyWithoutCrawlSourceNestedInput = {\n    create?: XOR<political_news_crawler_crawl_alertsCreateWithoutCrawlSourceInput, political_news_crawler_crawl_alertsUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_crawl_alertsCreateWithoutCrawlSourceInput[] | political_news_crawler_crawl_alertsUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_crawl_alertsCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_crawl_alertsCreateOrConnectWithoutCrawlSourceInput[]\n    upsert?: political_news_crawler_crawl_alertsUpsertWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_crawl_alertsUpsertWithWhereUniqueWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_crawl_alertsCreateManyCrawlSourceInputEnvelope\n    set?: political_news_crawler_crawl_alertsWhereUniqueInput | political_news_crawler_crawl_alertsWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_alertsWhereUniqueInput | political_news_crawler_crawl_alertsWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_alertsWhereUniqueInput | political_news_crawler_crawl_alertsWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_alertsWhereUniqueInput | political_news_crawler_crawl_alertsWhereUniqueInput[]\n    update?: political_news_crawler_crawl_alertsUpdateWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_crawl_alertsUpdateWithWhereUniqueWithoutCrawlSourceInput[]\n    updateMany?: political_news_crawler_crawl_alertsUpdateManyWithWhereWithoutCrawlSourceInput | political_news_crawler_crawl_alertsUpdateManyWithWhereWithoutCrawlSourceInput[]\n    deleteMany?: political_news_crawler_crawl_alertsScalarWhereInput | political_news_crawler_crawl_alertsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedUpdateManyWithoutCrawlSourceNestedInput = {\n    create?: XOR<political_news_crawler_crawl_schedulesCreateWithoutCrawlSourceInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_crawl_schedulesCreateWithoutCrawlSourceInput[] | political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlSourceInput[]\n    upsert?: political_news_crawler_crawl_schedulesUpsertWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_crawl_schedulesUpsertWithWhereUniqueWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_crawl_schedulesCreateManyCrawlSourceInputEnvelope\n    set?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    update?: political_news_crawler_crawl_schedulesUpdateWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_crawl_schedulesUpdateWithWhereUniqueWithoutCrawlSourceInput[]\n    updateMany?: political_news_crawler_crawl_schedulesUpdateManyWithWhereWithoutCrawlSourceInput | political_news_crawler_crawl_schedulesUpdateManyWithWhereWithoutCrawlSourceInput[]\n    deleteMany?: political_news_crawler_crawl_schedulesScalarWhereInput | political_news_crawler_crawl_schedulesScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlSourceNestedInput = {\n    create?: XOR<political_news_crawler_crawl_jobsCreateWithoutCrawlSourceInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_crawl_jobsCreateWithoutCrawlSourceInput[] | political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlSourceInput[]\n    upsert?: political_news_crawler_crawl_jobsUpsertWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_crawl_jobsUpsertWithWhereUniqueWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_crawl_jobsCreateManyCrawlSourceInputEnvelope\n    set?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    update?: political_news_crawler_crawl_jobsUpdateWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_crawl_jobsUpdateWithWhereUniqueWithoutCrawlSourceInput[]\n    updateMany?: political_news_crawler_crawl_jobsUpdateManyWithWhereWithoutCrawlSourceInput | political_news_crawler_crawl_jobsUpdateManyWithWhereWithoutCrawlSourceInput[]\n    deleteMany?: political_news_crawler_crawl_jobsScalarWhereInput | political_news_crawler_crawl_jobsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlSourceNestedInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutCrawlSourceInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_raw_data_storageCreateWithoutCrawlSourceInput[] | political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlSourceInput[]\n    upsert?: political_news_crawler_raw_data_storageUpsertWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_raw_data_storageUpsertWithWhereUniqueWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_raw_data_storageCreateManyCrawlSourceInputEnvelope\n    set?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    disconnect?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    delete?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    update?: political_news_crawler_raw_data_storageUpdateWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_raw_data_storageUpdateWithWhereUniqueWithoutCrawlSourceInput[]\n    updateMany?: political_news_crawler_raw_data_storageUpdateManyWithWhereWithoutCrawlSourceInput | political_news_crawler_raw_data_storageUpdateManyWithWhereWithoutCrawlSourceInput[]\n    deleteMany?: political_news_crawler_raw_data_storageScalarWhereInput | political_news_crawler_raw_data_storageScalarWhereInput[]\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedUpdateManyWithoutCrawlSourceNestedInput = {\n    create?: XOR<political_news_crawler_llm_jobsCreateWithoutCrawlSourceInput, political_news_crawler_llm_jobsUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_llm_jobsCreateWithoutCrawlSourceInput[] | political_news_crawler_llm_jobsUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_llm_jobsCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_llm_jobsCreateOrConnectWithoutCrawlSourceInput[]\n    upsert?: political_news_crawler_llm_jobsUpsertWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_llm_jobsUpsertWithWhereUniqueWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_llm_jobsCreateManyCrawlSourceInputEnvelope\n    set?: political_news_crawler_llm_jobsWhereUniqueInput | political_news_crawler_llm_jobsWhereUniqueInput[]\n    disconnect?: political_news_crawler_llm_jobsWhereUniqueInput | political_news_crawler_llm_jobsWhereUniqueInput[]\n    delete?: political_news_crawler_llm_jobsWhereUniqueInput | political_news_crawler_llm_jobsWhereUniqueInput[]\n    connect?: political_news_crawler_llm_jobsWhereUniqueInput | political_news_crawler_llm_jobsWhereUniqueInput[]\n    update?: political_news_crawler_llm_jobsUpdateWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_llm_jobsUpdateWithWhereUniqueWithoutCrawlSourceInput[]\n    updateMany?: political_news_crawler_llm_jobsUpdateManyWithWhereWithoutCrawlSourceInput | political_news_crawler_llm_jobsUpdateManyWithWhereWithoutCrawlSourceInput[]\n    deleteMany?: political_news_crawler_llm_jobsScalarWhereInput | political_news_crawler_llm_jobsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_alertsUncheckedUpdateManyWithoutCrawlSourceNestedInput = {\n    create?: XOR<political_news_crawler_crawl_alertsCreateWithoutCrawlSourceInput, political_news_crawler_crawl_alertsUncheckedCreateWithoutCrawlSourceInput> | political_news_crawler_crawl_alertsCreateWithoutCrawlSourceInput[] | political_news_crawler_crawl_alertsUncheckedCreateWithoutCrawlSourceInput[]\n    connectOrCreate?: political_news_crawler_crawl_alertsCreateOrConnectWithoutCrawlSourceInput | political_news_crawler_crawl_alertsCreateOrConnectWithoutCrawlSourceInput[]\n    upsert?: political_news_crawler_crawl_alertsUpsertWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_crawl_alertsUpsertWithWhereUniqueWithoutCrawlSourceInput[]\n    createMany?: political_news_crawler_crawl_alertsCreateManyCrawlSourceInputEnvelope\n    set?: political_news_crawler_crawl_alertsWhereUniqueInput | political_news_crawler_crawl_alertsWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_alertsWhereUniqueInput | political_news_crawler_crawl_alertsWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_alertsWhereUniqueInput | political_news_crawler_crawl_alertsWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_alertsWhereUniqueInput | political_news_crawler_crawl_alertsWhereUniqueInput[]\n    update?: political_news_crawler_crawl_alertsUpdateWithWhereUniqueWithoutCrawlSourceInput | political_news_crawler_crawl_alertsUpdateWithWhereUniqueWithoutCrawlSourceInput[]\n    updateMany?: political_news_crawler_crawl_alertsUpdateManyWithWhereWithoutCrawlSourceInput | political_news_crawler_crawl_alertsUpdateManyWithWhereWithoutCrawlSourceInput[]\n    deleteMany?: political_news_crawler_crawl_alertsScalarWhereInput | political_news_crawler_crawl_alertsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateNestedManyWithoutCrawlPolicyInput = {\n    create?: XOR<political_news_crawler_crawl_schedulesCreateWithoutCrawlPolicyInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlPolicyInput> | political_news_crawler_crawl_schedulesCreateWithoutCrawlPolicyInput[] | political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlPolicyInput[]\n    connectOrCreate?: political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlPolicyInput | political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlPolicyInput[]\n    createMany?: political_news_crawler_crawl_schedulesCreateManyCrawlPolicyInputEnvelope\n    connect?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedCreateNestedManyWithoutCrawlPolicyInput = {\n    create?: XOR<political_news_crawler_crawl_schedulesCreateWithoutCrawlPolicyInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlPolicyInput> | political_news_crawler_crawl_schedulesCreateWithoutCrawlPolicyInput[] | political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlPolicyInput[]\n    connectOrCreate?: political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlPolicyInput | political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlPolicyInput[]\n    createMany?: political_news_crawler_crawl_schedulesCreateManyCrawlPolicyInputEnvelope\n    connect?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n  }\n\n  export type IntFieldUpdateOperationsInput = {\n    set?: number\n    increment?: number\n    decrement?: number\n    multiply?: number\n    divide?: number\n  }\n\n  export type FloatFieldUpdateOperationsInput = {\n    set?: number\n    increment?: number\n    decrement?: number\n    multiply?: number\n    divide?: number\n  }\n\n  export type political_news_crawler_crawl_schedulesUpdateManyWithoutCrawlPolicyNestedInput = {\n    create?: XOR<political_news_crawler_crawl_schedulesCreateWithoutCrawlPolicyInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlPolicyInput> | political_news_crawler_crawl_schedulesCreateWithoutCrawlPolicyInput[] | political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlPolicyInput[]\n    connectOrCreate?: political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlPolicyInput | political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlPolicyInput[]\n    upsert?: political_news_crawler_crawl_schedulesUpsertWithWhereUniqueWithoutCrawlPolicyInput | political_news_crawler_crawl_schedulesUpsertWithWhereUniqueWithoutCrawlPolicyInput[]\n    createMany?: political_news_crawler_crawl_schedulesCreateManyCrawlPolicyInputEnvelope\n    set?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    update?: political_news_crawler_crawl_schedulesUpdateWithWhereUniqueWithoutCrawlPolicyInput | political_news_crawler_crawl_schedulesUpdateWithWhereUniqueWithoutCrawlPolicyInput[]\n    updateMany?: political_news_crawler_crawl_schedulesUpdateManyWithWhereWithoutCrawlPolicyInput | political_news_crawler_crawl_schedulesUpdateManyWithWhereWithoutCrawlPolicyInput[]\n    deleteMany?: political_news_crawler_crawl_schedulesScalarWhereInput | political_news_crawler_crawl_schedulesScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedUpdateManyWithoutCrawlPolicyNestedInput = {\n    create?: XOR<political_news_crawler_crawl_schedulesCreateWithoutCrawlPolicyInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlPolicyInput> | political_news_crawler_crawl_schedulesCreateWithoutCrawlPolicyInput[] | political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlPolicyInput[]\n    connectOrCreate?: political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlPolicyInput | political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlPolicyInput[]\n    upsert?: political_news_crawler_crawl_schedulesUpsertWithWhereUniqueWithoutCrawlPolicyInput | political_news_crawler_crawl_schedulesUpsertWithWhereUniqueWithoutCrawlPolicyInput[]\n    createMany?: political_news_crawler_crawl_schedulesCreateManyCrawlPolicyInputEnvelope\n    set?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_schedulesWhereUniqueInput | political_news_crawler_crawl_schedulesWhereUniqueInput[]\n    update?: political_news_crawler_crawl_schedulesUpdateWithWhereUniqueWithoutCrawlPolicyInput | political_news_crawler_crawl_schedulesUpdateWithWhereUniqueWithoutCrawlPolicyInput[]\n    updateMany?: political_news_crawler_crawl_schedulesUpdateManyWithWhereWithoutCrawlPolicyInput | political_news_crawler_crawl_schedulesUpdateManyWithWhereWithoutCrawlPolicyInput[]\n    deleteMany?: political_news_crawler_crawl_schedulesScalarWhereInput | political_news_crawler_crawl_schedulesScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    create?: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_schedulesInput>\n    connectOrCreate?: political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_crawl_schedulesInput\n    connect?: political_news_crawler_crawl_sourcesWhereUniqueInput\n  }\n\n  export type political_news_crawler_crawl_policiesCreateNestedOneWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    create?: XOR<political_news_crawler_crawl_policiesCreateWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_policiesUncheckedCreateWithoutPolitical_news_crawler_crawl_schedulesInput>\n    connectOrCreate?: political_news_crawler_crawl_policiesCreateOrConnectWithoutPolitical_news_crawler_crawl_schedulesInput\n    connect?: political_news_crawler_crawl_policiesWhereUniqueInput\n  }\n\n  export type political_news_crawler_crawl_jobsCreateNestedManyWithoutCrawlScheduleInput = {\n    create?: XOR<political_news_crawler_crawl_jobsCreateWithoutCrawlScheduleInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlScheduleInput> | political_news_crawler_crawl_jobsCreateWithoutCrawlScheduleInput[] | political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlScheduleInput[]\n    connectOrCreate?: political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlScheduleInput | political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlScheduleInput[]\n    createMany?: political_news_crawler_crawl_jobsCreateManyCrawlScheduleInputEnvelope\n    connect?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedCreateNestedManyWithoutCrawlScheduleInput = {\n    create?: XOR<political_news_crawler_crawl_jobsCreateWithoutCrawlScheduleInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlScheduleInput> | political_news_crawler_crawl_jobsCreateWithoutCrawlScheduleInput[] | political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlScheduleInput[]\n    connectOrCreate?: political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlScheduleInput | political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlScheduleInput[]\n    createMany?: political_news_crawler_crawl_jobsCreateManyCrawlScheduleInputEnvelope\n    connect?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_schedulesNestedInput = {\n    create?: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_schedulesInput>\n    connectOrCreate?: political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_crawl_schedulesInput\n    upsert?: political_news_crawler_crawl_sourcesUpsertWithoutPolitical_news_crawler_crawl_schedulesInput\n    connect?: political_news_crawler_crawl_sourcesWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_crawl_sourcesUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_crawl_schedulesInput>, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_crawl_schedulesInput>\n  }\n\n  export type political_news_crawler_crawl_policiesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_schedulesNestedInput = {\n    create?: XOR<political_news_crawler_crawl_policiesCreateWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_policiesUncheckedCreateWithoutPolitical_news_crawler_crawl_schedulesInput>\n    connectOrCreate?: political_news_crawler_crawl_policiesCreateOrConnectWithoutPolitical_news_crawler_crawl_schedulesInput\n    upsert?: political_news_crawler_crawl_policiesUpsertWithoutPolitical_news_crawler_crawl_schedulesInput\n    connect?: political_news_crawler_crawl_policiesWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_crawl_policiesUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_policiesUpdateWithoutPolitical_news_crawler_crawl_schedulesInput>, political_news_crawler_crawl_policiesUncheckedUpdateWithoutPolitical_news_crawler_crawl_schedulesInput>\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateManyWithoutCrawlScheduleNestedInput = {\n    create?: XOR<political_news_crawler_crawl_jobsCreateWithoutCrawlScheduleInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlScheduleInput> | political_news_crawler_crawl_jobsCreateWithoutCrawlScheduleInput[] | political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlScheduleInput[]\n    connectOrCreate?: political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlScheduleInput | political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlScheduleInput[]\n    upsert?: political_news_crawler_crawl_jobsUpsertWithWhereUniqueWithoutCrawlScheduleInput | political_news_crawler_crawl_jobsUpsertWithWhereUniqueWithoutCrawlScheduleInput[]\n    createMany?: political_news_crawler_crawl_jobsCreateManyCrawlScheduleInputEnvelope\n    set?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    update?: political_news_crawler_crawl_jobsUpdateWithWhereUniqueWithoutCrawlScheduleInput | political_news_crawler_crawl_jobsUpdateWithWhereUniqueWithoutCrawlScheduleInput[]\n    updateMany?: political_news_crawler_crawl_jobsUpdateManyWithWhereWithoutCrawlScheduleInput | political_news_crawler_crawl_jobsUpdateManyWithWhereWithoutCrawlScheduleInput[]\n    deleteMany?: political_news_crawler_crawl_jobsScalarWhereInput | political_news_crawler_crawl_jobsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlScheduleNestedInput = {\n    create?: XOR<political_news_crawler_crawl_jobsCreateWithoutCrawlScheduleInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlScheduleInput> | political_news_crawler_crawl_jobsCreateWithoutCrawlScheduleInput[] | political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlScheduleInput[]\n    connectOrCreate?: political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlScheduleInput | political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlScheduleInput[]\n    upsert?: political_news_crawler_crawl_jobsUpsertWithWhereUniqueWithoutCrawlScheduleInput | political_news_crawler_crawl_jobsUpsertWithWhereUniqueWithoutCrawlScheduleInput[]\n    createMany?: political_news_crawler_crawl_jobsCreateManyCrawlScheduleInputEnvelope\n    set?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_jobsWhereUniqueInput | political_news_crawler_crawl_jobsWhereUniqueInput[]\n    update?: political_news_crawler_crawl_jobsUpdateWithWhereUniqueWithoutCrawlScheduleInput | political_news_crawler_crawl_jobsUpdateWithWhereUniqueWithoutCrawlScheduleInput[]\n    updateMany?: political_news_crawler_crawl_jobsUpdateManyWithWhereWithoutCrawlScheduleInput | political_news_crawler_crawl_jobsUpdateManyWithWhereWithoutCrawlScheduleInput[]\n    deleteMany?: political_news_crawler_crawl_jobsScalarWhereInput | political_news_crawler_crawl_jobsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_crawl_jobsInput = {\n    create?: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_jobsInput>\n    connectOrCreate?: political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_crawl_jobsInput\n    connect?: political_news_crawler_crawl_sourcesWhereUniqueInput\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateNestedOneWithoutPolitical_news_crawler_crawl_jobsInput = {\n    create?: XOR<political_news_crawler_crawl_schedulesCreateWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutPolitical_news_crawler_crawl_jobsInput>\n    connectOrCreate?: political_news_crawler_crawl_schedulesCreateOrConnectWithoutPolitical_news_crawler_crawl_jobsInput\n    connect?: political_news_crawler_crawl_schedulesWhereUniqueInput\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateNestedManyWithoutCrawlJobInput = {\n    create?: XOR<political_news_crawler_crawl_attemptsCreateWithoutCrawlJobInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutCrawlJobInput> | political_news_crawler_crawl_attemptsCreateWithoutCrawlJobInput[] | political_news_crawler_crawl_attemptsUncheckedCreateWithoutCrawlJobInput[]\n    connectOrCreate?: political_news_crawler_crawl_attemptsCreateOrConnectWithoutCrawlJobInput | political_news_crawler_crawl_attemptsCreateOrConnectWithoutCrawlJobInput[]\n    createMany?: political_news_crawler_crawl_attemptsCreateManyCrawlJobInputEnvelope\n    connect?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_raw_data_storageCreateNestedManyWithoutCrawlJobInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutCrawlJobInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlJobInput> | political_news_crawler_raw_data_storageCreateWithoutCrawlJobInput[] | political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlJobInput[]\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlJobInput | political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlJobInput[]\n    createMany?: political_news_crawler_raw_data_storageCreateManyCrawlJobInputEnvelope\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedCreateNestedManyWithoutCrawlJobInput = {\n    create?: XOR<political_news_crawler_crawl_attemptsCreateWithoutCrawlJobInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutCrawlJobInput> | political_news_crawler_crawl_attemptsCreateWithoutCrawlJobInput[] | political_news_crawler_crawl_attemptsUncheckedCreateWithoutCrawlJobInput[]\n    connectOrCreate?: political_news_crawler_crawl_attemptsCreateOrConnectWithoutCrawlJobInput | political_news_crawler_crawl_attemptsCreateOrConnectWithoutCrawlJobInput[]\n    createMany?: political_news_crawler_crawl_attemptsCreateManyCrawlJobInputEnvelope\n    connect?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedCreateNestedManyWithoutCrawlJobInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutCrawlJobInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlJobInput> | political_news_crawler_raw_data_storageCreateWithoutCrawlJobInput[] | political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlJobInput[]\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlJobInput | political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlJobInput[]\n    createMany?: political_news_crawler_raw_data_storageCreateManyCrawlJobInputEnvelope\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_jobsNestedInput = {\n    create?: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_jobsInput>\n    connectOrCreate?: political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_crawl_jobsInput\n    upsert?: political_news_crawler_crawl_sourcesUpsertWithoutPolitical_news_crawler_crawl_jobsInput\n    connect?: political_news_crawler_crawl_sourcesWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_crawl_sourcesUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_crawl_jobsInput>, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_crawl_jobsInput>\n  }\n\n  export type political_news_crawler_crawl_schedulesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_jobsNestedInput = {\n    create?: XOR<political_news_crawler_crawl_schedulesCreateWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutPolitical_news_crawler_crawl_jobsInput>\n    connectOrCreate?: political_news_crawler_crawl_schedulesCreateOrConnectWithoutPolitical_news_crawler_crawl_jobsInput\n    upsert?: political_news_crawler_crawl_schedulesUpsertWithoutPolitical_news_crawler_crawl_jobsInput\n    connect?: political_news_crawler_crawl_schedulesWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_crawl_schedulesUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_schedulesUpdateWithoutPolitical_news_crawler_crawl_jobsInput>, political_news_crawler_crawl_schedulesUncheckedUpdateWithoutPolitical_news_crawler_crawl_jobsInput>\n  }\n\n  export type political_news_crawler_crawl_attemptsUpdateManyWithoutCrawlJobNestedInput = {\n    create?: XOR<political_news_crawler_crawl_attemptsCreateWithoutCrawlJobInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutCrawlJobInput> | political_news_crawler_crawl_attemptsCreateWithoutCrawlJobInput[] | political_news_crawler_crawl_attemptsUncheckedCreateWithoutCrawlJobInput[]\n    connectOrCreate?: political_news_crawler_crawl_attemptsCreateOrConnectWithoutCrawlJobInput | political_news_crawler_crawl_attemptsCreateOrConnectWithoutCrawlJobInput[]\n    upsert?: political_news_crawler_crawl_attemptsUpsertWithWhereUniqueWithoutCrawlJobInput | political_news_crawler_crawl_attemptsUpsertWithWhereUniqueWithoutCrawlJobInput[]\n    createMany?: political_news_crawler_crawl_attemptsCreateManyCrawlJobInputEnvelope\n    set?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    update?: political_news_crawler_crawl_attemptsUpdateWithWhereUniqueWithoutCrawlJobInput | political_news_crawler_crawl_attemptsUpdateWithWhereUniqueWithoutCrawlJobInput[]\n    updateMany?: political_news_crawler_crawl_attemptsUpdateManyWithWhereWithoutCrawlJobInput | political_news_crawler_crawl_attemptsUpdateManyWithWhereWithoutCrawlJobInput[]\n    deleteMany?: political_news_crawler_crawl_attemptsScalarWhereInput | political_news_crawler_crawl_attemptsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateManyWithoutCrawlJobNestedInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutCrawlJobInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlJobInput> | political_news_crawler_raw_data_storageCreateWithoutCrawlJobInput[] | political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlJobInput[]\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlJobInput | political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlJobInput[]\n    upsert?: political_news_crawler_raw_data_storageUpsertWithWhereUniqueWithoutCrawlJobInput | political_news_crawler_raw_data_storageUpsertWithWhereUniqueWithoutCrawlJobInput[]\n    createMany?: political_news_crawler_raw_data_storageCreateManyCrawlJobInputEnvelope\n    set?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    disconnect?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    delete?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    update?: political_news_crawler_raw_data_storageUpdateWithWhereUniqueWithoutCrawlJobInput | political_news_crawler_raw_data_storageUpdateWithWhereUniqueWithoutCrawlJobInput[]\n    updateMany?: political_news_crawler_raw_data_storageUpdateManyWithWhereWithoutCrawlJobInput | political_news_crawler_raw_data_storageUpdateManyWithWhereWithoutCrawlJobInput[]\n    deleteMany?: political_news_crawler_raw_data_storageScalarWhereInput | political_news_crawler_raw_data_storageScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutCrawlJobNestedInput = {\n    create?: XOR<political_news_crawler_crawl_attemptsCreateWithoutCrawlJobInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutCrawlJobInput> | political_news_crawler_crawl_attemptsCreateWithoutCrawlJobInput[] | political_news_crawler_crawl_attemptsUncheckedCreateWithoutCrawlJobInput[]\n    connectOrCreate?: political_news_crawler_crawl_attemptsCreateOrConnectWithoutCrawlJobInput | political_news_crawler_crawl_attemptsCreateOrConnectWithoutCrawlJobInput[]\n    upsert?: political_news_crawler_crawl_attemptsUpsertWithWhereUniqueWithoutCrawlJobInput | political_news_crawler_crawl_attemptsUpsertWithWhereUniqueWithoutCrawlJobInput[]\n    createMany?: political_news_crawler_crawl_attemptsCreateManyCrawlJobInputEnvelope\n    set?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    update?: political_news_crawler_crawl_attemptsUpdateWithWhereUniqueWithoutCrawlJobInput | political_news_crawler_crawl_attemptsUpdateWithWhereUniqueWithoutCrawlJobInput[]\n    updateMany?: political_news_crawler_crawl_attemptsUpdateManyWithWhereWithoutCrawlJobInput | political_news_crawler_crawl_attemptsUpdateManyWithWhereWithoutCrawlJobInput[]\n    deleteMany?: political_news_crawler_crawl_attemptsScalarWhereInput | political_news_crawler_crawl_attemptsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlJobNestedInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutCrawlJobInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlJobInput> | political_news_crawler_raw_data_storageCreateWithoutCrawlJobInput[] | political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlJobInput[]\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlJobInput | political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlJobInput[]\n    upsert?: political_news_crawler_raw_data_storageUpsertWithWhereUniqueWithoutCrawlJobInput | political_news_crawler_raw_data_storageUpsertWithWhereUniqueWithoutCrawlJobInput[]\n    createMany?: political_news_crawler_raw_data_storageCreateManyCrawlJobInputEnvelope\n    set?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    disconnect?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    delete?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput | political_news_crawler_raw_data_storageWhereUniqueInput[]\n    update?: political_news_crawler_raw_data_storageUpdateWithWhereUniqueWithoutCrawlJobInput | political_news_crawler_raw_data_storageUpdateWithWhereUniqueWithoutCrawlJobInput[]\n    updateMany?: political_news_crawler_raw_data_storageUpdateManyWithWhereWithoutCrawlJobInput | political_news_crawler_raw_data_storageUpdateManyWithWhereWithoutCrawlJobInput[]\n    deleteMany?: political_news_crawler_raw_data_storageScalarWhereInput | political_news_crawler_raw_data_storageScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_jobsCreateNestedOneWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    create?: XOR<political_news_crawler_crawl_jobsCreateWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutPolitical_news_crawler_crawl_attemptsInput>\n    connectOrCreate?: political_news_crawler_crawl_jobsCreateOrConnectWithoutPolitical_news_crawler_crawl_attemptsInput\n    connect?: political_news_crawler_crawl_jobsWhereUniqueInput\n  }\n\n  export type political_news_crawler_raw_data_storageCreateNestedOneWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_crawl_attemptsInput>\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutPolitical_news_crawler_crawl_attemptsInput\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput\n  }\n\n  export type political_news_crawler_crawled_newsCreateNestedManyWithoutCrawlAttemptInput = {\n    create?: XOR<political_news_crawler_crawled_newsCreateWithoutCrawlAttemptInput, political_news_crawler_crawled_newsUncheckedCreateWithoutCrawlAttemptInput> | political_news_crawler_crawled_newsCreateWithoutCrawlAttemptInput[] | political_news_crawler_crawled_newsUncheckedCreateWithoutCrawlAttemptInput[]\n    connectOrCreate?: political_news_crawler_crawled_newsCreateOrConnectWithoutCrawlAttemptInput | political_news_crawler_crawled_newsCreateOrConnectWithoutCrawlAttemptInput[]\n    createMany?: political_news_crawler_crawled_newsCreateManyCrawlAttemptInputEnvelope\n    connect?: political_news_crawler_crawled_newsWhereUniqueInput | political_news_crawler_crawled_newsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawled_newsUncheckedCreateNestedManyWithoutCrawlAttemptInput = {\n    create?: XOR<political_news_crawler_crawled_newsCreateWithoutCrawlAttemptInput, political_news_crawler_crawled_newsUncheckedCreateWithoutCrawlAttemptInput> | political_news_crawler_crawled_newsCreateWithoutCrawlAttemptInput[] | political_news_crawler_crawled_newsUncheckedCreateWithoutCrawlAttemptInput[]\n    connectOrCreate?: political_news_crawler_crawled_newsCreateOrConnectWithoutCrawlAttemptInput | political_news_crawler_crawled_newsCreateOrConnectWithoutCrawlAttemptInput[]\n    createMany?: political_news_crawler_crawled_newsCreateManyCrawlAttemptInputEnvelope\n    connect?: political_news_crawler_crawled_newsWhereUniqueInput | political_news_crawler_crawled_newsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateOneRequiredWithoutPolitical_news_crawler_crawl_attemptsNestedInput = {\n    create?: XOR<political_news_crawler_crawl_jobsCreateWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutPolitical_news_crawler_crawl_attemptsInput>\n    connectOrCreate?: political_news_crawler_crawl_jobsCreateOrConnectWithoutPolitical_news_crawler_crawl_attemptsInput\n    upsert?: political_news_crawler_crawl_jobsUpsertWithoutPolitical_news_crawler_crawl_attemptsInput\n    connect?: political_news_crawler_crawl_jobsWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_crawl_jobsUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_crawl_jobsUpdateWithoutPolitical_news_crawler_crawl_attemptsInput>, political_news_crawler_crawl_jobsUncheckedUpdateWithoutPolitical_news_crawler_crawl_attemptsInput>\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateOneWithoutPolitical_news_crawler_crawl_attemptsNestedInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_crawl_attemptsInput>\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutPolitical_news_crawler_crawl_attemptsInput\n    upsert?: political_news_crawler_raw_data_storageUpsertWithoutPolitical_news_crawler_crawl_attemptsInput\n    disconnect?: political_news_crawler_raw_data_storageWhereInput | boolean\n    delete?: political_news_crawler_raw_data_storageWhereInput | boolean\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_raw_data_storageUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_raw_data_storageUpdateWithoutPolitical_news_crawler_crawl_attemptsInput>, political_news_crawler_raw_data_storageUncheckedUpdateWithoutPolitical_news_crawler_crawl_attemptsInput>\n  }\n\n  export type political_news_crawler_crawled_newsUpdateManyWithoutCrawlAttemptNestedInput = {\n    create?: XOR<political_news_crawler_crawled_newsCreateWithoutCrawlAttemptInput, political_news_crawler_crawled_newsUncheckedCreateWithoutCrawlAttemptInput> | political_news_crawler_crawled_newsCreateWithoutCrawlAttemptInput[] | political_news_crawler_crawled_newsUncheckedCreateWithoutCrawlAttemptInput[]\n    connectOrCreate?: political_news_crawler_crawled_newsCreateOrConnectWithoutCrawlAttemptInput | political_news_crawler_crawled_newsCreateOrConnectWithoutCrawlAttemptInput[]\n    upsert?: political_news_crawler_crawled_newsUpsertWithWhereUniqueWithoutCrawlAttemptInput | political_news_crawler_crawled_newsUpsertWithWhereUniqueWithoutCrawlAttemptInput[]\n    createMany?: political_news_crawler_crawled_newsCreateManyCrawlAttemptInputEnvelope\n    set?: political_news_crawler_crawled_newsWhereUniqueInput | political_news_crawler_crawled_newsWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawled_newsWhereUniqueInput | political_news_crawler_crawled_newsWhereUniqueInput[]\n    delete?: political_news_crawler_crawled_newsWhereUniqueInput | political_news_crawler_crawled_newsWhereUniqueInput[]\n    connect?: political_news_crawler_crawled_newsWhereUniqueInput | political_news_crawler_crawled_newsWhereUniqueInput[]\n    update?: political_news_crawler_crawled_newsUpdateWithWhereUniqueWithoutCrawlAttemptInput | political_news_crawler_crawled_newsUpdateWithWhereUniqueWithoutCrawlAttemptInput[]\n    updateMany?: political_news_crawler_crawled_newsUpdateManyWithWhereWithoutCrawlAttemptInput | political_news_crawler_crawled_newsUpdateManyWithWhereWithoutCrawlAttemptInput[]\n    deleteMany?: political_news_crawler_crawled_newsScalarWhereInput | political_news_crawler_crawled_newsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawled_newsUncheckedUpdateManyWithoutCrawlAttemptNestedInput = {\n    create?: XOR<political_news_crawler_crawled_newsCreateWithoutCrawlAttemptInput, political_news_crawler_crawled_newsUncheckedCreateWithoutCrawlAttemptInput> | political_news_crawler_crawled_newsCreateWithoutCrawlAttemptInput[] | political_news_crawler_crawled_newsUncheckedCreateWithoutCrawlAttemptInput[]\n    connectOrCreate?: political_news_crawler_crawled_newsCreateOrConnectWithoutCrawlAttemptInput | political_news_crawler_crawled_newsCreateOrConnectWithoutCrawlAttemptInput[]\n    upsert?: political_news_crawler_crawled_newsUpsertWithWhereUniqueWithoutCrawlAttemptInput | political_news_crawler_crawled_newsUpsertWithWhereUniqueWithoutCrawlAttemptInput[]\n    createMany?: political_news_crawler_crawled_newsCreateManyCrawlAttemptInputEnvelope\n    set?: political_news_crawler_crawled_newsWhereUniqueInput | political_news_crawler_crawled_newsWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawled_newsWhereUniqueInput | political_news_crawler_crawled_newsWhereUniqueInput[]\n    delete?: political_news_crawler_crawled_newsWhereUniqueInput | political_news_crawler_crawled_newsWhereUniqueInput[]\n    connect?: political_news_crawler_crawled_newsWhereUniqueInput | political_news_crawler_crawled_newsWhereUniqueInput[]\n    update?: political_news_crawler_crawled_newsUpdateWithWhereUniqueWithoutCrawlAttemptInput | political_news_crawler_crawled_newsUpdateWithWhereUniqueWithoutCrawlAttemptInput[]\n    updateMany?: political_news_crawler_crawled_newsUpdateManyWithWhereWithoutCrawlAttemptInput | political_news_crawler_crawled_newsUpdateManyWithWhereWithoutCrawlAttemptInput[]\n    deleteMany?: political_news_crawler_crawled_newsScalarWhereInput | political_news_crawler_crawled_newsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateNestedOneWithoutPolitical_news_crawler_crawled_newsInput = {\n    create?: XOR<political_news_crawler_crawl_attemptsCreateWithoutPolitical_news_crawler_crawled_newsInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutPolitical_news_crawler_crawled_newsInput>\n    connectOrCreate?: political_news_crawler_crawl_attemptsCreateOrConnectWithoutPolitical_news_crawler_crawled_newsInput\n    connect?: political_news_crawler_crawl_attemptsWhereUniqueInput\n  }\n\n  export type political_news_crawler_topic_mentionsCreateNestedManyWithoutCrawledNewsInput = {\n    create?: XOR<political_news_crawler_topic_mentionsCreateWithoutCrawledNewsInput, political_news_crawler_topic_mentionsUncheckedCreateWithoutCrawledNewsInput> | political_news_crawler_topic_mentionsCreateWithoutCrawledNewsInput[] | political_news_crawler_topic_mentionsUncheckedCreateWithoutCrawledNewsInput[]\n    connectOrCreate?: political_news_crawler_topic_mentionsCreateOrConnectWithoutCrawledNewsInput | political_news_crawler_topic_mentionsCreateOrConnectWithoutCrawledNewsInput[]\n    createMany?: political_news_crawler_topic_mentionsCreateManyCrawledNewsInputEnvelope\n    connect?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_topic_mentionsUncheckedCreateNestedManyWithoutCrawledNewsInput = {\n    create?: XOR<political_news_crawler_topic_mentionsCreateWithoutCrawledNewsInput, political_news_crawler_topic_mentionsUncheckedCreateWithoutCrawledNewsInput> | political_news_crawler_topic_mentionsCreateWithoutCrawledNewsInput[] | political_news_crawler_topic_mentionsUncheckedCreateWithoutCrawledNewsInput[]\n    connectOrCreate?: political_news_crawler_topic_mentionsCreateOrConnectWithoutCrawledNewsInput | political_news_crawler_topic_mentionsCreateOrConnectWithoutCrawledNewsInput[]\n    createMany?: political_news_crawler_topic_mentionsCreateManyCrawledNewsInputEnvelope\n    connect?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_attemptsUpdateOneRequiredWithoutPolitical_news_crawler_crawled_newsNestedInput = {\n    create?: XOR<political_news_crawler_crawl_attemptsCreateWithoutPolitical_news_crawler_crawled_newsInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutPolitical_news_crawler_crawled_newsInput>\n    connectOrCreate?: political_news_crawler_crawl_attemptsCreateOrConnectWithoutPolitical_news_crawler_crawled_newsInput\n    upsert?: political_news_crawler_crawl_attemptsUpsertWithoutPolitical_news_crawler_crawled_newsInput\n    connect?: political_news_crawler_crawl_attemptsWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_crawl_attemptsUpdateToOneWithWhereWithoutPolitical_news_crawler_crawled_newsInput, political_news_crawler_crawl_attemptsUpdateWithoutPolitical_news_crawler_crawled_newsInput>, political_news_crawler_crawl_attemptsUncheckedUpdateWithoutPolitical_news_crawler_crawled_newsInput>\n  }\n\n  export type political_news_crawler_topic_mentionsUpdateManyWithoutCrawledNewsNestedInput = {\n    create?: XOR<political_news_crawler_topic_mentionsCreateWithoutCrawledNewsInput, political_news_crawler_topic_mentionsUncheckedCreateWithoutCrawledNewsInput> | political_news_crawler_topic_mentionsCreateWithoutCrawledNewsInput[] | political_news_crawler_topic_mentionsUncheckedCreateWithoutCrawledNewsInput[]\n    connectOrCreate?: political_news_crawler_topic_mentionsCreateOrConnectWithoutCrawledNewsInput | political_news_crawler_topic_mentionsCreateOrConnectWithoutCrawledNewsInput[]\n    upsert?: political_news_crawler_topic_mentionsUpsertWithWhereUniqueWithoutCrawledNewsInput | political_news_crawler_topic_mentionsUpsertWithWhereUniqueWithoutCrawledNewsInput[]\n    createMany?: political_news_crawler_topic_mentionsCreateManyCrawledNewsInputEnvelope\n    set?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    disconnect?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    delete?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    connect?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    update?: political_news_crawler_topic_mentionsUpdateWithWhereUniqueWithoutCrawledNewsInput | political_news_crawler_topic_mentionsUpdateWithWhereUniqueWithoutCrawledNewsInput[]\n    updateMany?: political_news_crawler_topic_mentionsUpdateManyWithWhereWithoutCrawledNewsInput | political_news_crawler_topic_mentionsUpdateManyWithWhereWithoutCrawledNewsInput[]\n    deleteMany?: political_news_crawler_topic_mentionsScalarWhereInput | political_news_crawler_topic_mentionsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_topic_mentionsUncheckedUpdateManyWithoutCrawledNewsNestedInput = {\n    create?: XOR<political_news_crawler_topic_mentionsCreateWithoutCrawledNewsInput, political_news_crawler_topic_mentionsUncheckedCreateWithoutCrawledNewsInput> | political_news_crawler_topic_mentionsCreateWithoutCrawledNewsInput[] | political_news_crawler_topic_mentionsUncheckedCreateWithoutCrawledNewsInput[]\n    connectOrCreate?: political_news_crawler_topic_mentionsCreateOrConnectWithoutCrawledNewsInput | political_news_crawler_topic_mentionsCreateOrConnectWithoutCrawledNewsInput[]\n    upsert?: political_news_crawler_topic_mentionsUpsertWithWhereUniqueWithoutCrawledNewsInput | political_news_crawler_topic_mentionsUpsertWithWhereUniqueWithoutCrawledNewsInput[]\n    createMany?: political_news_crawler_topic_mentionsCreateManyCrawledNewsInputEnvelope\n    set?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    disconnect?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    delete?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    connect?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    update?: political_news_crawler_topic_mentionsUpdateWithWhereUniqueWithoutCrawledNewsInput | political_news_crawler_topic_mentionsUpdateWithWhereUniqueWithoutCrawledNewsInput[]\n    updateMany?: political_news_crawler_topic_mentionsUpdateManyWithWhereWithoutCrawledNewsInput | political_news_crawler_topic_mentionsUpdateManyWithWhereWithoutCrawledNewsInput[]\n    deleteMany?: political_news_crawler_topic_mentionsScalarWhereInput | political_news_crawler_topic_mentionsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_raw_data_storageInput = {\n    create?: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_raw_data_storageInput>\n    connectOrCreate?: political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_raw_data_storageInput\n    connect?: political_news_crawler_crawl_sourcesWhereUniqueInput\n  }\n\n  export type political_news_crawler_crawl_jobsCreateNestedOneWithoutPolitical_news_crawler_raw_data_storageInput = {\n    create?: XOR<political_news_crawler_crawl_jobsCreateWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutPolitical_news_crawler_raw_data_storageInput>\n    connectOrCreate?: political_news_crawler_crawl_jobsCreateOrConnectWithoutPolitical_news_crawler_raw_data_storageInput\n    connect?: political_news_crawler_crawl_jobsWhereUniqueInput\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateNestedManyWithoutRawDataStorageInput = {\n    create?: XOR<political_news_crawler_crawl_attemptsCreateWithoutRawDataStorageInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutRawDataStorageInput> | political_news_crawler_crawl_attemptsCreateWithoutRawDataStorageInput[] | political_news_crawler_crawl_attemptsUncheckedCreateWithoutRawDataStorageInput[]\n    connectOrCreate?: political_news_crawler_crawl_attemptsCreateOrConnectWithoutRawDataStorageInput | political_news_crawler_crawl_attemptsCreateOrConnectWithoutRawDataStorageInput[]\n    createMany?: political_news_crawler_crawl_attemptsCreateManyRawDataStorageInputEnvelope\n    connect?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_local_cache_filesCreateNestedManyWithoutRawDataStorageInput = {\n    create?: XOR<political_news_crawler_local_cache_filesCreateWithoutRawDataStorageInput, political_news_crawler_local_cache_filesUncheckedCreateWithoutRawDataStorageInput> | political_news_crawler_local_cache_filesCreateWithoutRawDataStorageInput[] | political_news_crawler_local_cache_filesUncheckedCreateWithoutRawDataStorageInput[]\n    connectOrCreate?: political_news_crawler_local_cache_filesCreateOrConnectWithoutRawDataStorageInput | political_news_crawler_local_cache_filesCreateOrConnectWithoutRawDataStorageInput[]\n    createMany?: political_news_crawler_local_cache_filesCreateManyRawDataStorageInputEnvelope\n    connect?: political_news_crawler_local_cache_filesWhereUniqueInput | political_news_crawler_local_cache_filesWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_processed_contentCreateNestedManyWithoutRawDataStorageInput = {\n    create?: XOR<political_news_crawler_processed_contentCreateWithoutRawDataStorageInput, political_news_crawler_processed_contentUncheckedCreateWithoutRawDataStorageInput> | political_news_crawler_processed_contentCreateWithoutRawDataStorageInput[] | political_news_crawler_processed_contentUncheckedCreateWithoutRawDataStorageInput[]\n    connectOrCreate?: political_news_crawler_processed_contentCreateOrConnectWithoutRawDataStorageInput | political_news_crawler_processed_contentCreateOrConnectWithoutRawDataStorageInput[]\n    createMany?: political_news_crawler_processed_contentCreateManyRawDataStorageInputEnvelope\n    connect?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedCreateNestedManyWithoutRawDataStorageInput = {\n    create?: XOR<political_news_crawler_crawl_attemptsCreateWithoutRawDataStorageInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutRawDataStorageInput> | political_news_crawler_crawl_attemptsCreateWithoutRawDataStorageInput[] | political_news_crawler_crawl_attemptsUncheckedCreateWithoutRawDataStorageInput[]\n    connectOrCreate?: political_news_crawler_crawl_attemptsCreateOrConnectWithoutRawDataStorageInput | political_news_crawler_crawl_attemptsCreateOrConnectWithoutRawDataStorageInput[]\n    createMany?: political_news_crawler_crawl_attemptsCreateManyRawDataStorageInputEnvelope\n    connect?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_local_cache_filesUncheckedCreateNestedManyWithoutRawDataStorageInput = {\n    create?: XOR<political_news_crawler_local_cache_filesCreateWithoutRawDataStorageInput, political_news_crawler_local_cache_filesUncheckedCreateWithoutRawDataStorageInput> | political_news_crawler_local_cache_filesCreateWithoutRawDataStorageInput[] | political_news_crawler_local_cache_filesUncheckedCreateWithoutRawDataStorageInput[]\n    connectOrCreate?: political_news_crawler_local_cache_filesCreateOrConnectWithoutRawDataStorageInput | political_news_crawler_local_cache_filesCreateOrConnectWithoutRawDataStorageInput[]\n    createMany?: political_news_crawler_local_cache_filesCreateManyRawDataStorageInputEnvelope\n    connect?: political_news_crawler_local_cache_filesWhereUniqueInput | political_news_crawler_local_cache_filesWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_processed_contentUncheckedCreateNestedManyWithoutRawDataStorageInput = {\n    create?: XOR<political_news_crawler_processed_contentCreateWithoutRawDataStorageInput, political_news_crawler_processed_contentUncheckedCreateWithoutRawDataStorageInput> | political_news_crawler_processed_contentCreateWithoutRawDataStorageInput[] | political_news_crawler_processed_contentUncheckedCreateWithoutRawDataStorageInput[]\n    connectOrCreate?: political_news_crawler_processed_contentCreateOrConnectWithoutRawDataStorageInput | political_news_crawler_processed_contentCreateOrConnectWithoutRawDataStorageInput[]\n    createMany?: political_news_crawler_processed_contentCreateManyRawDataStorageInputEnvelope\n    connect?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_raw_data_storageNestedInput = {\n    create?: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_raw_data_storageInput>\n    connectOrCreate?: political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_raw_data_storageInput\n    upsert?: political_news_crawler_crawl_sourcesUpsertWithoutPolitical_news_crawler_raw_data_storageInput\n    connect?: political_news_crawler_crawl_sourcesWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_crawl_sourcesUpdateToOneWithWhereWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_raw_data_storageInput>, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_raw_data_storageInput>\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateOneWithoutPolitical_news_crawler_raw_data_storageNestedInput = {\n    create?: XOR<political_news_crawler_crawl_jobsCreateWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutPolitical_news_crawler_raw_data_storageInput>\n    connectOrCreate?: political_news_crawler_crawl_jobsCreateOrConnectWithoutPolitical_news_crawler_raw_data_storageInput\n    upsert?: political_news_crawler_crawl_jobsUpsertWithoutPolitical_news_crawler_raw_data_storageInput\n    disconnect?: political_news_crawler_crawl_jobsWhereInput | boolean\n    delete?: political_news_crawler_crawl_jobsWhereInput | boolean\n    connect?: political_news_crawler_crawl_jobsWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_crawl_jobsUpdateToOneWithWhereWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_jobsUpdateWithoutPolitical_news_crawler_raw_data_storageInput>, political_news_crawler_crawl_jobsUncheckedUpdateWithoutPolitical_news_crawler_raw_data_storageInput>\n  }\n\n  export type political_news_crawler_crawl_attemptsUpdateManyWithoutRawDataStorageNestedInput = {\n    create?: XOR<political_news_crawler_crawl_attemptsCreateWithoutRawDataStorageInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutRawDataStorageInput> | political_news_crawler_crawl_attemptsCreateWithoutRawDataStorageInput[] | political_news_crawler_crawl_attemptsUncheckedCreateWithoutRawDataStorageInput[]\n    connectOrCreate?: political_news_crawler_crawl_attemptsCreateOrConnectWithoutRawDataStorageInput | political_news_crawler_crawl_attemptsCreateOrConnectWithoutRawDataStorageInput[]\n    upsert?: political_news_crawler_crawl_attemptsUpsertWithWhereUniqueWithoutRawDataStorageInput | political_news_crawler_crawl_attemptsUpsertWithWhereUniqueWithoutRawDataStorageInput[]\n    createMany?: political_news_crawler_crawl_attemptsCreateManyRawDataStorageInputEnvelope\n    set?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    update?: political_news_crawler_crawl_attemptsUpdateWithWhereUniqueWithoutRawDataStorageInput | political_news_crawler_crawl_attemptsUpdateWithWhereUniqueWithoutRawDataStorageInput[]\n    updateMany?: political_news_crawler_crawl_attemptsUpdateManyWithWhereWithoutRawDataStorageInput | political_news_crawler_crawl_attemptsUpdateManyWithWhereWithoutRawDataStorageInput[]\n    deleteMany?: political_news_crawler_crawl_attemptsScalarWhereInput | political_news_crawler_crawl_attemptsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_local_cache_filesUpdateManyWithoutRawDataStorageNestedInput = {\n    create?: XOR<political_news_crawler_local_cache_filesCreateWithoutRawDataStorageInput, political_news_crawler_local_cache_filesUncheckedCreateWithoutRawDataStorageInput> | political_news_crawler_local_cache_filesCreateWithoutRawDataStorageInput[] | political_news_crawler_local_cache_filesUncheckedCreateWithoutRawDataStorageInput[]\n    connectOrCreate?: political_news_crawler_local_cache_filesCreateOrConnectWithoutRawDataStorageInput | political_news_crawler_local_cache_filesCreateOrConnectWithoutRawDataStorageInput[]\n    upsert?: political_news_crawler_local_cache_filesUpsertWithWhereUniqueWithoutRawDataStorageInput | political_news_crawler_local_cache_filesUpsertWithWhereUniqueWithoutRawDataStorageInput[]\n    createMany?: political_news_crawler_local_cache_filesCreateManyRawDataStorageInputEnvelope\n    set?: political_news_crawler_local_cache_filesWhereUniqueInput | political_news_crawler_local_cache_filesWhereUniqueInput[]\n    disconnect?: political_news_crawler_local_cache_filesWhereUniqueInput | political_news_crawler_local_cache_filesWhereUniqueInput[]\n    delete?: political_news_crawler_local_cache_filesWhereUniqueInput | political_news_crawler_local_cache_filesWhereUniqueInput[]\n    connect?: political_news_crawler_local_cache_filesWhereUniqueInput | political_news_crawler_local_cache_filesWhereUniqueInput[]\n    update?: political_news_crawler_local_cache_filesUpdateWithWhereUniqueWithoutRawDataStorageInput | political_news_crawler_local_cache_filesUpdateWithWhereUniqueWithoutRawDataStorageInput[]\n    updateMany?: political_news_crawler_local_cache_filesUpdateManyWithWhereWithoutRawDataStorageInput | political_news_crawler_local_cache_filesUpdateManyWithWhereWithoutRawDataStorageInput[]\n    deleteMany?: political_news_crawler_local_cache_filesScalarWhereInput | political_news_crawler_local_cache_filesScalarWhereInput[]\n  }\n\n  export type political_news_crawler_processed_contentUpdateManyWithoutRawDataStorageNestedInput = {\n    create?: XOR<political_news_crawler_processed_contentCreateWithoutRawDataStorageInput, political_news_crawler_processed_contentUncheckedCreateWithoutRawDataStorageInput> | political_news_crawler_processed_contentCreateWithoutRawDataStorageInput[] | political_news_crawler_processed_contentUncheckedCreateWithoutRawDataStorageInput[]\n    connectOrCreate?: political_news_crawler_processed_contentCreateOrConnectWithoutRawDataStorageInput | political_news_crawler_processed_contentCreateOrConnectWithoutRawDataStorageInput[]\n    upsert?: political_news_crawler_processed_contentUpsertWithWhereUniqueWithoutRawDataStorageInput | political_news_crawler_processed_contentUpsertWithWhereUniqueWithoutRawDataStorageInput[]\n    createMany?: political_news_crawler_processed_contentCreateManyRawDataStorageInputEnvelope\n    set?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    disconnect?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    delete?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    connect?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    update?: political_news_crawler_processed_contentUpdateWithWhereUniqueWithoutRawDataStorageInput | political_news_crawler_processed_contentUpdateWithWhereUniqueWithoutRawDataStorageInput[]\n    updateMany?: political_news_crawler_processed_contentUpdateManyWithWhereWithoutRawDataStorageInput | political_news_crawler_processed_contentUpdateManyWithWhereWithoutRawDataStorageInput[]\n    deleteMany?: political_news_crawler_processed_contentScalarWhereInput | political_news_crawler_processed_contentScalarWhereInput[]\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutRawDataStorageNestedInput = {\n    create?: XOR<political_news_crawler_crawl_attemptsCreateWithoutRawDataStorageInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutRawDataStorageInput> | political_news_crawler_crawl_attemptsCreateWithoutRawDataStorageInput[] | political_news_crawler_crawl_attemptsUncheckedCreateWithoutRawDataStorageInput[]\n    connectOrCreate?: political_news_crawler_crawl_attemptsCreateOrConnectWithoutRawDataStorageInput | political_news_crawler_crawl_attemptsCreateOrConnectWithoutRawDataStorageInput[]\n    upsert?: political_news_crawler_crawl_attemptsUpsertWithWhereUniqueWithoutRawDataStorageInput | political_news_crawler_crawl_attemptsUpsertWithWhereUniqueWithoutRawDataStorageInput[]\n    createMany?: political_news_crawler_crawl_attemptsCreateManyRawDataStorageInputEnvelope\n    set?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    disconnect?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    delete?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    connect?: political_news_crawler_crawl_attemptsWhereUniqueInput | political_news_crawler_crawl_attemptsWhereUniqueInput[]\n    update?: political_news_crawler_crawl_attemptsUpdateWithWhereUniqueWithoutRawDataStorageInput | political_news_crawler_crawl_attemptsUpdateWithWhereUniqueWithoutRawDataStorageInput[]\n    updateMany?: political_news_crawler_crawl_attemptsUpdateManyWithWhereWithoutRawDataStorageInput | political_news_crawler_crawl_attemptsUpdateManyWithWhereWithoutRawDataStorageInput[]\n    deleteMany?: political_news_crawler_crawl_attemptsScalarWhereInput | political_news_crawler_crawl_attemptsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_local_cache_filesUncheckedUpdateManyWithoutRawDataStorageNestedInput = {\n    create?: XOR<political_news_crawler_local_cache_filesCreateWithoutRawDataStorageInput, political_news_crawler_local_cache_filesUncheckedCreateWithoutRawDataStorageInput> | political_news_crawler_local_cache_filesCreateWithoutRawDataStorageInput[] | political_news_crawler_local_cache_filesUncheckedCreateWithoutRawDataStorageInput[]\n    connectOrCreate?: political_news_crawler_local_cache_filesCreateOrConnectWithoutRawDataStorageInput | political_news_crawler_local_cache_filesCreateOrConnectWithoutRawDataStorageInput[]\n    upsert?: political_news_crawler_local_cache_filesUpsertWithWhereUniqueWithoutRawDataStorageInput | political_news_crawler_local_cache_filesUpsertWithWhereUniqueWithoutRawDataStorageInput[]\n    createMany?: political_news_crawler_local_cache_filesCreateManyRawDataStorageInputEnvelope\n    set?: political_news_crawler_local_cache_filesWhereUniqueInput | political_news_crawler_local_cache_filesWhereUniqueInput[]\n    disconnect?: political_news_crawler_local_cache_filesWhereUniqueInput | political_news_crawler_local_cache_filesWhereUniqueInput[]\n    delete?: political_news_crawler_local_cache_filesWhereUniqueInput | political_news_crawler_local_cache_filesWhereUniqueInput[]\n    connect?: political_news_crawler_local_cache_filesWhereUniqueInput | political_news_crawler_local_cache_filesWhereUniqueInput[]\n    update?: political_news_crawler_local_cache_filesUpdateWithWhereUniqueWithoutRawDataStorageInput | political_news_crawler_local_cache_filesUpdateWithWhereUniqueWithoutRawDataStorageInput[]\n    updateMany?: political_news_crawler_local_cache_filesUpdateManyWithWhereWithoutRawDataStorageInput | political_news_crawler_local_cache_filesUpdateManyWithWhereWithoutRawDataStorageInput[]\n    deleteMany?: political_news_crawler_local_cache_filesScalarWhereInput | political_news_crawler_local_cache_filesScalarWhereInput[]\n  }\n\n  export type political_news_crawler_processed_contentUncheckedUpdateManyWithoutRawDataStorageNestedInput = {\n    create?: XOR<political_news_crawler_processed_contentCreateWithoutRawDataStorageInput, political_news_crawler_processed_contentUncheckedCreateWithoutRawDataStorageInput> | political_news_crawler_processed_contentCreateWithoutRawDataStorageInput[] | political_news_crawler_processed_contentUncheckedCreateWithoutRawDataStorageInput[]\n    connectOrCreate?: political_news_crawler_processed_contentCreateOrConnectWithoutRawDataStorageInput | political_news_crawler_processed_contentCreateOrConnectWithoutRawDataStorageInput[]\n    upsert?: political_news_crawler_processed_contentUpsertWithWhereUniqueWithoutRawDataStorageInput | political_news_crawler_processed_contentUpsertWithWhereUniqueWithoutRawDataStorageInput[]\n    createMany?: political_news_crawler_processed_contentCreateManyRawDataStorageInputEnvelope\n    set?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    disconnect?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    delete?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    connect?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    update?: political_news_crawler_processed_contentUpdateWithWhereUniqueWithoutRawDataStorageInput | political_news_crawler_processed_contentUpdateWithWhereUniqueWithoutRawDataStorageInput[]\n    updateMany?: political_news_crawler_processed_contentUpdateManyWithWhereWithoutRawDataStorageInput | political_news_crawler_processed_contentUpdateManyWithWhereWithoutRawDataStorageInput[]\n    deleteMany?: political_news_crawler_processed_contentScalarWhereInput | political_news_crawler_processed_contentScalarWhereInput[]\n  }\n\n  export type political_news_crawler_raw_data_storageCreateNestedOneWithoutPolitical_news_crawler_local_cache_filesInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_local_cache_filesInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_local_cache_filesInput>\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutPolitical_news_crawler_local_cache_filesInput\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateOneRequiredWithoutPolitical_news_crawler_local_cache_filesNestedInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_local_cache_filesInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_local_cache_filesInput>\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutPolitical_news_crawler_local_cache_filesInput\n    upsert?: political_news_crawler_raw_data_storageUpsertWithoutPolitical_news_crawler_local_cache_filesInput\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_raw_data_storageUpdateToOneWithWhereWithoutPolitical_news_crawler_local_cache_filesInput, political_news_crawler_raw_data_storageUpdateWithoutPolitical_news_crawler_local_cache_filesInput>, political_news_crawler_raw_data_storageUncheckedUpdateWithoutPolitical_news_crawler_local_cache_filesInput>\n  }\n\n  export type political_news_crawler_raw_data_storageCreateNestedOneWithoutPolitical_news_crawler_processed_contentInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_processed_contentInput>\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutPolitical_news_crawler_processed_contentInput\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput\n  }\n\n  export type political_news_crawler_llm_jobsCreateNestedOneWithoutPolitical_news_crawler_processed_contentInput = {\n    create?: XOR<political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_processed_contentInput>\n    connectOrCreate?: political_news_crawler_llm_jobsCreateOrConnectWithoutPolitical_news_crawler_processed_contentInput\n    connect?: political_news_crawler_llm_jobsWhereUniqueInput\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateOneRequiredWithoutPolitical_news_crawler_processed_contentNestedInput = {\n    create?: XOR<political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_processed_contentInput>\n    connectOrCreate?: political_news_crawler_raw_data_storageCreateOrConnectWithoutPolitical_news_crawler_processed_contentInput\n    upsert?: political_news_crawler_raw_data_storageUpsertWithoutPolitical_news_crawler_processed_contentInput\n    connect?: political_news_crawler_raw_data_storageWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_raw_data_storageUpdateToOneWithWhereWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_raw_data_storageUpdateWithoutPolitical_news_crawler_processed_contentInput>, political_news_crawler_raw_data_storageUncheckedUpdateWithoutPolitical_news_crawler_processed_contentInput>\n  }\n\n  export type political_news_crawler_llm_jobsUpdateOneWithoutPolitical_news_crawler_processed_contentNestedInput = {\n    create?: XOR<political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_processed_contentInput>\n    connectOrCreate?: political_news_crawler_llm_jobsCreateOrConnectWithoutPolitical_news_crawler_processed_contentInput\n    upsert?: political_news_crawler_llm_jobsUpsertWithoutPolitical_news_crawler_processed_contentInput\n    disconnect?: political_news_crawler_llm_jobsWhereInput | boolean\n    delete?: political_news_crawler_llm_jobsWhereInput | boolean\n    connect?: political_news_crawler_llm_jobsWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_llm_jobsUpdateToOneWithWhereWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_llm_jobsUpdateWithoutPolitical_news_crawler_processed_contentInput>, political_news_crawler_llm_jobsUncheckedUpdateWithoutPolitical_news_crawler_processed_contentInput>\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_llm_jobsInput = {\n    create?: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_llm_jobsInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_llm_jobsInput>\n    connectOrCreate?: political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_llm_jobsInput\n    connect?: political_news_crawler_crawl_sourcesWhereUniqueInput\n  }\n\n  export type political_news_crawler_processed_contentCreateNestedManyWithoutLlmJobInput = {\n    create?: XOR<political_news_crawler_processed_contentCreateWithoutLlmJobInput, political_news_crawler_processed_contentUncheckedCreateWithoutLlmJobInput> | political_news_crawler_processed_contentCreateWithoutLlmJobInput[] | political_news_crawler_processed_contentUncheckedCreateWithoutLlmJobInput[]\n    connectOrCreate?: political_news_crawler_processed_contentCreateOrConnectWithoutLlmJobInput | political_news_crawler_processed_contentCreateOrConnectWithoutLlmJobInput[]\n    createMany?: political_news_crawler_processed_contentCreateManyLlmJobInputEnvelope\n    connect?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_llm_resultsCreateNestedManyWithoutLlmJobInput = {\n    create?: XOR<political_news_crawler_llm_resultsCreateWithoutLlmJobInput, political_news_crawler_llm_resultsUncheckedCreateWithoutLlmJobInput> | political_news_crawler_llm_resultsCreateWithoutLlmJobInput[] | political_news_crawler_llm_resultsUncheckedCreateWithoutLlmJobInput[]\n    connectOrCreate?: political_news_crawler_llm_resultsCreateOrConnectWithoutLlmJobInput | political_news_crawler_llm_resultsCreateOrConnectWithoutLlmJobInput[]\n    createMany?: political_news_crawler_llm_resultsCreateManyLlmJobInputEnvelope\n    connect?: political_news_crawler_llm_resultsWhereUniqueInput | political_news_crawler_llm_resultsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_processing_metadataCreateNestedManyWithoutLlmJobInput = {\n    create?: XOR<political_news_crawler_processing_metadataCreateWithoutLlmJobInput, political_news_crawler_processing_metadataUncheckedCreateWithoutLlmJobInput> | political_news_crawler_processing_metadataCreateWithoutLlmJobInput[] | political_news_crawler_processing_metadataUncheckedCreateWithoutLlmJobInput[]\n    connectOrCreate?: political_news_crawler_processing_metadataCreateOrConnectWithoutLlmJobInput | political_news_crawler_processing_metadataCreateOrConnectWithoutLlmJobInput[]\n    createMany?: political_news_crawler_processing_metadataCreateManyLlmJobInputEnvelope\n    connect?: political_news_crawler_processing_metadataWhereUniqueInput | political_news_crawler_processing_metadataWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_processed_contentUncheckedCreateNestedManyWithoutLlmJobInput = {\n    create?: XOR<political_news_crawler_processed_contentCreateWithoutLlmJobInput, political_news_crawler_processed_contentUncheckedCreateWithoutLlmJobInput> | political_news_crawler_processed_contentCreateWithoutLlmJobInput[] | political_news_crawler_processed_contentUncheckedCreateWithoutLlmJobInput[]\n    connectOrCreate?: political_news_crawler_processed_contentCreateOrConnectWithoutLlmJobInput | political_news_crawler_processed_contentCreateOrConnectWithoutLlmJobInput[]\n    createMany?: political_news_crawler_processed_contentCreateManyLlmJobInputEnvelope\n    connect?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_llm_resultsUncheckedCreateNestedManyWithoutLlmJobInput = {\n    create?: XOR<political_news_crawler_llm_resultsCreateWithoutLlmJobInput, political_news_crawler_llm_resultsUncheckedCreateWithoutLlmJobInput> | political_news_crawler_llm_resultsCreateWithoutLlmJobInput[] | political_news_crawler_llm_resultsUncheckedCreateWithoutLlmJobInput[]\n    connectOrCreate?: political_news_crawler_llm_resultsCreateOrConnectWithoutLlmJobInput | political_news_crawler_llm_resultsCreateOrConnectWithoutLlmJobInput[]\n    createMany?: political_news_crawler_llm_resultsCreateManyLlmJobInputEnvelope\n    connect?: political_news_crawler_llm_resultsWhereUniqueInput | political_news_crawler_llm_resultsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_processing_metadataUncheckedCreateNestedManyWithoutLlmJobInput = {\n    create?: XOR<political_news_crawler_processing_metadataCreateWithoutLlmJobInput, political_news_crawler_processing_metadataUncheckedCreateWithoutLlmJobInput> | political_news_crawler_processing_metadataCreateWithoutLlmJobInput[] | political_news_crawler_processing_metadataUncheckedCreateWithoutLlmJobInput[]\n    connectOrCreate?: political_news_crawler_processing_metadataCreateOrConnectWithoutLlmJobInput | political_news_crawler_processing_metadataCreateOrConnectWithoutLlmJobInput[]\n    createMany?: political_news_crawler_processing_metadataCreateManyLlmJobInputEnvelope\n    connect?: political_news_crawler_processing_metadataWhereUniqueInput | political_news_crawler_processing_metadataWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_llm_jobsNestedInput = {\n    create?: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_llm_jobsInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_llm_jobsInput>\n    connectOrCreate?: political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_llm_jobsInput\n    upsert?: political_news_crawler_crawl_sourcesUpsertWithoutPolitical_news_crawler_llm_jobsInput\n    connect?: political_news_crawler_crawl_sourcesWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_crawl_sourcesUpdateToOneWithWhereWithoutPolitical_news_crawler_llm_jobsInput, political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_llm_jobsInput>, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_llm_jobsInput>\n  }\n\n  export type political_news_crawler_processed_contentUpdateManyWithoutLlmJobNestedInput = {\n    create?: XOR<political_news_crawler_processed_contentCreateWithoutLlmJobInput, political_news_crawler_processed_contentUncheckedCreateWithoutLlmJobInput> | political_news_crawler_processed_contentCreateWithoutLlmJobInput[] | political_news_crawler_processed_contentUncheckedCreateWithoutLlmJobInput[]\n    connectOrCreate?: political_news_crawler_processed_contentCreateOrConnectWithoutLlmJobInput | political_news_crawler_processed_contentCreateOrConnectWithoutLlmJobInput[]\n    upsert?: political_news_crawler_processed_contentUpsertWithWhereUniqueWithoutLlmJobInput | political_news_crawler_processed_contentUpsertWithWhereUniqueWithoutLlmJobInput[]\n    createMany?: political_news_crawler_processed_contentCreateManyLlmJobInputEnvelope\n    set?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    disconnect?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    delete?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    connect?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    update?: political_news_crawler_processed_contentUpdateWithWhereUniqueWithoutLlmJobInput | political_news_crawler_processed_contentUpdateWithWhereUniqueWithoutLlmJobInput[]\n    updateMany?: political_news_crawler_processed_contentUpdateManyWithWhereWithoutLlmJobInput | political_news_crawler_processed_contentUpdateManyWithWhereWithoutLlmJobInput[]\n    deleteMany?: political_news_crawler_processed_contentScalarWhereInput | political_news_crawler_processed_contentScalarWhereInput[]\n  }\n\n  export type political_news_crawler_llm_resultsUpdateManyWithoutLlmJobNestedInput = {\n    create?: XOR<political_news_crawler_llm_resultsCreateWithoutLlmJobInput, political_news_crawler_llm_resultsUncheckedCreateWithoutLlmJobInput> | political_news_crawler_llm_resultsCreateWithoutLlmJobInput[] | political_news_crawler_llm_resultsUncheckedCreateWithoutLlmJobInput[]\n    connectOrCreate?: political_news_crawler_llm_resultsCreateOrConnectWithoutLlmJobInput | political_news_crawler_llm_resultsCreateOrConnectWithoutLlmJobInput[]\n    upsert?: political_news_crawler_llm_resultsUpsertWithWhereUniqueWithoutLlmJobInput | political_news_crawler_llm_resultsUpsertWithWhereUniqueWithoutLlmJobInput[]\n    createMany?: political_news_crawler_llm_resultsCreateManyLlmJobInputEnvelope\n    set?: political_news_crawler_llm_resultsWhereUniqueInput | political_news_crawler_llm_resultsWhereUniqueInput[]\n    disconnect?: political_news_crawler_llm_resultsWhereUniqueInput | political_news_crawler_llm_resultsWhereUniqueInput[]\n    delete?: political_news_crawler_llm_resultsWhereUniqueInput | political_news_crawler_llm_resultsWhereUniqueInput[]\n    connect?: political_news_crawler_llm_resultsWhereUniqueInput | political_news_crawler_llm_resultsWhereUniqueInput[]\n    update?: political_news_crawler_llm_resultsUpdateWithWhereUniqueWithoutLlmJobInput | political_news_crawler_llm_resultsUpdateWithWhereUniqueWithoutLlmJobInput[]\n    updateMany?: political_news_crawler_llm_resultsUpdateManyWithWhereWithoutLlmJobInput | political_news_crawler_llm_resultsUpdateManyWithWhereWithoutLlmJobInput[]\n    deleteMany?: political_news_crawler_llm_resultsScalarWhereInput | political_news_crawler_llm_resultsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_processing_metadataUpdateManyWithoutLlmJobNestedInput = {\n    create?: XOR<political_news_crawler_processing_metadataCreateWithoutLlmJobInput, political_news_crawler_processing_metadataUncheckedCreateWithoutLlmJobInput> | political_news_crawler_processing_metadataCreateWithoutLlmJobInput[] | political_news_crawler_processing_metadataUncheckedCreateWithoutLlmJobInput[]\n    connectOrCreate?: political_news_crawler_processing_metadataCreateOrConnectWithoutLlmJobInput | political_news_crawler_processing_metadataCreateOrConnectWithoutLlmJobInput[]\n    upsert?: political_news_crawler_processing_metadataUpsertWithWhereUniqueWithoutLlmJobInput | political_news_crawler_processing_metadataUpsertWithWhereUniqueWithoutLlmJobInput[]\n    createMany?: political_news_crawler_processing_metadataCreateManyLlmJobInputEnvelope\n    set?: political_news_crawler_processing_metadataWhereUniqueInput | political_news_crawler_processing_metadataWhereUniqueInput[]\n    disconnect?: political_news_crawler_processing_metadataWhereUniqueInput | political_news_crawler_processing_metadataWhereUniqueInput[]\n    delete?: political_news_crawler_processing_metadataWhereUniqueInput | political_news_crawler_processing_metadataWhereUniqueInput[]\n    connect?: political_news_crawler_processing_metadataWhereUniqueInput | political_news_crawler_processing_metadataWhereUniqueInput[]\n    update?: political_news_crawler_processing_metadataUpdateWithWhereUniqueWithoutLlmJobInput | political_news_crawler_processing_metadataUpdateWithWhereUniqueWithoutLlmJobInput[]\n    updateMany?: political_news_crawler_processing_metadataUpdateManyWithWhereWithoutLlmJobInput | political_news_crawler_processing_metadataUpdateManyWithWhereWithoutLlmJobInput[]\n    deleteMany?: political_news_crawler_processing_metadataScalarWhereInput | political_news_crawler_processing_metadataScalarWhereInput[]\n  }\n\n  export type political_news_crawler_processed_contentUncheckedUpdateManyWithoutLlmJobNestedInput = {\n    create?: XOR<political_news_crawler_processed_contentCreateWithoutLlmJobInput, political_news_crawler_processed_contentUncheckedCreateWithoutLlmJobInput> | political_news_crawler_processed_contentCreateWithoutLlmJobInput[] | political_news_crawler_processed_contentUncheckedCreateWithoutLlmJobInput[]\n    connectOrCreate?: political_news_crawler_processed_contentCreateOrConnectWithoutLlmJobInput | political_news_crawler_processed_contentCreateOrConnectWithoutLlmJobInput[]\n    upsert?: political_news_crawler_processed_contentUpsertWithWhereUniqueWithoutLlmJobInput | political_news_crawler_processed_contentUpsertWithWhereUniqueWithoutLlmJobInput[]\n    createMany?: political_news_crawler_processed_contentCreateManyLlmJobInputEnvelope\n    set?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    disconnect?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    delete?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    connect?: political_news_crawler_processed_contentWhereUniqueInput | political_news_crawler_processed_contentWhereUniqueInput[]\n    update?: political_news_crawler_processed_contentUpdateWithWhereUniqueWithoutLlmJobInput | political_news_crawler_processed_contentUpdateWithWhereUniqueWithoutLlmJobInput[]\n    updateMany?: political_news_crawler_processed_contentUpdateManyWithWhereWithoutLlmJobInput | political_news_crawler_processed_contentUpdateManyWithWhereWithoutLlmJobInput[]\n    deleteMany?: political_news_crawler_processed_contentScalarWhereInput | political_news_crawler_processed_contentScalarWhereInput[]\n  }\n\n  export type political_news_crawler_llm_resultsUncheckedUpdateManyWithoutLlmJobNestedInput = {\n    create?: XOR<political_news_crawler_llm_resultsCreateWithoutLlmJobInput, political_news_crawler_llm_resultsUncheckedCreateWithoutLlmJobInput> | political_news_crawler_llm_resultsCreateWithoutLlmJobInput[] | political_news_crawler_llm_resultsUncheckedCreateWithoutLlmJobInput[]\n    connectOrCreate?: political_news_crawler_llm_resultsCreateOrConnectWithoutLlmJobInput | political_news_crawler_llm_resultsCreateOrConnectWithoutLlmJobInput[]\n    upsert?: political_news_crawler_llm_resultsUpsertWithWhereUniqueWithoutLlmJobInput | political_news_crawler_llm_resultsUpsertWithWhereUniqueWithoutLlmJobInput[]\n    createMany?: political_news_crawler_llm_resultsCreateManyLlmJobInputEnvelope\n    set?: political_news_crawler_llm_resultsWhereUniqueInput | political_news_crawler_llm_resultsWhereUniqueInput[]\n    disconnect?: political_news_crawler_llm_resultsWhereUniqueInput | political_news_crawler_llm_resultsWhereUniqueInput[]\n    delete?: political_news_crawler_llm_resultsWhereUniqueInput | political_news_crawler_llm_resultsWhereUniqueInput[]\n    connect?: political_news_crawler_llm_resultsWhereUniqueInput | political_news_crawler_llm_resultsWhereUniqueInput[]\n    update?: political_news_crawler_llm_resultsUpdateWithWhereUniqueWithoutLlmJobInput | political_news_crawler_llm_resultsUpdateWithWhereUniqueWithoutLlmJobInput[]\n    updateMany?: political_news_crawler_llm_resultsUpdateManyWithWhereWithoutLlmJobInput | political_news_crawler_llm_resultsUpdateManyWithWhereWithoutLlmJobInput[]\n    deleteMany?: political_news_crawler_llm_resultsScalarWhereInput | political_news_crawler_llm_resultsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_processing_metadataUncheckedUpdateManyWithoutLlmJobNestedInput = {\n    create?: XOR<political_news_crawler_processing_metadataCreateWithoutLlmJobInput, political_news_crawler_processing_metadataUncheckedCreateWithoutLlmJobInput> | political_news_crawler_processing_metadataCreateWithoutLlmJobInput[] | political_news_crawler_processing_metadataUncheckedCreateWithoutLlmJobInput[]\n    connectOrCreate?: political_news_crawler_processing_metadataCreateOrConnectWithoutLlmJobInput | political_news_crawler_processing_metadataCreateOrConnectWithoutLlmJobInput[]\n    upsert?: political_news_crawler_processing_metadataUpsertWithWhereUniqueWithoutLlmJobInput | political_news_crawler_processing_metadataUpsertWithWhereUniqueWithoutLlmJobInput[]\n    createMany?: political_news_crawler_processing_metadataCreateManyLlmJobInputEnvelope\n    set?: political_news_crawler_processing_metadataWhereUniqueInput | political_news_crawler_processing_metadataWhereUniqueInput[]\n    disconnect?: political_news_crawler_processing_metadataWhereUniqueInput | political_news_crawler_processing_metadataWhereUniqueInput[]\n    delete?: political_news_crawler_processing_metadataWhereUniqueInput | political_news_crawler_processing_metadataWhereUniqueInput[]\n    connect?: political_news_crawler_processing_metadataWhereUniqueInput | political_news_crawler_processing_metadataWhereUniqueInput[]\n    update?: political_news_crawler_processing_metadataUpdateWithWhereUniqueWithoutLlmJobInput | political_news_crawler_processing_metadataUpdateWithWhereUniqueWithoutLlmJobInput[]\n    updateMany?: political_news_crawler_processing_metadataUpdateManyWithWhereWithoutLlmJobInput | political_news_crawler_processing_metadataUpdateManyWithWhereWithoutLlmJobInput[]\n    deleteMany?: political_news_crawler_processing_metadataScalarWhereInput | political_news_crawler_processing_metadataScalarWhereInput[]\n  }\n\n  export type political_news_crawler_llm_jobsCreateNestedOneWithoutPolitical_news_crawler_llm_resultsInput = {\n    create?: XOR<political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_llm_resultsInput, political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_llm_resultsInput>\n    connectOrCreate?: political_news_crawler_llm_jobsCreateOrConnectWithoutPolitical_news_crawler_llm_resultsInput\n    connect?: political_news_crawler_llm_jobsWhereUniqueInput\n  }\n\n  export type political_news_crawler_llm_jobsUpdateOneRequiredWithoutPolitical_news_crawler_llm_resultsNestedInput = {\n    create?: XOR<political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_llm_resultsInput, political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_llm_resultsInput>\n    connectOrCreate?: political_news_crawler_llm_jobsCreateOrConnectWithoutPolitical_news_crawler_llm_resultsInput\n    upsert?: political_news_crawler_llm_jobsUpsertWithoutPolitical_news_crawler_llm_resultsInput\n    connect?: political_news_crawler_llm_jobsWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_llm_jobsUpdateToOneWithWhereWithoutPolitical_news_crawler_llm_resultsInput, political_news_crawler_llm_jobsUpdateWithoutPolitical_news_crawler_llm_resultsInput>, political_news_crawler_llm_jobsUncheckedUpdateWithoutPolitical_news_crawler_llm_resultsInput>\n  }\n\n  export type political_news_crawler_llm_jobsCreateNestedOneWithoutPolitical_news_crawler_processing_metadataInput = {\n    create?: XOR<political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_processing_metadataInput, political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_processing_metadataInput>\n    connectOrCreate?: political_news_crawler_llm_jobsCreateOrConnectWithoutPolitical_news_crawler_processing_metadataInput\n    connect?: political_news_crawler_llm_jobsWhereUniqueInput\n  }\n\n  export type political_news_crawler_llm_jobsUpdateOneRequiredWithoutPolitical_news_crawler_processing_metadataNestedInput = {\n    create?: XOR<political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_processing_metadataInput, political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_processing_metadataInput>\n    connectOrCreate?: political_news_crawler_llm_jobsCreateOrConnectWithoutPolitical_news_crawler_processing_metadataInput\n    upsert?: political_news_crawler_llm_jobsUpsertWithoutPolitical_news_crawler_processing_metadataInput\n    connect?: political_news_crawler_llm_jobsWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_llm_jobsUpdateToOneWithWhereWithoutPolitical_news_crawler_processing_metadataInput, political_news_crawler_llm_jobsUpdateWithoutPolitical_news_crawler_processing_metadataInput>, political_news_crawler_llm_jobsUncheckedUpdateWithoutPolitical_news_crawler_processing_metadataInput>\n  }\n\n  export type political_news_crawler_popular_topicsCreateNestedOneWithoutPolitical_news_crawler_popularity_scoresInput = {\n    create?: XOR<political_news_crawler_popular_topicsCreateWithoutPolitical_news_crawler_popularity_scoresInput, political_news_crawler_popular_topicsUncheckedCreateWithoutPolitical_news_crawler_popularity_scoresInput>\n    connectOrCreate?: political_news_crawler_popular_topicsCreateOrConnectWithoutPolitical_news_crawler_popularity_scoresInput\n    connect?: political_news_crawler_popular_topicsWhereUniqueInput\n  }\n\n  export type political_news_crawler_popular_topicsUpdateOneRequiredWithoutPolitical_news_crawler_popularity_scoresNestedInput = {\n    create?: XOR<political_news_crawler_popular_topicsCreateWithoutPolitical_news_crawler_popularity_scoresInput, political_news_crawler_popular_topicsUncheckedCreateWithoutPolitical_news_crawler_popularity_scoresInput>\n    connectOrCreate?: political_news_crawler_popular_topicsCreateOrConnectWithoutPolitical_news_crawler_popularity_scoresInput\n    upsert?: political_news_crawler_popular_topicsUpsertWithoutPolitical_news_crawler_popularity_scoresInput\n    connect?: political_news_crawler_popular_topicsWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_popular_topicsUpdateToOneWithWhereWithoutPolitical_news_crawler_popularity_scoresInput, political_news_crawler_popular_topicsUpdateWithoutPolitical_news_crawler_popularity_scoresInput>, political_news_crawler_popular_topicsUncheckedUpdateWithoutPolitical_news_crawler_popularity_scoresInput>\n  }\n\n  export type political_news_crawler_popularity_scoresCreateNestedManyWithoutPopularTopicInput = {\n    create?: XOR<political_news_crawler_popularity_scoresCreateWithoutPopularTopicInput, political_news_crawler_popularity_scoresUncheckedCreateWithoutPopularTopicInput> | political_news_crawler_popularity_scoresCreateWithoutPopularTopicInput[] | political_news_crawler_popularity_scoresUncheckedCreateWithoutPopularTopicInput[]\n    connectOrCreate?: political_news_crawler_popularity_scoresCreateOrConnectWithoutPopularTopicInput | political_news_crawler_popularity_scoresCreateOrConnectWithoutPopularTopicInput[]\n    createMany?: political_news_crawler_popularity_scoresCreateManyPopularTopicInputEnvelope\n    connect?: political_news_crawler_popularity_scoresWhereUniqueInput | political_news_crawler_popularity_scoresWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_topic_mentionsCreateNestedManyWithoutPopularTopicInput = {\n    create?: XOR<political_news_crawler_topic_mentionsCreateWithoutPopularTopicInput, political_news_crawler_topic_mentionsUncheckedCreateWithoutPopularTopicInput> | political_news_crawler_topic_mentionsCreateWithoutPopularTopicInput[] | political_news_crawler_topic_mentionsUncheckedCreateWithoutPopularTopicInput[]\n    connectOrCreate?: political_news_crawler_topic_mentionsCreateOrConnectWithoutPopularTopicInput | political_news_crawler_topic_mentionsCreateOrConnectWithoutPopularTopicInput[]\n    createMany?: political_news_crawler_topic_mentionsCreateManyPopularTopicInputEnvelope\n    connect?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_popularity_scoresUncheckedCreateNestedManyWithoutPopularTopicInput = {\n    create?: XOR<political_news_crawler_popularity_scoresCreateWithoutPopularTopicInput, political_news_crawler_popularity_scoresUncheckedCreateWithoutPopularTopicInput> | political_news_crawler_popularity_scoresCreateWithoutPopularTopicInput[] | political_news_crawler_popularity_scoresUncheckedCreateWithoutPopularTopicInput[]\n    connectOrCreate?: political_news_crawler_popularity_scoresCreateOrConnectWithoutPopularTopicInput | political_news_crawler_popularity_scoresCreateOrConnectWithoutPopularTopicInput[]\n    createMany?: political_news_crawler_popularity_scoresCreateManyPopularTopicInputEnvelope\n    connect?: political_news_crawler_popularity_scoresWhereUniqueInput | political_news_crawler_popularity_scoresWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_topic_mentionsUncheckedCreateNestedManyWithoutPopularTopicInput = {\n    create?: XOR<political_news_crawler_topic_mentionsCreateWithoutPopularTopicInput, political_news_crawler_topic_mentionsUncheckedCreateWithoutPopularTopicInput> | political_news_crawler_topic_mentionsCreateWithoutPopularTopicInput[] | political_news_crawler_topic_mentionsUncheckedCreateWithoutPopularTopicInput[]\n    connectOrCreate?: political_news_crawler_topic_mentionsCreateOrConnectWithoutPopularTopicInput | political_news_crawler_topic_mentionsCreateOrConnectWithoutPopularTopicInput[]\n    createMany?: political_news_crawler_topic_mentionsCreateManyPopularTopicInputEnvelope\n    connect?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n  }\n\n  export type political_news_crawler_popularity_scoresUpdateManyWithoutPopularTopicNestedInput = {\n    create?: XOR<political_news_crawler_popularity_scoresCreateWithoutPopularTopicInput, political_news_crawler_popularity_scoresUncheckedCreateWithoutPopularTopicInput> | political_news_crawler_popularity_scoresCreateWithoutPopularTopicInput[] | political_news_crawler_popularity_scoresUncheckedCreateWithoutPopularTopicInput[]\n    connectOrCreate?: political_news_crawler_popularity_scoresCreateOrConnectWithoutPopularTopicInput | political_news_crawler_popularity_scoresCreateOrConnectWithoutPopularTopicInput[]\n    upsert?: political_news_crawler_popularity_scoresUpsertWithWhereUniqueWithoutPopularTopicInput | political_news_crawler_popularity_scoresUpsertWithWhereUniqueWithoutPopularTopicInput[]\n    createMany?: political_news_crawler_popularity_scoresCreateManyPopularTopicInputEnvelope\n    set?: political_news_crawler_popularity_scoresWhereUniqueInput | political_news_crawler_popularity_scoresWhereUniqueInput[]\n    disconnect?: political_news_crawler_popularity_scoresWhereUniqueInput | political_news_crawler_popularity_scoresWhereUniqueInput[]\n    delete?: political_news_crawler_popularity_scoresWhereUniqueInput | political_news_crawler_popularity_scoresWhereUniqueInput[]\n    connect?: political_news_crawler_popularity_scoresWhereUniqueInput | political_news_crawler_popularity_scoresWhereUniqueInput[]\n    update?: political_news_crawler_popularity_scoresUpdateWithWhereUniqueWithoutPopularTopicInput | political_news_crawler_popularity_scoresUpdateWithWhereUniqueWithoutPopularTopicInput[]\n    updateMany?: political_news_crawler_popularity_scoresUpdateManyWithWhereWithoutPopularTopicInput | political_news_crawler_popularity_scoresUpdateManyWithWhereWithoutPopularTopicInput[]\n    deleteMany?: political_news_crawler_popularity_scoresScalarWhereInput | political_news_crawler_popularity_scoresScalarWhereInput[]\n  }\n\n  export type political_news_crawler_topic_mentionsUpdateManyWithoutPopularTopicNestedInput = {\n    create?: XOR<political_news_crawler_topic_mentionsCreateWithoutPopularTopicInput, political_news_crawler_topic_mentionsUncheckedCreateWithoutPopularTopicInput> | political_news_crawler_topic_mentionsCreateWithoutPopularTopicInput[] | political_news_crawler_topic_mentionsUncheckedCreateWithoutPopularTopicInput[]\n    connectOrCreate?: political_news_crawler_topic_mentionsCreateOrConnectWithoutPopularTopicInput | political_news_crawler_topic_mentionsCreateOrConnectWithoutPopularTopicInput[]\n    upsert?: political_news_crawler_topic_mentionsUpsertWithWhereUniqueWithoutPopularTopicInput | political_news_crawler_topic_mentionsUpsertWithWhereUniqueWithoutPopularTopicInput[]\n    createMany?: political_news_crawler_topic_mentionsCreateManyPopularTopicInputEnvelope\n    set?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    disconnect?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    delete?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    connect?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    update?: political_news_crawler_topic_mentionsUpdateWithWhereUniqueWithoutPopularTopicInput | political_news_crawler_topic_mentionsUpdateWithWhereUniqueWithoutPopularTopicInput[]\n    updateMany?: political_news_crawler_topic_mentionsUpdateManyWithWhereWithoutPopularTopicInput | political_news_crawler_topic_mentionsUpdateManyWithWhereWithoutPopularTopicInput[]\n    deleteMany?: political_news_crawler_topic_mentionsScalarWhereInput | political_news_crawler_topic_mentionsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_popularity_scoresUncheckedUpdateManyWithoutPopularTopicNestedInput = {\n    create?: XOR<political_news_crawler_popularity_scoresCreateWithoutPopularTopicInput, political_news_crawler_popularity_scoresUncheckedCreateWithoutPopularTopicInput> | political_news_crawler_popularity_scoresCreateWithoutPopularTopicInput[] | political_news_crawler_popularity_scoresUncheckedCreateWithoutPopularTopicInput[]\n    connectOrCreate?: political_news_crawler_popularity_scoresCreateOrConnectWithoutPopularTopicInput | political_news_crawler_popularity_scoresCreateOrConnectWithoutPopularTopicInput[]\n    upsert?: political_news_crawler_popularity_scoresUpsertWithWhereUniqueWithoutPopularTopicInput | political_news_crawler_popularity_scoresUpsertWithWhereUniqueWithoutPopularTopicInput[]\n    createMany?: political_news_crawler_popularity_scoresCreateManyPopularTopicInputEnvelope\n    set?: political_news_crawler_popularity_scoresWhereUniqueInput | political_news_crawler_popularity_scoresWhereUniqueInput[]\n    disconnect?: political_news_crawler_popularity_scoresWhereUniqueInput | political_news_crawler_popularity_scoresWhereUniqueInput[]\n    delete?: political_news_crawler_popularity_scoresWhereUniqueInput | political_news_crawler_popularity_scoresWhereUniqueInput[]\n    connect?: political_news_crawler_popularity_scoresWhereUniqueInput | political_news_crawler_popularity_scoresWhereUniqueInput[]\n    update?: political_news_crawler_popularity_scoresUpdateWithWhereUniqueWithoutPopularTopicInput | political_news_crawler_popularity_scoresUpdateWithWhereUniqueWithoutPopularTopicInput[]\n    updateMany?: political_news_crawler_popularity_scoresUpdateManyWithWhereWithoutPopularTopicInput | political_news_crawler_popularity_scoresUpdateManyWithWhereWithoutPopularTopicInput[]\n    deleteMany?: political_news_crawler_popularity_scoresScalarWhereInput | political_news_crawler_popularity_scoresScalarWhereInput[]\n  }\n\n  export type political_news_crawler_topic_mentionsUncheckedUpdateManyWithoutPopularTopicNestedInput = {\n    create?: XOR<political_news_crawler_topic_mentionsCreateWithoutPopularTopicInput, political_news_crawler_topic_mentionsUncheckedCreateWithoutPopularTopicInput> | political_news_crawler_topic_mentionsCreateWithoutPopularTopicInput[] | political_news_crawler_topic_mentionsUncheckedCreateWithoutPopularTopicInput[]\n    connectOrCreate?: political_news_crawler_topic_mentionsCreateOrConnectWithoutPopularTopicInput | political_news_crawler_topic_mentionsCreateOrConnectWithoutPopularTopicInput[]\n    upsert?: political_news_crawler_topic_mentionsUpsertWithWhereUniqueWithoutPopularTopicInput | political_news_crawler_topic_mentionsUpsertWithWhereUniqueWithoutPopularTopicInput[]\n    createMany?: political_news_crawler_topic_mentionsCreateManyPopularTopicInputEnvelope\n    set?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    disconnect?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    delete?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    connect?: political_news_crawler_topic_mentionsWhereUniqueInput | political_news_crawler_topic_mentionsWhereUniqueInput[]\n    update?: political_news_crawler_topic_mentionsUpdateWithWhereUniqueWithoutPopularTopicInput | political_news_crawler_topic_mentionsUpdateWithWhereUniqueWithoutPopularTopicInput[]\n    updateMany?: political_news_crawler_topic_mentionsUpdateManyWithWhereWithoutPopularTopicInput | political_news_crawler_topic_mentionsUpdateManyWithWhereWithoutPopularTopicInput[]\n    deleteMany?: political_news_crawler_topic_mentionsScalarWhereInput | political_news_crawler_topic_mentionsScalarWhereInput[]\n  }\n\n  export type political_news_crawler_popular_topicsCreateNestedOneWithoutPolitical_news_crawler_topic_mentionsInput = {\n    create?: XOR<political_news_crawler_popular_topicsCreateWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_popular_topicsUncheckedCreateWithoutPolitical_news_crawler_topic_mentionsInput>\n    connectOrCreate?: political_news_crawler_popular_topicsCreateOrConnectWithoutPolitical_news_crawler_topic_mentionsInput\n    connect?: political_news_crawler_popular_topicsWhereUniqueInput\n  }\n\n  export type political_news_crawler_crawled_newsCreateNestedOneWithoutPolitical_news_crawler_topic_mentionsInput = {\n    create?: XOR<political_news_crawler_crawled_newsCreateWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_crawled_newsUncheckedCreateWithoutPolitical_news_crawler_topic_mentionsInput>\n    connectOrCreate?: political_news_crawler_crawled_newsCreateOrConnectWithoutPolitical_news_crawler_topic_mentionsInput\n    connect?: political_news_crawler_crawled_newsWhereUniqueInput\n  }\n\n  export type political_news_crawler_popular_topicsUpdateOneRequiredWithoutPolitical_news_crawler_topic_mentionsNestedInput = {\n    create?: XOR<political_news_crawler_popular_topicsCreateWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_popular_topicsUncheckedCreateWithoutPolitical_news_crawler_topic_mentionsInput>\n    connectOrCreate?: political_news_crawler_popular_topicsCreateOrConnectWithoutPolitical_news_crawler_topic_mentionsInput\n    upsert?: political_news_crawler_popular_topicsUpsertWithoutPolitical_news_crawler_topic_mentionsInput\n    connect?: political_news_crawler_popular_topicsWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_popular_topicsUpdateToOneWithWhereWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_popular_topicsUpdateWithoutPolitical_news_crawler_topic_mentionsInput>, political_news_crawler_popular_topicsUncheckedUpdateWithoutPolitical_news_crawler_topic_mentionsInput>\n  }\n\n  export type political_news_crawler_crawled_newsUpdateOneRequiredWithoutPolitical_news_crawler_topic_mentionsNestedInput = {\n    create?: XOR<political_news_crawler_crawled_newsCreateWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_crawled_newsUncheckedCreateWithoutPolitical_news_crawler_topic_mentionsInput>\n    connectOrCreate?: political_news_crawler_crawled_newsCreateOrConnectWithoutPolitical_news_crawler_topic_mentionsInput\n    upsert?: political_news_crawler_crawled_newsUpsertWithoutPolitical_news_crawler_topic_mentionsInput\n    connect?: political_news_crawler_crawled_newsWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_crawled_newsUpdateToOneWithWhereWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_crawled_newsUpdateWithoutPolitical_news_crawler_topic_mentionsInput>, political_news_crawler_crawled_newsUncheckedUpdateWithoutPolitical_news_crawler_topic_mentionsInput>\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_crawl_alertsInput = {\n    create?: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_alertsInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_alertsInput>\n    connectOrCreate?: political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_crawl_alertsInput\n    connect?: political_news_crawler_crawl_sourcesWhereUniqueInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_alertsNestedInput = {\n    create?: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_alertsInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_alertsInput>\n    connectOrCreate?: political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_crawl_alertsInput\n    upsert?: political_news_crawler_crawl_sourcesUpsertWithoutPolitical_news_crawler_crawl_alertsInput\n    connect?: political_news_crawler_crawl_sourcesWhereUniqueInput\n    update?: XOR<XOR<political_news_crawler_crawl_sourcesUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_alertsInput, political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_crawl_alertsInput>, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_crawl_alertsInput>\n  }\n\n  export type NestedUuidFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel>\n    in?: string[] | ListStringFieldRefInput<$PrismaModel>\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel>\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    not?: NestedUuidFilter<$PrismaModel> | string\n  }\n\n  export type NestedStringFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel>\n    in?: string[] | ListStringFieldRefInput<$PrismaModel>\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel>\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    contains?: string | StringFieldRefInput<$PrismaModel>\n    startsWith?: string | StringFieldRefInput<$PrismaModel>\n    endsWith?: string | StringFieldRefInput<$PrismaModel>\n    not?: NestedStringFilter<$PrismaModel> | string\n  }\n\n  export type NestedBoolFilter<$PrismaModel = never> = {\n    equals?: boolean | BooleanFieldRefInput<$PrismaModel>\n    not?: NestedBoolFilter<$PrismaModel> | boolean\n  }\n\n  export type NestedStringNullableFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel> | null\n    in?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    contains?: string | StringFieldRefInput<$PrismaModel>\n    startsWith?: string | StringFieldRefInput<$PrismaModel>\n    endsWith?: string | StringFieldRefInput<$PrismaModel>\n    not?: NestedStringNullableFilter<$PrismaModel> | string | null\n  }\n\n  export type NestedDateTimeFilter<$PrismaModel = never> = {\n    equals?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    in?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel>\n    notIn?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel>\n    lt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    lte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    not?: NestedDateTimeFilter<$PrismaModel> | Date | string\n  }\n\n  export type NestedDateTimeNullableFilter<$PrismaModel = never> = {\n    equals?: Date | string | DateTimeFieldRefInput<$PrismaModel> | null\n    in?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel> | null\n    notIn?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel> | null\n    lt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    lte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    not?: NestedDateTimeNullableFilter<$PrismaModel> | Date | string | null\n  }\n\n  export type NestedUuidWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel>\n    in?: string[] | ListStringFieldRefInput<$PrismaModel>\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel>\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    not?: NestedUuidWithAggregatesFilter<$PrismaModel> | string\n    _count?: NestedIntFilter<$PrismaModel>\n    _min?: NestedStringFilter<$PrismaModel>\n    _max?: NestedStringFilter<$PrismaModel>\n  }\n\n  export type NestedIntFilter<$PrismaModel = never> = {\n    equals?: number | IntFieldRefInput<$PrismaModel>\n    in?: number[] | ListIntFieldRefInput<$PrismaModel>\n    notIn?: number[] | ListIntFieldRefInput<$PrismaModel>\n    lt?: number | IntFieldRefInput<$PrismaModel>\n    lte?: number | IntFieldRefInput<$PrismaModel>\n    gt?: number | IntFieldRefInput<$PrismaModel>\n    gte?: number | IntFieldRefInput<$PrismaModel>\n    not?: NestedIntFilter<$PrismaModel> | number\n  }\n\n  export type NestedStringWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel>\n    in?: string[] | ListStringFieldRefInput<$PrismaModel>\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel>\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    contains?: string | StringFieldRefInput<$PrismaModel>\n    startsWith?: string | StringFieldRefInput<$PrismaModel>\n    endsWith?: string | StringFieldRefInput<$PrismaModel>\n    not?: NestedStringWithAggregatesFilter<$PrismaModel> | string\n    _count?: NestedIntFilter<$PrismaModel>\n    _min?: NestedStringFilter<$PrismaModel>\n    _max?: NestedStringFilter<$PrismaModel>\n  }\n\n  export type NestedBoolWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: boolean | BooleanFieldRefInput<$PrismaModel>\n    not?: NestedBoolWithAggregatesFilter<$PrismaModel> | boolean\n    _count?: NestedIntFilter<$PrismaModel>\n    _min?: NestedBoolFilter<$PrismaModel>\n    _max?: NestedBoolFilter<$PrismaModel>\n  }\n\n  export type NestedStringNullableWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel> | null\n    in?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    contains?: string | StringFieldRefInput<$PrismaModel>\n    startsWith?: string | StringFieldRefInput<$PrismaModel>\n    endsWith?: string | StringFieldRefInput<$PrismaModel>\n    not?: NestedStringNullableWithAggregatesFilter<$PrismaModel> | string | null\n    _count?: NestedIntNullableFilter<$PrismaModel>\n    _min?: NestedStringNullableFilter<$PrismaModel>\n    _max?: NestedStringNullableFilter<$PrismaModel>\n  }\n\n  export type NestedIntNullableFilter<$PrismaModel = never> = {\n    equals?: number | IntFieldRefInput<$PrismaModel> | null\n    in?: number[] | ListIntFieldRefInput<$PrismaModel> | null\n    notIn?: number[] | ListIntFieldRefInput<$PrismaModel> | null\n    lt?: number | IntFieldRefInput<$PrismaModel>\n    lte?: number | IntFieldRefInput<$PrismaModel>\n    gt?: number | IntFieldRefInput<$PrismaModel>\n    gte?: number | IntFieldRefInput<$PrismaModel>\n    not?: NestedIntNullableFilter<$PrismaModel> | number | null\n  }\n\n  export type NestedDateTimeWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    in?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel>\n    notIn?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel>\n    lt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    lte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    not?: NestedDateTimeWithAggregatesFilter<$PrismaModel> | Date | string\n    _count?: NestedIntFilter<$PrismaModel>\n    _min?: NestedDateTimeFilter<$PrismaModel>\n    _max?: NestedDateTimeFilter<$PrismaModel>\n  }\n\n  export type NestedDateTimeNullableWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: Date | string | DateTimeFieldRefInput<$PrismaModel> | null\n    in?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel> | null\n    notIn?: Date[] | string[] | ListDateTimeFieldRefInput<$PrismaModel> | null\n    lt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    lte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gt?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    gte?: Date | string | DateTimeFieldRefInput<$PrismaModel>\n    not?: NestedDateTimeNullableWithAggregatesFilter<$PrismaModel> | Date | string | null\n    _count?: NestedIntNullableFilter<$PrismaModel>\n    _min?: NestedDateTimeNullableFilter<$PrismaModel>\n    _max?: NestedDateTimeNullableFilter<$PrismaModel>\n  }\n\n  export type NestedFloatFilter<$PrismaModel = never> = {\n    equals?: number | FloatFieldRefInput<$PrismaModel>\n    in?: number[] | ListFloatFieldRefInput<$PrismaModel>\n    notIn?: number[] | ListFloatFieldRefInput<$PrismaModel>\n    lt?: number | FloatFieldRefInput<$PrismaModel>\n    lte?: number | FloatFieldRefInput<$PrismaModel>\n    gt?: number | FloatFieldRefInput<$PrismaModel>\n    gte?: number | FloatFieldRefInput<$PrismaModel>\n    not?: NestedFloatFilter<$PrismaModel> | number\n  }\n\n  export type NestedIntWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: number | IntFieldRefInput<$PrismaModel>\n    in?: number[] | ListIntFieldRefInput<$PrismaModel>\n    notIn?: number[] | ListIntFieldRefInput<$PrismaModel>\n    lt?: number | IntFieldRefInput<$PrismaModel>\n    lte?: number | IntFieldRefInput<$PrismaModel>\n    gt?: number | IntFieldRefInput<$PrismaModel>\n    gte?: number | IntFieldRefInput<$PrismaModel>\n    not?: NestedIntWithAggregatesFilter<$PrismaModel> | number\n    _count?: NestedIntFilter<$PrismaModel>\n    _avg?: NestedFloatFilter<$PrismaModel>\n    _sum?: NestedIntFilter<$PrismaModel>\n    _min?: NestedIntFilter<$PrismaModel>\n    _max?: NestedIntFilter<$PrismaModel>\n  }\n\n  export type NestedFloatWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: number | FloatFieldRefInput<$PrismaModel>\n    in?: number[] | ListFloatFieldRefInput<$PrismaModel>\n    notIn?: number[] | ListFloatFieldRefInput<$PrismaModel>\n    lt?: number | FloatFieldRefInput<$PrismaModel>\n    lte?: number | FloatFieldRefInput<$PrismaModel>\n    gt?: number | FloatFieldRefInput<$PrismaModel>\n    gte?: number | FloatFieldRefInput<$PrismaModel>\n    not?: NestedFloatWithAggregatesFilter<$PrismaModel> | number\n    _count?: NestedIntFilter<$PrismaModel>\n    _avg?: NestedFloatFilter<$PrismaModel>\n    _sum?: NestedFloatFilter<$PrismaModel>\n    _min?: NestedFloatFilter<$PrismaModel>\n    _max?: NestedFloatFilter<$PrismaModel>\n  }\n\n  export type NestedUuidNullableFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel> | null\n    in?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    not?: NestedUuidNullableFilter<$PrismaModel> | string | null\n  }\n\n  export type NestedUuidNullableWithAggregatesFilter<$PrismaModel = never> = {\n    equals?: string | StringFieldRefInput<$PrismaModel> | null\n    in?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    notIn?: string[] | ListStringFieldRefInput<$PrismaModel> | null\n    lt?: string | StringFieldRefInput<$PrismaModel>\n    lte?: string | StringFieldRefInput<$PrismaModel>\n    gt?: string | StringFieldRefInput<$PrismaModel>\n    gte?: string | StringFieldRefInput<$PrismaModel>\n    not?: NestedUuidNullableWithAggregatesFilter<$PrismaModel> | string | null\n    _count?: NestedIntNullableFilter<$PrismaModel>\n    _min?: NestedStringNullableFilter<$PrismaModel>\n    _max?: NestedStringNullableFilter<$PrismaModel>\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateWithoutCrawlSourceInput = {\n    id: string\n    schedule_expression: string\n    last_crawled_at?: Date | string | null\n    next_crawl_at?: Date | string | null\n    is_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawlPolicy: political_news_crawler_crawl_policiesCreateNestedOneWithoutPolitical_news_crawler_crawl_schedulesInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsCreateNestedManyWithoutCrawlScheduleInput\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlSourceInput = {\n    id: string\n    crawl_policy_id: string\n    schedule_expression: string\n    last_crawled_at?: Date | string | null\n    next_crawl_at?: Date | string | null\n    is_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedCreateNestedManyWithoutCrawlScheduleInput\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlSourceInput = {\n    where: political_news_crawler_crawl_schedulesWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_schedulesCreateWithoutCrawlSourceInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateManyCrawlSourceInputEnvelope = {\n    data: political_news_crawler_crawl_schedulesCreateManyCrawlSourceInput | political_news_crawler_crawl_schedulesCreateManyCrawlSourceInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_crawl_jobsCreateWithoutCrawlSourceInput = {\n    id: string\n    active: boolean\n    last_run_started_at?: Date | string | null\n    last_run_completed_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawlSchedule: political_news_crawler_crawl_schedulesCreateNestedOneWithoutPolitical_news_crawler_crawl_jobsInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsCreateNestedManyWithoutCrawlJobInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageCreateNestedManyWithoutCrawlJobInput\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlSourceInput = {\n    id: string\n    crawl_schedule_id: string\n    active: boolean\n    last_run_started_at?: Date | string | null\n    last_run_completed_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedCreateNestedManyWithoutCrawlJobInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedCreateNestedManyWithoutCrawlJobInput\n  }\n\n  export type political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlSourceInput = {\n    where: political_news_crawler_crawl_jobsWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_jobsCreateWithoutCrawlSourceInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_crawl_jobsCreateManyCrawlSourceInputEnvelope = {\n    data: political_news_crawler_crawl_jobsCreateManyCrawlSourceInput | political_news_crawler_crawl_jobsCreateManyCrawlSourceInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_raw_data_storageCreateWithoutCrawlSourceInput = {\n    id: string\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    crawlJob?: political_news_crawler_crawl_jobsCreateNestedOneWithoutPolitical_news_crawler_raw_data_storageInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentCreateNestedManyWithoutRawDataStorageInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlSourceInput = {\n    id: string\n    crawl_job_id?: string | null\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUncheckedCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedCreateNestedManyWithoutRawDataStorageInput\n  }\n\n  export type political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlSourceInput = {\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n    create: XOR<political_news_crawler_raw_data_storageCreateWithoutCrawlSourceInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_raw_data_storageCreateManyCrawlSourceInputEnvelope = {\n    data: political_news_crawler_raw_data_storageCreateManyCrawlSourceInput | political_news_crawler_raw_data_storageCreateManyCrawlSourceInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_llm_jobsCreateWithoutCrawlSourceInput = {\n    id: string\n    status: string\n    parameters: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataCreateNestedManyWithoutLlmJobInput\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedCreateWithoutCrawlSourceInput = {\n    id: string\n    status: string\n    parameters: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsUncheckedCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataUncheckedCreateNestedManyWithoutLlmJobInput\n  }\n\n  export type political_news_crawler_llm_jobsCreateOrConnectWithoutCrawlSourceInput = {\n    where: political_news_crawler_llm_jobsWhereUniqueInput\n    create: XOR<political_news_crawler_llm_jobsCreateWithoutCrawlSourceInput, political_news_crawler_llm_jobsUncheckedCreateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_llm_jobsCreateManyCrawlSourceInputEnvelope = {\n    data: political_news_crawler_llm_jobsCreateManyCrawlSourceInput | political_news_crawler_llm_jobsCreateManyCrawlSourceInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_crawl_alertsCreateWithoutCrawlSourceInput = {\n    id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_crawl_alertsUncheckedCreateWithoutCrawlSourceInput = {\n    id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_crawl_alertsCreateOrConnectWithoutCrawlSourceInput = {\n    where: political_news_crawler_crawl_alertsWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_alertsCreateWithoutCrawlSourceInput, political_news_crawler_crawl_alertsUncheckedCreateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_crawl_alertsCreateManyCrawlSourceInputEnvelope = {\n    data: political_news_crawler_crawl_alertsCreateManyCrawlSourceInput | political_news_crawler_crawl_alertsCreateManyCrawlSourceInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_crawl_schedulesUpsertWithWhereUniqueWithoutCrawlSourceInput = {\n    where: political_news_crawler_crawl_schedulesWhereUniqueInput\n    update: XOR<political_news_crawler_crawl_schedulesUpdateWithoutCrawlSourceInput, political_news_crawler_crawl_schedulesUncheckedUpdateWithoutCrawlSourceInput>\n    create: XOR<political_news_crawler_crawl_schedulesCreateWithoutCrawlSourceInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_crawl_schedulesUpdateWithWhereUniqueWithoutCrawlSourceInput = {\n    where: political_news_crawler_crawl_schedulesWhereUniqueInput\n    data: XOR<political_news_crawler_crawl_schedulesUpdateWithoutCrawlSourceInput, political_news_crawler_crawl_schedulesUncheckedUpdateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_crawl_schedulesUpdateManyWithWhereWithoutCrawlSourceInput = {\n    where: political_news_crawler_crawl_schedulesScalarWhereInput\n    data: XOR<political_news_crawler_crawl_schedulesUpdateManyMutationInput, political_news_crawler_crawl_schedulesUncheckedUpdateManyWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_crawl_schedulesScalarWhereInput = {\n    AND?: political_news_crawler_crawl_schedulesScalarWhereInput | political_news_crawler_crawl_schedulesScalarWhereInput[]\n    OR?: political_news_crawler_crawl_schedulesScalarWhereInput[]\n    NOT?: political_news_crawler_crawl_schedulesScalarWhereInput | political_news_crawler_crawl_schedulesScalarWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_crawl_schedules\"> | string\n    crawl_source_id?: UuidFilter<\"political_news_crawler_crawl_schedules\"> | string\n    crawl_policy_id?: UuidFilter<\"political_news_crawler_crawl_schedules\"> | string\n    schedule_expression?: StringFilter<\"political_news_crawler_crawl_schedules\"> | string\n    last_crawled_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_schedules\"> | Date | string | null\n    next_crawl_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_schedules\"> | Date | string | null\n    is_enabled?: BoolFilter<\"political_news_crawler_crawl_schedules\"> | boolean\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_schedules\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_schedules\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_schedules\"> | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_jobsUpsertWithWhereUniqueWithoutCrawlSourceInput = {\n    where: political_news_crawler_crawl_jobsWhereUniqueInput\n    update: XOR<political_news_crawler_crawl_jobsUpdateWithoutCrawlSourceInput, political_news_crawler_crawl_jobsUncheckedUpdateWithoutCrawlSourceInput>\n    create: XOR<political_news_crawler_crawl_jobsCreateWithoutCrawlSourceInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateWithWhereUniqueWithoutCrawlSourceInput = {\n    where: political_news_crawler_crawl_jobsWhereUniqueInput\n    data: XOR<political_news_crawler_crawl_jobsUpdateWithoutCrawlSourceInput, political_news_crawler_crawl_jobsUncheckedUpdateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateManyWithWhereWithoutCrawlSourceInput = {\n    where: political_news_crawler_crawl_jobsScalarWhereInput\n    data: XOR<political_news_crawler_crawl_jobsUpdateManyMutationInput, political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_crawl_jobsScalarWhereInput = {\n    AND?: political_news_crawler_crawl_jobsScalarWhereInput | political_news_crawler_crawl_jobsScalarWhereInput[]\n    OR?: political_news_crawler_crawl_jobsScalarWhereInput[]\n    NOT?: political_news_crawler_crawl_jobsScalarWhereInput | political_news_crawler_crawl_jobsScalarWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_crawl_jobs\"> | string\n    crawl_source_id?: UuidFilter<\"political_news_crawler_crawl_jobs\"> | string\n    crawl_schedule_id?: UuidFilter<\"political_news_crawler_crawl_jobs\"> | string\n    active?: BoolFilter<\"political_news_crawler_crawl_jobs\"> | boolean\n    last_run_started_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_jobs\"> | Date | string | null\n    last_run_completed_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_jobs\"> | Date | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_jobs\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_jobs\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_jobs\"> | Date | string | null\n  }\n\n  export type political_news_crawler_raw_data_storageUpsertWithWhereUniqueWithoutCrawlSourceInput = {\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n    update: XOR<political_news_crawler_raw_data_storageUpdateWithoutCrawlSourceInput, political_news_crawler_raw_data_storageUncheckedUpdateWithoutCrawlSourceInput>\n    create: XOR<political_news_crawler_raw_data_storageCreateWithoutCrawlSourceInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateWithWhereUniqueWithoutCrawlSourceInput = {\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n    data: XOR<political_news_crawler_raw_data_storageUpdateWithoutCrawlSourceInput, political_news_crawler_raw_data_storageUncheckedUpdateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateManyWithWhereWithoutCrawlSourceInput = {\n    where: political_news_crawler_raw_data_storageScalarWhereInput\n    data: XOR<political_news_crawler_raw_data_storageUpdateManyMutationInput, political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_raw_data_storageScalarWhereInput = {\n    AND?: political_news_crawler_raw_data_storageScalarWhereInput | political_news_crawler_raw_data_storageScalarWhereInput[]\n    OR?: political_news_crawler_raw_data_storageScalarWhereInput[]\n    NOT?: political_news_crawler_raw_data_storageScalarWhereInput | political_news_crawler_raw_data_storageScalarWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_raw_data_storage\"> | string\n    crawl_source_id?: UuidFilter<\"political_news_crawler_raw_data_storage\"> | string\n    crawl_job_id?: UuidNullableFilter<\"political_news_crawler_raw_data_storage\"> | string | null\n    storage_key?: StringFilter<\"political_news_crawler_raw_data_storage\"> | string\n    file_format?: StringFilter<\"political_news_crawler_raw_data_storage\"> | string\n    file_size_bytes?: IntFilter<\"political_news_crawler_raw_data_storage\"> | number\n    checksum?: StringNullableFilter<\"political_news_crawler_raw_data_storage\"> | string | null\n    crawl_timestamp?: DateTimeFilter<\"political_news_crawler_raw_data_storage\"> | Date | string\n    created_at?: DateTimeFilter<\"political_news_crawler_raw_data_storage\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_raw_data_storage\"> | Date | string\n  }\n\n  export type political_news_crawler_llm_jobsUpsertWithWhereUniqueWithoutCrawlSourceInput = {\n    where: political_news_crawler_llm_jobsWhereUniqueInput\n    update: XOR<political_news_crawler_llm_jobsUpdateWithoutCrawlSourceInput, political_news_crawler_llm_jobsUncheckedUpdateWithoutCrawlSourceInput>\n    create: XOR<political_news_crawler_llm_jobsCreateWithoutCrawlSourceInput, political_news_crawler_llm_jobsUncheckedCreateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_llm_jobsUpdateWithWhereUniqueWithoutCrawlSourceInput = {\n    where: political_news_crawler_llm_jobsWhereUniqueInput\n    data: XOR<political_news_crawler_llm_jobsUpdateWithoutCrawlSourceInput, political_news_crawler_llm_jobsUncheckedUpdateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_llm_jobsUpdateManyWithWhereWithoutCrawlSourceInput = {\n    where: political_news_crawler_llm_jobsScalarWhereInput\n    data: XOR<political_news_crawler_llm_jobsUpdateManyMutationInput, political_news_crawler_llm_jobsUncheckedUpdateManyWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_llm_jobsScalarWhereInput = {\n    AND?: political_news_crawler_llm_jobsScalarWhereInput | political_news_crawler_llm_jobsScalarWhereInput[]\n    OR?: political_news_crawler_llm_jobsScalarWhereInput[]\n    NOT?: political_news_crawler_llm_jobsScalarWhereInput | political_news_crawler_llm_jobsScalarWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_llm_jobs\"> | string\n    crawl_source_id?: UuidFilter<\"political_news_crawler_llm_jobs\"> | string\n    status?: StringFilter<\"political_news_crawler_llm_jobs\"> | string\n    parameters?: StringFilter<\"political_news_crawler_llm_jobs\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_llm_jobs\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_llm_jobs\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_llm_jobs\"> | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_alertsUpsertWithWhereUniqueWithoutCrawlSourceInput = {\n    where: political_news_crawler_crawl_alertsWhereUniqueInput\n    update: XOR<political_news_crawler_crawl_alertsUpdateWithoutCrawlSourceInput, political_news_crawler_crawl_alertsUncheckedUpdateWithoutCrawlSourceInput>\n    create: XOR<political_news_crawler_crawl_alertsCreateWithoutCrawlSourceInput, political_news_crawler_crawl_alertsUncheckedCreateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_crawl_alertsUpdateWithWhereUniqueWithoutCrawlSourceInput = {\n    where: political_news_crawler_crawl_alertsWhereUniqueInput\n    data: XOR<political_news_crawler_crawl_alertsUpdateWithoutCrawlSourceInput, political_news_crawler_crawl_alertsUncheckedUpdateWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_crawl_alertsUpdateManyWithWhereWithoutCrawlSourceInput = {\n    where: political_news_crawler_crawl_alertsScalarWhereInput\n    data: XOR<political_news_crawler_crawl_alertsUpdateManyMutationInput, political_news_crawler_crawl_alertsUncheckedUpdateManyWithoutCrawlSourceInput>\n  }\n\n  export type political_news_crawler_crawl_alertsScalarWhereInput = {\n    AND?: political_news_crawler_crawl_alertsScalarWhereInput | political_news_crawler_crawl_alertsScalarWhereInput[]\n    OR?: political_news_crawler_crawl_alertsScalarWhereInput[]\n    NOT?: political_news_crawler_crawl_alertsScalarWhereInput | political_news_crawler_crawl_alertsScalarWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_crawl_alerts\"> | string\n    crawl_source_id?: UuidFilter<\"political_news_crawler_crawl_alerts\"> | string\n    alert_type?: StringFilter<\"political_news_crawler_crawl_alerts\"> | string\n    message?: StringFilter<\"political_news_crawler_crawl_alerts\"> | string\n    severity?: StringFilter<\"political_news_crawler_crawl_alerts\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_alerts\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_alerts\"> | Date | string\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateWithoutCrawlPolicyInput = {\n    id: string\n    schedule_expression: string\n    last_crawled_at?: Date | string | null\n    next_crawl_at?: Date | string | null\n    is_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_crawl_schedulesInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsCreateNestedManyWithoutCrawlScheduleInput\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlPolicyInput = {\n    id: string\n    crawl_source_id: string\n    schedule_expression: string\n    last_crawled_at?: Date | string | null\n    next_crawl_at?: Date | string | null\n    is_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedCreateNestedManyWithoutCrawlScheduleInput\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateOrConnectWithoutCrawlPolicyInput = {\n    where: political_news_crawler_crawl_schedulesWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_schedulesCreateWithoutCrawlPolicyInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlPolicyInput>\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateManyCrawlPolicyInputEnvelope = {\n    data: political_news_crawler_crawl_schedulesCreateManyCrawlPolicyInput | political_news_crawler_crawl_schedulesCreateManyCrawlPolicyInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_crawl_schedulesUpsertWithWhereUniqueWithoutCrawlPolicyInput = {\n    where: political_news_crawler_crawl_schedulesWhereUniqueInput\n    update: XOR<political_news_crawler_crawl_schedulesUpdateWithoutCrawlPolicyInput, political_news_crawler_crawl_schedulesUncheckedUpdateWithoutCrawlPolicyInput>\n    create: XOR<political_news_crawler_crawl_schedulesCreateWithoutCrawlPolicyInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutCrawlPolicyInput>\n  }\n\n  export type political_news_crawler_crawl_schedulesUpdateWithWhereUniqueWithoutCrawlPolicyInput = {\n    where: political_news_crawler_crawl_schedulesWhereUniqueInput\n    data: XOR<political_news_crawler_crawl_schedulesUpdateWithoutCrawlPolicyInput, political_news_crawler_crawl_schedulesUncheckedUpdateWithoutCrawlPolicyInput>\n  }\n\n  export type political_news_crawler_crawl_schedulesUpdateManyWithWhereWithoutCrawlPolicyInput = {\n    where: political_news_crawler_crawl_schedulesScalarWhereInput\n    data: XOR<political_news_crawler_crawl_schedulesUpdateManyMutationInput, political_news_crawler_crawl_schedulesUncheckedUpdateManyWithoutCrawlPolicyInput>\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsCreateNestedManyWithoutCrawlSourceInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUncheckedCreateNestedManyWithoutCrawlSourceInput\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    where: political_news_crawler_crawl_sourcesWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_schedulesInput>\n  }\n\n  export type political_news_crawler_crawl_policiesCreateWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    id: string\n    policy_name: string\n    max_crawl_frequency_minutes: number\n    max_retry_attempts: number\n    backoff_multiplier: number\n    ban_detection_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_crawl_policiesUncheckedCreateWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    id: string\n    policy_name: string\n    max_crawl_frequency_minutes: number\n    max_retry_attempts: number\n    backoff_multiplier: number\n    ban_detection_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_crawl_policiesCreateOrConnectWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    where: political_news_crawler_crawl_policiesWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_policiesCreateWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_policiesUncheckedCreateWithoutPolitical_news_crawler_crawl_schedulesInput>\n  }\n\n  export type political_news_crawler_crawl_jobsCreateWithoutCrawlScheduleInput = {\n    id: string\n    active: boolean\n    last_run_started_at?: Date | string | null\n    last_run_completed_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_crawl_jobsInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsCreateNestedManyWithoutCrawlJobInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageCreateNestedManyWithoutCrawlJobInput\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlScheduleInput = {\n    id: string\n    crawl_source_id: string\n    active: boolean\n    last_run_started_at?: Date | string | null\n    last_run_completed_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedCreateNestedManyWithoutCrawlJobInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedCreateNestedManyWithoutCrawlJobInput\n  }\n\n  export type political_news_crawler_crawl_jobsCreateOrConnectWithoutCrawlScheduleInput = {\n    where: political_news_crawler_crawl_jobsWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_jobsCreateWithoutCrawlScheduleInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlScheduleInput>\n  }\n\n  export type political_news_crawler_crawl_jobsCreateManyCrawlScheduleInputEnvelope = {\n    data: political_news_crawler_crawl_jobsCreateManyCrawlScheduleInput | political_news_crawler_crawl_jobsCreateManyCrawlScheduleInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_crawl_sourcesUpsertWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    update: XOR<political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_crawl_schedulesInput>\n    create: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_schedulesInput>\n    where?: political_news_crawler_crawl_sourcesWhereInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    where?: political_news_crawler_crawl_sourcesWhereInput\n    data: XOR<political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_crawl_schedulesInput>\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUpdateManyWithoutCrawlSourceNestedInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n  }\n\n  export type political_news_crawler_crawl_policiesUpsertWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    update: XOR<political_news_crawler_crawl_policiesUpdateWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_policiesUncheckedUpdateWithoutPolitical_news_crawler_crawl_schedulesInput>\n    create: XOR<political_news_crawler_crawl_policiesCreateWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_policiesUncheckedCreateWithoutPolitical_news_crawler_crawl_schedulesInput>\n    where?: political_news_crawler_crawl_policiesWhereInput\n  }\n\n  export type political_news_crawler_crawl_policiesUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    where?: political_news_crawler_crawl_policiesWhereInput\n    data: XOR<political_news_crawler_crawl_policiesUpdateWithoutPolitical_news_crawler_crawl_schedulesInput, political_news_crawler_crawl_policiesUncheckedUpdateWithoutPolitical_news_crawler_crawl_schedulesInput>\n  }\n\n  export type political_news_crawler_crawl_policiesUpdateWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    policy_name?: StringFieldUpdateOperationsInput | string\n    max_crawl_frequency_minutes?: IntFieldUpdateOperationsInput | number\n    max_retry_attempts?: IntFieldUpdateOperationsInput | number\n    backoff_multiplier?: FloatFieldUpdateOperationsInput | number\n    ban_detection_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_policiesUncheckedUpdateWithoutPolitical_news_crawler_crawl_schedulesInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    policy_name?: StringFieldUpdateOperationsInput | string\n    max_crawl_frequency_minutes?: IntFieldUpdateOperationsInput | number\n    max_retry_attempts?: IntFieldUpdateOperationsInput | number\n    backoff_multiplier?: FloatFieldUpdateOperationsInput | number\n    ban_detection_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_jobsUpsertWithWhereUniqueWithoutCrawlScheduleInput = {\n    where: political_news_crawler_crawl_jobsWhereUniqueInput\n    update: XOR<political_news_crawler_crawl_jobsUpdateWithoutCrawlScheduleInput, political_news_crawler_crawl_jobsUncheckedUpdateWithoutCrawlScheduleInput>\n    create: XOR<political_news_crawler_crawl_jobsCreateWithoutCrawlScheduleInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutCrawlScheduleInput>\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateWithWhereUniqueWithoutCrawlScheduleInput = {\n    where: political_news_crawler_crawl_jobsWhereUniqueInput\n    data: XOR<political_news_crawler_crawl_jobsUpdateWithoutCrawlScheduleInput, political_news_crawler_crawl_jobsUncheckedUpdateWithoutCrawlScheduleInput>\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateManyWithWhereWithoutCrawlScheduleInput = {\n    where: political_news_crawler_crawl_jobsScalarWhereInput\n    data: XOR<political_news_crawler_crawl_jobsUpdateManyMutationInput, political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlScheduleInput>\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_jobsInput = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsCreateNestedManyWithoutCrawlSourceInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_jobsInput = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUncheckedCreateNestedManyWithoutCrawlSourceInput\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_crawl_jobsInput = {\n    where: political_news_crawler_crawl_sourcesWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_jobsInput>\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateWithoutPolitical_news_crawler_crawl_jobsInput = {\n    id: string\n    schedule_expression: string\n    last_crawled_at?: Date | string | null\n    next_crawl_at?: Date | string | null\n    is_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_crawl_schedulesInput\n    crawlPolicy: political_news_crawler_crawl_policiesCreateNestedOneWithoutPolitical_news_crawler_crawl_schedulesInput\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedCreateWithoutPolitical_news_crawler_crawl_jobsInput = {\n    id: string\n    crawl_source_id: string\n    crawl_policy_id: string\n    schedule_expression: string\n    last_crawled_at?: Date | string | null\n    next_crawl_at?: Date | string | null\n    is_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateOrConnectWithoutPolitical_news_crawler_crawl_jobsInput = {\n    where: political_news_crawler_crawl_schedulesWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_schedulesCreateWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutPolitical_news_crawler_crawl_jobsInput>\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateWithoutCrawlJobInput = {\n    id: string\n    started_at: Date | string\n    completed_at?: Date | string | null\n    success: boolean\n    error_message?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    rawDataStorage?: political_news_crawler_raw_data_storageCreateNestedOneWithoutPolitical_news_crawler_crawl_attemptsInput\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsCreateNestedManyWithoutCrawlAttemptInput\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedCreateWithoutCrawlJobInput = {\n    id: string\n    raw_data_storage_id?: string | null\n    started_at: Date | string\n    completed_at?: Date | string | null\n    success: boolean\n    error_message?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsUncheckedCreateNestedManyWithoutCrawlAttemptInput\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateOrConnectWithoutCrawlJobInput = {\n    where: political_news_crawler_crawl_attemptsWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_attemptsCreateWithoutCrawlJobInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutCrawlJobInput>\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateManyCrawlJobInputEnvelope = {\n    data: political_news_crawler_crawl_attemptsCreateManyCrawlJobInput | political_news_crawler_crawl_attemptsCreateManyCrawlJobInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_raw_data_storageCreateWithoutCrawlJobInput = {\n    id: string\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_raw_data_storageInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentCreateNestedManyWithoutRawDataStorageInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlJobInput = {\n    id: string\n    crawl_source_id: string\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUncheckedCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedCreateNestedManyWithoutRawDataStorageInput\n  }\n\n  export type political_news_crawler_raw_data_storageCreateOrConnectWithoutCrawlJobInput = {\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n    create: XOR<political_news_crawler_raw_data_storageCreateWithoutCrawlJobInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlJobInput>\n  }\n\n  export type political_news_crawler_raw_data_storageCreateManyCrawlJobInputEnvelope = {\n    data: political_news_crawler_raw_data_storageCreateManyCrawlJobInput | political_news_crawler_raw_data_storageCreateManyCrawlJobInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_crawl_sourcesUpsertWithoutPolitical_news_crawler_crawl_jobsInput = {\n    update: XOR<political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_crawl_jobsInput>\n    create: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_jobsInput>\n    where?: political_news_crawler_crawl_sourcesWhereInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_jobsInput = {\n    where?: political_news_crawler_crawl_sourcesWhereInput\n    data: XOR<political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_crawl_jobsInput>\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_crawl_jobsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUpdateManyWithoutCrawlSourceNestedInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_crawl_jobsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n  }\n\n  export type political_news_crawler_crawl_schedulesUpsertWithoutPolitical_news_crawler_crawl_jobsInput = {\n    update: XOR<political_news_crawler_crawl_schedulesUpdateWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_schedulesUncheckedUpdateWithoutPolitical_news_crawler_crawl_jobsInput>\n    create: XOR<political_news_crawler_crawl_schedulesCreateWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_schedulesUncheckedCreateWithoutPolitical_news_crawler_crawl_jobsInput>\n    where?: political_news_crawler_crawl_schedulesWhereInput\n  }\n\n  export type political_news_crawler_crawl_schedulesUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_jobsInput = {\n    where?: political_news_crawler_crawl_schedulesWhereInput\n    data: XOR<political_news_crawler_crawl_schedulesUpdateWithoutPolitical_news_crawler_crawl_jobsInput, political_news_crawler_crawl_schedulesUncheckedUpdateWithoutPolitical_news_crawler_crawl_jobsInput>\n  }\n\n  export type political_news_crawler_crawl_schedulesUpdateWithoutPolitical_news_crawler_crawl_jobsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    schedule_expression?: StringFieldUpdateOperationsInput | string\n    last_crawled_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    next_crawl_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    is_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_schedulesNestedInput\n    crawlPolicy?: political_news_crawler_crawl_policiesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_schedulesNestedInput\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedUpdateWithoutPolitical_news_crawler_crawl_jobsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    crawl_policy_id?: StringFieldUpdateOperationsInput | string\n    schedule_expression?: StringFieldUpdateOperationsInput | string\n    last_crawled_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    next_crawl_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    is_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_attemptsUpsertWithWhereUniqueWithoutCrawlJobInput = {\n    where: political_news_crawler_crawl_attemptsWhereUniqueInput\n    update: XOR<political_news_crawler_crawl_attemptsUpdateWithoutCrawlJobInput, political_news_crawler_crawl_attemptsUncheckedUpdateWithoutCrawlJobInput>\n    create: XOR<political_news_crawler_crawl_attemptsCreateWithoutCrawlJobInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutCrawlJobInput>\n  }\n\n  export type political_news_crawler_crawl_attemptsUpdateWithWhereUniqueWithoutCrawlJobInput = {\n    where: political_news_crawler_crawl_attemptsWhereUniqueInput\n    data: XOR<political_news_crawler_crawl_attemptsUpdateWithoutCrawlJobInput, political_news_crawler_crawl_attemptsUncheckedUpdateWithoutCrawlJobInput>\n  }\n\n  export type political_news_crawler_crawl_attemptsUpdateManyWithWhereWithoutCrawlJobInput = {\n    where: political_news_crawler_crawl_attemptsScalarWhereInput\n    data: XOR<political_news_crawler_crawl_attemptsUpdateManyMutationInput, political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutCrawlJobInput>\n  }\n\n  export type political_news_crawler_crawl_attemptsScalarWhereInput = {\n    AND?: political_news_crawler_crawl_attemptsScalarWhereInput | political_news_crawler_crawl_attemptsScalarWhereInput[]\n    OR?: political_news_crawler_crawl_attemptsScalarWhereInput[]\n    NOT?: political_news_crawler_crawl_attemptsScalarWhereInput | political_news_crawler_crawl_attemptsScalarWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_crawl_attempts\"> | string\n    crawl_job_id?: UuidFilter<\"political_news_crawler_crawl_attempts\"> | string\n    raw_data_storage_id?: UuidNullableFilter<\"political_news_crawler_crawl_attempts\"> | string | null\n    started_at?: DateTimeFilter<\"political_news_crawler_crawl_attempts\"> | Date | string\n    completed_at?: DateTimeNullableFilter<\"political_news_crawler_crawl_attempts\"> | Date | string | null\n    success?: BoolFilter<\"political_news_crawler_crawl_attempts\"> | boolean\n    error_message?: StringNullableFilter<\"political_news_crawler_crawl_attempts\"> | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_crawl_attempts\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawl_attempts\"> | Date | string\n  }\n\n  export type political_news_crawler_raw_data_storageUpsertWithWhereUniqueWithoutCrawlJobInput = {\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n    update: XOR<political_news_crawler_raw_data_storageUpdateWithoutCrawlJobInput, political_news_crawler_raw_data_storageUncheckedUpdateWithoutCrawlJobInput>\n    create: XOR<political_news_crawler_raw_data_storageCreateWithoutCrawlJobInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutCrawlJobInput>\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateWithWhereUniqueWithoutCrawlJobInput = {\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n    data: XOR<political_news_crawler_raw_data_storageUpdateWithoutCrawlJobInput, political_news_crawler_raw_data_storageUncheckedUpdateWithoutCrawlJobInput>\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateManyWithWhereWithoutCrawlJobInput = {\n    where: political_news_crawler_raw_data_storageScalarWhereInput\n    data: XOR<political_news_crawler_raw_data_storageUpdateManyMutationInput, political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlJobInput>\n  }\n\n  export type political_news_crawler_crawl_jobsCreateWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    id: string\n    active: boolean\n    last_run_started_at?: Date | string | null\n    last_run_completed_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_crawl_jobsInput\n    crawlSchedule: political_news_crawler_crawl_schedulesCreateNestedOneWithoutPolitical_news_crawler_crawl_jobsInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageCreateNestedManyWithoutCrawlJobInput\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedCreateWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    id: string\n    crawl_source_id: string\n    crawl_schedule_id: string\n    active: boolean\n    last_run_started_at?: Date | string | null\n    last_run_completed_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedCreateNestedManyWithoutCrawlJobInput\n  }\n\n  export type political_news_crawler_crawl_jobsCreateOrConnectWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    where: political_news_crawler_crawl_jobsWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_jobsCreateWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutPolitical_news_crawler_crawl_attemptsInput>\n  }\n\n  export type political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    id: string\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_raw_data_storageInput\n    crawlJob?: political_news_crawler_crawl_jobsCreateNestedOneWithoutPolitical_news_crawler_raw_data_storageInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentCreateNestedManyWithoutRawDataStorageInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    id: string\n    crawl_source_id: string\n    crawl_job_id?: string | null\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUncheckedCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedCreateNestedManyWithoutRawDataStorageInput\n  }\n\n  export type political_news_crawler_raw_data_storageCreateOrConnectWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n    create: XOR<political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_crawl_attemptsInput>\n  }\n\n  export type political_news_crawler_crawled_newsCreateWithoutCrawlAttemptInput = {\n    id: string\n    url: string\n    title?: string | null\n    published_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsCreateNestedManyWithoutCrawledNewsInput\n  }\n\n  export type political_news_crawler_crawled_newsUncheckedCreateWithoutCrawlAttemptInput = {\n    id: string\n    url: string\n    title?: string | null\n    published_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsUncheckedCreateNestedManyWithoutCrawledNewsInput\n  }\n\n  export type political_news_crawler_crawled_newsCreateOrConnectWithoutCrawlAttemptInput = {\n    where: political_news_crawler_crawled_newsWhereUniqueInput\n    create: XOR<political_news_crawler_crawled_newsCreateWithoutCrawlAttemptInput, political_news_crawler_crawled_newsUncheckedCreateWithoutCrawlAttemptInput>\n  }\n\n  export type political_news_crawler_crawled_newsCreateManyCrawlAttemptInputEnvelope = {\n    data: political_news_crawler_crawled_newsCreateManyCrawlAttemptInput | political_news_crawler_crawled_newsCreateManyCrawlAttemptInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_crawl_jobsUpsertWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    update: XOR<political_news_crawler_crawl_jobsUpdateWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_crawl_jobsUncheckedUpdateWithoutPolitical_news_crawler_crawl_attemptsInput>\n    create: XOR<political_news_crawler_crawl_jobsCreateWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutPolitical_news_crawler_crawl_attemptsInput>\n    where?: political_news_crawler_crawl_jobsWhereInput\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    where?: political_news_crawler_crawl_jobsWhereInput\n    data: XOR<political_news_crawler_crawl_jobsUpdateWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_crawl_jobsUncheckedUpdateWithoutPolitical_news_crawler_crawl_attemptsInput>\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_jobsNestedInput\n    crawlSchedule?: political_news_crawler_crawl_schedulesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_jobsNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUpdateManyWithoutCrawlJobNestedInput\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedUpdateWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    crawl_schedule_id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlJobNestedInput\n  }\n\n  export type political_news_crawler_raw_data_storageUpsertWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    update: XOR<political_news_crawler_raw_data_storageUpdateWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_raw_data_storageUncheckedUpdateWithoutPolitical_news_crawler_crawl_attemptsInput>\n    create: XOR<political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_crawl_attemptsInput>\n    where?: political_news_crawler_raw_data_storageWhereInput\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    where?: political_news_crawler_raw_data_storageWhereInput\n    data: XOR<political_news_crawler_raw_data_storageUpdateWithoutPolitical_news_crawler_crawl_attemptsInput, political_news_crawler_raw_data_storageUncheckedUpdateWithoutPolitical_news_crawler_crawl_attemptsInput>\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_raw_data_storageNestedInput\n    crawlJob?: political_news_crawler_crawl_jobsUpdateOneWithoutPolitical_news_crawler_raw_data_storageNestedInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUpdateManyWithoutRawDataStorageNestedInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedUpdateWithoutPolitical_news_crawler_crawl_attemptsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    crawl_job_id?: NullableStringFieldUpdateOperationsInput | string | null\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUncheckedUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedUpdateManyWithoutRawDataStorageNestedInput\n  }\n\n  export type political_news_crawler_crawled_newsUpsertWithWhereUniqueWithoutCrawlAttemptInput = {\n    where: political_news_crawler_crawled_newsWhereUniqueInput\n    update: XOR<political_news_crawler_crawled_newsUpdateWithoutCrawlAttemptInput, political_news_crawler_crawled_newsUncheckedUpdateWithoutCrawlAttemptInput>\n    create: XOR<political_news_crawler_crawled_newsCreateWithoutCrawlAttemptInput, political_news_crawler_crawled_newsUncheckedCreateWithoutCrawlAttemptInput>\n  }\n\n  export type political_news_crawler_crawled_newsUpdateWithWhereUniqueWithoutCrawlAttemptInput = {\n    where: political_news_crawler_crawled_newsWhereUniqueInput\n    data: XOR<political_news_crawler_crawled_newsUpdateWithoutCrawlAttemptInput, political_news_crawler_crawled_newsUncheckedUpdateWithoutCrawlAttemptInput>\n  }\n\n  export type political_news_crawler_crawled_newsUpdateManyWithWhereWithoutCrawlAttemptInput = {\n    where: political_news_crawler_crawled_newsScalarWhereInput\n    data: XOR<political_news_crawler_crawled_newsUpdateManyMutationInput, political_news_crawler_crawled_newsUncheckedUpdateManyWithoutCrawlAttemptInput>\n  }\n\n  export type political_news_crawler_crawled_newsScalarWhereInput = {\n    AND?: political_news_crawler_crawled_newsScalarWhereInput | political_news_crawler_crawled_newsScalarWhereInput[]\n    OR?: political_news_crawler_crawled_newsScalarWhereInput[]\n    NOT?: political_news_crawler_crawled_newsScalarWhereInput | political_news_crawler_crawled_newsScalarWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_crawled_news\"> | string\n    crawl_attempt_id?: UuidFilter<\"political_news_crawler_crawled_news\"> | string\n    url?: StringFilter<\"political_news_crawler_crawled_news\"> | string\n    title?: StringNullableFilter<\"political_news_crawler_crawled_news\"> | string | null\n    published_at?: DateTimeNullableFilter<\"political_news_crawler_crawled_news\"> | Date | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_crawled_news\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_crawled_news\"> | Date | string\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateWithoutPolitical_news_crawler_crawled_newsInput = {\n    id: string\n    started_at: Date | string\n    completed_at?: Date | string | null\n    success: boolean\n    error_message?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    crawlJob: political_news_crawler_crawl_jobsCreateNestedOneWithoutPolitical_news_crawler_crawl_attemptsInput\n    rawDataStorage?: political_news_crawler_raw_data_storageCreateNestedOneWithoutPolitical_news_crawler_crawl_attemptsInput\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedCreateWithoutPolitical_news_crawler_crawled_newsInput = {\n    id: string\n    crawl_job_id: string\n    raw_data_storage_id?: string | null\n    started_at: Date | string\n    completed_at?: Date | string | null\n    success: boolean\n    error_message?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateOrConnectWithoutPolitical_news_crawler_crawled_newsInput = {\n    where: political_news_crawler_crawl_attemptsWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_attemptsCreateWithoutPolitical_news_crawler_crawled_newsInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutPolitical_news_crawler_crawled_newsInput>\n  }\n\n  export type political_news_crawler_topic_mentionsCreateWithoutCrawledNewsInput = {\n    id: string\n    mention_context?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    popularTopic: political_news_crawler_popular_topicsCreateNestedOneWithoutPolitical_news_crawler_topic_mentionsInput\n  }\n\n  export type political_news_crawler_topic_mentionsUncheckedCreateWithoutCrawledNewsInput = {\n    id: string\n    political_news_crawler_popular_topic_id: string\n    mention_context?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsCreateOrConnectWithoutCrawledNewsInput = {\n    where: political_news_crawler_topic_mentionsWhereUniqueInput\n    create: XOR<political_news_crawler_topic_mentionsCreateWithoutCrawledNewsInput, political_news_crawler_topic_mentionsUncheckedCreateWithoutCrawledNewsInput>\n  }\n\n  export type political_news_crawler_topic_mentionsCreateManyCrawledNewsInputEnvelope = {\n    data: political_news_crawler_topic_mentionsCreateManyCrawledNewsInput | political_news_crawler_topic_mentionsCreateManyCrawledNewsInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_crawl_attemptsUpsertWithoutPolitical_news_crawler_crawled_newsInput = {\n    update: XOR<political_news_crawler_crawl_attemptsUpdateWithoutPolitical_news_crawler_crawled_newsInput, political_news_crawler_crawl_attemptsUncheckedUpdateWithoutPolitical_news_crawler_crawled_newsInput>\n    create: XOR<political_news_crawler_crawl_attemptsCreateWithoutPolitical_news_crawler_crawled_newsInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutPolitical_news_crawler_crawled_newsInput>\n    where?: political_news_crawler_crawl_attemptsWhereInput\n  }\n\n  export type political_news_crawler_crawl_attemptsUpdateToOneWithWhereWithoutPolitical_news_crawler_crawled_newsInput = {\n    where?: political_news_crawler_crawl_attemptsWhereInput\n    data: XOR<political_news_crawler_crawl_attemptsUpdateWithoutPolitical_news_crawler_crawled_newsInput, political_news_crawler_crawl_attemptsUncheckedUpdateWithoutPolitical_news_crawler_crawled_newsInput>\n  }\n\n  export type political_news_crawler_crawl_attemptsUpdateWithoutPolitical_news_crawler_crawled_newsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    started_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    success?: BoolFieldUpdateOperationsInput | boolean\n    error_message?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    crawlJob?: political_news_crawler_crawl_jobsUpdateOneRequiredWithoutPolitical_news_crawler_crawl_attemptsNestedInput\n    rawDataStorage?: political_news_crawler_raw_data_storageUpdateOneWithoutPolitical_news_crawler_crawl_attemptsNestedInput\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedUpdateWithoutPolitical_news_crawler_crawled_newsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_job_id?: StringFieldUpdateOperationsInput | string\n    raw_data_storage_id?: NullableStringFieldUpdateOperationsInput | string | null\n    started_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    success?: BoolFieldUpdateOperationsInput | boolean\n    error_message?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_topic_mentionsUpsertWithWhereUniqueWithoutCrawledNewsInput = {\n    where: political_news_crawler_topic_mentionsWhereUniqueInput\n    update: XOR<political_news_crawler_topic_mentionsUpdateWithoutCrawledNewsInput, political_news_crawler_topic_mentionsUncheckedUpdateWithoutCrawledNewsInput>\n    create: XOR<political_news_crawler_topic_mentionsCreateWithoutCrawledNewsInput, political_news_crawler_topic_mentionsUncheckedCreateWithoutCrawledNewsInput>\n  }\n\n  export type political_news_crawler_topic_mentionsUpdateWithWhereUniqueWithoutCrawledNewsInput = {\n    where: political_news_crawler_topic_mentionsWhereUniqueInput\n    data: XOR<political_news_crawler_topic_mentionsUpdateWithoutCrawledNewsInput, political_news_crawler_topic_mentionsUncheckedUpdateWithoutCrawledNewsInput>\n  }\n\n  export type political_news_crawler_topic_mentionsUpdateManyWithWhereWithoutCrawledNewsInput = {\n    where: political_news_crawler_topic_mentionsScalarWhereInput\n    data: XOR<political_news_crawler_topic_mentionsUpdateManyMutationInput, political_news_crawler_topic_mentionsUncheckedUpdateManyWithoutCrawledNewsInput>\n  }\n\n  export type political_news_crawler_topic_mentionsScalarWhereInput = {\n    AND?: political_news_crawler_topic_mentionsScalarWhereInput | political_news_crawler_topic_mentionsScalarWhereInput[]\n    OR?: political_news_crawler_topic_mentionsScalarWhereInput[]\n    NOT?: political_news_crawler_topic_mentionsScalarWhereInput | political_news_crawler_topic_mentionsScalarWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_topic_mentions\"> | string\n    political_news_crawler_popular_topic_id?: UuidFilter<\"political_news_crawler_topic_mentions\"> | string\n    political_news_crawler_crawled_news_id?: UuidFilter<\"political_news_crawler_topic_mentions\"> | string\n    mention_context?: StringNullableFilter<\"political_news_crawler_topic_mentions\"> | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_topic_mentions\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_topic_mentions\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_topic_mentions\"> | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_raw_data_storageInput = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsCreateNestedManyWithoutCrawlSourceInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_raw_data_storageInput = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUncheckedCreateNestedManyWithoutCrawlSourceInput\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_raw_data_storageInput = {\n    where: political_news_crawler_crawl_sourcesWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_raw_data_storageInput>\n  }\n\n  export type political_news_crawler_crawl_jobsCreateWithoutPolitical_news_crawler_raw_data_storageInput = {\n    id: string\n    active: boolean\n    last_run_started_at?: Date | string | null\n    last_run_completed_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_crawl_jobsInput\n    crawlSchedule: political_news_crawler_crawl_schedulesCreateNestedOneWithoutPolitical_news_crawler_crawl_jobsInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsCreateNestedManyWithoutCrawlJobInput\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedCreateWithoutPolitical_news_crawler_raw_data_storageInput = {\n    id: string\n    crawl_source_id: string\n    crawl_schedule_id: string\n    active: boolean\n    last_run_started_at?: Date | string | null\n    last_run_completed_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedCreateNestedManyWithoutCrawlJobInput\n  }\n\n  export type political_news_crawler_crawl_jobsCreateOrConnectWithoutPolitical_news_crawler_raw_data_storageInput = {\n    where: political_news_crawler_crawl_jobsWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_jobsCreateWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutPolitical_news_crawler_raw_data_storageInput>\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateWithoutRawDataStorageInput = {\n    id: string\n    started_at: Date | string\n    completed_at?: Date | string | null\n    success: boolean\n    error_message?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    crawlJob: political_news_crawler_crawl_jobsCreateNestedOneWithoutPolitical_news_crawler_crawl_attemptsInput\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsCreateNestedManyWithoutCrawlAttemptInput\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedCreateWithoutRawDataStorageInput = {\n    id: string\n    crawl_job_id: string\n    started_at: Date | string\n    completed_at?: Date | string | null\n    success: boolean\n    error_message?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsUncheckedCreateNestedManyWithoutCrawlAttemptInput\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateOrConnectWithoutRawDataStorageInput = {\n    where: political_news_crawler_crawl_attemptsWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_attemptsCreateWithoutRawDataStorageInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutRawDataStorageInput>\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateManyRawDataStorageInputEnvelope = {\n    data: political_news_crawler_crawl_attemptsCreateManyRawDataStorageInput | political_news_crawler_crawl_attemptsCreateManyRawDataStorageInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_local_cache_filesCreateWithoutRawDataStorageInput = {\n    id: string\n    local_file_path: string\n    file_size_bytes: number\n    ttl_expiration_at: Date | string\n    deleted_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_local_cache_filesUncheckedCreateWithoutRawDataStorageInput = {\n    id: string\n    local_file_path: string\n    file_size_bytes: number\n    ttl_expiration_at: Date | string\n    deleted_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_local_cache_filesCreateOrConnectWithoutRawDataStorageInput = {\n    where: political_news_crawler_local_cache_filesWhereUniqueInput\n    create: XOR<political_news_crawler_local_cache_filesCreateWithoutRawDataStorageInput, political_news_crawler_local_cache_filesUncheckedCreateWithoutRawDataStorageInput>\n  }\n\n  export type political_news_crawler_local_cache_filesCreateManyRawDataStorageInputEnvelope = {\n    data: political_news_crawler_local_cache_filesCreateManyRawDataStorageInput | political_news_crawler_local_cache_filesCreateManyRawDataStorageInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_processed_contentCreateWithoutRawDataStorageInput = {\n    id: string\n    content_type: string\n    content_body: string\n    generation_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    llmJob?: political_news_crawler_llm_jobsCreateNestedOneWithoutPolitical_news_crawler_processed_contentInput\n  }\n\n  export type political_news_crawler_processed_contentUncheckedCreateWithoutRawDataStorageInput = {\n    id: string\n    llm_job_id?: string | null\n    content_type: string\n    content_body: string\n    generation_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_processed_contentCreateOrConnectWithoutRawDataStorageInput = {\n    where: political_news_crawler_processed_contentWhereUniqueInput\n    create: XOR<political_news_crawler_processed_contentCreateWithoutRawDataStorageInput, political_news_crawler_processed_contentUncheckedCreateWithoutRawDataStorageInput>\n  }\n\n  export type political_news_crawler_processed_contentCreateManyRawDataStorageInputEnvelope = {\n    data: political_news_crawler_processed_contentCreateManyRawDataStorageInput | political_news_crawler_processed_contentCreateManyRawDataStorageInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_crawl_sourcesUpsertWithoutPolitical_news_crawler_raw_data_storageInput = {\n    update: XOR<political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_raw_data_storageInput>\n    create: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_raw_data_storageInput>\n    where?: political_news_crawler_crawl_sourcesWhereInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateToOneWithWhereWithoutPolitical_news_crawler_raw_data_storageInput = {\n    where?: political_news_crawler_crawl_sourcesWhereInput\n    data: XOR<political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_raw_data_storageInput>\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_raw_data_storageInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUpdateManyWithoutCrawlSourceNestedInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_raw_data_storageInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n  }\n\n  export type political_news_crawler_crawl_jobsUpsertWithoutPolitical_news_crawler_raw_data_storageInput = {\n    update: XOR<political_news_crawler_crawl_jobsUpdateWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_jobsUncheckedUpdateWithoutPolitical_news_crawler_raw_data_storageInput>\n    create: XOR<political_news_crawler_crawl_jobsCreateWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_jobsUncheckedCreateWithoutPolitical_news_crawler_raw_data_storageInput>\n    where?: political_news_crawler_crawl_jobsWhereInput\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateToOneWithWhereWithoutPolitical_news_crawler_raw_data_storageInput = {\n    where?: political_news_crawler_crawl_jobsWhereInput\n    data: XOR<political_news_crawler_crawl_jobsUpdateWithoutPolitical_news_crawler_raw_data_storageInput, political_news_crawler_crawl_jobsUncheckedUpdateWithoutPolitical_news_crawler_raw_data_storageInput>\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateWithoutPolitical_news_crawler_raw_data_storageInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_jobsNestedInput\n    crawlSchedule?: political_news_crawler_crawl_schedulesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_jobsNestedInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUpdateManyWithoutCrawlJobNestedInput\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedUpdateWithoutPolitical_news_crawler_raw_data_storageInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    crawl_schedule_id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutCrawlJobNestedInput\n  }\n\n  export type political_news_crawler_crawl_attemptsUpsertWithWhereUniqueWithoutRawDataStorageInput = {\n    where: political_news_crawler_crawl_attemptsWhereUniqueInput\n    update: XOR<political_news_crawler_crawl_attemptsUpdateWithoutRawDataStorageInput, political_news_crawler_crawl_attemptsUncheckedUpdateWithoutRawDataStorageInput>\n    create: XOR<political_news_crawler_crawl_attemptsCreateWithoutRawDataStorageInput, political_news_crawler_crawl_attemptsUncheckedCreateWithoutRawDataStorageInput>\n  }\n\n  export type political_news_crawler_crawl_attemptsUpdateWithWhereUniqueWithoutRawDataStorageInput = {\n    where: political_news_crawler_crawl_attemptsWhereUniqueInput\n    data: XOR<political_news_crawler_crawl_attemptsUpdateWithoutRawDataStorageInput, political_news_crawler_crawl_attemptsUncheckedUpdateWithoutRawDataStorageInput>\n  }\n\n  export type political_news_crawler_crawl_attemptsUpdateManyWithWhereWithoutRawDataStorageInput = {\n    where: political_news_crawler_crawl_attemptsScalarWhereInput\n    data: XOR<political_news_crawler_crawl_attemptsUpdateManyMutationInput, political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutRawDataStorageInput>\n  }\n\n  export type political_news_crawler_local_cache_filesUpsertWithWhereUniqueWithoutRawDataStorageInput = {\n    where: political_news_crawler_local_cache_filesWhereUniqueInput\n    update: XOR<political_news_crawler_local_cache_filesUpdateWithoutRawDataStorageInput, political_news_crawler_local_cache_filesUncheckedUpdateWithoutRawDataStorageInput>\n    create: XOR<political_news_crawler_local_cache_filesCreateWithoutRawDataStorageInput, political_news_crawler_local_cache_filesUncheckedCreateWithoutRawDataStorageInput>\n  }\n\n  export type political_news_crawler_local_cache_filesUpdateWithWhereUniqueWithoutRawDataStorageInput = {\n    where: political_news_crawler_local_cache_filesWhereUniqueInput\n    data: XOR<political_news_crawler_local_cache_filesUpdateWithoutRawDataStorageInput, political_news_crawler_local_cache_filesUncheckedUpdateWithoutRawDataStorageInput>\n  }\n\n  export type political_news_crawler_local_cache_filesUpdateManyWithWhereWithoutRawDataStorageInput = {\n    where: political_news_crawler_local_cache_filesScalarWhereInput\n    data: XOR<political_news_crawler_local_cache_filesUpdateManyMutationInput, political_news_crawler_local_cache_filesUncheckedUpdateManyWithoutRawDataStorageInput>\n  }\n\n  export type political_news_crawler_local_cache_filesScalarWhereInput = {\n    AND?: political_news_crawler_local_cache_filesScalarWhereInput | political_news_crawler_local_cache_filesScalarWhereInput[]\n    OR?: political_news_crawler_local_cache_filesScalarWhereInput[]\n    NOT?: political_news_crawler_local_cache_filesScalarWhereInput | political_news_crawler_local_cache_filesScalarWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_local_cache_files\"> | string\n    raw_data_storage_id?: UuidFilter<\"political_news_crawler_local_cache_files\"> | string\n    local_file_path?: StringFilter<\"political_news_crawler_local_cache_files\"> | string\n    file_size_bytes?: IntFilter<\"political_news_crawler_local_cache_files\"> | number\n    ttl_expiration_at?: DateTimeFilter<\"political_news_crawler_local_cache_files\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_local_cache_files\"> | Date | string | null\n    created_at?: DateTimeFilter<\"political_news_crawler_local_cache_files\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_local_cache_files\"> | Date | string\n  }\n\n  export type political_news_crawler_processed_contentUpsertWithWhereUniqueWithoutRawDataStorageInput = {\n    where: political_news_crawler_processed_contentWhereUniqueInput\n    update: XOR<political_news_crawler_processed_contentUpdateWithoutRawDataStorageInput, political_news_crawler_processed_contentUncheckedUpdateWithoutRawDataStorageInput>\n    create: XOR<political_news_crawler_processed_contentCreateWithoutRawDataStorageInput, political_news_crawler_processed_contentUncheckedCreateWithoutRawDataStorageInput>\n  }\n\n  export type political_news_crawler_processed_contentUpdateWithWhereUniqueWithoutRawDataStorageInput = {\n    where: political_news_crawler_processed_contentWhereUniqueInput\n    data: XOR<political_news_crawler_processed_contentUpdateWithoutRawDataStorageInput, political_news_crawler_processed_contentUncheckedUpdateWithoutRawDataStorageInput>\n  }\n\n  export type political_news_crawler_processed_contentUpdateManyWithWhereWithoutRawDataStorageInput = {\n    where: political_news_crawler_processed_contentScalarWhereInput\n    data: XOR<political_news_crawler_processed_contentUpdateManyMutationInput, political_news_crawler_processed_contentUncheckedUpdateManyWithoutRawDataStorageInput>\n  }\n\n  export type political_news_crawler_processed_contentScalarWhereInput = {\n    AND?: political_news_crawler_processed_contentScalarWhereInput | political_news_crawler_processed_contentScalarWhereInput[]\n    OR?: political_news_crawler_processed_contentScalarWhereInput[]\n    NOT?: political_news_crawler_processed_contentScalarWhereInput | political_news_crawler_processed_contentScalarWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_processed_content\"> | string\n    raw_data_storage_id?: UuidFilter<\"political_news_crawler_processed_content\"> | string\n    llm_job_id?: UuidNullableFilter<\"political_news_crawler_processed_content\"> | string | null\n    content_type?: StringFilter<\"political_news_crawler_processed_content\"> | string\n    content_body?: StringFilter<\"political_news_crawler_processed_content\"> | string\n    generation_timestamp?: DateTimeFilter<\"political_news_crawler_processed_content\"> | Date | string\n    created_at?: DateTimeFilter<\"political_news_crawler_processed_content\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_processed_content\"> | Date | string\n  }\n\n  export type political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_local_cache_filesInput = {\n    id: string\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_raw_data_storageInput\n    crawlJob?: political_news_crawler_crawl_jobsCreateNestedOneWithoutPolitical_news_crawler_raw_data_storageInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentCreateNestedManyWithoutRawDataStorageInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_local_cache_filesInput = {\n    id: string\n    crawl_source_id: string\n    crawl_job_id?: string | null\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedCreateNestedManyWithoutRawDataStorageInput\n  }\n\n  export type political_news_crawler_raw_data_storageCreateOrConnectWithoutPolitical_news_crawler_local_cache_filesInput = {\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n    create: XOR<political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_local_cache_filesInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_local_cache_filesInput>\n  }\n\n  export type political_news_crawler_raw_data_storageUpsertWithoutPolitical_news_crawler_local_cache_filesInput = {\n    update: XOR<political_news_crawler_raw_data_storageUpdateWithoutPolitical_news_crawler_local_cache_filesInput, political_news_crawler_raw_data_storageUncheckedUpdateWithoutPolitical_news_crawler_local_cache_filesInput>\n    create: XOR<political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_local_cache_filesInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_local_cache_filesInput>\n    where?: political_news_crawler_raw_data_storageWhereInput\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateToOneWithWhereWithoutPolitical_news_crawler_local_cache_filesInput = {\n    where?: political_news_crawler_raw_data_storageWhereInput\n    data: XOR<political_news_crawler_raw_data_storageUpdateWithoutPolitical_news_crawler_local_cache_filesInput, political_news_crawler_raw_data_storageUncheckedUpdateWithoutPolitical_news_crawler_local_cache_filesInput>\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateWithoutPolitical_news_crawler_local_cache_filesInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_raw_data_storageNestedInput\n    crawlJob?: political_news_crawler_crawl_jobsUpdateOneWithoutPolitical_news_crawler_raw_data_storageNestedInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUpdateManyWithoutRawDataStorageNestedInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedUpdateWithoutPolitical_news_crawler_local_cache_filesInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    crawl_job_id?: NullableStringFieldUpdateOperationsInput | string | null\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedUpdateManyWithoutRawDataStorageNestedInput\n  }\n\n  export type political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_processed_contentInput = {\n    id: string\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_raw_data_storageInput\n    crawlJob?: political_news_crawler_crawl_jobsCreateNestedOneWithoutPolitical_news_crawler_raw_data_storageInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesCreateNestedManyWithoutRawDataStorageInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_processed_contentInput = {\n    id: string\n    crawl_source_id: string\n    crawl_job_id?: string | null\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedCreateNestedManyWithoutRawDataStorageInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUncheckedCreateNestedManyWithoutRawDataStorageInput\n  }\n\n  export type political_news_crawler_raw_data_storageCreateOrConnectWithoutPolitical_news_crawler_processed_contentInput = {\n    where: political_news_crawler_raw_data_storageWhereUniqueInput\n    create: XOR<political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_processed_contentInput>\n  }\n\n  export type political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_processed_contentInput = {\n    id: string\n    status: string\n    parameters: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_llm_jobsInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataCreateNestedManyWithoutLlmJobInput\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_processed_contentInput = {\n    id: string\n    crawl_source_id: string\n    status: string\n    parameters: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsUncheckedCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataUncheckedCreateNestedManyWithoutLlmJobInput\n  }\n\n  export type political_news_crawler_llm_jobsCreateOrConnectWithoutPolitical_news_crawler_processed_contentInput = {\n    where: political_news_crawler_llm_jobsWhereUniqueInput\n    create: XOR<political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_processed_contentInput>\n  }\n\n  export type political_news_crawler_raw_data_storageUpsertWithoutPolitical_news_crawler_processed_contentInput = {\n    update: XOR<political_news_crawler_raw_data_storageUpdateWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_raw_data_storageUncheckedUpdateWithoutPolitical_news_crawler_processed_contentInput>\n    create: XOR<political_news_crawler_raw_data_storageCreateWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_raw_data_storageUncheckedCreateWithoutPolitical_news_crawler_processed_contentInput>\n    where?: political_news_crawler_raw_data_storageWhereInput\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateToOneWithWhereWithoutPolitical_news_crawler_processed_contentInput = {\n    where?: political_news_crawler_raw_data_storageWhereInput\n    data: XOR<political_news_crawler_raw_data_storageUpdateWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_raw_data_storageUncheckedUpdateWithoutPolitical_news_crawler_processed_contentInput>\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateWithoutPolitical_news_crawler_processed_contentInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_raw_data_storageNestedInput\n    crawlJob?: political_news_crawler_crawl_jobsUpdateOneWithoutPolitical_news_crawler_raw_data_storageNestedInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUpdateManyWithoutRawDataStorageNestedInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedUpdateWithoutPolitical_news_crawler_processed_contentInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    crawl_job_id?: NullableStringFieldUpdateOperationsInput | string | null\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUncheckedUpdateManyWithoutRawDataStorageNestedInput\n  }\n\n  export type political_news_crawler_llm_jobsUpsertWithoutPolitical_news_crawler_processed_contentInput = {\n    update: XOR<political_news_crawler_llm_jobsUpdateWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_llm_jobsUncheckedUpdateWithoutPolitical_news_crawler_processed_contentInput>\n    create: XOR<political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_processed_contentInput>\n    where?: political_news_crawler_llm_jobsWhereInput\n  }\n\n  export type political_news_crawler_llm_jobsUpdateToOneWithWhereWithoutPolitical_news_crawler_processed_contentInput = {\n    where?: political_news_crawler_llm_jobsWhereInput\n    data: XOR<political_news_crawler_llm_jobsUpdateWithoutPolitical_news_crawler_processed_contentInput, political_news_crawler_llm_jobsUncheckedUpdateWithoutPolitical_news_crawler_processed_contentInput>\n  }\n\n  export type political_news_crawler_llm_jobsUpdateWithoutPolitical_news_crawler_processed_contentInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    status?: StringFieldUpdateOperationsInput | string\n    parameters?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_llm_jobsNestedInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataUpdateManyWithoutLlmJobNestedInput\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedUpdateWithoutPolitical_news_crawler_processed_contentInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    status?: StringFieldUpdateOperationsInput | string\n    parameters?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsUncheckedUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataUncheckedUpdateManyWithoutLlmJobNestedInput\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_llm_jobsInput = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsCreateNestedManyWithoutCrawlSourceInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_llm_jobsInput = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUncheckedCreateNestedManyWithoutCrawlSourceInput\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_llm_jobsInput = {\n    where: political_news_crawler_crawl_sourcesWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_llm_jobsInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_llm_jobsInput>\n  }\n\n  export type political_news_crawler_processed_contentCreateWithoutLlmJobInput = {\n    id: string\n    content_type: string\n    content_body: string\n    generation_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    rawDataStorage: political_news_crawler_raw_data_storageCreateNestedOneWithoutPolitical_news_crawler_processed_contentInput\n  }\n\n  export type political_news_crawler_processed_contentUncheckedCreateWithoutLlmJobInput = {\n    id: string\n    raw_data_storage_id: string\n    content_type: string\n    content_body: string\n    generation_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_processed_contentCreateOrConnectWithoutLlmJobInput = {\n    where: political_news_crawler_processed_contentWhereUniqueInput\n    create: XOR<political_news_crawler_processed_contentCreateWithoutLlmJobInput, political_news_crawler_processed_contentUncheckedCreateWithoutLlmJobInput>\n  }\n\n  export type political_news_crawler_processed_contentCreateManyLlmJobInputEnvelope = {\n    data: political_news_crawler_processed_contentCreateManyLlmJobInput | political_news_crawler_processed_contentCreateManyLlmJobInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_llm_resultsCreateWithoutLlmJobInput = {\n    id: string\n    content_type: string\n    content_text: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_llm_resultsUncheckedCreateWithoutLlmJobInput = {\n    id: string\n    content_type: string\n    content_text: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_llm_resultsCreateOrConnectWithoutLlmJobInput = {\n    where: political_news_crawler_llm_resultsWhereUniqueInput\n    create: XOR<political_news_crawler_llm_resultsCreateWithoutLlmJobInput, political_news_crawler_llm_resultsUncheckedCreateWithoutLlmJobInput>\n  }\n\n  export type political_news_crawler_llm_resultsCreateManyLlmJobInputEnvelope = {\n    data: political_news_crawler_llm_resultsCreateManyLlmJobInput | political_news_crawler_llm_resultsCreateManyLlmJobInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_processing_metadataCreateWithoutLlmJobInput = {\n    id: string\n    metadata_key: string\n    metadata_value: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_processing_metadataUncheckedCreateWithoutLlmJobInput = {\n    id: string\n    metadata_key: string\n    metadata_value: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_processing_metadataCreateOrConnectWithoutLlmJobInput = {\n    where: political_news_crawler_processing_metadataWhereUniqueInput\n    create: XOR<political_news_crawler_processing_metadataCreateWithoutLlmJobInput, political_news_crawler_processing_metadataUncheckedCreateWithoutLlmJobInput>\n  }\n\n  export type political_news_crawler_processing_metadataCreateManyLlmJobInputEnvelope = {\n    data: political_news_crawler_processing_metadataCreateManyLlmJobInput | political_news_crawler_processing_metadataCreateManyLlmJobInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_crawl_sourcesUpsertWithoutPolitical_news_crawler_llm_jobsInput = {\n    update: XOR<political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_llm_jobsInput, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_llm_jobsInput>\n    create: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_llm_jobsInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_llm_jobsInput>\n    where?: political_news_crawler_crawl_sourcesWhereInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateToOneWithWhereWithoutPolitical_news_crawler_llm_jobsInput = {\n    where?: political_news_crawler_crawl_sourcesWhereInput\n    data: XOR<political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_llm_jobsInput, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_llm_jobsInput>\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_llm_jobsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUpdateManyWithoutCrawlSourceNestedInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_llm_jobsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_alerts?: political_news_crawler_crawl_alertsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n  }\n\n  export type political_news_crawler_processed_contentUpsertWithWhereUniqueWithoutLlmJobInput = {\n    where: political_news_crawler_processed_contentWhereUniqueInput\n    update: XOR<political_news_crawler_processed_contentUpdateWithoutLlmJobInput, political_news_crawler_processed_contentUncheckedUpdateWithoutLlmJobInput>\n    create: XOR<political_news_crawler_processed_contentCreateWithoutLlmJobInput, political_news_crawler_processed_contentUncheckedCreateWithoutLlmJobInput>\n  }\n\n  export type political_news_crawler_processed_contentUpdateWithWhereUniqueWithoutLlmJobInput = {\n    where: political_news_crawler_processed_contentWhereUniqueInput\n    data: XOR<political_news_crawler_processed_contentUpdateWithoutLlmJobInput, political_news_crawler_processed_contentUncheckedUpdateWithoutLlmJobInput>\n  }\n\n  export type political_news_crawler_processed_contentUpdateManyWithWhereWithoutLlmJobInput = {\n    where: political_news_crawler_processed_contentScalarWhereInput\n    data: XOR<political_news_crawler_processed_contentUpdateManyMutationInput, political_news_crawler_processed_contentUncheckedUpdateManyWithoutLlmJobInput>\n  }\n\n  export type political_news_crawler_llm_resultsUpsertWithWhereUniqueWithoutLlmJobInput = {\n    where: political_news_crawler_llm_resultsWhereUniqueInput\n    update: XOR<political_news_crawler_llm_resultsUpdateWithoutLlmJobInput, political_news_crawler_llm_resultsUncheckedUpdateWithoutLlmJobInput>\n    create: XOR<political_news_crawler_llm_resultsCreateWithoutLlmJobInput, political_news_crawler_llm_resultsUncheckedCreateWithoutLlmJobInput>\n  }\n\n  export type political_news_crawler_llm_resultsUpdateWithWhereUniqueWithoutLlmJobInput = {\n    where: political_news_crawler_llm_resultsWhereUniqueInput\n    data: XOR<political_news_crawler_llm_resultsUpdateWithoutLlmJobInput, political_news_crawler_llm_resultsUncheckedUpdateWithoutLlmJobInput>\n  }\n\n  export type political_news_crawler_llm_resultsUpdateManyWithWhereWithoutLlmJobInput = {\n    where: political_news_crawler_llm_resultsScalarWhereInput\n    data: XOR<political_news_crawler_llm_resultsUpdateManyMutationInput, political_news_crawler_llm_resultsUncheckedUpdateManyWithoutLlmJobInput>\n  }\n\n  export type political_news_crawler_llm_resultsScalarWhereInput = {\n    AND?: political_news_crawler_llm_resultsScalarWhereInput | political_news_crawler_llm_resultsScalarWhereInput[]\n    OR?: political_news_crawler_llm_resultsScalarWhereInput[]\n    NOT?: political_news_crawler_llm_resultsScalarWhereInput | political_news_crawler_llm_resultsScalarWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_llm_results\"> | string\n    llm_job_id?: UuidFilter<\"political_news_crawler_llm_results\"> | string\n    content_type?: StringFilter<\"political_news_crawler_llm_results\"> | string\n    content_text?: StringFilter<\"political_news_crawler_llm_results\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_llm_results\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_llm_results\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_llm_results\"> | Date | string | null\n  }\n\n  export type political_news_crawler_processing_metadataUpsertWithWhereUniqueWithoutLlmJobInput = {\n    where: political_news_crawler_processing_metadataWhereUniqueInput\n    update: XOR<political_news_crawler_processing_metadataUpdateWithoutLlmJobInput, political_news_crawler_processing_metadataUncheckedUpdateWithoutLlmJobInput>\n    create: XOR<political_news_crawler_processing_metadataCreateWithoutLlmJobInput, political_news_crawler_processing_metadataUncheckedCreateWithoutLlmJobInput>\n  }\n\n  export type political_news_crawler_processing_metadataUpdateWithWhereUniqueWithoutLlmJobInput = {\n    where: political_news_crawler_processing_metadataWhereUniqueInput\n    data: XOR<political_news_crawler_processing_metadataUpdateWithoutLlmJobInput, political_news_crawler_processing_metadataUncheckedUpdateWithoutLlmJobInput>\n  }\n\n  export type political_news_crawler_processing_metadataUpdateManyWithWhereWithoutLlmJobInput = {\n    where: political_news_crawler_processing_metadataScalarWhereInput\n    data: XOR<political_news_crawler_processing_metadataUpdateManyMutationInput, political_news_crawler_processing_metadataUncheckedUpdateManyWithoutLlmJobInput>\n  }\n\n  export type political_news_crawler_processing_metadataScalarWhereInput = {\n    AND?: political_news_crawler_processing_metadataScalarWhereInput | political_news_crawler_processing_metadataScalarWhereInput[]\n    OR?: political_news_crawler_processing_metadataScalarWhereInput[]\n    NOT?: political_news_crawler_processing_metadataScalarWhereInput | political_news_crawler_processing_metadataScalarWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_processing_metadata\"> | string\n    llm_job_id?: UuidFilter<\"political_news_crawler_processing_metadata\"> | string\n    metadata_key?: StringFilter<\"political_news_crawler_processing_metadata\"> | string\n    metadata_value?: StringFilter<\"political_news_crawler_processing_metadata\"> | string\n    created_at?: DateTimeFilter<\"political_news_crawler_processing_metadata\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_processing_metadata\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_processing_metadata\"> | Date | string | null\n  }\n\n  export type political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_llm_resultsInput = {\n    id: string\n    status: string\n    parameters: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_llm_jobsInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataCreateNestedManyWithoutLlmJobInput\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_llm_resultsInput = {\n    id: string\n    crawl_source_id: string\n    status: string\n    parameters: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataUncheckedCreateNestedManyWithoutLlmJobInput\n  }\n\n  export type political_news_crawler_llm_jobsCreateOrConnectWithoutPolitical_news_crawler_llm_resultsInput = {\n    where: political_news_crawler_llm_jobsWhereUniqueInput\n    create: XOR<political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_llm_resultsInput, political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_llm_resultsInput>\n  }\n\n  export type political_news_crawler_llm_jobsUpsertWithoutPolitical_news_crawler_llm_resultsInput = {\n    update: XOR<political_news_crawler_llm_jobsUpdateWithoutPolitical_news_crawler_llm_resultsInput, political_news_crawler_llm_jobsUncheckedUpdateWithoutPolitical_news_crawler_llm_resultsInput>\n    create: XOR<political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_llm_resultsInput, political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_llm_resultsInput>\n    where?: political_news_crawler_llm_jobsWhereInput\n  }\n\n  export type political_news_crawler_llm_jobsUpdateToOneWithWhereWithoutPolitical_news_crawler_llm_resultsInput = {\n    where?: political_news_crawler_llm_jobsWhereInput\n    data: XOR<political_news_crawler_llm_jobsUpdateWithoutPolitical_news_crawler_llm_resultsInput, political_news_crawler_llm_jobsUncheckedUpdateWithoutPolitical_news_crawler_llm_resultsInput>\n  }\n\n  export type political_news_crawler_llm_jobsUpdateWithoutPolitical_news_crawler_llm_resultsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    status?: StringFieldUpdateOperationsInput | string\n    parameters?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_llm_jobsNestedInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataUpdateManyWithoutLlmJobNestedInput\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedUpdateWithoutPolitical_news_crawler_llm_resultsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    status?: StringFieldUpdateOperationsInput | string\n    parameters?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataUncheckedUpdateManyWithoutLlmJobNestedInput\n  }\n\n  export type political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_processing_metadataInput = {\n    id: string\n    status: string\n    parameters: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawlSource: political_news_crawler_crawl_sourcesCreateNestedOneWithoutPolitical_news_crawler_llm_jobsInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsCreateNestedManyWithoutLlmJobInput\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_processing_metadataInput = {\n    id: string\n    crawl_source_id: string\n    status: string\n    parameters: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedCreateNestedManyWithoutLlmJobInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsUncheckedCreateNestedManyWithoutLlmJobInput\n  }\n\n  export type political_news_crawler_llm_jobsCreateOrConnectWithoutPolitical_news_crawler_processing_metadataInput = {\n    where: political_news_crawler_llm_jobsWhereUniqueInput\n    create: XOR<political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_processing_metadataInput, political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_processing_metadataInput>\n  }\n\n  export type political_news_crawler_llm_jobsUpsertWithoutPolitical_news_crawler_processing_metadataInput = {\n    update: XOR<political_news_crawler_llm_jobsUpdateWithoutPolitical_news_crawler_processing_metadataInput, political_news_crawler_llm_jobsUncheckedUpdateWithoutPolitical_news_crawler_processing_metadataInput>\n    create: XOR<political_news_crawler_llm_jobsCreateWithoutPolitical_news_crawler_processing_metadataInput, political_news_crawler_llm_jobsUncheckedCreateWithoutPolitical_news_crawler_processing_metadataInput>\n    where?: political_news_crawler_llm_jobsWhereInput\n  }\n\n  export type political_news_crawler_llm_jobsUpdateToOneWithWhereWithoutPolitical_news_crawler_processing_metadataInput = {\n    where?: political_news_crawler_llm_jobsWhereInput\n    data: XOR<political_news_crawler_llm_jobsUpdateWithoutPolitical_news_crawler_processing_metadataInput, political_news_crawler_llm_jobsUncheckedUpdateWithoutPolitical_news_crawler_processing_metadataInput>\n  }\n\n  export type political_news_crawler_llm_jobsUpdateWithoutPolitical_news_crawler_processing_metadataInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    status?: StringFieldUpdateOperationsInput | string\n    parameters?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_llm_jobsNestedInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsUpdateManyWithoutLlmJobNestedInput\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedUpdateWithoutPolitical_news_crawler_processing_metadataInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    status?: StringFieldUpdateOperationsInput | string\n    parameters?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsUncheckedUpdateManyWithoutLlmJobNestedInput\n  }\n\n  export type political_news_crawler_popular_topicsCreateWithoutPolitical_news_crawler_popularity_scoresInput = {\n    id: string\n    topic_code: string\n    title: string\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsCreateNestedManyWithoutPopularTopicInput\n  }\n\n  export type political_news_crawler_popular_topicsUncheckedCreateWithoutPolitical_news_crawler_popularity_scoresInput = {\n    id: string\n    topic_code: string\n    title: string\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsUncheckedCreateNestedManyWithoutPopularTopicInput\n  }\n\n  export type political_news_crawler_popular_topicsCreateOrConnectWithoutPolitical_news_crawler_popularity_scoresInput = {\n    where: political_news_crawler_popular_topicsWhereUniqueInput\n    create: XOR<political_news_crawler_popular_topicsCreateWithoutPolitical_news_crawler_popularity_scoresInput, political_news_crawler_popular_topicsUncheckedCreateWithoutPolitical_news_crawler_popularity_scoresInput>\n  }\n\n  export type political_news_crawler_popular_topicsUpsertWithoutPolitical_news_crawler_popularity_scoresInput = {\n    update: XOR<political_news_crawler_popular_topicsUpdateWithoutPolitical_news_crawler_popularity_scoresInput, political_news_crawler_popular_topicsUncheckedUpdateWithoutPolitical_news_crawler_popularity_scoresInput>\n    create: XOR<political_news_crawler_popular_topicsCreateWithoutPolitical_news_crawler_popularity_scoresInput, political_news_crawler_popular_topicsUncheckedCreateWithoutPolitical_news_crawler_popularity_scoresInput>\n    where?: political_news_crawler_popular_topicsWhereInput\n  }\n\n  export type political_news_crawler_popular_topicsUpdateToOneWithWhereWithoutPolitical_news_crawler_popularity_scoresInput = {\n    where?: political_news_crawler_popular_topicsWhereInput\n    data: XOR<political_news_crawler_popular_topicsUpdateWithoutPolitical_news_crawler_popularity_scoresInput, political_news_crawler_popular_topicsUncheckedUpdateWithoutPolitical_news_crawler_popularity_scoresInput>\n  }\n\n  export type political_news_crawler_popular_topicsUpdateWithoutPolitical_news_crawler_popularity_scoresInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    topic_code?: StringFieldUpdateOperationsInput | string\n    title?: StringFieldUpdateOperationsInput | string\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsUpdateManyWithoutPopularTopicNestedInput\n  }\n\n  export type political_news_crawler_popular_topicsUncheckedUpdateWithoutPolitical_news_crawler_popularity_scoresInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    topic_code?: StringFieldUpdateOperationsInput | string\n    title?: StringFieldUpdateOperationsInput | string\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsUncheckedUpdateManyWithoutPopularTopicNestedInput\n  }\n\n  export type political_news_crawler_popularity_scoresCreateWithoutPopularTopicInput = {\n    id: string\n    score: number\n    decay_factor: number\n    snapshot_at: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_popularity_scoresUncheckedCreateWithoutPopularTopicInput = {\n    id: string\n    score: number\n    decay_factor: number\n    snapshot_at: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_popularity_scoresCreateOrConnectWithoutPopularTopicInput = {\n    where: political_news_crawler_popularity_scoresWhereUniqueInput\n    create: XOR<political_news_crawler_popularity_scoresCreateWithoutPopularTopicInput, political_news_crawler_popularity_scoresUncheckedCreateWithoutPopularTopicInput>\n  }\n\n  export type political_news_crawler_popularity_scoresCreateManyPopularTopicInputEnvelope = {\n    data: political_news_crawler_popularity_scoresCreateManyPopularTopicInput | political_news_crawler_popularity_scoresCreateManyPopularTopicInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_topic_mentionsCreateWithoutPopularTopicInput = {\n    id: string\n    mention_context?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    crawledNews: political_news_crawler_crawled_newsCreateNestedOneWithoutPolitical_news_crawler_topic_mentionsInput\n  }\n\n  export type political_news_crawler_topic_mentionsUncheckedCreateWithoutPopularTopicInput = {\n    id: string\n    political_news_crawler_crawled_news_id: string\n    mention_context?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsCreateOrConnectWithoutPopularTopicInput = {\n    where: political_news_crawler_topic_mentionsWhereUniqueInput\n    create: XOR<political_news_crawler_topic_mentionsCreateWithoutPopularTopicInput, political_news_crawler_topic_mentionsUncheckedCreateWithoutPopularTopicInput>\n  }\n\n  export type political_news_crawler_topic_mentionsCreateManyPopularTopicInputEnvelope = {\n    data: political_news_crawler_topic_mentionsCreateManyPopularTopicInput | political_news_crawler_topic_mentionsCreateManyPopularTopicInput[]\n    skipDuplicates?: boolean\n  }\n\n  export type political_news_crawler_popularity_scoresUpsertWithWhereUniqueWithoutPopularTopicInput = {\n    where: political_news_crawler_popularity_scoresWhereUniqueInput\n    update: XOR<political_news_crawler_popularity_scoresUpdateWithoutPopularTopicInput, political_news_crawler_popularity_scoresUncheckedUpdateWithoutPopularTopicInput>\n    create: XOR<political_news_crawler_popularity_scoresCreateWithoutPopularTopicInput, political_news_crawler_popularity_scoresUncheckedCreateWithoutPopularTopicInput>\n  }\n\n  export type political_news_crawler_popularity_scoresUpdateWithWhereUniqueWithoutPopularTopicInput = {\n    where: political_news_crawler_popularity_scoresWhereUniqueInput\n    data: XOR<political_news_crawler_popularity_scoresUpdateWithoutPopularTopicInput, political_news_crawler_popularity_scoresUncheckedUpdateWithoutPopularTopicInput>\n  }\n\n  export type political_news_crawler_popularity_scoresUpdateManyWithWhereWithoutPopularTopicInput = {\n    where: political_news_crawler_popularity_scoresScalarWhereInput\n    data: XOR<political_news_crawler_popularity_scoresUpdateManyMutationInput, political_news_crawler_popularity_scoresUncheckedUpdateManyWithoutPopularTopicInput>\n  }\n\n  export type political_news_crawler_popularity_scoresScalarWhereInput = {\n    AND?: political_news_crawler_popularity_scoresScalarWhereInput | political_news_crawler_popularity_scoresScalarWhereInput[]\n    OR?: political_news_crawler_popularity_scoresScalarWhereInput[]\n    NOT?: political_news_crawler_popularity_scoresScalarWhereInput | political_news_crawler_popularity_scoresScalarWhereInput[]\n    id?: UuidFilter<\"political_news_crawler_popularity_scores\"> | string\n    political_news_crawler_popular_topic_id?: UuidFilter<\"political_news_crawler_popularity_scores\"> | string\n    score?: FloatFilter<\"political_news_crawler_popularity_scores\"> | number\n    decay_factor?: FloatFilter<\"political_news_crawler_popularity_scores\"> | number\n    snapshot_at?: DateTimeFilter<\"political_news_crawler_popularity_scores\"> | Date | string\n    created_at?: DateTimeFilter<\"political_news_crawler_popularity_scores\"> | Date | string\n    updated_at?: DateTimeFilter<\"political_news_crawler_popularity_scores\"> | Date | string\n    deleted_at?: DateTimeNullableFilter<\"political_news_crawler_popularity_scores\"> | Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsUpsertWithWhereUniqueWithoutPopularTopicInput = {\n    where: political_news_crawler_topic_mentionsWhereUniqueInput\n    update: XOR<political_news_crawler_topic_mentionsUpdateWithoutPopularTopicInput, political_news_crawler_topic_mentionsUncheckedUpdateWithoutPopularTopicInput>\n    create: XOR<political_news_crawler_topic_mentionsCreateWithoutPopularTopicInput, political_news_crawler_topic_mentionsUncheckedCreateWithoutPopularTopicInput>\n  }\n\n  export type political_news_crawler_topic_mentionsUpdateWithWhereUniqueWithoutPopularTopicInput = {\n    where: political_news_crawler_topic_mentionsWhereUniqueInput\n    data: XOR<political_news_crawler_topic_mentionsUpdateWithoutPopularTopicInput, political_news_crawler_topic_mentionsUncheckedUpdateWithoutPopularTopicInput>\n  }\n\n  export type political_news_crawler_topic_mentionsUpdateManyWithWhereWithoutPopularTopicInput = {\n    where: political_news_crawler_topic_mentionsScalarWhereInput\n    data: XOR<political_news_crawler_topic_mentionsUpdateManyMutationInput, political_news_crawler_topic_mentionsUncheckedUpdateManyWithoutPopularTopicInput>\n  }\n\n  export type political_news_crawler_popular_topicsCreateWithoutPolitical_news_crawler_topic_mentionsInput = {\n    id: string\n    topic_code: string\n    title: string\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_popularity_scores?: political_news_crawler_popularity_scoresCreateNestedManyWithoutPopularTopicInput\n  }\n\n  export type political_news_crawler_popular_topicsUncheckedCreateWithoutPolitical_news_crawler_topic_mentionsInput = {\n    id: string\n    topic_code: string\n    title: string\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_popularity_scores?: political_news_crawler_popularity_scoresUncheckedCreateNestedManyWithoutPopularTopicInput\n  }\n\n  export type political_news_crawler_popular_topicsCreateOrConnectWithoutPolitical_news_crawler_topic_mentionsInput = {\n    where: political_news_crawler_popular_topicsWhereUniqueInput\n    create: XOR<political_news_crawler_popular_topicsCreateWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_popular_topicsUncheckedCreateWithoutPolitical_news_crawler_topic_mentionsInput>\n  }\n\n  export type political_news_crawler_crawled_newsCreateWithoutPolitical_news_crawler_topic_mentionsInput = {\n    id: string\n    url: string\n    title?: string | null\n    published_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    crawlAttempt: political_news_crawler_crawl_attemptsCreateNestedOneWithoutPolitical_news_crawler_crawled_newsInput\n  }\n\n  export type political_news_crawler_crawled_newsUncheckedCreateWithoutPolitical_news_crawler_topic_mentionsInput = {\n    id: string\n    crawl_attempt_id: string\n    url: string\n    title?: string | null\n    published_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_crawled_newsCreateOrConnectWithoutPolitical_news_crawler_topic_mentionsInput = {\n    where: political_news_crawler_crawled_newsWhereUniqueInput\n    create: XOR<political_news_crawler_crawled_newsCreateWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_crawled_newsUncheckedCreateWithoutPolitical_news_crawler_topic_mentionsInput>\n  }\n\n  export type political_news_crawler_popular_topicsUpsertWithoutPolitical_news_crawler_topic_mentionsInput = {\n    update: XOR<political_news_crawler_popular_topicsUpdateWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_popular_topicsUncheckedUpdateWithoutPolitical_news_crawler_topic_mentionsInput>\n    create: XOR<political_news_crawler_popular_topicsCreateWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_popular_topicsUncheckedCreateWithoutPolitical_news_crawler_topic_mentionsInput>\n    where?: political_news_crawler_popular_topicsWhereInput\n  }\n\n  export type political_news_crawler_popular_topicsUpdateToOneWithWhereWithoutPolitical_news_crawler_topic_mentionsInput = {\n    where?: political_news_crawler_popular_topicsWhereInput\n    data: XOR<political_news_crawler_popular_topicsUpdateWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_popular_topicsUncheckedUpdateWithoutPolitical_news_crawler_topic_mentionsInput>\n  }\n\n  export type political_news_crawler_popular_topicsUpdateWithoutPolitical_news_crawler_topic_mentionsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    topic_code?: StringFieldUpdateOperationsInput | string\n    title?: StringFieldUpdateOperationsInput | string\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_popularity_scores?: political_news_crawler_popularity_scoresUpdateManyWithoutPopularTopicNestedInput\n  }\n\n  export type political_news_crawler_popular_topicsUncheckedUpdateWithoutPolitical_news_crawler_topic_mentionsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    topic_code?: StringFieldUpdateOperationsInput | string\n    title?: StringFieldUpdateOperationsInput | string\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_popularity_scores?: political_news_crawler_popularity_scoresUncheckedUpdateManyWithoutPopularTopicNestedInput\n  }\n\n  export type political_news_crawler_crawled_newsUpsertWithoutPolitical_news_crawler_topic_mentionsInput = {\n    update: XOR<political_news_crawler_crawled_newsUpdateWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_crawled_newsUncheckedUpdateWithoutPolitical_news_crawler_topic_mentionsInput>\n    create: XOR<political_news_crawler_crawled_newsCreateWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_crawled_newsUncheckedCreateWithoutPolitical_news_crawler_topic_mentionsInput>\n    where?: political_news_crawler_crawled_newsWhereInput\n  }\n\n  export type political_news_crawler_crawled_newsUpdateToOneWithWhereWithoutPolitical_news_crawler_topic_mentionsInput = {\n    where?: political_news_crawler_crawled_newsWhereInput\n    data: XOR<political_news_crawler_crawled_newsUpdateWithoutPolitical_news_crawler_topic_mentionsInput, political_news_crawler_crawled_newsUncheckedUpdateWithoutPolitical_news_crawler_topic_mentionsInput>\n  }\n\n  export type political_news_crawler_crawled_newsUpdateWithoutPolitical_news_crawler_topic_mentionsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    url?: StringFieldUpdateOperationsInput | string\n    title?: NullableStringFieldUpdateOperationsInput | string | null\n    published_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    crawlAttempt?: political_news_crawler_crawl_attemptsUpdateOneRequiredWithoutPolitical_news_crawler_crawled_newsNestedInput\n  }\n\n  export type political_news_crawler_crawled_newsUncheckedUpdateWithoutPolitical_news_crawler_topic_mentionsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_attempt_id?: StringFieldUpdateOperationsInput | string\n    url?: StringFieldUpdateOperationsInput | string\n    title?: NullableStringFieldUpdateOperationsInput | string | null\n    published_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_alertsInput = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsCreateNestedManyWithoutCrawlSourceInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_alertsInput = {\n    id: string\n    source_code: string\n    source_url: string\n    is_active: boolean\n    description?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedCreateNestedManyWithoutCrawlSourceInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUncheckedCreateNestedManyWithoutCrawlSourceInput\n  }\n\n  export type political_news_crawler_crawl_sourcesCreateOrConnectWithoutPolitical_news_crawler_crawl_alertsInput = {\n    where: political_news_crawler_crawl_sourcesWhereUniqueInput\n    create: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_alertsInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_alertsInput>\n  }\n\n  export type political_news_crawler_crawl_sourcesUpsertWithoutPolitical_news_crawler_crawl_alertsInput = {\n    update: XOR<political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_crawl_alertsInput, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_crawl_alertsInput>\n    create: XOR<political_news_crawler_crawl_sourcesCreateWithoutPolitical_news_crawler_crawl_alertsInput, political_news_crawler_crawl_sourcesUncheckedCreateWithoutPolitical_news_crawler_crawl_alertsInput>\n    where?: political_news_crawler_crawl_sourcesWhereInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateToOneWithWhereWithoutPolitical_news_crawler_crawl_alertsInput = {\n    where?: political_news_crawler_crawl_sourcesWhereInput\n    data: XOR<political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_crawl_alertsInput, political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_crawl_alertsInput>\n  }\n\n  export type political_news_crawler_crawl_sourcesUpdateWithoutPolitical_news_crawler_crawl_alertsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUpdateManyWithoutCrawlSourceNestedInput\n  }\n\n  export type political_news_crawler_crawl_sourcesUncheckedUpdateWithoutPolitical_news_crawler_crawl_alertsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    source_code?: StringFieldUpdateOperationsInput | string\n    source_url?: StringFieldUpdateOperationsInput | string\n    is_active?: BoolFieldUpdateOperationsInput | boolean\n    description?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_schedules?: political_news_crawler_crawl_schedulesUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlSourceNestedInput\n    political_news_crawler_llm_jobs?: political_news_crawler_llm_jobsUncheckedUpdateManyWithoutCrawlSourceNestedInput\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateManyCrawlSourceInput = {\n    id: string\n    crawl_policy_id: string\n    schedule_expression: string\n    last_crawled_at?: Date | string | null\n    next_crawl_at?: Date | string | null\n    is_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_crawl_jobsCreateManyCrawlSourceInput = {\n    id: string\n    crawl_schedule_id: string\n    active: boolean\n    last_run_started_at?: Date | string | null\n    last_run_completed_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_raw_data_storageCreateManyCrawlSourceInput = {\n    id: string\n    crawl_job_id?: string | null\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_llm_jobsCreateManyCrawlSourceInput = {\n    id: string\n    status: string\n    parameters: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_crawl_alertsCreateManyCrawlSourceInput = {\n    id: string\n    alert_type: string\n    message: string\n    severity: string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_crawl_schedulesUpdateWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    schedule_expression?: StringFieldUpdateOperationsInput | string\n    last_crawled_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    next_crawl_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    is_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawlPolicy?: political_news_crawler_crawl_policiesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_schedulesNestedInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUpdateManyWithoutCrawlScheduleNestedInput\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedUpdateWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_policy_id?: StringFieldUpdateOperationsInput | string\n    schedule_expression?: StringFieldUpdateOperationsInput | string\n    last_crawled_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    next_crawl_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    is_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlScheduleNestedInput\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedUpdateManyWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_policy_id?: StringFieldUpdateOperationsInput | string\n    schedule_expression?: StringFieldUpdateOperationsInput | string\n    last_crawled_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    next_crawl_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    is_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawlSchedule?: political_news_crawler_crawl_schedulesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_jobsNestedInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUpdateManyWithoutCrawlJobNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUpdateManyWithoutCrawlJobNestedInput\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedUpdateWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_schedule_id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutCrawlJobNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlJobNestedInput\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_schedule_id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    crawlJob?: political_news_crawler_crawl_jobsUpdateOneWithoutPolitical_news_crawler_raw_data_storageNestedInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUpdateManyWithoutRawDataStorageNestedInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedUpdateWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_job_id?: NullableStringFieldUpdateOperationsInput | string | null\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUncheckedUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedUpdateManyWithoutRawDataStorageNestedInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_job_id?: NullableStringFieldUpdateOperationsInput | string | null\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_llm_jobsUpdateWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    status?: StringFieldUpdateOperationsInput | string\n    parameters?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataUpdateManyWithoutLlmJobNestedInput\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedUpdateWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    status?: StringFieldUpdateOperationsInput | string\n    parameters?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_llm_results?: political_news_crawler_llm_resultsUncheckedUpdateManyWithoutLlmJobNestedInput\n    political_news_crawler_processing_metadata?: political_news_crawler_processing_metadataUncheckedUpdateManyWithoutLlmJobNestedInput\n  }\n\n  export type political_news_crawler_llm_jobsUncheckedUpdateManyWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    status?: StringFieldUpdateOperationsInput | string\n    parameters?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_alertsUpdateWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_crawl_alertsUncheckedUpdateWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_crawl_alertsUncheckedUpdateManyWithoutCrawlSourceInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    alert_type?: StringFieldUpdateOperationsInput | string\n    message?: StringFieldUpdateOperationsInput | string\n    severity?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_crawl_schedulesCreateManyCrawlPolicyInput = {\n    id: string\n    crawl_source_id: string\n    schedule_expression: string\n    last_crawled_at?: Date | string | null\n    next_crawl_at?: Date | string | null\n    is_enabled: boolean\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_crawl_schedulesUpdateWithoutCrawlPolicyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    schedule_expression?: StringFieldUpdateOperationsInput | string\n    last_crawled_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    next_crawl_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    is_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_schedulesNestedInput\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUpdateManyWithoutCrawlScheduleNestedInput\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedUpdateWithoutCrawlPolicyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    schedule_expression?: StringFieldUpdateOperationsInput | string\n    last_crawled_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    next_crawl_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    is_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_jobs?: political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlScheduleNestedInput\n  }\n\n  export type political_news_crawler_crawl_schedulesUncheckedUpdateManyWithoutCrawlPolicyInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    schedule_expression?: StringFieldUpdateOperationsInput | string\n    last_crawled_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    next_crawl_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    is_enabled?: BoolFieldUpdateOperationsInput | boolean\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_jobsCreateManyCrawlScheduleInput = {\n    id: string\n    crawl_source_id: string\n    active: boolean\n    last_run_started_at?: Date | string | null\n    last_run_completed_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_crawl_jobsUpdateWithoutCrawlScheduleInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_crawl_jobsNestedInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUpdateManyWithoutCrawlJobNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUpdateManyWithoutCrawlJobNestedInput\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedUpdateWithoutCrawlScheduleInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutCrawlJobNestedInput\n    political_news_crawler_raw_data_storage?: political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlJobNestedInput\n  }\n\n  export type political_news_crawler_crawl_jobsUncheckedUpdateManyWithoutCrawlScheduleInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    active?: BoolFieldUpdateOperationsInput | boolean\n    last_run_started_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    last_run_completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateManyCrawlJobInput = {\n    id: string\n    raw_data_storage_id?: string | null\n    started_at: Date | string\n    completed_at?: Date | string | null\n    success: boolean\n    error_message?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_raw_data_storageCreateManyCrawlJobInput = {\n    id: string\n    crawl_source_id: string\n    storage_key: string\n    file_format: string\n    file_size_bytes: number\n    checksum?: string | null\n    crawl_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_crawl_attemptsUpdateWithoutCrawlJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    started_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    success?: BoolFieldUpdateOperationsInput | boolean\n    error_message?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    rawDataStorage?: political_news_crawler_raw_data_storageUpdateOneWithoutPolitical_news_crawler_crawl_attemptsNestedInput\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsUpdateManyWithoutCrawlAttemptNestedInput\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedUpdateWithoutCrawlJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    raw_data_storage_id?: NullableStringFieldUpdateOperationsInput | string | null\n    started_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    success?: BoolFieldUpdateOperationsInput | boolean\n    error_message?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsUncheckedUpdateManyWithoutCrawlAttemptNestedInput\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutCrawlJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    raw_data_storage_id?: NullableStringFieldUpdateOperationsInput | string | null\n    started_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    success?: BoolFieldUpdateOperationsInput | boolean\n    error_message?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_raw_data_storageUpdateWithoutCrawlJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    crawlSource?: political_news_crawler_crawl_sourcesUpdateOneRequiredWithoutPolitical_news_crawler_raw_data_storageNestedInput\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUpdateManyWithoutRawDataStorageNestedInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedUpdateWithoutCrawlJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    political_news_crawler_crawl_attempts?: political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_local_cache_files?: political_news_crawler_local_cache_filesUncheckedUpdateManyWithoutRawDataStorageNestedInput\n    political_news_crawler_processed_content?: political_news_crawler_processed_contentUncheckedUpdateManyWithoutRawDataStorageNestedInput\n  }\n\n  export type political_news_crawler_raw_data_storageUncheckedUpdateManyWithoutCrawlJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_source_id?: StringFieldUpdateOperationsInput | string\n    storage_key?: StringFieldUpdateOperationsInput | string\n    file_format?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    checksum?: NullableStringFieldUpdateOperationsInput | string | null\n    crawl_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_crawled_newsCreateManyCrawlAttemptInput = {\n    id: string\n    url: string\n    title?: string | null\n    published_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_crawled_newsUpdateWithoutCrawlAttemptInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    url?: StringFieldUpdateOperationsInput | string\n    title?: NullableStringFieldUpdateOperationsInput | string | null\n    published_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsUpdateManyWithoutCrawledNewsNestedInput\n  }\n\n  export type political_news_crawler_crawled_newsUncheckedUpdateWithoutCrawlAttemptInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    url?: StringFieldUpdateOperationsInput | string\n    title?: NullableStringFieldUpdateOperationsInput | string | null\n    published_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    political_news_crawler_topic_mentions?: political_news_crawler_topic_mentionsUncheckedUpdateManyWithoutCrawledNewsNestedInput\n  }\n\n  export type political_news_crawler_crawled_newsUncheckedUpdateManyWithoutCrawlAttemptInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    url?: StringFieldUpdateOperationsInput | string\n    title?: NullableStringFieldUpdateOperationsInput | string | null\n    published_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_topic_mentionsCreateManyCrawledNewsInput = {\n    id: string\n    political_news_crawler_popular_topic_id: string\n    mention_context?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsUpdateWithoutCrawledNewsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    mention_context?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    popularTopic?: political_news_crawler_popular_topicsUpdateOneRequiredWithoutPolitical_news_crawler_topic_mentionsNestedInput\n  }\n\n  export type political_news_crawler_topic_mentionsUncheckedUpdateWithoutCrawledNewsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    political_news_crawler_popular_topic_id?: StringFieldUpdateOperationsInput | string\n    mention_context?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsUncheckedUpdateManyWithoutCrawledNewsInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    political_news_crawler_popular_topic_id?: StringFieldUpdateOperationsInput | string\n    mention_context?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_crawl_attemptsCreateManyRawDataStorageInput = {\n    id: string\n    crawl_job_id: string\n    started_at: Date | string\n    completed_at?: Date | string | null\n    success: boolean\n    error_message?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_local_cache_filesCreateManyRawDataStorageInput = {\n    id: string\n    local_file_path: string\n    file_size_bytes: number\n    ttl_expiration_at: Date | string\n    deleted_at?: Date | string | null\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_processed_contentCreateManyRawDataStorageInput = {\n    id: string\n    llm_job_id?: string | null\n    content_type: string\n    content_body: string\n    generation_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_crawl_attemptsUpdateWithoutRawDataStorageInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    started_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    success?: BoolFieldUpdateOperationsInput | boolean\n    error_message?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    crawlJob?: political_news_crawler_crawl_jobsUpdateOneRequiredWithoutPolitical_news_crawler_crawl_attemptsNestedInput\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsUpdateManyWithoutCrawlAttemptNestedInput\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedUpdateWithoutRawDataStorageInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_job_id?: StringFieldUpdateOperationsInput | string\n    started_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    success?: BoolFieldUpdateOperationsInput | boolean\n    error_message?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    political_news_crawler_crawled_news?: political_news_crawler_crawled_newsUncheckedUpdateManyWithoutCrawlAttemptNestedInput\n  }\n\n  export type political_news_crawler_crawl_attemptsUncheckedUpdateManyWithoutRawDataStorageInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    crawl_job_id?: StringFieldUpdateOperationsInput | string\n    started_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    completed_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    success?: BoolFieldUpdateOperationsInput | boolean\n    error_message?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_local_cache_filesUpdateWithoutRawDataStorageInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    local_file_path?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    ttl_expiration_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_local_cache_filesUncheckedUpdateWithoutRawDataStorageInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    local_file_path?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    ttl_expiration_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_local_cache_filesUncheckedUpdateManyWithoutRawDataStorageInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    local_file_path?: StringFieldUpdateOperationsInput | string\n    file_size_bytes?: IntFieldUpdateOperationsInput | number\n    ttl_expiration_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_processed_contentUpdateWithoutRawDataStorageInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_body?: StringFieldUpdateOperationsInput | string\n    generation_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    llmJob?: political_news_crawler_llm_jobsUpdateOneWithoutPolitical_news_crawler_processed_contentNestedInput\n  }\n\n  export type political_news_crawler_processed_contentUncheckedUpdateWithoutRawDataStorageInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    llm_job_id?: NullableStringFieldUpdateOperationsInput | string | null\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_body?: StringFieldUpdateOperationsInput | string\n    generation_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_processed_contentUncheckedUpdateManyWithoutRawDataStorageInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    llm_job_id?: NullableStringFieldUpdateOperationsInput | string | null\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_body?: StringFieldUpdateOperationsInput | string\n    generation_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_processed_contentCreateManyLlmJobInput = {\n    id: string\n    raw_data_storage_id: string\n    content_type: string\n    content_body: string\n    generation_timestamp: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n  }\n\n  export type political_news_crawler_llm_resultsCreateManyLlmJobInput = {\n    id: string\n    content_type: string\n    content_text: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_processing_metadataCreateManyLlmJobInput = {\n    id: string\n    metadata_key: string\n    metadata_value: string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_processed_contentUpdateWithoutLlmJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_body?: StringFieldUpdateOperationsInput | string\n    generation_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    rawDataStorage?: political_news_crawler_raw_data_storageUpdateOneRequiredWithoutPolitical_news_crawler_processed_contentNestedInput\n  }\n\n  export type political_news_crawler_processed_contentUncheckedUpdateWithoutLlmJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    raw_data_storage_id?: StringFieldUpdateOperationsInput | string\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_body?: StringFieldUpdateOperationsInput | string\n    generation_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_processed_contentUncheckedUpdateManyWithoutLlmJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    raw_data_storage_id?: StringFieldUpdateOperationsInput | string\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_body?: StringFieldUpdateOperationsInput | string\n    generation_timestamp?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n  }\n\n  export type political_news_crawler_llm_resultsUpdateWithoutLlmJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_text?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_llm_resultsUncheckedUpdateWithoutLlmJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_text?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_llm_resultsUncheckedUpdateManyWithoutLlmJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    content_type?: StringFieldUpdateOperationsInput | string\n    content_text?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_processing_metadataUpdateWithoutLlmJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    metadata_key?: StringFieldUpdateOperationsInput | string\n    metadata_value?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_processing_metadataUncheckedUpdateWithoutLlmJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    metadata_key?: StringFieldUpdateOperationsInput | string\n    metadata_value?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_processing_metadataUncheckedUpdateManyWithoutLlmJobInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    metadata_key?: StringFieldUpdateOperationsInput | string\n    metadata_value?: StringFieldUpdateOperationsInput | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_popularity_scoresCreateManyPopularTopicInput = {\n    id: string\n    score: number\n    decay_factor: number\n    snapshot_at: Date | string\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsCreateManyPopularTopicInput = {\n    id: string\n    political_news_crawler_crawled_news_id: string\n    mention_context?: string | null\n    created_at: Date | string\n    updated_at: Date | string\n    deleted_at?: Date | string | null\n  }\n\n  export type political_news_crawler_popularity_scoresUpdateWithoutPopularTopicInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    score?: FloatFieldUpdateOperationsInput | number\n    decay_factor?: FloatFieldUpdateOperationsInput | number\n    snapshot_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_popularity_scoresUncheckedUpdateWithoutPopularTopicInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    score?: FloatFieldUpdateOperationsInput | number\n    decay_factor?: FloatFieldUpdateOperationsInput | number\n    snapshot_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_popularity_scoresUncheckedUpdateManyWithoutPopularTopicInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    score?: FloatFieldUpdateOperationsInput | number\n    decay_factor?: FloatFieldUpdateOperationsInput | number\n    snapshot_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsUpdateWithoutPopularTopicInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    mention_context?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n    crawledNews?: political_news_crawler_crawled_newsUpdateOneRequiredWithoutPolitical_news_crawler_topic_mentionsNestedInput\n  }\n\n  export type political_news_crawler_topic_mentionsUncheckedUpdateWithoutPopularTopicInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    political_news_crawler_crawled_news_id?: StringFieldUpdateOperationsInput | string\n    mention_context?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n  export type political_news_crawler_topic_mentionsUncheckedUpdateManyWithoutPopularTopicInput = {\n    id?: StringFieldUpdateOperationsInput | string\n    political_news_crawler_crawled_news_id?: StringFieldUpdateOperationsInput | string\n    mention_context?: NullableStringFieldUpdateOperationsInput | string | null\n    created_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    updated_at?: DateTimeFieldUpdateOperationsInput | Date | string\n    deleted_at?: NullableDateTimeFieldUpdateOperationsInput | Date | string | null\n  }\n\n\n\n  /**\n   * Batch Payload for updateMany & deleteMany & createMany\n   */\n\n  export type BatchPayload = {\n    count: number\n  }\n\n  /**\n   * DMMF\n   */\n  export const dmmf: runtime.BaseDMMF\n}","node_modules/.prisma/client/runtime/index-browser.d.ts":"declare class AnyNull extends NullTypesEnumValue {\r\n    #private;\r\n}\r\n\r\ndeclare type Args<T, F extends Operation> = T extends {\r\n    [K: symbol]: {\r\n        types: {\r\n            operations: {\r\n                [K in F]: {\r\n                    args: any;\r\n                };\r\n            };\r\n        };\r\n    };\r\n} ? T[symbol]['types']['operations'][F]['args'] : any;\r\n\r\ndeclare class DbNull extends NullTypesEnumValue {\r\n    #private;\r\n}\r\n\r\nexport declare function Decimal(n: Decimal.Value): Decimal;\r\n\r\nexport declare namespace Decimal {\r\n    export type Constructor = typeof Decimal;\r\n    export type Instance = Decimal;\r\n    export type Rounding = 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8;\r\n    export type Modulo = Rounding | 9;\r\n    export type Value = string | number | Decimal;\r\n\r\n    // http://mikemcl.github.io/decimal.js/#constructor-properties\r\n    export interface Config {\r\n        precision?: number;\r\n        rounding?: Rounding;\r\n        toExpNeg?: number;\r\n        toExpPos?: number;\r\n        minE?: number;\r\n        maxE?: number;\r\n        crypto?: boolean;\r\n        modulo?: Modulo;\r\n        defaults?: boolean;\r\n    }\r\n}\r\n\r\nexport declare class Decimal {\r\n    readonly d: number[];\r\n    readonly e: number;\r\n    readonly s: number;\r\n\r\n    constructor(n: Decimal.Value);\r\n\r\n    absoluteValue(): Decimal;\r\n    abs(): Decimal;\r\n\r\n    ceil(): Decimal;\r\n\r\n    clampedTo(min: Decimal.Value, max: Decimal.Value): Decimal;\r\n    clamp(min: Decimal.Value, max: Decimal.Value): Decimal;\r\n\r\n    comparedTo(n: Decimal.Value): number;\r\n    cmp(n: Decimal.Value): number;\r\n\r\n    cosine(): Decimal;\r\n    cos(): Decimal;\r\n\r\n    cubeRoot(): Decimal;\r\n    cbrt(): Decimal;\r\n\r\n    decimalPlaces(): number;\r\n    dp(): number;\r\n\r\n    dividedBy(n: Decimal.Value): Decimal;\r\n    div(n: Decimal.Value): Decimal;\r\n\r\n    dividedToIntegerBy(n: Decimal.Value): Decimal;\r\n    divToInt(n: Decimal.Value): Decimal;\r\n\r\n    equals(n: Decimal.Value): boolean;\r\n    eq(n: Decimal.Value): boolean;\r\n\r\n    floor(): Decimal;\r\n\r\n    greaterThan(n: Decimal.Value): boolean;\r\n    gt(n: Decimal.Value): boolean;\r\n\r\n    greaterThanOrEqualTo(n: Decimal.Value): boolean;\r\n    gte(n: Decimal.Value): boolean;\r\n\r\n    hyperbolicCosine(): Decimal;\r\n    cosh(): Decimal;\r\n\r\n    hyperbolicSine(): Decimal;\r\n    sinh(): Decimal;\r\n\r\n    hyperbolicTangent(): Decimal;\r\n    tanh(): Decimal;\r\n\r\n    inverseCosine(): Decimal;\r\n    acos(): Decimal;\r\n\r\n    inverseHyperbolicCosine(): Decimal;\r\n    acosh(): Decimal;\r\n\r\n    inverseHyperbolicSine(): Decimal;\r\n    asinh(): Decimal;\r\n\r\n    inverseHyperbolicTangent(): Decimal;\r\n    atanh(): Decimal;\r\n\r\n    inverseSine(): Decimal;\r\n    asin(): Decimal;\r\n\r\n    inverseTangent(): Decimal;\r\n    atan(): Decimal;\r\n\r\n    isFinite(): boolean;\r\n\r\n    isInteger(): boolean;\r\n    isInt(): boolean;\r\n\r\n    isNaN(): boolean;\r\n\r\n    isNegative(): boolean;\r\n    isNeg(): boolean;\r\n\r\n    isPositive(): boolean;\r\n    isPos(): boolean;\r\n\r\n    isZero(): boolean;\r\n\r\n    lessThan(n: Decimal.Value): boolean;\r\n    lt(n: Decimal.Value): boolean;\r\n\r\n    lessThanOrEqualTo(n: Decimal.Value): boolean;\r\n    lte(n: Decimal.Value): boolean;\r\n\r\n    logarithm(n?: Decimal.Value): Decimal;\r\n    log(n?: Decimal.Value): Decimal;\r\n\r\n    minus(n: Decimal.Value): Decimal;\r\n    sub(n: Decimal.Value): Decimal;\r\n\r\n    modulo(n: Decimal.Value): Decimal;\r\n    mod(n: Decimal.Value): Decimal;\r\n\r\n    naturalExponential(): Decimal;\r\n    exp(): Decimal;\r\n\r\n    naturalLogarithm(): Decimal;\r\n    ln(): Decimal;\r\n\r\n    negated(): Decimal;\r\n    neg(): Decimal;\r\n\r\n    plus(n: Decimal.Value): Decimal;\r\n    add(n: Decimal.Value): Decimal;\r\n\r\n    precision(includeZeros?: boolean): number;\r\n    sd(includeZeros?: boolean): number;\r\n\r\n    round(): Decimal;\r\n\r\n    sine() : Decimal;\r\n    sin() : Decimal;\r\n\r\n    squareRoot(): Decimal;\r\n    sqrt(): Decimal;\r\n\r\n    tangent() : Decimal;\r\n    tan() : Decimal;\r\n\r\n    times(n: Decimal.Value): Decimal;\r\n    mul(n: Decimal.Value) : Decimal;\r\n\r\n    toBinary(significantDigits?: number): string;\r\n    toBinary(significantDigits: number, rounding: Decimal.Rounding): string;\r\n\r\n    toDecimalPlaces(decimalPlaces?: number): Decimal;\r\n    toDecimalPlaces(decimalPlaces: number, rounding: Decimal.Rounding): Decimal;\r\n    toDP(decimalPlaces?: number): Decimal;\r\n    toDP(decimalPlaces: number, rounding: Decimal.Rounding): Decimal;\r\n\r\n    toExponential(decimalPlaces?: number): string;\r\n    toExponential(decimalPlaces: number, rounding: Decimal.Rounding): string;\r\n\r\n    toFixed(decimalPlaces?: number): string;\r\n    toFixed(decimalPlaces: number, rounding: Decimal.Rounding): string;\r\n\r\n    toFraction(max_denominator?: Decimal.Value): Decimal[];\r\n\r\n    toHexadecimal(significantDigits?: number): string;\r\n    toHexadecimal(significantDigits: number, rounding: Decimal.Rounding): string;\r\n    toHex(significantDigits?: number): string;\r\n    toHex(significantDigits: number, rounding?: Decimal.Rounding): string;\r\n\r\n    toJSON(): string;\r\n\r\n    toNearest(n: Decimal.Value, rounding?: Decimal.Rounding): Decimal;\r\n\r\n    toNumber(): number;\r\n\r\n    toOctal(significantDigits?: number): string;\r\n    toOctal(significantDigits: number, rounding: Decimal.Rounding): string;\r\n\r\n    toPower(n: Decimal.Value): Decimal;\r\n    pow(n: Decimal.Value): Decimal;\r\n\r\n    toPrecision(significantDigits?: number): string;\r\n    toPrecision(significantDigits: number, rounding: Decimal.Rounding): string;\r\n\r\n    toSignificantDigits(significantDigits?: number): Decimal;\r\n    toSignificantDigits(significantDigits: number, rounding: Decimal.Rounding): Decimal;\r\n    toSD(significantDigits?: number): Decimal;\r\n    toSD(significantDigits: number, rounding: Decimal.Rounding): Decimal;\r\n\r\n    toString(): string;\r\n\r\n    truncated(): Decimal;\r\n    trunc(): Decimal;\r\n\r\n    valueOf(): string;\r\n\r\n    static abs(n: Decimal.Value): Decimal;\r\n    static acos(n: Decimal.Value): Decimal;\r\n    static acosh(n: Decimal.Value): Decimal;\r\n    static add(x: Decimal.Value, y: Decimal.Value): Decimal;\r\n    static asin(n: Decimal.Value): Decimal;\r\n    static asinh(n: Decimal.Value): Decimal;\r\n    static atan(n: Decimal.Value): Decimal;\r\n    static atanh(n: Decimal.Value): Decimal;\r\n    static atan2(y: Decimal.Value, x: Decimal.Value): Decimal;\r\n    static cbrt(n: Decimal.Value): Decimal;\r\n    static ceil(n: Decimal.Value): Decimal;\r\n    static clamp(n: Decimal.Value, min: Decimal.Value, max: Decimal.Value): Decimal;\r\n    static clone(object?: Decimal.Config): Decimal.Constructor;\r\n    static config(object: Decimal.Config): Decimal.Constructor;\r\n    static cos(n: Decimal.Value): Decimal;\r\n    static cosh(n: Decimal.Value): Decimal;\r\n    static div(x: Decimal.Value, y: Decimal.Value): Decimal;\r\n    static exp(n: Decimal.Value): Decimal;\r\n    static floor(n: Decimal.Value): Decimal;\r\n    static hypot(...n: Decimal.Value[]): Decimal;\r\n    static isDecimal(object: any): object is Decimal;\r\n    static ln(n: Decimal.Value): Decimal;\r\n    static log(n: Decimal.Value, base?: Decimal.Value): Decimal;\r\n    static log2(n: Decimal.Value): Decimal;\r\n    static log10(n: Decimal.Value): Decimal;\r\n    static max(...n: Decimal.Value[]): Decimal;\r\n    static min(...n: Decimal.Value[]): Decimal;\r\n    static mod(x: Decimal.Value, y: Decimal.Value): Decimal;\r\n    static mul(x: Decimal.Value, y: Decimal.Value): Decimal;\r\n    static noConflict(): Decimal.Constructor;   // Browser only\r\n    static pow(base: Decimal.Value, exponent: Decimal.Value): Decimal;\r\n    static random(significantDigits?: number): Decimal;\r\n    static round(n: Decimal.Value): Decimal;\r\n    static set(object: Decimal.Config): Decimal.Constructor;\r\n    static sign(n: Decimal.Value): number;\r\n    static sin(n: Decimal.Value): Decimal;\r\n    static sinh(n: Decimal.Value): Decimal;\r\n    static sqrt(n: Decimal.Value): Decimal;\r\n    static sub(x: Decimal.Value, y: Decimal.Value): Decimal;\r\n    static sum(...n: Decimal.Value[]): Decimal;\r\n    static tan(n: Decimal.Value): Decimal;\r\n    static tanh(n: Decimal.Value): Decimal;\r\n    static trunc(n: Decimal.Value): Decimal;\r\n\r\n    static readonly default?: Decimal.Constructor;\r\n    static readonly Decimal?: Decimal.Constructor;\r\n\r\n    static readonly precision: number;\r\n    static readonly rounding: Decimal.Rounding;\r\n    static readonly toExpNeg: number;\r\n    static readonly toExpPos: number;\r\n    static readonly minE: number;\r\n    static readonly maxE: number;\r\n    static readonly crypto: boolean;\r\n    static readonly modulo: Decimal.Modulo;\r\n\r\n    static readonly ROUND_UP: 0;\r\n    static readonly ROUND_DOWN: 1;\r\n    static readonly ROUND_CEIL: 2;\r\n    static readonly ROUND_FLOOR: 3;\r\n    static readonly ROUND_HALF_UP: 4;\r\n    static readonly ROUND_HALF_DOWN: 5;\r\n    static readonly ROUND_HALF_EVEN: 6;\r\n    static readonly ROUND_HALF_CEIL: 7;\r\n    static readonly ROUND_HALF_FLOOR: 8;\r\n    static readonly EUCLID: 9;\r\n}\r\n\r\ndeclare type Exact<A, W> = (A extends unknown ? (W extends A ? {\r\n    [K in keyof A]: Exact<A[K], W[K]>;\r\n} : W) : never) | (A extends Narrowable ? A : never);\r\n\r\nexport declare function getRuntime(): GetRuntimeOutput;\r\n\r\ndeclare type GetRuntimeOutput = {\r\n    id: RuntimeName;\r\n    prettyName: string;\r\n    isEdge: boolean;\r\n};\r\n\r\ndeclare class JsonNull extends NullTypesEnumValue {\r\n    #private;\r\n}\r\n\r\n/**\r\n * Generates more strict variant of an enum which, unlike regular enum,\r\n * throws on non-existing property access. This can be useful in following situations:\r\n * - we have an API, that accepts both `undefined` and `SomeEnumType` as an input\r\n * - enum values are generated dynamically from DMMF.\r\n *\r\n * In that case, if using normal enums and no compile-time typechecking, using non-existing property\r\n * will result in `undefined` value being used, which will be accepted. Using strict enum\r\n * in this case will help to have a runtime exception, telling you that you are probably doing something wrong.\r\n *\r\n * Note: if you need to check for existence of a value in the enum you can still use either\r\n * `in` operator or `hasOwnProperty` function.\r\n *\r\n * @param definition\r\n * @returns\r\n */\r\nexport declare function makeStrictEnum<T extends Record<PropertyKey, string | number>>(definition: T): T;\r\n\r\ndeclare type Narrowable = string | number | bigint | boolean | [];\r\n\r\ndeclare class NullTypesEnumValue extends ObjectEnumValue {\r\n    _getNamespace(): string;\r\n}\r\n\r\n/**\r\n * Base class for unique values of object-valued enums.\r\n */\r\ndeclare abstract class ObjectEnumValue {\r\n    constructor(arg?: symbol);\r\n    abstract _getNamespace(): string;\r\n    _getName(): string;\r\n    toString(): string;\r\n}\r\n\r\nexport declare const objectEnumValues: {\r\n    classes: {\r\n        DbNull: typeof DbNull;\r\n        JsonNull: typeof JsonNull;\r\n        AnyNull: typeof AnyNull;\r\n    };\r\n    instances: {\r\n        DbNull: DbNull;\r\n        JsonNull: JsonNull;\r\n        AnyNull: AnyNull;\r\n    };\r\n};\r\n\r\ndeclare type Operation = 'findFirst' | 'findFirstOrThrow' | 'findUnique' | 'findUniqueOrThrow' | 'findMany' | 'create' | 'createMany' | 'createManyAndReturn' | 'update' | 'updateMany' | 'updateManyAndReturn' | 'upsert' | 'delete' | 'deleteMany' | 'aggregate' | 'count' | 'groupBy' | '$queryRaw' | '$executeRaw' | '$queryRawUnsafe' | '$executeRawUnsafe' | 'findRaw' | 'aggregateRaw' | '$runCommandRaw';\r\n\r\ndeclare namespace Public {\r\n    export {\r\n        validator\r\n    }\r\n}\r\nexport { Public }\r\n\r\ndeclare type RuntimeName = 'workerd' | 'deno' | 'netlify' | 'node' | 'bun' | 'edge-light' | '';\r\n\r\ndeclare function validator<V>(): <S>(select: Exact<S, V>) => S;\r\n\r\ndeclare function validator<C, M extends Exclude<keyof C, `$${string}`>, O extends keyof C[M] & Operation>(client: C, model: M, operation: O): <S>(select: Exact<S, Args<C[M], O>>) => S;\r\n\r\ndeclare function validator<C, M extends Exclude<keyof C, `$${string}`>, O extends keyof C[M] & Operation, P extends keyof Args<C[M], O>>(client: C, model: M, operation: O, prop: P): <S>(select: Exact<S, Args<C[M], O>[P]>) => S;\r\n\r\nexport { }\r\n","node_modules/.prisma/client/runtime/library.d.ts":"/**\r\n * @param this\r\n */\r\ndeclare function $extends(this: Client, extension: ExtensionArgs | ((client: Client) => Client)): Client;\r\n\r\ndeclare type AccelerateEngineConfig = {\r\n    inlineSchema: EngineConfig['inlineSchema'];\r\n    inlineSchemaHash: EngineConfig['inlineSchemaHash'];\r\n    env: EngineConfig['env'];\r\n    generator?: {\r\n        previewFeatures: string[];\r\n    };\r\n    inlineDatasources: EngineConfig['inlineDatasources'];\r\n    overrideDatasources: EngineConfig['overrideDatasources'];\r\n    clientVersion: EngineConfig['clientVersion'];\r\n    engineVersion: EngineConfig['engineVersion'];\r\n    logEmitter: EngineConfig['logEmitter'];\r\n    logQueries?: EngineConfig['logQueries'];\r\n    logLevel?: EngineConfig['logLevel'];\r\n    tracingHelper: EngineConfig['tracingHelper'];\r\n    accelerateUtils?: AccelerateUtils;\r\n};\r\n\r\n/**\r\n * A stripped down interface of `fetch` that `@prisma/extension-accelerate`\r\n * relies on. It must be in sync with the corresponding definition in the\r\n * Accelerate extension.\r\n *\r\n * This is the actual interface exposed by the extension. We can't use the\r\n * custom fetch function provided by it as normal fetch because the API is\r\n * different. Notably, `headers` must be an object and not a `Headers`\r\n * instance, and `url` must be a `string` and not a `URL`.\r\n *\r\n * The return type is `Response` but we can't specify this in an exported type\r\n * because it would end up referencing external types from `@types/node` or DOM\r\n * which can fail typechecking depending on TypeScript configuration in a user's\r\n * project.\r\n */\r\ndeclare type AccelerateExtensionFetch = (url: string, options: {\r\n    body?: string;\r\n    method?: string;\r\n    headers: Record<string, string>;\r\n}) => Promise<unknown>;\r\n\r\ndeclare type AccelerateExtensionFetchDecorator = (fetch: AccelerateExtensionFetch) => AccelerateExtensionFetch;\r\n\r\ndeclare type AccelerateUtils = EngineConfig['accelerateUtils'];\r\n\r\nexport declare type Action = keyof typeof DMMF_2.ModelAction | 'executeRaw' | 'queryRaw' | 'runCommandRaw';\r\n\r\ndeclare type ActiveConnectorType = Exclude<ConnectorType, 'postgres' | 'prisma+postgres'>;\r\n\r\n/**\r\n * An interface that exposes some basic information about the\r\n * adapter like its name and provider type.\r\n */\r\ndeclare interface AdapterInfo {\r\n    readonly provider: Provider;\r\n    readonly adapterName: (typeof officialPrismaAdapters)[number] | (string & {});\r\n}\r\n\r\nexport declare type Aggregate = '_count' | '_max' | '_min' | '_avg' | '_sum';\r\n\r\nexport declare type AllModelsToStringIndex<TypeMap extends TypeMapDef, Args extends Record<string, any>, K extends PropertyKey> = Args extends {\r\n    [P in K]: {\r\n        $allModels: infer AllModels;\r\n    };\r\n} ? {\r\n    [P in K]: Record<TypeMap['meta']['modelProps'], AllModels>;\r\n} : {};\r\n\r\ndeclare class AnyNull extends NullTypesEnumValue {\r\n    #private;\r\n}\r\n\r\nexport declare type ApplyOmit<T, OmitConfig> = Compute<{\r\n    [K in keyof T as OmitValue<OmitConfig, K> extends true ? never : K]: T[K];\r\n}>;\r\n\r\nexport declare type Args<T, F extends Operation> = T extends {\r\n    [K: symbol]: {\r\n        types: {\r\n            operations: {\r\n                [K in F]: {\r\n                    args: any;\r\n                };\r\n            };\r\n        };\r\n    };\r\n} ? T[symbol]['types']['operations'][F]['args'] : any;\r\n\r\nexport declare type Args_3<T, F extends Operation> = Args<T, F>;\r\n\r\ndeclare type ArgScalarType = 'string' | 'int' | 'bigint' | 'float' | 'decimal' | 'boolean' | 'enum' | 'uuid' | 'json' | 'datetime' | 'bytes' | 'unknown';\r\n\r\ndeclare type ArgType = {\r\n    scalarType: ArgScalarType;\r\n    dbType?: string;\r\n    arity: Arity;\r\n};\r\n\r\ndeclare type Arity = 'scalar' | 'list';\r\n\r\n/**\r\n * Attributes is a map from string to attribute values.\r\n *\r\n * Note: only the own enumerable keys are counted as valid attribute keys.\r\n */\r\ndeclare interface Attributes {\r\n    [attributeKey: string]: AttributeValue | undefined;\r\n}\r\n\r\n/**\r\n * Attribute values may be any non-nullish primitive value except an object.\r\n *\r\n * null or undefined attribute values are invalid and will result in undefined behavior.\r\n */\r\ndeclare type AttributeValue = string | number | boolean | Array<null | undefined | string> | Array<null | undefined | number> | Array<null | undefined | boolean>;\r\n\r\nexport declare type BaseDMMF = {\r\n    readonly datamodel: Omit<DMMF_2.Datamodel, 'indexes'>;\r\n};\r\n\r\ndeclare type BatchArgs = {\r\n    queries: BatchQuery[];\r\n    transaction?: {\r\n        isolationLevel?: IsolationLevel_2;\r\n    };\r\n};\r\n\r\ndeclare type BatchInternalParams = {\r\n    requests: RequestParams[];\r\n    customDataProxyFetch?: AccelerateExtensionFetchDecorator;\r\n};\r\n\r\ndeclare type BatchQuery = {\r\n    model: string | undefined;\r\n    operation: string;\r\n    args: JsArgs | RawQueryArgs;\r\n};\r\n\r\ndeclare type BatchQueryEngineResult<T> = QueryEngineResultData<T> | Error;\r\n\r\ndeclare type BatchQueryOptionsCb = (args: BatchQueryOptionsCbArgs) => Promise<any>;\r\n\r\ndeclare type BatchQueryOptionsCbArgs = {\r\n    args: BatchArgs;\r\n    query: (args: BatchArgs, __internalParams?: BatchInternalParams) => Promise<unknown[]>;\r\n    __internalParams: BatchInternalParams;\r\n};\r\n\r\ndeclare type BatchResponse = MultiBatchResponse | CompactedBatchResponse;\r\n\r\ndeclare type BatchTransactionOptions = {\r\n    isolationLevel?: Transaction_2.IsolationLevel;\r\n};\r\n\r\ndeclare interface BinaryTargetsEnvValue {\r\n    fromEnvVar: string | null;\r\n    value: string;\r\n    native?: boolean;\r\n}\r\n\r\nexport declare type Call<F extends Fn, P> = (F & {\r\n    params: P;\r\n})['returns'];\r\n\r\ndeclare interface CallSite {\r\n    getLocation(): LocationInFile | null;\r\n}\r\n\r\nexport declare type Cast<A, W> = A extends W ? A : W;\r\n\r\ndeclare type Client = ReturnType<typeof getPrismaClient> extends new () => infer T ? T : never;\r\n\r\nexport declare type ClientArg = {\r\n    [MethodName in string]: unknown;\r\n};\r\n\r\nexport declare type ClientArgs = {\r\n    client: ClientArg;\r\n};\r\n\r\nexport declare type ClientBuiltInProp = keyof DynamicClientExtensionThisBuiltin<never, never, never>;\r\n\r\nexport declare type ClientOptionDef = undefined | {\r\n    [K in string]: any;\r\n};\r\n\r\nexport declare type ClientOtherOps = {\r\n    $queryRaw<T = unknown>(query: TemplateStringsArray | Sql, ...values: any[]): PrismaPromise<T>;\r\n    $queryRawTyped<T>(query: TypedSql<unknown[], T>): PrismaPromise<T[]>;\r\n    $queryRawUnsafe<T = unknown>(query: string, ...values: any[]): PrismaPromise<T>;\r\n    $executeRaw(query: TemplateStringsArray | Sql, ...values: any[]): PrismaPromise<number>;\r\n    $executeRawUnsafe(query: string, ...values: any[]): PrismaPromise<number>;\r\n    $runCommandRaw(command: InputJsonObject): PrismaPromise<JsonObject>;\r\n};\r\n\r\ndeclare type ColumnType = (typeof ColumnTypeEnum)[keyof typeof ColumnTypeEnum];\r\n\r\ndeclare const ColumnTypeEnum: {\r\n    readonly Int32: 0;\r\n    readonly Int64: 1;\r\n    readonly Float: 2;\r\n    readonly Double: 3;\r\n    readonly Numeric: 4;\r\n    readonly Boolean: 5;\r\n    readonly Character: 6;\r\n    readonly Text: 7;\r\n    readonly Date: 8;\r\n    readonly Time: 9;\r\n    readonly DateTime: 10;\r\n    readonly Json: 11;\r\n    readonly Enum: 12;\r\n    readonly Bytes: 13;\r\n    readonly Set: 14;\r\n    readonly Uuid: 15;\r\n    readonly Int32Array: 64;\r\n    readonly Int64Array: 65;\r\n    readonly FloatArray: 66;\r\n    readonly DoubleArray: 67;\r\n    readonly NumericArray: 68;\r\n    readonly BooleanArray: 69;\r\n    readonly CharacterArray: 70;\r\n    readonly TextArray: 71;\r\n    readonly DateArray: 72;\r\n    readonly TimeArray: 73;\r\n    readonly DateTimeArray: 74;\r\n    readonly JsonArray: 75;\r\n    readonly EnumArray: 76;\r\n    readonly BytesArray: 77;\r\n    readonly UuidArray: 78;\r\n    readonly UnknownNumber: 128;\r\n};\r\n\r\ndeclare type CompactedBatchResponse = {\r\n    type: 'compacted';\r\n    plan: QueryPlanNode;\r\n    arguments: Record<string, {}>[];\r\n    nestedSelection: string[];\r\n    keys: string[];\r\n    expectNonEmpty: boolean;\r\n};\r\n\r\ndeclare type CompilerWasmLoadingConfig = {\r\n    /**\r\n     * WASM-bindgen runtime for corresponding module\r\n     */\r\n    getRuntime: () => Promise<{\r\n        __wbg_set_wasm(exports: unknown): void;\r\n        QueryCompiler: QueryCompilerConstructor;\r\n    }>;\r\n    /**\r\n     * Loads the raw wasm module for the wasm compiler engine. This configuration is\r\n     * generated specifically for each type of client, eg. Node.js client and Edge\r\n     * clients will have different implementations.\r\n     * @remarks this is a callback on purpose, we only load the wasm if needed.\r\n     * @remarks only used by ClientEngine\r\n     */\r\n    getQueryCompilerWasmModule: () => Promise<unknown>;\r\n};\r\n\r\nexport declare type Compute<T> = T extends Function ? T : {\r\n    [K in keyof T]: T[K];\r\n} & unknown;\r\n\r\nexport declare type ComputeDeep<T> = T extends Function ? T : {\r\n    [K in keyof T]: ComputeDeep<T[K]>;\r\n} & unknown;\r\n\r\ndeclare type ComputedField = {\r\n    name: string;\r\n    needs: string[];\r\n    compute: ResultArgsFieldCompute;\r\n};\r\n\r\ndeclare type ComputedFieldsMap = {\r\n    [fieldName: string]: ComputedField;\r\n};\r\n\r\ndeclare type ConnectionInfo = {\r\n    schemaName?: string;\r\n    maxBindValues?: number;\r\n    supportsRelationJoins: boolean;\r\n};\r\n\r\ndeclare type ConnectorType = 'mysql' | 'mongodb' | 'sqlite' | 'postgresql' | 'postgres' | 'prisma+postgres' | 'sqlserver' | 'cockroachdb';\r\n\r\ndeclare interface Context {\r\n    /**\r\n     * Get a value from the context.\r\n     *\r\n     * @param key key which identifies a context value\r\n     */\r\n    getValue(key: symbol): unknown;\r\n    /**\r\n     * Create a new context which inherits from this context and has\r\n     * the given key set to the given value.\r\n     *\r\n     * @param key context key for which to set the value\r\n     * @param value value to set for the given key\r\n     */\r\n    setValue(key: symbol, value: unknown): Context;\r\n    /**\r\n     * Return a new context which inherits from this context but does\r\n     * not contain a value for the given key.\r\n     *\r\n     * @param key context key for which to clear a value\r\n     */\r\n    deleteValue(key: symbol): Context;\r\n}\r\n\r\ndeclare type Context_2<T> = T extends {\r\n    [K: symbol]: {\r\n        ctx: infer C;\r\n    };\r\n} ? C & T & {\r\n    /**\r\n     * @deprecated Use `$name` instead.\r\n     */\r\n    name?: string;\r\n    $name?: string;\r\n    $parent?: unknown;\r\n} : T & {\r\n    /**\r\n     * @deprecated Use `$name` instead.\r\n     */\r\n    name?: string;\r\n    $name?: string;\r\n    $parent?: unknown;\r\n};\r\n\r\nexport declare type Count<O> = {\r\n    [K in keyof O]: Count<number>;\r\n} & {};\r\n\r\nexport declare function createParam(name: string): Param<unknown, string>;\r\n\r\ndeclare class DataLoader<T = unknown> {\r\n    private options;\r\n    batches: {\r\n        [key: string]: Job[];\r\n    };\r\n    private tickActive;\r\n    constructor(options: DataLoaderOptions<T>);\r\n    request(request: T): Promise<any>;\r\n    private dispatchBatches;\r\n    get [Symbol.toStringTag](): string;\r\n}\r\n\r\ndeclare type DataLoaderOptions<T> = {\r\n    singleLoader: (request: T) => Promise<any>;\r\n    batchLoader: (request: T[]) => Promise<any[]>;\r\n    batchBy: (request: T) => string | undefined;\r\n    batchOrder: (requestA: T, requestB: T) => number;\r\n};\r\n\r\ndeclare type Datamodel = ReadonlyDeep_2<{\r\n    models: Model[];\r\n    enums: DatamodelEnum[];\r\n    types: Model[];\r\n    indexes: Index[];\r\n}>;\r\n\r\ndeclare type DatamodelEnum = ReadonlyDeep_2<{\r\n    name: string;\r\n    values: EnumValue[];\r\n    dbName?: string | null;\r\n    documentation?: string;\r\n}>;\r\n\r\ndeclare function datamodelEnumToSchemaEnum(datamodelEnum: DatamodelEnum): SchemaEnum;\r\n\r\ndeclare type DataRule = {\r\n    type: 'rowCountEq';\r\n    args: number;\r\n} | {\r\n    type: 'rowCountNeq';\r\n    args: number;\r\n} | {\r\n    type: 'affectedRowCountEq';\r\n    args: number;\r\n} | {\r\n    type: 'never';\r\n};\r\n\r\ndeclare type Datasource = {\r\n    url?: string;\r\n};\r\n\r\ndeclare type Datasources = {\r\n    [name in string]: Datasource;\r\n};\r\n\r\ndeclare class DbNull extends NullTypesEnumValue {\r\n    #private;\r\n}\r\n\r\nexport declare const Debug: typeof debugCreate & {\r\n    enable(namespace: any): void;\r\n    disable(): any;\r\n    enabled(namespace: string): boolean;\r\n    log: (...args: string[]) => void;\r\n    formatters: {};\r\n};\r\n\r\n/**\r\n * Create a new debug instance with the given namespace.\r\n *\r\n * @example\r\n * ```ts\r\n * import Debug from '@prisma/debug'\r\n * const debug = Debug('prisma:client')\r\n * debug('Hello World')\r\n * ```\r\n */\r\ndeclare function debugCreate(namespace: string): ((...args: any[]) => void) & {\r\n    color: string;\r\n    enabled: boolean;\r\n    namespace: string;\r\n    log: (...args: string[]) => void;\r\n    extend: () => void;\r\n};\r\n\r\nexport declare function Decimal(n: Decimal.Value): Decimal;\r\n\r\nexport declare namespace Decimal {\r\n    export type Constructor = typeof Decimal;\r\n    export type Instance = Decimal;\r\n    export type Rounding = 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8;\r\n    export type Modulo = Rounding | 9;\r\n    export type Value = string | number | Decimal;\r\n\r\n    // http://mikemcl.github.io/decimal.js/#constructor-properties\r\n    export interface Config {\r\n        precision?: number;\r\n        rounding?: Rounding;\r\n        toExpNeg?: number;\r\n        toExpPos?: number;\r\n        minE?: number;\r\n        maxE?: number;\r\n        crypto?: boolean;\r\n        modulo?: Modulo;\r\n        defaults?: boolean;\r\n    }\r\n}\r\n\r\nexport declare class Decimal {\r\n    readonly d: number[];\r\n    readonly e: number;\r\n    readonly s: number;\r\n\r\n    constructor(n: Decimal.Value);\r\n\r\n    absoluteValue(): Decimal;\r\n    abs(): Decimal;\r\n\r\n    ceil(): Decimal;\r\n\r\n    clampedTo(min: Decimal.Value, max: Decimal.Value): Decimal;\r\n    clamp(min: Decimal.Value, max: Decimal.Value): Decimal;\r\n\r\n    comparedTo(n: Decimal.Value): number;\r\n    cmp(n: Decimal.Value): number;\r\n\r\n    cosine(): Decimal;\r\n    cos(): Decimal;\r\n\r\n    cubeRoot(): Decimal;\r\n    cbrt(): Decimal;\r\n\r\n    decimalPlaces(): number;\r\n    dp(): number;\r\n\r\n    dividedBy(n: Decimal.Value): Decimal;\r\n    div(n: Decimal.Value): Decimal;\r\n\r\n    dividedToIntegerBy(n: Decimal.Value): Decimal;\r\n    divToInt(n: Decimal.Value): Decimal;\r\n\r\n    equals(n: Decimal.Value): boolean;\r\n    eq(n: Decimal.Value): boolean;\r\n\r\n    floor(): Decimal;\r\n\r\n    greaterThan(n: Decimal.Value): boolean;\r\n    gt(n: Decimal.Value): boolean;\r\n\r\n    greaterThanOrEqualTo(n: Decimal.Value): boolean;\r\n    gte(n: Decimal.Value): boolean;\r\n\r\n    hyperbolicCosine(): Decimal;\r\n    cosh(): Decimal;\r\n\r\n    hyperbolicSine(): Decimal;\r\n    sinh(): Decimal;\r\n\r\n    hyperbolicTangent(): Decimal;\r\n    tanh(): Decimal;\r\n\r\n    inverseCosine(): Decimal;\r\n    acos(): Decimal;\r\n\r\n    inverseHyperbolicCosine(): Decimal;\r\n    acosh(): Decimal;\r\n\r\n    inverseHyperbolicSine(): Decimal;\r\n    asinh(): Decimal;\r\n\r\n    inverseHyperbolicTangent(): Decimal;\r\n    atanh(): Decimal;\r\n\r\n    inverseSine(): Decimal;\r\n    asin(): Decimal;\r\n\r\n    inverseTangent(): Decimal;\r\n    atan(): Decimal;\r\n\r\n    isFinite(): boolean;\r\n\r\n    isInteger(): boolean;\r\n    isInt(): boolean;\r\n\r\n    isNaN(): boolean;\r\n\r\n    isNegative(): boolean;\r\n    isNeg(): boolean;\r\n\r\n    isPositive(): boolean;\r\n    isPos(): boolean;\r\n\r\n    isZero(): boolean;\r\n\r\n    lessThan(n: Decimal.Value): boolean;\r\n    lt(n: Decimal.Value): boolean;\r\n\r\n    lessThanOrEqualTo(n: Decimal.Value): boolean;\r\n    lte(n: Decimal.Value): boolean;\r\n\r\n    logarithm(n?: Decimal.Value): Decimal;\r\n    log(n?: Decimal.Value): Decimal;\r\n\r\n    minus(n: Decimal.Value): Decimal;\r\n    sub(n: Decimal.Value): Decimal;\r\n\r\n    modulo(n: Decimal.Value): Decimal;\r\n    mod(n: Decimal.Value): Decimal;\r\n\r\n    naturalExponential(): Decimal;\r\n    exp(): Decimal;\r\n\r\n    naturalLogarithm(): Decimal;\r\n    ln(): Decimal;\r\n\r\n    negated(): Decimal;\r\n    neg(): Decimal;\r\n\r\n    plus(n: Decimal.Value): Decimal;\r\n    add(n: Decimal.Value): Decimal;\r\n\r\n    precision(includeZeros?: boolean): number;\r\n    sd(includeZeros?: boolean): number;\r\n\r\n    round(): Decimal;\r\n\r\n    sine() : Decimal;\r\n    sin() : Decimal;\r\n\r\n    squareRoot(): Decimal;\r\n    sqrt(): Decimal;\r\n\r\n    tangent() : Decimal;\r\n    tan() : Decimal;\r\n\r\n    times(n: Decimal.Value): Decimal;\r\n    mul(n: Decimal.Value) : Decimal;\r\n\r\n    toBinary(significantDigits?: number): string;\r\n    toBinary(significantDigits: number, rounding: Decimal.Rounding): string;\r\n\r\n    toDecimalPlaces(decimalPlaces?: number): Decimal;\r\n    toDecimalPlaces(decimalPlaces: number, rounding: Decimal.Rounding): Decimal;\r\n    toDP(decimalPlaces?: number): Decimal;\r\n    toDP(decimalPlaces: number, rounding: Decimal.Rounding): Decimal;\r\n\r\n    toExponential(decimalPlaces?: number): string;\r\n    toExponential(decimalPlaces: number, rounding: Decimal.Rounding): string;\r\n\r\n    toFixed(decimalPlaces?: number): string;\r\n    toFixed(decimalPlaces: number, rounding: Decimal.Rounding): string;\r\n\r\n    toFraction(max_denominator?: Decimal.Value): Decimal[];\r\n\r\n    toHexadecimal(significantDigits?: number): string;\r\n    toHexadecimal(significantDigits: number, rounding: Decimal.Rounding): string;\r\n    toHex(significantDigits?: number): string;\r\n    toHex(significantDigits: number, rounding?: Decimal.Rounding): string;\r\n\r\n    toJSON(): string;\r\n\r\n    toNearest(n: Decimal.Value, rounding?: Decimal.Rounding): Decimal;\r\n\r\n    toNumber(): number;\r\n\r\n    toOctal(significantDigits?: number): string;\r\n    toOctal(significantDigits: number, rounding: Decimal.Rounding): string;\r\n\r\n    toPower(n: Decimal.Value): Decimal;\r\n    pow(n: Decimal.Value): Decimal;\r\n\r\n    toPrecision(significantDigits?: number): string;\r\n    toPrecision(significantDigits: number, rounding: Decimal.Rounding): string;\r\n\r\n    toSignificantDigits(significantDigits?: number): Decimal;\r\n    toSignificantDigits(significantDigits: number, rounding: Decimal.Rounding): Decimal;\r\n    toSD(significantDigits?: number): Decimal;\r\n    toSD(significantDigits: number, rounding: Decimal.Rounding): Decimal;\r\n\r\n    toString(): string;\r\n\r\n    truncated(): Decimal;\r\n    trunc(): Decimal;\r\n\r\n    valueOf(): string;\r\n\r\n    static abs(n: Decimal.Value): Decimal;\r\n    static acos(n: Decimal.Value): Decimal;\r\n    static acosh(n: Decimal.Value): Decimal;\r\n    static add(x: Decimal.Value, y: Decimal.Value): Decimal;\r\n    static asin(n: Decimal.Value): Decimal;\r\n    static asinh(n: Decimal.Value): Decimal;\r\n    static atan(n: Decimal.Value): Decimal;\r\n    static atanh(n: Decimal.Value): Decimal;\r\n    static atan2(y: Decimal.Value, x: Decimal.Value): Decimal;\r\n    static cbrt(n: Decimal.Value): Decimal;\r\n    static ceil(n: Decimal.Value): Decimal;\r\n    static clamp(n: Decimal.Value, min: Decimal.Value, max: Decimal.Value): Decimal;\r\n    static clone(object?: Decimal.Config): Decimal.Constructor;\r\n    static config(object: Decimal.Config): Decimal.Constructor;\r\n    static cos(n: Decimal.Value): Decimal;\r\n    static cosh(n: Decimal.Value): Decimal;\r\n    static div(x: Decimal.Value, y: Decimal.Value): Decimal;\r\n    static exp(n: Decimal.Value): Decimal;\r\n    static floor(n: Decimal.Value): Decimal;\r\n    static hypot(...n: Decimal.Value[]): Decimal;\r\n    static isDecimal(object: any): object is Decimal;\r\n    static ln(n: Decimal.Value): Decimal;\r\n    static log(n: Decimal.Value, base?: Decimal.Value): Decimal;\r\n    static log2(n: Decimal.Value): Decimal;\r\n    static log10(n: Decimal.Value): Decimal;\r\n    static max(...n: Decimal.Value[]): Decimal;\r\n    static min(...n: Decimal.Value[]): Decimal;\r\n    static mod(x: Decimal.Value, y: Decimal.Value): Decimal;\r\n    static mul(x: Decimal.Value, y: Decimal.Value): Decimal;\r\n    static noConflict(): Decimal.Constructor;   // Browser only\r\n    static pow(base: Decimal.Value, exponent: Decimal.Value): Decimal;\r\n    static random(significantDigits?: number): Decimal;\r\n    static round(n: Decimal.Value): Decimal;\r\n    static set(object: Decimal.Config): Decimal.Constructor;\r\n    static sign(n: Decimal.Value): number;\r\n    static sin(n: Decimal.Value): Decimal;\r\n    static sinh(n: Decimal.Value): Decimal;\r\n    static sqrt(n: Decimal.Value): Decimal;\r\n    static sub(x: Decimal.Value, y: Decimal.Value): Decimal;\r\n    static sum(...n: Decimal.Value[]): Decimal;\r\n    static tan(n: Decimal.Value): Decimal;\r\n    static tanh(n: Decimal.Value): Decimal;\r\n    static trunc(n: Decimal.Value): Decimal;\r\n\r\n    static readonly default?: Decimal.Constructor;\r\n    static readonly Decimal?: Decimal.Constructor;\r\n\r\n    static readonly precision: number;\r\n    static readonly rounding: Decimal.Rounding;\r\n    static readonly toExpNeg: number;\r\n    static readonly toExpPos: number;\r\n    static readonly minE: number;\r\n    static readonly maxE: number;\r\n    static readonly crypto: boolean;\r\n    static readonly modulo: Decimal.Modulo;\r\n\r\n    static readonly ROUND_UP: 0;\r\n    static readonly ROUND_DOWN: 1;\r\n    static readonly ROUND_CEIL: 2;\r\n    static readonly ROUND_FLOOR: 3;\r\n    static readonly ROUND_HALF_UP: 4;\r\n    static readonly ROUND_HALF_DOWN: 5;\r\n    static readonly ROUND_HALF_EVEN: 6;\r\n    static readonly ROUND_HALF_CEIL: 7;\r\n    static readonly ROUND_HALF_FLOOR: 8;\r\n    static readonly EUCLID: 9;\r\n}\r\n\r\n/**\r\n * Interface for any Decimal.js-like library\r\n * Allows us to accept Decimal.js from different\r\n * versions and some compatible alternatives\r\n */\r\nexport declare interface DecimalJsLike {\r\n    d: number[];\r\n    e: number;\r\n    s: number;\r\n    toFixed(): string;\r\n}\r\n\r\nexport declare type DefaultArgs = InternalArgs<{}, {}, {}, {}>;\r\n\r\nexport declare type DefaultSelection<Payload extends OperationPayload, Args = {}, GlobalOmitOptions = {}> = Args extends {\r\n    omit: infer LocalOmit;\r\n} ? ApplyOmit<UnwrapPayload<{\r\n    default: Payload;\r\n}>['default'], PatchFlat<LocalOmit, ExtractGlobalOmit<GlobalOmitOptions, Uncapitalize<Payload['name']>>>> : ApplyOmit<UnwrapPayload<{\r\n    default: Payload;\r\n}>['default'], ExtractGlobalOmit<GlobalOmitOptions, Uncapitalize<Payload['name']>>>;\r\n\r\nexport declare function defineDmmfProperty(target: object, runtimeDataModel: RuntimeDataModel): void;\r\n\r\ndeclare function defineExtension(ext: ExtensionArgs | ((client: Client) => Client)): (client: Client) => Client;\r\n\r\ndeclare const denylist: readonly [\"$connect\", \"$disconnect\", \"$on\", \"$transaction\", \"$extends\"];\r\n\r\ndeclare type Deprecation = ReadonlyDeep_2<{\r\n    sinceVersion: string;\r\n    reason: string;\r\n    plannedRemovalVersion?: string;\r\n}>;\r\n\r\ndeclare type DeserializedResponse = Array<Record<string, unknown>>;\r\n\r\nexport declare function deserializeJsonResponse(result: unknown): unknown;\r\n\r\nexport declare function deserializeRawResult(response: RawResponse): DeserializedResponse;\r\n\r\nexport declare type DevTypeMapDef = {\r\n    meta: {\r\n        modelProps: string;\r\n    };\r\n    model: {\r\n        [Model in PropertyKey]: {\r\n            [Operation in PropertyKey]: DevTypeMapFnDef;\r\n        };\r\n    };\r\n    other: {\r\n        [Operation in PropertyKey]: DevTypeMapFnDef;\r\n    };\r\n};\r\n\r\nexport declare type DevTypeMapFnDef = {\r\n    args: any;\r\n    result: any;\r\n    payload: OperationPayload;\r\n};\r\n\r\nexport declare namespace DMMF {\r\n    export {\r\n        datamodelEnumToSchemaEnum,\r\n        Document_2 as Document,\r\n        Mappings,\r\n        OtherOperationMappings,\r\n        DatamodelEnum,\r\n        SchemaEnum,\r\n        EnumValue,\r\n        Datamodel,\r\n        uniqueIndex,\r\n        PrimaryKey,\r\n        Model,\r\n        FieldKind,\r\n        FieldNamespace,\r\n        FieldLocation,\r\n        Field,\r\n        FieldDefault,\r\n        FieldDefaultScalar,\r\n        Index,\r\n        IndexType,\r\n        IndexField,\r\n        SortOrder,\r\n        Schema,\r\n        Query,\r\n        QueryOutput,\r\n        TypeRef,\r\n        InputTypeRef,\r\n        SchemaArg,\r\n        OutputType,\r\n        SchemaField,\r\n        OutputTypeRef,\r\n        Deprecation,\r\n        InputType,\r\n        FieldRefType,\r\n        FieldRefAllowType,\r\n        ModelMapping,\r\n        ModelAction\r\n    }\r\n}\r\n\r\ndeclare namespace DMMF_2 {\r\n    export {\r\n        datamodelEnumToSchemaEnum,\r\n        Document_2 as Document,\r\n        Mappings,\r\n        OtherOperationMappings,\r\n        DatamodelEnum,\r\n        SchemaEnum,\r\n        EnumValue,\r\n        Datamodel,\r\n        uniqueIndex,\r\n        PrimaryKey,\r\n        Model,\r\n        FieldKind,\r\n        FieldNamespace,\r\n        FieldLocation,\r\n        Field,\r\n        FieldDefault,\r\n        FieldDefaultScalar,\r\n        Index,\r\n        IndexType,\r\n        IndexField,\r\n        SortOrder,\r\n        Schema,\r\n        Query,\r\n        QueryOutput,\r\n        TypeRef,\r\n        InputTypeRef,\r\n        SchemaArg,\r\n        OutputType,\r\n        SchemaField,\r\n        OutputTypeRef,\r\n        Deprecation,\r\n        InputType,\r\n        FieldRefType,\r\n        FieldRefAllowType,\r\n        ModelMapping,\r\n        ModelAction\r\n    }\r\n}\r\n\r\nexport declare function dmmfToRuntimeDataModel(dmmfDataModel: DMMF_2.Datamodel): RuntimeDataModel;\r\n\r\ndeclare type Document_2 = ReadonlyDeep_2<{\r\n    datamodel: Datamodel;\r\n    schema: Schema;\r\n    mappings: Mappings;\r\n}>;\r\n\r\n/**\r\n * A generic driver adapter factory that allows the user to instantiate a\r\n * driver adapter. The query and result types are specific to the adapter.\r\n */\r\ndeclare interface DriverAdapterFactory<Query, Result> extends AdapterInfo {\r\n    /**\r\n     * Instantiate a driver adapter.\r\n     */\r\n    connect(): Promise<Queryable<Query, Result>>;\r\n}\r\n\r\ndeclare type DynamicArgType = ArgType | {\r\n    arity: 'tuple';\r\n    elements: ArgType[];\r\n};\r\n\r\n/** Client */\r\nexport declare type DynamicClientExtensionArgs<C_, TypeMap extends TypeMapDef, TypeMapCb extends TypeMapCbDef, ExtArgs extends Record<string, any>> = {\r\n    [P in keyof C_]: unknown;\r\n} & {\r\n    [K: symbol]: {\r\n        ctx: Optional<DynamicClientExtensionThis<TypeMap, TypeMapCb, ExtArgs>, ITXClientDenyList> & {\r\n            $parent: Optional<DynamicClientExtensionThis<TypeMap, TypeMapCb, ExtArgs>, ITXClientDenyList>;\r\n        };\r\n    };\r\n};\r\n\r\nexport declare type DynamicClientExtensionThis<TypeMap extends TypeMapDef, TypeMapCb extends TypeMapCbDef, ExtArgs extends Record<string, any>> = {\r\n    [P in keyof ExtArgs['client']]: Return<ExtArgs['client'][P]>;\r\n} & {\r\n    [P in Exclude<TypeMap['meta']['modelProps'], keyof ExtArgs['client']>]: DynamicModelExtensionThis<TypeMap, ModelKey<TypeMap, P>, ExtArgs>;\r\n} & {\r\n    [P in Exclude<keyof TypeMap['other']['operations'], keyof ExtArgs['client']>]: P extends keyof ClientOtherOps ? ClientOtherOps[P] : never;\r\n} & {\r\n    [P in Exclude<ClientBuiltInProp, keyof ExtArgs['client']>]: DynamicClientExtensionThisBuiltin<TypeMap, TypeMapCb, ExtArgs>[P];\r\n} & {\r\n    [K: symbol]: {\r\n        types: TypeMap['other'];\r\n    };\r\n};\r\n\r\nexport declare type DynamicClientExtensionThisBuiltin<TypeMap extends TypeMapDef, TypeMapCb extends TypeMapCbDef, ExtArgs extends Record<string, any>> = {\r\n    $extends: ExtendsHook<'extends', TypeMapCb, ExtArgs, Call<TypeMapCb, {\r\n        extArgs: ExtArgs;\r\n    }>>;\r\n    $transaction<P extends PrismaPromise<any>[]>(arg: [...P], options?: {\r\n        isolationLevel?: TypeMap['meta']['txIsolationLevel'];\r\n    }): Promise<UnwrapTuple<P>>;\r\n    $transaction<R>(fn: (client: Omit<DynamicClientExtensionThis<TypeMap, TypeMapCb, ExtArgs>, ITXClientDenyList>) => Promise<R>, options?: {\r\n        maxWait?: number;\r\n        timeout?: number;\r\n        isolationLevel?: TypeMap['meta']['txIsolationLevel'];\r\n    }): Promise<R>;\r\n    $disconnect(): Promise<void>;\r\n    $connect(): Promise<void>;\r\n};\r\n\r\n/** Model */\r\nexport declare type DynamicModelExtensionArgs<M_, TypeMap extends TypeMapDef, TypeMapCb extends TypeMapCbDef, ExtArgs extends Record<string, any>> = {\r\n    [K in keyof M_]: K extends '$allModels' ? {\r\n        [P in keyof M_[K]]?: unknown;\r\n    } & {\r\n        [K: symbol]: {};\r\n    } : K extends TypeMap['meta']['modelProps'] ? {\r\n        [P in keyof M_[K]]?: unknown;\r\n    } & {\r\n        [K: symbol]: {\r\n            ctx: DynamicModelExtensionThis<TypeMap, ModelKey<TypeMap, K>, ExtArgs> & {\r\n                $parent: DynamicClientExtensionThis<TypeMap, TypeMapCb, ExtArgs>;\r\n            } & {\r\n                $name: ModelKey<TypeMap, K>;\r\n            } & {\r\n                /**\r\n                 * @deprecated Use `$name` instead.\r\n                 */\r\n                name: ModelKey<TypeMap, K>;\r\n            };\r\n        };\r\n    } : never;\r\n};\r\n\r\nexport declare type DynamicModelExtensionFluentApi<TypeMap extends TypeMapDef, M extends PropertyKey, P extends PropertyKey, Null> = {\r\n    [K in keyof TypeMap['model'][M]['payload']['objects']]: <A>(args?: Exact<A, Path<TypeMap['model'][M]['operations'][P]['args']['select'], [K]>>) => PrismaPromise<Path<DynamicModelExtensionFnResultBase<TypeMap, M, {\r\n        select: {\r\n            [P in K]: A;\r\n        };\r\n    }, P>, [K]> | Null> & DynamicModelExtensionFluentApi<TypeMap, (TypeMap['model'][M]['payload']['objects'][K] & {})['name'], P, Null | Select<TypeMap['model'][M]['payload']['objects'][K], null>>;\r\n};\r\n\r\nexport declare type DynamicModelExtensionFnResult<TypeMap extends TypeMapDef, M extends PropertyKey, A, P extends PropertyKey, Null> = P extends FluentOperation ? DynamicModelExtensionFluentApi<TypeMap, M, P, Null> & PrismaPromise<DynamicModelExtensionFnResultBase<TypeMap, M, A, P> | Null> : PrismaPromise<DynamicModelExtensionFnResultBase<TypeMap, M, A, P>>;\r\n\r\nexport declare type DynamicModelExtensionFnResultBase<TypeMap extends TypeMapDef, M extends PropertyKey, A, P extends PropertyKey> = GetResult<TypeMap['model'][M]['payload'], A, P & Operation, TypeMap['globalOmitOptions']>;\r\n\r\nexport declare type DynamicModelExtensionFnResultNull<P extends PropertyKey> = P extends 'findUnique' | 'findFirst' ? null : never;\r\n\r\nexport declare type DynamicModelExtensionOperationFn<TypeMap extends TypeMapDef, M extends PropertyKey, P extends PropertyKey> = {} extends TypeMap['model'][M]['operations'][P]['args'] ? <A extends TypeMap['model'][M]['operations'][P]['args']>(args?: Exact<A, TypeMap['model'][M]['operations'][P]['args']>) => DynamicModelExtensionFnResult<TypeMap, M, A, P, DynamicModelExtensionFnResultNull<P>> : <A extends TypeMap['model'][M]['operations'][P]['args']>(args: Exact<A, TypeMap['model'][M]['operations'][P]['args']>) => DynamicModelExtensionFnResult<TypeMap, M, A, P, DynamicModelExtensionFnResultNull<P>>;\r\n\r\nexport declare type DynamicModelExtensionThis<TypeMap extends TypeMapDef, M extends PropertyKey, ExtArgs extends Record<string, any>> = {\r\n    [P in keyof ExtArgs['model'][Uncapitalize<M & string>]]: Return<ExtArgs['model'][Uncapitalize<M & string>][P]>;\r\n} & {\r\n    [P in Exclude<keyof TypeMap['model'][M]['operations'], keyof ExtArgs['model'][Uncapitalize<M & string>]>]: DynamicModelExtensionOperationFn<TypeMap, M, P>;\r\n} & {\r\n    [P in Exclude<'fields', keyof ExtArgs['model'][Uncapitalize<M & string>]>]: TypeMap['model'][M]['fields'];\r\n} & {\r\n    [K: symbol]: {\r\n        types: TypeMap['model'][M];\r\n    };\r\n};\r\n\r\n/** Query */\r\nexport declare type DynamicQueryExtensionArgs<Q_, TypeMap extends TypeMapDef> = {\r\n    [K in keyof Q_]: K extends '$allOperations' ? (args: {\r\n        model?: string;\r\n        operation: string;\r\n        args: any;\r\n        query: (args: any) => PrismaPromise<any>;\r\n    }) => Promise<any> : K extends '$allModels' ? {\r\n        [P in keyof Q_[K] | keyof TypeMap['model'][keyof TypeMap['model']]['operations'] | '$allOperations']?: P extends '$allOperations' ? DynamicQueryExtensionCb<TypeMap, 'model', keyof TypeMap['model'], keyof TypeMap['model'][keyof TypeMap['model']]['operations']> : P extends keyof TypeMap['model'][keyof TypeMap['model']]['operations'] ? DynamicQueryExtensionCb<TypeMap, 'model', keyof TypeMap['model'], P> : never;\r\n    } : K extends TypeMap['meta']['modelProps'] ? {\r\n        [P in keyof Q_[K] | keyof TypeMap['model'][ModelKey<TypeMap, K>]['operations'] | '$allOperations']?: P extends '$allOperations' ? DynamicQueryExtensionCb<TypeMap, 'model', ModelKey<TypeMap, K>, keyof TypeMap['model'][ModelKey<TypeMap, K>]['operations']> : P extends keyof TypeMap['model'][ModelKey<TypeMap, K>]['operations'] ? DynamicQueryExtensionCb<TypeMap, 'model', ModelKey<TypeMap, K>, P> : never;\r\n    } : K extends keyof TypeMap['other']['operations'] ? DynamicQueryExtensionCb<[TypeMap], 0, 'other', K> : never;\r\n};\r\n\r\nexport declare type DynamicQueryExtensionCb<TypeMap extends TypeMapDef, _0 extends PropertyKey, _1 extends PropertyKey, _2 extends PropertyKey> = <A extends DynamicQueryExtensionCbArgs<TypeMap, _0, _1, _2>>(args: A) => Promise<TypeMap[_0][_1][_2]['result']>;\r\n\r\nexport declare type DynamicQueryExtensionCbArgs<TypeMap extends TypeMapDef, _0 extends PropertyKey, _1 extends PropertyKey, _2 extends PropertyKey> = (_1 extends unknown ? _2 extends unknown ? {\r\n    args: DynamicQueryExtensionCbArgsArgs<TypeMap, _0, _1, _2>;\r\n    model: _0 extends 0 ? undefined : _1;\r\n    operation: _2;\r\n    query: <A extends DynamicQueryExtensionCbArgsArgs<TypeMap, _0, _1, _2>>(args: A) => PrismaPromise<TypeMap[_0][_1]['operations'][_2]['result']>;\r\n} : never : never) & {\r\n    query: (args: DynamicQueryExtensionCbArgsArgs<TypeMap, _0, _1, _2>) => PrismaPromise<TypeMap[_0][_1]['operations'][_2]['result']>;\r\n};\r\n\r\nexport declare type DynamicQueryExtensionCbArgsArgs<TypeMap extends TypeMapDef, _0 extends PropertyKey, _1 extends PropertyKey, _2 extends PropertyKey> = _2 extends '$queryRaw' | '$executeRaw' ? Sql : TypeMap[_0][_1]['operations'][_2]['args'];\r\n\r\n/** Result */\r\nexport declare type DynamicResultExtensionArgs<R_, TypeMap extends TypeMapDef> = {\r\n    [K in keyof R_]: {\r\n        [P in keyof R_[K]]?: {\r\n            needs?: DynamicResultExtensionNeeds<TypeMap, ModelKey<TypeMap, K>, R_[K][P]>;\r\n            compute(data: DynamicResultExtensionData<TypeMap, ModelKey<TypeMap, K>, R_[K][P]>): any;\r\n        };\r\n    };\r\n};\r\n\r\nexport declare type DynamicResultExtensionData<TypeMap extends TypeMapDef, M extends PropertyKey, S> = GetFindResult<TypeMap['model'][M]['payload'], {\r\n    select: S;\r\n}, {}>;\r\n\r\nexport declare type DynamicResultExtensionNeeds<TypeMap extends TypeMapDef, M extends PropertyKey, S> = {\r\n    [K in keyof S]: K extends keyof TypeMap['model'][M]['payload']['scalars'] ? S[K] : never;\r\n} & {\r\n    [N in keyof TypeMap['model'][M]['payload']['scalars']]?: boolean;\r\n};\r\n\r\n/**\r\n * Placeholder value for \"no text\".\r\n */\r\nexport declare const empty: Sql;\r\n\r\nexport declare type EmptyToUnknown<T> = T;\r\n\r\ndeclare interface Engine<InteractiveTransactionPayload = unknown> {\r\n    /** The name of the engine. This is meant to be consumed externally */\r\n    readonly name: string;\r\n    onBeforeExit(callback: () => Promise<void>): void;\r\n    start(): Promise<void>;\r\n    stop(): Promise<void>;\r\n    version(forceRun?: boolean): Promise<string> | string;\r\n    request<T>(query: JsonQuery, options: RequestOptions<InteractiveTransactionPayload>): Promise<QueryEngineResultData<T>>;\r\n    requestBatch<T>(queries: JsonQuery[], options: RequestBatchOptions<InteractiveTransactionPayload>): Promise<BatchQueryEngineResult<T>[]>;\r\n    transaction(action: 'start', headers: Transaction_2.TransactionHeaders, options: Transaction_2.Options): Promise<Transaction_2.InteractiveTransactionInfo<unknown>>;\r\n    transaction(action: 'commit', headers: Transaction_2.TransactionHeaders, info: Transaction_2.InteractiveTransactionInfo<unknown>): Promise<void>;\r\n    transaction(action: 'rollback', headers: Transaction_2.TransactionHeaders, info: Transaction_2.InteractiveTransactionInfo<unknown>): Promise<void>;\r\n    metrics(options: MetricsOptionsJson): Promise<Metrics>;\r\n    metrics(options: MetricsOptionsPrometheus): Promise<string>;\r\n    applyPendingMigrations(): Promise<void>;\r\n}\r\n\r\ndeclare interface EngineConfig {\r\n    cwd: string;\r\n    dirname: string;\r\n    enableDebugLogs?: boolean;\r\n    allowTriggerPanic?: boolean;\r\n    prismaPath?: string;\r\n    generator?: GeneratorConfig;\r\n    /**\r\n     * @remarks this field is used internally by Policy, do not rename or remove\r\n     */\r\n    overrideDatasources: Datasources;\r\n    showColors?: boolean;\r\n    logQueries?: boolean;\r\n    logLevel?: 'info' | 'warn';\r\n    env: Record<string, string>;\r\n    flags?: string[];\r\n    clientVersion: string;\r\n    engineVersion: string;\r\n    previewFeatures?: string[];\r\n    engineEndpoint?: string;\r\n    activeProvider?: string;\r\n    logEmitter: LogEmitter;\r\n    transactionOptions: Transaction_2.Options;\r\n    /**\r\n     * Instance of a Driver Adapter, e.g., like one provided by `@prisma/adapter-planetscale`.\r\n     * If set, this is only used in the library engine, and all queries would be performed through it,\r\n     * rather than Prisma's Rust drivers.\r\n     * @remarks only used by LibraryEngine.ts\r\n     */\r\n    adapter?: SqlDriverAdapterFactory;\r\n    /**\r\n     * The contents of the schema encoded into a string\r\n     */\r\n    inlineSchema: string;\r\n    /**\r\n     * The contents of the datasource url saved in a string\r\n     * @remarks only used by DataProxyEngine.ts\r\n     * @remarks this field is used internally by Policy, do not rename or remove\r\n     */\r\n    inlineDatasources: GetPrismaClientConfig['inlineDatasources'];\r\n    /**\r\n     * The string hash that was produced for a given schema\r\n     * @remarks only used by DataProxyEngine.ts\r\n     */\r\n    inlineSchemaHash: string;\r\n    /**\r\n     * The helper for interaction with OTEL tracing\r\n     * @remarks enabling is determined by the client and @prisma/instrumentation package\r\n     */\r\n    tracingHelper: TracingHelper;\r\n    /**\r\n     * Information about whether we have not found a schema.prisma file in the\r\n     * default location, and that we fell back to finding the schema.prisma file\r\n     * in the current working directory. This usually means it has been bundled.\r\n     */\r\n    isBundled?: boolean;\r\n    /**\r\n     * Web Assembly module loading configuration\r\n     */\r\n    engineWasm?: EngineWasmLoadingConfig;\r\n    compilerWasm?: CompilerWasmLoadingConfig;\r\n    /**\r\n     * Allows Accelerate to use runtime utilities from the client. These are\r\n     * necessary for the AccelerateEngine to function correctly.\r\n     */\r\n    accelerateUtils?: {\r\n        resolveDatasourceUrl: typeof resolveDatasourceUrl;\r\n        getBatchRequestPayload: typeof getBatchRequestPayload;\r\n        prismaGraphQLToJSError: typeof prismaGraphQLToJSError;\r\n        PrismaClientUnknownRequestError: typeof PrismaClientUnknownRequestError;\r\n        PrismaClientInitializationError: typeof PrismaClientInitializationError;\r\n        PrismaClientKnownRequestError: typeof PrismaClientKnownRequestError;\r\n        debug: (...args: any[]) => void;\r\n        engineVersion: string;\r\n        clientVersion: string;\r\n    };\r\n}\r\n\r\ndeclare type EngineEvent<E extends EngineEventType> = E extends QueryEventType ? QueryEvent : LogEvent;\r\n\r\ndeclare type EngineEventType = QueryEventType | LogEventType;\r\n\r\ndeclare type EngineSpan = {\r\n    id: EngineSpanId;\r\n    parentId: string | null;\r\n    name: string;\r\n    startTime: HrTime;\r\n    endTime: HrTime;\r\n    kind: EngineSpanKind;\r\n    attributes?: Record<string, unknown>;\r\n    links?: EngineSpanId[];\r\n};\r\n\r\ndeclare type EngineSpanId = string;\r\n\r\ndeclare type EngineSpanKind = 'client' | 'internal';\r\n\r\ndeclare type EngineWasmLoadingConfig = {\r\n    /**\r\n     * WASM-bindgen runtime for corresponding module\r\n     */\r\n    getRuntime: () => Promise<{\r\n        __wbg_set_wasm(exports: unknown): void;\r\n        QueryEngine: QueryEngineConstructor;\r\n    }>;\r\n    /**\r\n     * Loads the raw wasm module for the wasm query engine. This configuration is\r\n     * generated specifically for each type of client, eg. Node.js client and Edge\r\n     * clients will have different implementations.\r\n     * @remarks this is a callback on purpose, we only load the wasm if needed.\r\n     * @remarks only used by LibraryEngine\r\n     */\r\n    getQueryEngineWasmModule: () => Promise<unknown>;\r\n};\r\n\r\ndeclare type EnumValue = ReadonlyDeep_2<{\r\n    name: string;\r\n    dbName: string | null;\r\n}>;\r\n\r\ndeclare type EnvPaths = {\r\n    rootEnvPath: string | null;\r\n    schemaEnvPath: string | undefined;\r\n};\r\n\r\ndeclare interface EnvValue {\r\n    fromEnvVar: null | string;\r\n    value: null | string;\r\n}\r\n\r\nexport declare type Equals<A, B> = (<T>() => T extends A ? 1 : 2) extends (<T>() => T extends B ? 1 : 2) ? 1 : 0;\r\n\r\ndeclare type Error_2 = MappedError & {\r\n    originalCode?: string;\r\n    originalMessage?: string;\r\n};\r\n\r\ndeclare type ErrorCapturingFunction<T> = T extends (...args: infer A) => Promise<infer R> ? (...args: A) => Promise<Result_4<ErrorCapturingInterface<R>>> : T extends (...args: infer A) => infer R ? (...args: A) => Result_4<ErrorCapturingInterface<R>> : T;\r\n\r\ndeclare type ErrorCapturingInterface<T> = {\r\n    [K in keyof T]: ErrorCapturingFunction<T[K]>;\r\n};\r\n\r\ndeclare interface ErrorCapturingSqlDriverAdapter extends ErrorCapturingInterface<SqlDriverAdapter> {\r\n    readonly errorRegistry: ErrorRegistry;\r\n}\r\n\r\ndeclare type ErrorFormat = 'pretty' | 'colorless' | 'minimal';\r\n\r\ndeclare type ErrorRecord = {\r\n    error: unknown;\r\n};\r\n\r\ndeclare interface ErrorRegistry {\r\n    consumeError(id: number): ErrorRecord | undefined;\r\n}\r\n\r\ndeclare interface ErrorWithBatchIndex {\r\n    batchRequestIdx?: number;\r\n}\r\n\r\ndeclare type EventCallback<E extends ExtendedEventType> = [E] extends ['beforeExit'] ? () => Promise<void> : [E] extends [LogLevel] ? (event: EngineEvent<E>) => void : never;\r\n\r\nexport declare type Exact<A, W> = (A extends unknown ? (W extends A ? {\r\n    [K in keyof A]: Exact<A[K], W[K]>;\r\n} : W) : never) | (A extends Narrowable ? A : never);\r\n\r\n/**\r\n * Defines Exception.\r\n *\r\n * string or an object with one of (message or name or code) and optional stack\r\n */\r\ndeclare type Exception = ExceptionWithCode | ExceptionWithMessage | ExceptionWithName | string;\r\n\r\ndeclare interface ExceptionWithCode {\r\n    code: string | number;\r\n    name?: string;\r\n    message?: string;\r\n    stack?: string;\r\n}\r\n\r\ndeclare interface ExceptionWithMessage {\r\n    code?: string | number;\r\n    message: string;\r\n    name?: string;\r\n    stack?: string;\r\n}\r\n\r\ndeclare interface ExceptionWithName {\r\n    code?: string | number;\r\n    message?: string;\r\n    name: string;\r\n    stack?: string;\r\n}\r\n\r\ndeclare type ExtendedEventType = LogLevel | 'beforeExit';\r\n\r\ndeclare type ExtendedSpanOptions = SpanOptions & {\r\n    /** The name of the span */\r\n    name: string;\r\n    internal?: boolean;\r\n    /** Whether it propagates context (?=true) */\r\n    active?: boolean;\r\n    /** The context to append the span to */\r\n    context?: Context;\r\n};\r\n\r\n/** $extends, defineExtension */\r\nexport declare interface ExtendsHook<Variant extends 'extends' | 'define', TypeMapCb extends TypeMapCbDef, ExtArgs extends Record<string, any>, TypeMap extends TypeMapDef = Call<TypeMapCb, {\r\n    extArgs: ExtArgs;\r\n}>> {\r\n    extArgs: ExtArgs;\r\n    <R_ extends {\r\n        [K in TypeMap['meta']['modelProps'] | '$allModels']?: unknown;\r\n    }, R, M_ extends {\r\n        [K in TypeMap['meta']['modelProps'] | '$allModels']?: unknown;\r\n    }, M, Q_ extends {\r\n        [K in TypeMap['meta']['modelProps'] | '$allModels' | keyof TypeMap['other']['operations'] | '$allOperations']?: unknown;\r\n    }, C_ extends {\r\n        [K in string]?: unknown;\r\n    }, C, Args extends InternalArgs = InternalArgs<R, M, {}, C>, MergedArgs extends InternalArgs = MergeExtArgs<TypeMap, ExtArgs, Args>>(extension: ((client: DynamicClientExtensionThis<TypeMap, TypeMapCb, ExtArgs>) => {\r\n        $extends: {\r\n            extArgs: Args;\r\n        };\r\n    }) | {\r\n        name?: string;\r\n        query?: DynamicQueryExtensionArgs<Q_, TypeMap>;\r\n        result?: DynamicResultExtensionArgs<R_, TypeMap> & R;\r\n        model?: DynamicModelExtensionArgs<M_, TypeMap, TypeMapCb, ExtArgs> & M;\r\n        client?: DynamicClientExtensionArgs<C_, TypeMap, TypeMapCb, ExtArgs> & C;\r\n    }): {\r\n        extends: DynamicClientExtensionThis<Call<TypeMapCb, {\r\n            extArgs: MergedArgs;\r\n        }>, TypeMapCb, MergedArgs>;\r\n        define: (client: any) => {\r\n            $extends: {\r\n                extArgs: Args;\r\n            };\r\n        };\r\n    }[Variant];\r\n}\r\n\r\nexport declare type ExtensionArgs = Optional<RequiredExtensionArgs>;\r\n\r\ndeclare namespace Extensions {\r\n    export {\r\n        defineExtension,\r\n        getExtensionContext\r\n    }\r\n}\r\nexport { Extensions }\r\n\r\ndeclare namespace Extensions_2 {\r\n    export {\r\n        InternalArgs,\r\n        DefaultArgs,\r\n        GetPayloadResultExtensionKeys,\r\n        GetPayloadResultExtensionObject,\r\n        GetPayloadResult,\r\n        GetSelect,\r\n        GetOmit,\r\n        DynamicQueryExtensionArgs,\r\n        DynamicQueryExtensionCb,\r\n        DynamicQueryExtensionCbArgs,\r\n        DynamicQueryExtensionCbArgsArgs,\r\n        DynamicResultExtensionArgs,\r\n        DynamicResultExtensionNeeds,\r\n        DynamicResultExtensionData,\r\n        DynamicModelExtensionArgs,\r\n        DynamicModelExtensionThis,\r\n        DynamicModelExtensionOperationFn,\r\n        DynamicModelExtensionFnResult,\r\n        DynamicModelExtensionFnResultBase,\r\n        DynamicModelExtensionFluentApi,\r\n        DynamicModelExtensionFnResultNull,\r\n        DynamicClientExtensionArgs,\r\n        DynamicClientExtensionThis,\r\n        ClientBuiltInProp,\r\n        DynamicClientExtensionThisBuiltin,\r\n        ExtendsHook,\r\n        MergeExtArgs,\r\n        AllModelsToStringIndex,\r\n        TypeMapDef,\r\n        DevTypeMapDef,\r\n        DevTypeMapFnDef,\r\n        ClientOptionDef,\r\n        ClientOtherOps,\r\n        TypeMapCbDef,\r\n        ModelKey,\r\n        RequiredExtensionArgs as UserArgs\r\n    }\r\n}\r\n\r\nexport declare type ExtractGlobalOmit<Options, ModelName extends string> = Options extends {\r\n    omit: {\r\n        [K in ModelName]: infer GlobalOmit;\r\n    };\r\n} ? GlobalOmit : {};\r\n\r\ndeclare type Field = ReadonlyDeep_2<{\r\n    kind: FieldKind;\r\n    name: string;\r\n    isRequired: boolean;\r\n    isList: boolean;\r\n    isUnique: boolean;\r\n    isId: boolean;\r\n    isReadOnly: boolean;\r\n    isGenerated?: boolean;\r\n    isUpdatedAt?: boolean;\r\n    /**\r\n     * Describes the data type in the same the way it is defined in the Prisma schema:\r\n     * BigInt, Boolean, Bytes, DateTime, Decimal, Float, Int, JSON, String, $ModelName\r\n     */\r\n    type: string;\r\n    /**\r\n     * Native database type, if specified.\r\n     * For example, `@db.VarChar(191)` is encoded as `['VarChar', ['191']]`,\r\n     * `@db.Text` is encoded as `['Text', []]`.\r\n     */\r\n    nativeType?: [string, string[]] | null;\r\n    dbName?: string | null;\r\n    hasDefaultValue: boolean;\r\n    default?: FieldDefault | FieldDefaultScalar | FieldDefaultScalar[];\r\n    relationFromFields?: string[];\r\n    relationToFields?: string[];\r\n    relationOnDelete?: string;\r\n    relationOnUpdate?: string;\r\n    relationName?: string;\r\n    documentation?: string;\r\n}>;\r\n\r\ndeclare type FieldDefault = ReadonlyDeep_2<{\r\n    name: string;\r\n    args: Array<string | number>;\r\n}>;\r\n\r\ndeclare type FieldDefaultScalar = string | boolean | number;\r\n\r\ndeclare type FieldInitializer = {\r\n    type: 'value';\r\n    value: PrismaValue;\r\n} | {\r\n    type: 'lastInsertId';\r\n};\r\n\r\ndeclare type FieldKind = 'scalar' | 'object' | 'enum' | 'unsupported';\r\n\r\ndeclare type FieldLocation = 'scalar' | 'inputObjectTypes' | 'outputObjectTypes' | 'enumTypes' | 'fieldRefTypes';\r\n\r\ndeclare type FieldNamespace = 'model' | 'prisma';\r\n\r\ndeclare type FieldOperation = {\r\n    type: 'set';\r\n    value: PrismaValue;\r\n} | {\r\n    type: 'add';\r\n    value: PrismaValue;\r\n} | {\r\n    type: 'subtract';\r\n    value: PrismaValue;\r\n} | {\r\n    type: 'multiply';\r\n    value: PrismaValue;\r\n} | {\r\n    type: 'divide';\r\n    value: PrismaValue;\r\n};\r\n\r\n/**\r\n * A reference to a specific field of a specific model\r\n */\r\nexport declare interface FieldRef<Model, FieldType> {\r\n    readonly modelName: Model;\r\n    readonly name: string;\r\n    readonly typeName: FieldType;\r\n    readonly isList: boolean;\r\n}\r\n\r\ndeclare type FieldRefAllowType = TypeRef<'scalar' | 'enumTypes'>;\r\n\r\ndeclare type FieldRefType = ReadonlyDeep_2<{\r\n    name: string;\r\n    allowTypes: FieldRefAllowType[];\r\n    fields: SchemaArg[];\r\n}>;\r\n\r\ndeclare type FieldScalarType = {\r\n    type: 'string' | 'int' | 'bigint' | 'float' | 'boolean' | 'json' | 'object' | 'datetime' | 'decimal' | 'unsupported';\r\n} | {\r\n    type: 'enum';\r\n    name: string;\r\n} | {\r\n    type: 'bytes';\r\n    encoding: 'array' | 'base64' | 'hex';\r\n};\r\n\r\ndeclare type FieldType = {\r\n    arity: Arity;\r\n} & FieldScalarType;\r\n\r\ndeclare type FluentOperation = 'findUnique' | 'findUniqueOrThrow' | 'findFirst' | 'findFirstOrThrow' | 'create' | 'update' | 'upsert' | 'delete';\r\n\r\nexport declare interface Fn<Params = unknown, Returns = unknown> {\r\n    params: Params;\r\n    returns: Returns;\r\n}\r\n\r\ndeclare type Fragment = {\r\n    type: 'stringChunk';\r\n    chunk: string;\r\n} | {\r\n    type: 'parameter';\r\n} | {\r\n    type: 'parameterTuple';\r\n} | {\r\n    type: 'parameterTupleList';\r\n    itemPrefix: string;\r\n    itemSeparator: string;\r\n    itemSuffix: string;\r\n    groupSeparator: string;\r\n};\r\n\r\ndeclare interface GeneratorConfig {\r\n    name: string;\r\n    output: EnvValue | null;\r\n    isCustomOutput?: boolean;\r\n    provider: EnvValue;\r\n    config: {\r\n        /** `output` is a reserved name and will only be available directly at `generator.output` */\r\n        output?: never;\r\n        /** `provider` is a reserved name and will only be available directly at `generator.provider` */\r\n        provider?: never;\r\n        /** `binaryTargets` is a reserved name and will only be available directly at `generator.binaryTargets` */\r\n        binaryTargets?: never;\r\n        /** `previewFeatures` is a reserved name and will only be available directly at `generator.previewFeatures` */\r\n        previewFeatures?: never;\r\n    } & {\r\n        [key: string]: string | string[] | undefined;\r\n    };\r\n    binaryTargets: BinaryTargetsEnvValue[];\r\n    previewFeatures: string[];\r\n    envPaths?: EnvPaths;\r\n    sourceFilePath: string;\r\n}\r\n\r\nexport declare type GetAggregateResult<P extends OperationPayload, A> = {\r\n    [K in keyof A as K extends Aggregate ? K : never]: K extends '_count' ? A[K] extends true ? number : Count<A[K]> : {\r\n        [J in keyof A[K] & string]: P['scalars'][J] | null;\r\n    };\r\n};\r\n\r\ndeclare function getBatchRequestPayload(batch: JsonQuery[], transaction?: TransactionOptions_2<unknown>): QueryEngineBatchRequest;\r\n\r\nexport declare type GetBatchResult = {\r\n    count: number;\r\n};\r\n\r\nexport declare type GetCountResult<A> = A extends {\r\n    select: infer S;\r\n} ? (S extends true ? number : Count<S>) : number;\r\n\r\ndeclare function getExtensionContext<T>(that: T): Context_2<T>;\r\n\r\nexport declare type GetFindResult<P extends OperationPayload, A, GlobalOmitOptions> = Equals<A, any> extends 1 ? DefaultSelection<P, A, GlobalOmitOptions> : A extends {\r\n    select: infer S extends object;\r\n} & Record<string, unknown> | {\r\n    include: infer I extends object;\r\n} & Record<string, unknown> ? {\r\n    [K in keyof S | keyof I as (S & I)[K] extends false | undefined | Skip | null ? never : K]: (S & I)[K] extends object ? P extends SelectablePayloadFields<K, (infer O)[]> ? O extends OperationPayload ? GetFindResult<O, (S & I)[K], GlobalOmitOptions>[] : never : P extends SelectablePayloadFields<K, infer O | null> ? O extends OperationPayload ? GetFindResult<O, (S & I)[K], GlobalOmitOptions> | SelectField<P, K> & null : never : K extends '_count' ? Count<GetFindResult<P, (S & I)[K], GlobalOmitOptions>> : never : P extends SelectablePayloadFields<K, (infer O)[]> ? O extends OperationPayload ? DefaultSelection<O, {}, GlobalOmitOptions>[] : never : P extends SelectablePayloadFields<K, infer O | null> ? O extends OperationPayload ? DefaultSelection<O, {}, GlobalOmitOptions> | SelectField<P, K> & null : never : P extends {\r\n        scalars: {\r\n            [k in K]: infer O;\r\n        };\r\n    } ? O : K extends '_count' ? Count<P['objects']> : never;\r\n} & (A extends {\r\n    include: any;\r\n} & Record<string, unknown> ? DefaultSelection<P, A & {\r\n    omit: A['omit'];\r\n}, GlobalOmitOptions> : unknown) : DefaultSelection<P, A, GlobalOmitOptions>;\r\n\r\nexport declare type GetGroupByResult<P extends OperationPayload, A> = A extends {\r\n    by: string[];\r\n} ? Array<GetAggregateResult<P, A> & {\r\n    [K in A['by'][number]]: P['scalars'][K];\r\n}> : A extends {\r\n    by: string;\r\n} ? Array<GetAggregateResult<P, A> & {\r\n    [K in A['by']]: P['scalars'][K];\r\n}> : {}[];\r\n\r\nexport declare type GetOmit<BaseKeys extends string, R extends InternalArgs['result'][string], ExtraType = never> = {\r\n    [K in (string extends keyof R ? never : keyof R) | BaseKeys]?: boolean | ExtraType;\r\n};\r\n\r\nexport declare type GetPayloadResult<Base extends Record<any, any>, R extends InternalArgs['result'][string]> = Omit<Base, GetPayloadResultExtensionKeys<R>> & GetPayloadResultExtensionObject<R>;\r\n\r\nexport declare type GetPayloadResultExtensionKeys<R extends InternalArgs['result'][string], KR extends keyof R = string extends keyof R ? never : keyof R> = KR;\r\n\r\nexport declare type GetPayloadResultExtensionObject<R extends InternalArgs['result'][string]> = {\r\n    [K in GetPayloadResultExtensionKeys<R>]: R[K] extends () => {\r\n        compute: (...args: any) => infer C;\r\n    } ? C : never;\r\n};\r\n\r\nexport declare function getPrismaClient(config: GetPrismaClientConfig): {\r\n    new (optionsArg?: PrismaClientOptions): {\r\n        _originalClient: any;\r\n        _runtimeDataModel: RuntimeDataModel;\r\n        _requestHandler: RequestHandler;\r\n        _connectionPromise?: Promise<any> | undefined;\r\n        _disconnectionPromise?: Promise<any> | undefined;\r\n        _engineConfig: EngineConfig;\r\n        _accelerateEngineConfig: AccelerateEngineConfig;\r\n        _clientVersion: string;\r\n        _errorFormat: ErrorFormat;\r\n        _tracingHelper: TracingHelper;\r\n        _previewFeatures: string[];\r\n        _activeProvider: string;\r\n        _globalOmit?: GlobalOmitOptions | undefined;\r\n        _extensions: MergedExtensionsList;\r\n        /**\r\n         * @remarks This is used internally by Policy, do not rename or remove\r\n         */\r\n        _engine: Engine;\r\n        /**\r\n         * A fully constructed/applied Client that references the parent\r\n         * PrismaClient. This is used for Client extensions only.\r\n         */\r\n        _appliedParent: any;\r\n        _createPrismaPromise: PrismaPromiseFactory;\r\n        $on<E extends ExtendedEventType>(eventType: E, callback: EventCallback<E>): any;\r\n        $connect(): Promise<void>;\r\n        /**\r\n         * Disconnect from the database\r\n         */\r\n        $disconnect(): Promise<void>;\r\n        /**\r\n         * Executes a raw query and always returns a number\r\n         */\r\n        $executeRawInternal(transaction: PrismaPromiseTransaction | undefined, clientMethod: string, args: RawQueryArgs, middlewareArgsMapper?: MiddlewareArgsMapper<unknown, unknown>): Promise<number>;\r\n        /**\r\n         * Executes a raw query provided through a safe tag function\r\n         * @see https://github.com/prisma/prisma/issues/7142\r\n         *\r\n         * @param query\r\n         * @param values\r\n         * @returns\r\n         */\r\n        $executeRaw(query: TemplateStringsArray | Sql, ...values: any[]): PrismaPromise_2<unknown, any>;\r\n        /**\r\n         * Unsafe counterpart of `$executeRaw` that is susceptible to SQL injections\r\n         * @see https://github.com/prisma/prisma/issues/7142\r\n         *\r\n         * @param query\r\n         * @param values\r\n         * @returns\r\n         */\r\n        $executeRawUnsafe(query: string, ...values: RawValue[]): PrismaPromise_2<unknown, any>;\r\n        /**\r\n         * Executes a raw command only for MongoDB\r\n         *\r\n         * @param command\r\n         * @returns\r\n         */\r\n        $runCommandRaw(command: Record<string, JsInputValue>): PrismaPromise_2<unknown, any>;\r\n        /**\r\n         * Executes a raw query and returns selected data\r\n         */\r\n        $queryRawInternal(transaction: PrismaPromiseTransaction | undefined, clientMethod: string, args: RawQueryArgs, middlewareArgsMapper?: MiddlewareArgsMapper<unknown, unknown>): Promise<any>;\r\n        /**\r\n         * Executes a raw query provided through a safe tag function\r\n         * @see https://github.com/prisma/prisma/issues/7142\r\n         *\r\n         * @param query\r\n         * @param values\r\n         * @returns\r\n         */\r\n        $queryRaw(query: TemplateStringsArray | Sql, ...values: any[]): PrismaPromise_2<unknown, any>;\r\n        /**\r\n         * Counterpart to $queryRaw, that returns strongly typed results\r\n         * @param typedSql\r\n         */\r\n        $queryRawTyped(typedSql: UnknownTypedSql): PrismaPromise_2<unknown, any>;\r\n        /**\r\n         * Unsafe counterpart of `$queryRaw` that is susceptible to SQL injections\r\n         * @see https://github.com/prisma/prisma/issues/7142\r\n         *\r\n         * @param query\r\n         * @param values\r\n         * @returns\r\n         */\r\n        $queryRawUnsafe(query: string, ...values: RawValue[]): PrismaPromise_2<unknown, any>;\r\n        /**\r\n         * Execute a batch of requests in a transaction\r\n         * @param requests\r\n         * @param options\r\n         */\r\n        _transactionWithArray({ promises, options, }: {\r\n            promises: Array<PrismaPromise_2<any>>;\r\n            options?: BatchTransactionOptions;\r\n        }): Promise<any>;\r\n        /**\r\n         * Perform a long-running transaction\r\n         * @param callback\r\n         * @param options\r\n         * @returns\r\n         */\r\n        _transactionWithCallback({ callback, options, }: {\r\n            callback: (client: Client) => Promise<unknown>;\r\n            options?: Options;\r\n        }): Promise<unknown>;\r\n        _createItxClient(transaction: PrismaPromiseInteractiveTransaction): Client;\r\n        /**\r\n         * Execute queries within a transaction\r\n         * @param input a callback or a query list\r\n         * @param options to set timeouts (callback)\r\n         * @returns\r\n         */\r\n        $transaction(input: any, options?: any): Promise<any>;\r\n        /**\r\n         * Runs the middlewares over params before executing a request\r\n         * @param internalParams\r\n         * @returns\r\n         */\r\n        _request(internalParams: InternalRequestParams): Promise<any>;\r\n        _executeRequest({ args, clientMethod, dataPath, callsite, action, model, argsMapper, transaction, unpacker, otelParentCtx, customDataProxyFetch, }: InternalRequestParams): Promise<any>;\r\n        $metrics: MetricsClient;\r\n        /**\r\n         * Shortcut for checking a preview flag\r\n         * @param feature preview flag\r\n         * @returns\r\n         */\r\n        _hasPreviewFlag(feature: string): boolean;\r\n        $applyPendingMigrations(): Promise<void>;\r\n        $extends: typeof $extends;\r\n        readonly [Symbol.toStringTag]: string;\r\n    };\r\n};\r\n\r\n/**\r\n * Config that is stored into the generated client. When the generated client is\r\n * loaded, this same config is passed to {@link getPrismaClient} which creates a\r\n * closure with that config around a non-instantiated [[PrismaClient]].\r\n */\r\nexport declare type GetPrismaClientConfig = {\r\n    runtimeDataModel: RuntimeDataModel;\r\n    generator?: GeneratorConfig;\r\n    relativeEnvPaths?: {\r\n        rootEnvPath?: string | null;\r\n        schemaEnvPath?: string | null;\r\n    };\r\n    relativePath: string;\r\n    dirname: string;\r\n    clientVersion: string;\r\n    engineVersion: string;\r\n    datasourceNames: string[];\r\n    activeProvider: ActiveConnectorType;\r\n    /**\r\n     * The contents of the schema encoded into a string\r\n     * @remarks only used for the purpose of data proxy\r\n     */\r\n    inlineSchema: string;\r\n    /**\r\n     * A special env object just for the data proxy edge runtime.\r\n     * Allows bundlers to inject their own env variables (Vercel).\r\n     * Allows platforms to declare global variables as env (Workers).\r\n     * @remarks only used for the purpose of data proxy\r\n     */\r\n    injectableEdgeEnv?: () => LoadedEnv;\r\n    /**\r\n     * The contents of the datasource url saved in a string.\r\n     * This can either be an env var name or connection string.\r\n     * It is needed by the client to connect to the Data Proxy.\r\n     * @remarks only used for the purpose of data proxy\r\n     */\r\n    inlineDatasources: {\r\n        [name in string]: {\r\n            url: EnvValue;\r\n        };\r\n    };\r\n    /**\r\n     * The string hash that was produced for a given schema\r\n     * @remarks only used for the purpose of data proxy\r\n     */\r\n    inlineSchemaHash: string;\r\n    /**\r\n     * A marker to indicate that the client was not generated via `prisma\r\n     * generate` but was generated via `generate --postinstall` script instead.\r\n     * @remarks used to error for Vercel/Netlify for schema caching issues\r\n     */\r\n    postinstall?: boolean;\r\n    /**\r\n     * Information about the CI where the Prisma Client has been generated. The\r\n     * name of the CI environment is stored at generation time because CI\r\n     * information is not always available at runtime. Moreover, the edge client\r\n     * has no notion of environment variables, so this works around that.\r\n     * @remarks used to error for Vercel/Netlify for schema caching issues\r\n     */\r\n    ciName?: string;\r\n    /**\r\n     * Information about whether we have not found a schema.prisma file in the\r\n     * default location, and that we fell back to finding the schema.prisma file\r\n     * in the current working directory. This usually means it has been bundled.\r\n     */\r\n    isBundled?: boolean;\r\n    /**\r\n     * A boolean that is `false` when the client was generated with --no-engine. At\r\n     * runtime, this means the client will be bound to be using the Data Proxy.\r\n     */\r\n    copyEngine?: boolean;\r\n    /**\r\n     * Optional wasm loading configuration\r\n     */\r\n    engineWasm?: EngineWasmLoadingConfig;\r\n    compilerWasm?: CompilerWasmLoadingConfig;\r\n};\r\n\r\nexport declare type GetResult<Payload extends OperationPayload, Args, OperationName extends Operation = 'findUniqueOrThrow', GlobalOmitOptions = {}> = {\r\n    findUnique: GetFindResult<Payload, Args, GlobalOmitOptions> | null;\r\n    findUniqueOrThrow: GetFindResult<Payload, Args, GlobalOmitOptions>;\r\n    findFirst: GetFindResult<Payload, Args, GlobalOmitOptions> | null;\r\n    findFirstOrThrow: GetFindResult<Payload, Args, GlobalOmitOptions>;\r\n    findMany: GetFindResult<Payload, Args, GlobalOmitOptions>[];\r\n    create: GetFindResult<Payload, Args, GlobalOmitOptions>;\r\n    createMany: GetBatchResult;\r\n    createManyAndReturn: GetFindResult<Payload, Args, GlobalOmitOptions>[];\r\n    update: GetFindResult<Payload, Args, GlobalOmitOptions>;\r\n    updateMany: GetBatchResult;\r\n    updateManyAndReturn: GetFindResult<Payload, Args, GlobalOmitOptions>[];\r\n    upsert: GetFindResult<Payload, Args, GlobalOmitOptions>;\r\n    delete: GetFindResult<Payload, Args, GlobalOmitOptions>;\r\n    deleteMany: GetBatchResult;\r\n    aggregate: GetAggregateResult<Payload, Args>;\r\n    count: GetCountResult<Args>;\r\n    groupBy: GetGroupByResult<Payload, Args>;\r\n    $queryRaw: unknown;\r\n    $queryRawTyped: unknown;\r\n    $executeRaw: number;\r\n    $queryRawUnsafe: unknown;\r\n    $executeRawUnsafe: number;\r\n    $runCommandRaw: JsonObject;\r\n    findRaw: JsonObject;\r\n    aggregateRaw: JsonObject;\r\n}[OperationName];\r\n\r\nexport declare function getRuntime(): GetRuntimeOutput;\r\n\r\ndeclare type GetRuntimeOutput = {\r\n    id: RuntimeName;\r\n    prettyName: string;\r\n    isEdge: boolean;\r\n};\r\n\r\nexport declare type GetSelect<Base extends Record<any, any>, R extends InternalArgs['result'][string], KR extends keyof R = string extends keyof R ? never : keyof R> = {\r\n    [K in KR | keyof Base]?: K extends KR ? boolean : Base[K];\r\n};\r\n\r\ndeclare type GlobalOmitOptions = {\r\n    [modelName: string]: {\r\n        [fieldName: string]: boolean;\r\n    };\r\n};\r\n\r\ndeclare type HandleErrorParams = {\r\n    args: JsArgs;\r\n    error: any;\r\n    clientMethod: string;\r\n    callsite?: CallSite;\r\n    transaction?: PrismaPromiseTransaction;\r\n    modelName?: string;\r\n    globalOmit?: GlobalOmitOptions;\r\n};\r\n\r\ndeclare type HrTime = [number, number];\r\n\r\n/**\r\n * Defines High-Resolution Time.\r\n *\r\n * The first number, HrTime[0], is UNIX Epoch time in seconds since 00:00:00 UTC on 1 January 1970.\r\n * The second number, HrTime[1], represents the partial second elapsed since Unix Epoch time represented by first number in nanoseconds.\r\n * For example, 2021-01-01T12:30:10.150Z in UNIX Epoch time in milliseconds is represented as 1609504210150.\r\n * The first number is calculated by converting and truncating the Epoch time in milliseconds to seconds:\r\n * HrTime[0] = Math.trunc(1609504210150 / 1000) = 1609504210.\r\n * The second number is calculated by converting the digits after the decimal point of the subtraction, (1609504210150 / 1000) - HrTime[0], to nanoseconds:\r\n * HrTime[1] = Number((1609504210.150 - HrTime[0]).toFixed(9)) * 1e9 = 150000000.\r\n * This is represented in HrTime format as [1609504210, 150000000].\r\n */\r\ndeclare type HrTime_2 = [number, number];\r\n\r\ndeclare type Index = ReadonlyDeep_2<{\r\n    model: string;\r\n    type: IndexType;\r\n    isDefinedOnField: boolean;\r\n    name?: string;\r\n    dbName?: string;\r\n    algorithm?: string;\r\n    clustered?: boolean;\r\n    fields: IndexField[];\r\n}>;\r\n\r\ndeclare type IndexField = ReadonlyDeep_2<{\r\n    name: string;\r\n    sortOrder?: SortOrder;\r\n    length?: number;\r\n    operatorClass?: string;\r\n}>;\r\n\r\ndeclare type IndexType = 'id' | 'normal' | 'unique' | 'fulltext';\r\n\r\ndeclare type InMemoryOps = {\r\n    pagination: Pagination | null;\r\n    distinct: string[] | null;\r\n    reverse: boolean;\r\n    linkingFields: string[] | null;\r\n    nested: Record<string, InMemoryOps>;\r\n};\r\n\r\n/**\r\n * Matches a JSON array.\r\n * Unlike \\`JsonArray\\`, readonly arrays are assignable to this type.\r\n */\r\nexport declare interface InputJsonArray extends ReadonlyArray<InputJsonValue | null> {\r\n}\r\n\r\n/**\r\n * Matches a JSON object.\r\n * Unlike \\`JsonObject\\`, this type allows undefined and read-only properties.\r\n */\r\nexport declare type InputJsonObject = {\r\n    readonly [Key in string]?: InputJsonValue | null;\r\n};\r\n\r\n/**\r\n * Matches any valid value that can be used as an input for operations like\r\n * create and update as the value of a JSON field. Unlike \\`JsonValue\\`, this\r\n * type allows read-only arrays and read-only object properties and disallows\r\n * \\`null\\` at the top level.\r\n *\r\n * \\`null\\` cannot be used as the value of a JSON field because its meaning\r\n * would be ambiguous. Use \\`Prisma.JsonNull\\` to store the JSON null value or\r\n * \\`Prisma.DbNull\\` to clear the JSON value and set the field to the database\r\n * NULL value instead.\r\n *\r\n * @see https://www.prisma.io/docs/concepts/components/prisma-client/working-with-fields/working-with-json-fields#filtering-by-null-values\r\n */\r\nexport declare type InputJsonValue = string | number | boolean | InputJsonObject | InputJsonArray | {\r\n    toJSON(): unknown;\r\n};\r\n\r\ndeclare type InputType = ReadonlyDeep_2<{\r\n    name: string;\r\n    constraints: {\r\n        maxNumFields: number | null;\r\n        minNumFields: number | null;\r\n        fields?: string[];\r\n    };\r\n    meta?: {\r\n        source?: string;\r\n        grouping?: string;\r\n    };\r\n    fields: SchemaArg[];\r\n}>;\r\n\r\ndeclare type InputTypeRef = TypeRef<'scalar' | 'inputObjectTypes' | 'enumTypes' | 'fieldRefTypes'>;\r\n\r\ndeclare type InteractiveTransactionInfo<Payload = unknown> = {\r\n    /**\r\n     * Transaction ID returned by the query engine.\r\n     */\r\n    id: string;\r\n    /**\r\n     * Arbitrary payload the meaning of which depends on the `Engine` implementation.\r\n     * For example, `DataProxyEngine` needs to associate different API endpoints with transactions.\r\n     * In `LibraryEngine` and `BinaryEngine` it is currently not used.\r\n     */\r\n    payload: Payload;\r\n};\r\n\r\ndeclare type InteractiveTransactionOptions<Payload> = Transaction_2.InteractiveTransactionInfo<Payload>;\r\n\r\nexport declare type InternalArgs<R = {\r\n    [K in string]: {\r\n        [K in string]: unknown;\r\n    };\r\n}, M = {\r\n    [K in string]: {\r\n        [K in string]: unknown;\r\n    };\r\n}, Q = {\r\n    [K in string]: {\r\n        [K in string]: unknown;\r\n    };\r\n}, C = {\r\n    [K in string]: unknown;\r\n}> = {\r\n    result: {\r\n        [K in keyof R]: {\r\n            [P in keyof R[K]]: () => R[K][P];\r\n        };\r\n    };\r\n    model: {\r\n        [K in keyof M]: {\r\n            [P in keyof M[K]]: () => M[K][P];\r\n        };\r\n    };\r\n    query: {\r\n        [K in keyof Q]: {\r\n            [P in keyof Q[K]]: () => Q[K][P];\r\n        };\r\n    };\r\n    client: {\r\n        [K in keyof C]: () => C[K];\r\n    };\r\n};\r\n\r\ndeclare type InternalRequestParams = {\r\n    /**\r\n     * The original client method being called.\r\n     * Even though the rootField / operation can be changed,\r\n     * this method stays as it is, as it's what the user's\r\n     * code looks like\r\n     */\r\n    clientMethod: string;\r\n    /**\r\n     * Name of js model that triggered the request. Might be used\r\n     * for warnings or error messages\r\n     */\r\n    jsModelName?: string;\r\n    callsite?: CallSite;\r\n    transaction?: PrismaPromiseTransaction;\r\n    unpacker?: Unpacker;\r\n    otelParentCtx?: Context;\r\n    /** Used to \"desugar\" a user input into an \"expanded\" one */\r\n    argsMapper?: (args?: UserArgs_2) => UserArgs_2;\r\n    /** Used to convert args for middleware and back */\r\n    middlewareArgsMapper?: MiddlewareArgsMapper<unknown, unknown>;\r\n    /** Used for Accelerate client extension via Data Proxy */\r\n    customDataProxyFetch?: AccelerateExtensionFetchDecorator;\r\n} & Omit<QueryMiddlewareParams, 'runInTransaction'>;\r\n\r\ndeclare type IsolationLevel = 'READ UNCOMMITTED' | 'READ COMMITTED' | 'REPEATABLE READ' | 'SNAPSHOT' | 'SERIALIZABLE';\r\n\r\ndeclare type IsolationLevel_2 = 'ReadUncommitted' | 'ReadCommitted' | 'RepeatableRead' | 'Snapshot' | 'Serializable';\r\n\r\ndeclare function isSkip(value: unknown): value is Skip;\r\n\r\nexport declare function isTypedSql(value: unknown): value is UnknownTypedSql;\r\n\r\nexport declare type ITXClientDenyList = (typeof denylist)[number];\r\n\r\nexport declare const itxClientDenyList: readonly (string | symbol)[];\r\n\r\ndeclare interface Job {\r\n    resolve: (data: any) => void;\r\n    reject: (data: any) => void;\r\n    request: any;\r\n}\r\n\r\n/**\r\n * Create a SQL query for a list of values.\r\n */\r\nexport declare function join(values: readonly RawValue[], separator?: string, prefix?: string, suffix?: string): Sql;\r\n\r\ndeclare type JoinExpression = {\r\n    child: QueryPlanNode;\r\n    on: [left: string, right: string][];\r\n    parentField: string;\r\n    isRelationUnique: boolean;\r\n};\r\n\r\nexport declare type JsArgs = {\r\n    select?: Selection_2;\r\n    include?: Selection_2;\r\n    omit?: Omission;\r\n    [argName: string]: JsInputValue;\r\n};\r\n\r\nexport declare type JsInputValue = null | undefined | string | number | boolean | bigint | Uint8Array | Date | DecimalJsLike | ObjectEnumValue | RawParameters | JsonConvertible | FieldRef<string, unknown> | JsInputValue[] | Skip | {\r\n    [key: string]: JsInputValue;\r\n};\r\n\r\ndeclare type JsonArgumentValue = number | string | boolean | null | RawTaggedValue | JsonArgumentValue[] | {\r\n    [key: string]: JsonArgumentValue;\r\n};\r\n\r\n/**\r\n * From https://github.com/sindresorhus/type-fest/\r\n * Matches a JSON array.\r\n */\r\nexport declare interface JsonArray extends Array<JsonValue> {\r\n}\r\n\r\nexport declare type JsonBatchQuery = {\r\n    batch: JsonQuery[];\r\n    transaction?: {\r\n        isolationLevel?: IsolationLevel_2;\r\n    };\r\n};\r\n\r\nexport declare interface JsonConvertible {\r\n    toJSON(): unknown;\r\n}\r\n\r\ndeclare type JsonFieldSelection = {\r\n    arguments?: Record<string, JsonArgumentValue> | RawTaggedValue;\r\n    selection: JsonSelectionSet;\r\n};\r\n\r\ndeclare class JsonNull extends NullTypesEnumValue {\r\n    #private;\r\n}\r\n\r\n/**\r\n * From https://github.com/sindresorhus/type-fest/\r\n * Matches a JSON object.\r\n * This type can be useful to enforce some input to be JSON-compatible or as a super-type to be extended from.\r\n */\r\nexport declare type JsonObject = {\r\n    [Key in string]?: JsonValue;\r\n};\r\n\r\nexport declare type JsonQuery = {\r\n    modelName?: string;\r\n    action: JsonQueryAction;\r\n    query: JsonFieldSelection;\r\n};\r\n\r\ndeclare type JsonQueryAction = 'findUnique' | 'findUniqueOrThrow' | 'findFirst' | 'findFirstOrThrow' | 'findMany' | 'createOne' | 'createMany' | 'createManyAndReturn' | 'updateOne' | 'updateMany' | 'updateManyAndReturn' | 'deleteOne' | 'deleteMany' | 'upsertOne' | 'aggregate' | 'groupBy' | 'executeRaw' | 'queryRaw' | 'runCommandRaw' | 'findRaw' | 'aggregateRaw';\r\n\r\ndeclare type JsonSelectionSet = {\r\n    $scalars?: boolean;\r\n    $composites?: boolean;\r\n} & {\r\n    [fieldName: string]: boolean | JsonFieldSelection;\r\n};\r\n\r\n/**\r\n * From https://github.com/sindresorhus/type-fest/\r\n * Matches any valid JSON value.\r\n */\r\nexport declare type JsonValue = string | number | boolean | JsonObject | JsonArray | null;\r\n\r\nexport declare type JsOutputValue = null | string | number | boolean | bigint | Uint8Array | Date | Decimal | JsOutputValue[] | {\r\n    [key: string]: JsOutputValue;\r\n};\r\n\r\nexport declare type JsPromise<T> = Promise<T> & {};\r\n\r\ndeclare type KnownErrorParams = {\r\n    code: string;\r\n    clientVersion: string;\r\n    meta?: Record<string, unknown>;\r\n    batchRequestIdx?: number;\r\n};\r\n\r\n/**\r\n * A pointer from the current {@link Span} to another span in the same trace or\r\n * in a different trace.\r\n * Few examples of Link usage.\r\n * 1. Batch Processing: A batch of elements may contain elements associated\r\n *    with one or more traces/spans. Since there can only be one parent\r\n *    SpanContext, Link is used to keep reference to SpanContext of all\r\n *    elements in the batch.\r\n * 2. Public Endpoint: A SpanContext in incoming client request on a public\r\n *    endpoint is untrusted from service provider perspective. In such case it\r\n *    is advisable to start a new trace with appropriate sampling decision.\r\n *    However, it is desirable to associate incoming SpanContext to new trace\r\n *    initiated on service provider side so two traces (from Client and from\r\n *    Service Provider) can be correlated.\r\n */\r\ndeclare interface Link {\r\n    /** The {@link SpanContext} of a linked span. */\r\n    context: SpanContext;\r\n    /** A set of {@link SpanAttributes} on the link. */\r\n    attributes?: SpanAttributes;\r\n    /** Count of attributes of the link that were dropped due to collection limits */\r\n    droppedAttributesCount?: number;\r\n}\r\n\r\ndeclare type LoadedEnv = {\r\n    message?: string;\r\n    parsed: {\r\n        [x: string]: string;\r\n    };\r\n} | undefined;\r\n\r\ndeclare type LocationInFile = {\r\n    fileName: string;\r\n    lineNumber: number | null;\r\n    columnNumber: number | null;\r\n};\r\n\r\ndeclare type LogDefinition = {\r\n    level: LogLevel;\r\n    emit: 'stdout' | 'event';\r\n};\r\n\r\n/**\r\n * Typings for the events we emit.\r\n *\r\n * @remarks\r\n * If this is updated, our edge runtime shim needs to be updated as well.\r\n */\r\ndeclare type LogEmitter = {\r\n    on<E extends EngineEventType>(event: E, listener: (event: EngineEvent<E>) => void): LogEmitter;\r\n    emit(event: QueryEventType, payload: QueryEvent): boolean;\r\n    emit(event: LogEventType, payload: LogEvent): boolean;\r\n};\r\n\r\ndeclare type LogEvent = {\r\n    timestamp: Date;\r\n    message: string;\r\n    target: string;\r\n};\r\n\r\ndeclare type LogEventType = 'info' | 'warn' | 'error';\r\n\r\ndeclare type LogLevel = 'info' | 'query' | 'warn' | 'error';\r\n\r\n/**\r\n * Generates more strict variant of an enum which, unlike regular enum,\r\n * throws on non-existing property access. This can be useful in following situations:\r\n * - we have an API, that accepts both `undefined` and `SomeEnumType` as an input\r\n * - enum values are generated dynamically from DMMF.\r\n *\r\n * In that case, if using normal enums and no compile-time typechecking, using non-existing property\r\n * will result in `undefined` value being used, which will be accepted. Using strict enum\r\n * in this case will help to have a runtime exception, telling you that you are probably doing something wrong.\r\n *\r\n * Note: if you need to check for existence of a value in the enum you can still use either\r\n * `in` operator or `hasOwnProperty` function.\r\n *\r\n * @param definition\r\n * @returns\r\n */\r\nexport declare function makeStrictEnum<T extends Record<PropertyKey, string | number>>(definition: T): T;\r\n\r\nexport declare function makeTypedQueryFactory(sql: string): (...values: any[]) => TypedSql<any[], unknown>;\r\n\r\ndeclare type MappedError = {\r\n    kind: 'GenericJs';\r\n    id: number;\r\n} | {\r\n    kind: 'UnsupportedNativeDataType';\r\n    type: string;\r\n} | {\r\n    kind: 'InvalidIsolationLevel';\r\n    level: string;\r\n} | {\r\n    kind: 'LengthMismatch';\r\n    column?: string;\r\n} | {\r\n    kind: 'UniqueConstraintViolation';\r\n    constraint?: {\r\n        fields: string[];\r\n    } | {\r\n        index: string;\r\n    } | {\r\n        foreignKey: {};\r\n    };\r\n} | {\r\n    kind: 'NullConstraintViolation';\r\n    constraint?: {\r\n        fields: string[];\r\n    } | {\r\n        index: string;\r\n    } | {\r\n        foreignKey: {};\r\n    };\r\n} | {\r\n    kind: 'ForeignKeyConstraintViolation';\r\n    constraint?: {\r\n        fields: string[];\r\n    } | {\r\n        index: string;\r\n    } | {\r\n        foreignKey: {};\r\n    };\r\n} | {\r\n    kind: 'DatabaseNotReachable';\r\n    host?: string;\r\n    port?: number;\r\n} | {\r\n    kind: 'DatabaseDoesNotExist';\r\n    db?: string;\r\n} | {\r\n    kind: 'DatabaseAlreadyExists';\r\n    db?: string;\r\n} | {\r\n    kind: 'DatabaseAccessDenied';\r\n    db?: string;\r\n} | {\r\n    kind: 'ConnectionClosed';\r\n} | {\r\n    kind: 'TlsConnectionError';\r\n    reason: string;\r\n} | {\r\n    kind: 'AuthenticationFailed';\r\n    user?: string;\r\n} | {\r\n    kind: 'TransactionWriteConflict';\r\n} | {\r\n    kind: 'TableDoesNotExist';\r\n    table?: string;\r\n} | {\r\n    kind: 'ColumnNotFound';\r\n    column?: string;\r\n} | {\r\n    kind: 'TooManyConnections';\r\n    cause: string;\r\n} | {\r\n    kind: 'ValueOutOfRange';\r\n    cause: string;\r\n} | {\r\n    kind: 'MissingFullTextSearchIndex';\r\n} | {\r\n    kind: 'SocketTimeout';\r\n} | {\r\n    kind: 'InconsistentColumnData';\r\n    cause: string;\r\n} | {\r\n    kind: 'TransactionAlreadyClosed';\r\n    cause: string;\r\n} | {\r\n    kind: 'postgres';\r\n    code: string;\r\n    severity: string;\r\n    message: string;\r\n    detail: string | undefined;\r\n    column: string | undefined;\r\n    hint: string | undefined;\r\n} | {\r\n    kind: 'mysql';\r\n    code: number;\r\n    message: string;\r\n    state: string;\r\n} | {\r\n    kind: 'sqlite';\r\n    /**\r\n     * Sqlite extended error code: https://www.sqlite.org/rescode.html\r\n     */\r\n    extendedCode: number;\r\n    message: string;\r\n} | {\r\n    kind: 'mssql';\r\n    code: number;\r\n    message: string;\r\n};\r\n\r\ndeclare type Mappings = ReadonlyDeep_2<{\r\n    modelOperations: ModelMapping[];\r\n    otherOperations: {\r\n        read: string[];\r\n        write: string[];\r\n    };\r\n}>;\r\n\r\n/**\r\n * Class that holds the list of all extensions, applied to particular instance,\r\n * as well as resolved versions of the components that need to apply on\r\n * different levels. Main idea of this class: avoid re-resolving as much of the\r\n * stuff as possible when new extensions are added while also delaying the\r\n * resolve until the point it is actually needed. For example, computed fields\r\n * of the model won't be resolved unless the model is actually queried. Neither\r\n * adding extensions with `client` component only cause other components to\r\n * recompute.\r\n */\r\ndeclare class MergedExtensionsList {\r\n    private head?;\r\n    private constructor();\r\n    static empty(): MergedExtensionsList;\r\n    static single(extension: ExtensionArgs): MergedExtensionsList;\r\n    isEmpty(): boolean;\r\n    append(extension: ExtensionArgs): MergedExtensionsList;\r\n    getAllComputedFields(dmmfModelName: string): ComputedFieldsMap | undefined;\r\n    getAllClientExtensions(): ClientArg | undefined;\r\n    getAllModelExtensions(dmmfModelName: string): ModelArg | undefined;\r\n    getAllQueryCallbacks(jsModelName: string, operation: string): any;\r\n    getAllBatchQueryCallbacks(): BatchQueryOptionsCb[];\r\n}\r\n\r\nexport declare type MergeExtArgs<TypeMap extends TypeMapDef, ExtArgs extends Record<any, any>, Args extends Record<any, any>> = ComputeDeep<ExtArgs & Args & AllModelsToStringIndex<TypeMap, Args, 'result'> & AllModelsToStringIndex<TypeMap, Args, 'model'>>;\r\n\r\nexport declare type Metric<T> = {\r\n    key: string;\r\n    value: T;\r\n    labels: Record<string, string>;\r\n    description: string;\r\n};\r\n\r\nexport declare type MetricHistogram = {\r\n    buckets: MetricHistogramBucket[];\r\n    sum: number;\r\n    count: number;\r\n};\r\n\r\nexport declare type MetricHistogramBucket = [maxValue: number, count: number];\r\n\r\nexport declare type Metrics = {\r\n    counters: Metric<number>[];\r\n    gauges: Metric<number>[];\r\n    histograms: Metric<MetricHistogram>[];\r\n};\r\n\r\nexport declare class MetricsClient {\r\n    private _client;\r\n    constructor(client: Client);\r\n    /**\r\n     * Returns all metrics gathered up to this point in prometheus format.\r\n     * Result of this call can be exposed directly to prometheus scraping endpoint\r\n     *\r\n     * @param options\r\n     * @returns\r\n     */\r\n    prometheus(options?: MetricsOptions): Promise<string>;\r\n    /**\r\n     * Returns all metrics gathered up to this point in prometheus format.\r\n     *\r\n     * @param options\r\n     * @returns\r\n     */\r\n    json(options?: MetricsOptions): Promise<Metrics>;\r\n}\r\n\r\ndeclare type MetricsOptions = {\r\n    /**\r\n     * Labels to add to every metrics in key-value format\r\n     */\r\n    globalLabels?: Record<string, string>;\r\n};\r\n\r\ndeclare type MetricsOptionsCommon = {\r\n    globalLabels?: Record<string, string>;\r\n};\r\n\r\ndeclare type MetricsOptionsJson = {\r\n    format: 'json';\r\n} & MetricsOptionsCommon;\r\n\r\ndeclare type MetricsOptionsPrometheus = {\r\n    format: 'prometheus';\r\n} & MetricsOptionsCommon;\r\n\r\ndeclare type MiddlewareArgsMapper<RequestArgs, MiddlewareArgs> = {\r\n    requestArgsToMiddlewareArgs(requestArgs: RequestArgs): MiddlewareArgs;\r\n    middlewareArgsToRequestArgs(middlewareArgs: MiddlewareArgs): RequestArgs;\r\n};\r\n\r\ndeclare type Model = ReadonlyDeep_2<{\r\n    name: string;\r\n    dbName: string | null;\r\n    schema: string | null;\r\n    fields: Field[];\r\n    uniqueFields: string[][];\r\n    uniqueIndexes: uniqueIndex[];\r\n    documentation?: string;\r\n    primaryKey: PrimaryKey | null;\r\n    isGenerated?: boolean;\r\n}>;\r\n\r\ndeclare enum ModelAction {\r\n    findUnique = \"findUnique\",\r\n    findUniqueOrThrow = \"findUniqueOrThrow\",\r\n    findFirst = \"findFirst\",\r\n    findFirstOrThrow = \"findFirstOrThrow\",\r\n    findMany = \"findMany\",\r\n    create = \"create\",\r\n    createMany = \"createMany\",\r\n    createManyAndReturn = \"createManyAndReturn\",\r\n    update = \"update\",\r\n    updateMany = \"updateMany\",\r\n    updateManyAndReturn = \"updateManyAndReturn\",\r\n    upsert = \"upsert\",\r\n    delete = \"delete\",\r\n    deleteMany = \"deleteMany\",\r\n    groupBy = \"groupBy\",\r\n    count = \"count\",// TODO: count does not actually exist in DMMF\r\n    aggregate = \"aggregate\",\r\n    findRaw = \"findRaw\",\r\n    aggregateRaw = \"aggregateRaw\"\r\n}\r\n\r\nexport declare type ModelArg = {\r\n    [MethodName in string]: unknown;\r\n};\r\n\r\nexport declare type ModelArgs = {\r\n    model: {\r\n        [ModelName in string]: ModelArg;\r\n    };\r\n};\r\n\r\nexport declare type ModelKey<TypeMap extends TypeMapDef, M extends PropertyKey> = M extends keyof TypeMap['model'] ? M : Capitalize<M & string>;\r\n\r\ndeclare type ModelMapping = ReadonlyDeep_2<{\r\n    model: string;\r\n    plural: string;\r\n    findUnique?: string | null;\r\n    findUniqueOrThrow?: string | null;\r\n    findFirst?: string | null;\r\n    findFirstOrThrow?: string | null;\r\n    findMany?: string | null;\r\n    create?: string | null;\r\n    createMany?: string | null;\r\n    createManyAndReturn?: string | null;\r\n    update?: string | null;\r\n    updateMany?: string | null;\r\n    updateManyAndReturn?: string | null;\r\n    upsert?: string | null;\r\n    delete?: string | null;\r\n    deleteMany?: string | null;\r\n    aggregate?: string | null;\r\n    groupBy?: string | null;\r\n    count?: string | null;\r\n    findRaw?: string | null;\r\n    aggregateRaw?: string | null;\r\n}>;\r\n\r\nexport declare type ModelQueryOptionsCb = (args: ModelQueryOptionsCbArgs) => Promise<any>;\r\n\r\nexport declare type ModelQueryOptionsCbArgs = {\r\n    model: string;\r\n    operation: string;\r\n    args: JsArgs;\r\n    query: (args: JsArgs) => Promise<unknown>;\r\n};\r\n\r\ndeclare type MultiBatchResponse = {\r\n    type: 'multi';\r\n    plans: QueryPlanNode[];\r\n};\r\n\r\nexport declare type NameArgs = {\r\n    name?: string;\r\n};\r\n\r\nexport declare type Narrow<A> = {\r\n    [K in keyof A]: A[K] extends Function ? A[K] : Narrow<A[K]>;\r\n} | (A extends Narrowable ? A : never);\r\n\r\nexport declare type Narrowable = string | number | bigint | boolean | [];\r\n\r\nexport declare type NeverToUnknown<T> = [T] extends [never] ? unknown : T;\r\n\r\ndeclare class NullTypesEnumValue extends ObjectEnumValue {\r\n    _getNamespace(): string;\r\n}\r\n\r\n/**\r\n * Base class for unique values of object-valued enums.\r\n */\r\nexport declare abstract class ObjectEnumValue {\r\n    constructor(arg?: symbol);\r\n    abstract _getNamespace(): string;\r\n    _getName(): string;\r\n    toString(): string;\r\n}\r\n\r\nexport declare const objectEnumValues: {\r\n    classes: {\r\n        DbNull: typeof DbNull;\r\n        JsonNull: typeof JsonNull;\r\n        AnyNull: typeof AnyNull;\r\n    };\r\n    instances: {\r\n        DbNull: DbNull;\r\n        JsonNull: JsonNull;\r\n        AnyNull: AnyNull;\r\n    };\r\n};\r\n\r\ndeclare const officialPrismaAdapters: readonly [\"@prisma/adapter-planetscale\", \"@prisma/adapter-neon\", \"@prisma/adapter-libsql\", \"@prisma/adapter-better-sqlite3\", \"@prisma/adapter-d1\", \"@prisma/adapter-pg\", \"@prisma/adapter-mssql\", \"@prisma/adapter-mariadb\"];\r\n\r\nexport declare type Omission = Record<string, boolean | Skip>;\r\n\r\ndeclare type Omit_2<T, K extends string | number | symbol> = {\r\n    [P in keyof T as P extends K ? never : P]: T[P];\r\n};\r\nexport { Omit_2 as Omit }\r\n\r\nexport declare type OmitValue<Omit, Key> = Key extends keyof Omit ? Omit[Key] : false;\r\n\r\nexport declare type Operation = 'findFirst' | 'findFirstOrThrow' | 'findUnique' | 'findUniqueOrThrow' | 'findMany' | 'create' | 'createMany' | 'createManyAndReturn' | 'update' | 'updateMany' | 'updateManyAndReturn' | 'upsert' | 'delete' | 'deleteMany' | 'aggregate' | 'count' | 'groupBy' | '$queryRaw' | '$executeRaw' | '$queryRawUnsafe' | '$executeRawUnsafe' | 'findRaw' | 'aggregateRaw' | '$runCommandRaw';\r\n\r\nexport declare type OperationPayload = {\r\n    name: string;\r\n    scalars: {\r\n        [ScalarName in string]: unknown;\r\n    };\r\n    objects: {\r\n        [ObjectName in string]: unknown;\r\n    };\r\n    composites: {\r\n        [CompositeName in string]: unknown;\r\n    };\r\n};\r\n\r\nexport declare type Optional<O, K extends keyof any = keyof O> = {\r\n    [P in K & keyof O]?: O[P];\r\n} & {\r\n    [P in Exclude<keyof O, K>]: O[P];\r\n};\r\n\r\nexport declare type OptionalFlat<T> = {\r\n    [K in keyof T]?: T[K];\r\n};\r\n\r\nexport declare type OptionalKeys<O> = {\r\n    [K in keyof O]-?: {} extends Pick_2<O, K> ? K : never;\r\n}[keyof O];\r\n\r\ndeclare type Options = {\r\n    /** Timeout for starting the transaction */\r\n    maxWait?: number;\r\n    /** Timeout for the transaction body */\r\n    timeout?: number;\r\n    /** Transaction isolation level */\r\n    isolationLevel?: IsolationLevel_2;\r\n};\r\n\r\ndeclare type Options_2 = {\r\n    clientVersion: string;\r\n};\r\n\r\nexport declare type Or<A extends 1 | 0, B extends 1 | 0> = {\r\n    0: {\r\n        0: 0;\r\n        1: 1;\r\n    };\r\n    1: {\r\n        0: 1;\r\n        1: 1;\r\n    };\r\n}[A][B];\r\n\r\ndeclare type OtherOperationMappings = ReadonlyDeep_2<{\r\n    read: string[];\r\n    write: string[];\r\n}>;\r\n\r\ndeclare type OutputType = ReadonlyDeep_2<{\r\n    name: string;\r\n    fields: SchemaField[];\r\n}>;\r\n\r\ndeclare type OutputTypeRef = TypeRef<'scalar' | 'outputObjectTypes' | 'enumTypes'>;\r\n\r\ndeclare type Pagination = {\r\n    cursor: Record<string, PrismaValue> | null;\r\n    take: number | null;\r\n    skip: number | null;\r\n};\r\n\r\nexport declare function Param<$Type, $Value extends string>(name: $Value): Param<$Type, $Value>;\r\n\r\nexport declare type Param<out $Type, $Value extends string> = {\r\n    readonly name: $Value;\r\n};\r\n\r\nexport declare type PatchFlat<O1, O2> = O1 & Omit_2<O2, keyof O1>;\r\n\r\nexport declare type Path<O, P, Default = never> = O extends unknown ? P extends [infer K, ...infer R] ? K extends keyof O ? Path<O[K], R> : Default : O : never;\r\n\r\nexport declare type Payload<T, F extends Operation = never> = T extends {\r\n    [K: symbol]: {\r\n        types: {\r\n            payload: any;\r\n        };\r\n    };\r\n} ? T[symbol]['types']['payload'] : any;\r\n\r\nexport declare type PayloadToResult<P, O extends Record_2<any, any> = RenameAndNestPayloadKeys<P>> = {\r\n    [K in keyof O]?: O[K][K] extends any[] ? PayloadToResult<O[K][K][number]>[] : O[K][K] extends object ? PayloadToResult<O[K][K]> : O[K][K];\r\n};\r\n\r\ndeclare type Pick_2<T, K extends string | number | symbol> = {\r\n    [P in keyof T as P extends K ? P : never]: T[P];\r\n};\r\nexport { Pick_2 as Pick }\r\n\r\ndeclare interface PlaceholderFormat {\r\n    prefix: string;\r\n    hasNumbering: boolean;\r\n}\r\n\r\ndeclare type PrimaryKey = ReadonlyDeep_2<{\r\n    name: string | null;\r\n    fields: string[];\r\n}>;\r\n\r\nexport declare class PrismaClientInitializationError extends Error {\r\n    clientVersion: string;\r\n    errorCode?: string;\r\n    retryable?: boolean;\r\n    constructor(message: string, clientVersion: string, errorCode?: string);\r\n    get [Symbol.toStringTag](): string;\r\n}\r\n\r\nexport declare class PrismaClientKnownRequestError extends Error implements ErrorWithBatchIndex {\r\n    code: string;\r\n    meta?: Record<string, unknown>;\r\n    clientVersion: string;\r\n    batchRequestIdx?: number;\r\n    constructor(message: string, { code, clientVersion, meta, batchRequestIdx }: KnownErrorParams);\r\n    get [Symbol.toStringTag](): string;\r\n}\r\n\r\nexport declare type PrismaClientOptions = {\r\n    /**\r\n     * Overwrites the primary datasource url from your schema.prisma file\r\n     */\r\n    datasourceUrl?: string;\r\n    /**\r\n     * Instance of a Driver Adapter, e.g., like one provided by `@prisma/adapter-planetscale.\r\n     */\r\n    adapter?: SqlDriverAdapterFactory | null;\r\n    /**\r\n     * Overwrites the datasource url from your schema.prisma file\r\n     */\r\n    datasources?: Datasources;\r\n    /**\r\n     * @default \"colorless\"\r\n     */\r\n    errorFormat?: ErrorFormat;\r\n    /**\r\n     * The default values for Transaction options\r\n     * maxWait ?= 2000\r\n     * timeout ?= 5000\r\n     */\r\n    transactionOptions?: Transaction_2.Options;\r\n    /**\r\n     * @example\r\n     * \\`\\`\\`\r\n     * // Defaults to stdout\r\n     * log: ['query', 'info', 'warn']\r\n     *\r\n     * // Emit as events\r\n     * log: [\r\n     *  { emit: 'stdout', level: 'query' },\r\n     *  { emit: 'stdout', level: 'info' },\r\n     *  { emit: 'stdout', level: 'warn' }\r\n     * ]\r\n     * \\`\\`\\`\r\n     * Read more in our [docs](https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-client/logging#the-log-option).\r\n     */\r\n    log?: Array<LogLevel | LogDefinition>;\r\n    omit?: GlobalOmitOptions;\r\n    /**\r\n     * @internal\r\n     * You probably don't want to use this. \\`__internal\\` is used by internal tooling.\r\n     */\r\n    __internal?: {\r\n        debug?: boolean;\r\n        engine?: {\r\n            cwd?: string;\r\n            binaryPath?: string;\r\n            endpoint?: string;\r\n            allowTriggerPanic?: boolean;\r\n        };\r\n        /** This can be used for testing purposes */\r\n        configOverride?: (config: GetPrismaClientConfig) => GetPrismaClientConfig;\r\n    };\r\n};\r\n\r\nexport declare class PrismaClientRustPanicError extends Error {\r\n    clientVersion: string;\r\n    constructor(message: string, clientVersion: string);\r\n    get [Symbol.toStringTag](): string;\r\n}\r\n\r\nexport declare class PrismaClientUnknownRequestError extends Error implements ErrorWithBatchIndex {\r\n    clientVersion: string;\r\n    batchRequestIdx?: number;\r\n    constructor(message: string, { clientVersion, batchRequestIdx }: UnknownErrorParams);\r\n    get [Symbol.toStringTag](): string;\r\n}\r\n\r\nexport declare class PrismaClientValidationError extends Error {\r\n    name: string;\r\n    clientVersion: string;\r\n    constructor(message: string, { clientVersion }: Options_2);\r\n    get [Symbol.toStringTag](): string;\r\n}\r\n\r\ndeclare function prismaGraphQLToJSError({ error, user_facing_error }: RequestError, clientVersion: string, activeProvider: string): PrismaClientKnownRequestError | PrismaClientUnknownRequestError;\r\n\r\ndeclare type PrismaOperationSpec<TArgs, TAction = string> = {\r\n    args: TArgs;\r\n    action: TAction;\r\n    model: string;\r\n};\r\n\r\nexport declare interface PrismaPromise<T> extends Promise<T> {\r\n    [Symbol.toStringTag]: 'PrismaPromise';\r\n}\r\n\r\n/**\r\n * Prisma's `Promise` that is backwards-compatible. All additions on top of the\r\n * original `Promise` are optional so that it can be backwards-compatible.\r\n * @see [[createPrismaPromise]]\r\n */\r\ndeclare interface PrismaPromise_2<TResult, TSpec extends PrismaOperationSpec<unknown> = any> extends Promise<TResult> {\r\n    get spec(): TSpec;\r\n    /**\r\n     * Extension of the original `.then` function\r\n     * @param onfulfilled same as regular promises\r\n     * @param onrejected same as regular promises\r\n     * @param transaction transaction options\r\n     */\r\n    then<R1 = TResult, R2 = never>(onfulfilled?: (value: TResult) => R1 | PromiseLike<R1>, onrejected?: (error: unknown) => R2 | PromiseLike<R2>, transaction?: PrismaPromiseTransaction): Promise<R1 | R2>;\r\n    /**\r\n     * Extension of the original `.catch` function\r\n     * @param onrejected same as regular promises\r\n     * @param transaction transaction options\r\n     */\r\n    catch<R = never>(onrejected?: ((reason: any) => R | PromiseLike<R>) | undefined | null, transaction?: PrismaPromiseTransaction): Promise<TResult | R>;\r\n    /**\r\n     * Extension of the original `.finally` function\r\n     * @param onfinally same as regular promises\r\n     * @param transaction transaction options\r\n     */\r\n    finally(onfinally?: (() => void) | undefined | null, transaction?: PrismaPromiseTransaction): Promise<TResult>;\r\n    /**\r\n     * Called when executing a batch of regular tx\r\n     * @param transaction transaction options for batch tx\r\n     */\r\n    requestTransaction?(transaction: PrismaPromiseBatchTransaction): PromiseLike<unknown>;\r\n}\r\n\r\ndeclare type PrismaPromiseBatchTransaction = {\r\n    kind: 'batch';\r\n    id: number;\r\n    isolationLevel?: IsolationLevel_2;\r\n    index: number;\r\n    lock: PromiseLike<void>;\r\n};\r\n\r\ndeclare type PrismaPromiseCallback = (transaction?: PrismaPromiseTransaction) => Promise<unknown>;\r\n\r\n/**\r\n * Creates a [[PrismaPromise]]. It is Prisma's implementation of `Promise` which\r\n * is essentially a proxy for `Promise`. All the transaction-compatible client\r\n * methods return one, this allows for pre-preparing queries without executing\r\n * them until `.then` is called. It's the foundation of Prisma's query batching.\r\n * @param callback that will be wrapped within our promise implementation\r\n * @see [[PrismaPromise]]\r\n * @returns\r\n */\r\ndeclare type PrismaPromiseFactory = <T extends PrismaOperationSpec<unknown>>(callback: PrismaPromiseCallback, op?: T) => PrismaPromise_2<unknown>;\r\n\r\ndeclare type PrismaPromiseInteractiveTransaction<PayloadType = unknown> = {\r\n    kind: 'itx';\r\n    id: string;\r\n    payload: PayloadType;\r\n};\r\n\r\ndeclare type PrismaPromiseTransaction<PayloadType = unknown> = PrismaPromiseBatchTransaction | PrismaPromiseInteractiveTransaction<PayloadType>;\r\n\r\ndeclare type PrismaValue = string | boolean | number | PrismaValue[] | null | Record<string, unknown> | PrismaValuePlaceholder | PrismaValueGenerator;\r\n\r\ndeclare type PrismaValueGenerator = {\r\n    prisma__type: 'generatorCall';\r\n    prisma__value: {\r\n        name: string;\r\n        args: PrismaValue[];\r\n    };\r\n};\r\n\r\ndeclare type PrismaValuePlaceholder = {\r\n    prisma__type: 'param';\r\n    prisma__value: {\r\n        name: string;\r\n        type: string;\r\n    };\r\n};\r\n\r\nexport declare const PrivateResultType: unique symbol;\r\n\r\ndeclare type Provider = 'mysql' | 'postgres' | 'sqlite' | 'sqlserver';\r\n\r\ndeclare namespace Public {\r\n    export {\r\n        validator\r\n    }\r\n}\r\nexport { Public }\r\n\r\ndeclare namespace Public_2 {\r\n    export {\r\n        Args,\r\n        Result,\r\n        Payload,\r\n        PrismaPromise,\r\n        Operation,\r\n        Exact\r\n    }\r\n}\r\n\r\ndeclare type Query = ReadonlyDeep_2<{\r\n    name: string;\r\n    args: SchemaArg[];\r\n    output: QueryOutput;\r\n}>;\r\n\r\ndeclare interface Queryable<Query, Result> extends AdapterInfo {\r\n    /**\r\n     * Execute a query and return its result.\r\n     */\r\n    queryRaw(params: Query): Promise<Result>;\r\n    /**\r\n     * Execute a query and return the number of affected rows.\r\n     */\r\n    executeRaw(params: Query): Promise<number>;\r\n}\r\n\r\ndeclare type QueryCompiler = {\r\n    compile(request: string): {};\r\n    compileBatch(batchRequest: string): BatchResponse;\r\n    free(): void;\r\n};\r\n\r\ndeclare interface QueryCompilerConstructor {\r\n    new (options: QueryCompilerOptions): QueryCompiler;\r\n}\r\n\r\ndeclare type QueryCompilerOptions = {\r\n    datamodel: string;\r\n    provider: Provider;\r\n    connectionInfo: ConnectionInfo;\r\n};\r\n\r\ndeclare type QueryEngineBatchGraphQLRequest = {\r\n    batch: QueryEngineRequest[];\r\n    transaction?: boolean;\r\n    isolationLevel?: IsolationLevel_2;\r\n};\r\n\r\ndeclare type QueryEngineBatchRequest = QueryEngineBatchGraphQLRequest | JsonBatchQuery;\r\n\r\ndeclare type QueryEngineConfig = {\r\n    datamodel: string;\r\n    configDir: string;\r\n    logQueries: boolean;\r\n    ignoreEnvVarErrors: boolean;\r\n    datasourceOverrides: Record<string, string>;\r\n    env: Record<string, string | undefined>;\r\n    logLevel: QueryEngineLogLevel;\r\n    engineProtocol: QueryEngineProtocol;\r\n    enableTracing: boolean;\r\n};\r\n\r\ndeclare interface QueryEngineConstructor {\r\n    new (config: QueryEngineConfig, logger: (log: string) => void, adapter?: ErrorCapturingSqlDriverAdapter): QueryEngineInstance;\r\n}\r\n\r\ndeclare type QueryEngineInstance = {\r\n    connect(headers: string, requestId: string): Promise<void>;\r\n    disconnect(headers: string, requestId: string): Promise<void>;\r\n    /**\r\n     * Frees any resources allocated by the engine's WASM instance. This method is automatically created by WASM bindgen.\r\n     * Noop for other engines.\r\n     */\r\n    free?(): void;\r\n    /**\r\n     * @param requestStr JSON.stringified `QueryEngineRequest | QueryEngineBatchRequest`\r\n     * @param headersStr JSON.stringified `QueryEngineRequestHeaders`\r\n     */\r\n    query(requestStr: string, headersStr: string, transactionId: string | undefined, requestId: string): Promise<string>;\r\n    sdlSchema?(): Promise<string>;\r\n    startTransaction(options: string, traceHeaders: string, requestId: string): Promise<string>;\r\n    commitTransaction(id: string, traceHeaders: string, requestId: string): Promise<string>;\r\n    rollbackTransaction(id: string, traceHeaders: string, requestId: string): Promise<string>;\r\n    metrics?(options: string): Promise<string>;\r\n    applyPendingMigrations?(): Promise<void>;\r\n    trace(requestId: string): Promise<string | null>;\r\n};\r\n\r\ndeclare type QueryEngineLogLevel = 'trace' | 'debug' | 'info' | 'warn' | 'error' | 'off';\r\n\r\ndeclare type QueryEngineProtocol = 'graphql' | 'json';\r\n\r\ndeclare type QueryEngineRequest = {\r\n    query: string;\r\n    variables: Object;\r\n};\r\n\r\ndeclare type QueryEngineResultData<T> = {\r\n    data: T;\r\n};\r\n\r\ndeclare type QueryEvent = {\r\n    timestamp: Date;\r\n    query: string;\r\n    params: string;\r\n    duration: number;\r\n    target: string;\r\n};\r\n\r\ndeclare type QueryEventType = 'query';\r\n\r\ndeclare type QueryIntrospectionBuiltinType = 'int' | 'bigint' | 'float' | 'double' | 'string' | 'enum' | 'bytes' | 'bool' | 'char' | 'decimal' | 'json' | 'xml' | 'uuid' | 'datetime' | 'date' | 'time' | 'int-array' | 'bigint-array' | 'float-array' | 'double-array' | 'string-array' | 'char-array' | 'bytes-array' | 'bool-array' | 'decimal-array' | 'json-array' | 'xml-array' | 'uuid-array' | 'datetime-array' | 'date-array' | 'time-array' | 'null' | 'unknown';\r\n\r\ndeclare type QueryMiddlewareParams = {\r\n    /** The model this is executed on */\r\n    model?: string;\r\n    /** The action that is being handled */\r\n    action: Action;\r\n    /** TODO what is this */\r\n    dataPath: string[];\r\n    /** TODO what is this */\r\n    runInTransaction: boolean;\r\n    args?: UserArgs_2;\r\n};\r\n\r\nexport declare type QueryOptions = {\r\n    query: {\r\n        [ModelName in string]: {\r\n            [ModelAction in string]: ModelQueryOptionsCb;\r\n        } | QueryOptionsCb;\r\n    };\r\n};\r\n\r\nexport declare type QueryOptionsCb = (args: QueryOptionsCbArgs) => Promise<any>;\r\n\r\nexport declare type QueryOptionsCbArgs = {\r\n    model?: string;\r\n    operation: string;\r\n    args: JsArgs | RawQueryArgs;\r\n    query: (args: JsArgs | RawQueryArgs) => Promise<unknown>;\r\n};\r\n\r\ndeclare type QueryOutput = ReadonlyDeep_2<{\r\n    name: string;\r\n    isRequired: boolean;\r\n    isList: boolean;\r\n}>;\r\n\r\ndeclare type QueryPlanBinding = {\r\n    name: string;\r\n    expr: QueryPlanNode;\r\n};\r\n\r\ndeclare type QueryPlanDbQuery = {\r\n    type: 'rawSql';\r\n    sql: string;\r\n    args: PrismaValue[];\r\n    argTypes: ArgType[];\r\n} | {\r\n    type: 'templateSql';\r\n    fragments: Fragment[];\r\n    placeholderFormat: PlaceholderFormat;\r\n    args: PrismaValue[];\r\n    argTypes: DynamicArgType[];\r\n    chunkable: boolean;\r\n};\r\n\r\ndeclare type QueryPlanNode = {\r\n    type: 'value';\r\n    args: PrismaValue;\r\n} | {\r\n    type: 'seq';\r\n    args: QueryPlanNode[];\r\n} | {\r\n    type: 'get';\r\n    args: {\r\n        name: string;\r\n    };\r\n} | {\r\n    type: 'let';\r\n    args: {\r\n        bindings: QueryPlanBinding[];\r\n        expr: QueryPlanNode;\r\n    };\r\n} | {\r\n    type: 'getFirstNonEmpty';\r\n    args: {\r\n        names: string[];\r\n    };\r\n} | {\r\n    type: 'query';\r\n    args: QueryPlanDbQuery;\r\n} | {\r\n    type: 'execute';\r\n    args: QueryPlanDbQuery;\r\n} | {\r\n    type: 'reverse';\r\n    args: QueryPlanNode;\r\n} | {\r\n    type: 'sum';\r\n    args: QueryPlanNode[];\r\n} | {\r\n    type: 'concat';\r\n    args: QueryPlanNode[];\r\n} | {\r\n    type: 'unique';\r\n    args: QueryPlanNode;\r\n} | {\r\n    type: 'required';\r\n    args: QueryPlanNode;\r\n} | {\r\n    type: 'join';\r\n    args: {\r\n        parent: QueryPlanNode;\r\n        children: JoinExpression[];\r\n    };\r\n} | {\r\n    type: 'mapField';\r\n    args: {\r\n        field: string;\r\n        records: QueryPlanNode;\r\n    };\r\n} | {\r\n    type: 'transaction';\r\n    args: QueryPlanNode;\r\n} | {\r\n    type: 'dataMap';\r\n    args: {\r\n        expr: QueryPlanNode;\r\n        structure: ResultNode;\r\n        enums: Record<string, Record<string, string>>;\r\n    };\r\n} | {\r\n    type: 'validate';\r\n    args: {\r\n        expr: QueryPlanNode;\r\n        rules: DataRule[];\r\n    } & ValidationError;\r\n} | {\r\n    type: 'if';\r\n    args: {\r\n        value: QueryPlanNode;\r\n        rule: DataRule;\r\n        then: QueryPlanNode;\r\n        else: QueryPlanNode;\r\n    };\r\n} | {\r\n    type: 'unit';\r\n} | {\r\n    type: 'diff';\r\n    args: {\r\n        from: QueryPlanNode;\r\n        to: QueryPlanNode;\r\n    };\r\n} | {\r\n    type: 'initializeRecord';\r\n    args: {\r\n        expr: QueryPlanNode;\r\n        fields: Record<string, FieldInitializer>;\r\n    };\r\n} | {\r\n    type: 'mapRecord';\r\n    args: {\r\n        expr: QueryPlanNode;\r\n        fields: Record<string, FieldOperation>;\r\n    };\r\n} | {\r\n    type: 'process';\r\n    args: {\r\n        expr: QueryPlanNode;\r\n        operations: InMemoryOps;\r\n    };\r\n};\r\n\r\n/**\r\n * Create raw SQL statement.\r\n */\r\nexport declare function raw(value: string): Sql;\r\n\r\nexport declare type RawParameters = {\r\n    __prismaRawParameters__: true;\r\n    values: string;\r\n};\r\n\r\nexport declare type RawQueryArgs = Sql | UnknownTypedSql | [query: string, ...values: RawValue[]];\r\n\r\ndeclare type RawResponse = {\r\n    columns: string[];\r\n    types: QueryIntrospectionBuiltinType[];\r\n    rows: unknown[][];\r\n};\r\n\r\ndeclare type RawTaggedValue = {\r\n    $type: 'Raw';\r\n    value: unknown;\r\n};\r\n\r\n/**\r\n * Supported value or SQL instance.\r\n */\r\nexport declare type RawValue = Value | Sql;\r\n\r\nexport declare type ReadonlyDeep<T> = {\r\n    readonly [K in keyof T]: ReadonlyDeep<T[K]>;\r\n};\r\n\r\ndeclare type ReadonlyDeep_2<O> = {\r\n    +readonly [K in keyof O]: ReadonlyDeep_2<O[K]>;\r\n};\r\n\r\ndeclare type Record_2<T extends string | number | symbol, U> = {\r\n    [P in T]: U;\r\n};\r\nexport { Record_2 as Record }\r\n\r\nexport declare type RenameAndNestPayloadKeys<P> = {\r\n    [K in keyof P as K extends 'scalars' | 'objects' | 'composites' ? keyof P[K] : never]: P[K];\r\n};\r\n\r\ndeclare type RequestBatchOptions<InteractiveTransactionPayload> = {\r\n    transaction?: TransactionOptions_2<InteractiveTransactionPayload>;\r\n    traceparent?: string;\r\n    numTry?: number;\r\n    containsWrite: boolean;\r\n    customDataProxyFetch?: AccelerateExtensionFetchDecorator;\r\n};\r\n\r\ndeclare interface RequestError {\r\n    error: string;\r\n    user_facing_error: {\r\n        is_panic: boolean;\r\n        message: string;\r\n        meta?: Record<string, unknown>;\r\n        error_code?: string;\r\n        batch_request_idx?: number;\r\n    };\r\n}\r\n\r\ndeclare class RequestHandler {\r\n    client: Client;\r\n    dataloader: DataLoader<RequestParams>;\r\n    private logEmitter?;\r\n    constructor(client: Client, logEmitter?: LogEmitter);\r\n    request(params: RequestParams): Promise<any>;\r\n    mapQueryEngineResult({ dataPath, unpacker }: RequestParams, response: QueryEngineResultData<any>): any;\r\n    /**\r\n     * Handles the error and logs it, logging the error is done synchronously waiting for the event\r\n     * handlers to finish.\r\n     */\r\n    handleAndLogRequestError(params: HandleErrorParams): never;\r\n    handleRequestError({ error, clientMethod, callsite, transaction, args, modelName, globalOmit, }: HandleErrorParams): never;\r\n    sanitizeMessage(message: any): any;\r\n    unpack(data: unknown, dataPath: string[], unpacker?: Unpacker): any;\r\n    get [Symbol.toStringTag](): string;\r\n}\r\n\r\ndeclare type RequestOptions<InteractiveTransactionPayload> = {\r\n    traceparent?: string;\r\n    numTry?: number;\r\n    interactiveTransaction?: InteractiveTransactionOptions<InteractiveTransactionPayload>;\r\n    isWrite: boolean;\r\n    customDataProxyFetch?: AccelerateExtensionFetchDecorator;\r\n};\r\n\r\ndeclare type RequestParams = {\r\n    modelName?: string;\r\n    action: Action;\r\n    protocolQuery: JsonQuery;\r\n    dataPath: string[];\r\n    clientMethod: string;\r\n    callsite?: CallSite;\r\n    transaction?: PrismaPromiseTransaction;\r\n    extensions: MergedExtensionsList;\r\n    args?: any;\r\n    headers?: Record<string, string>;\r\n    unpacker?: Unpacker;\r\n    otelParentCtx?: Context;\r\n    otelChildCtx?: Context;\r\n    globalOmit?: GlobalOmitOptions;\r\n    customDataProxyFetch?: AccelerateExtensionFetchDecorator;\r\n};\r\n\r\ndeclare type RequiredExtensionArgs = NameArgs & ResultArgs & ModelArgs & ClientArgs & QueryOptions;\r\nexport { RequiredExtensionArgs }\r\nexport { RequiredExtensionArgs as UserArgs }\r\n\r\nexport declare type RequiredKeys<O> = {\r\n    [K in keyof O]-?: {} extends Pick_2<O, K> ? never : K;\r\n}[keyof O];\r\n\r\ndeclare function resolveDatasourceUrl({ inlineDatasources, overrideDatasources, env, clientVersion, }: {\r\n    inlineDatasources: GetPrismaClientConfig['inlineDatasources'];\r\n    overrideDatasources: Datasources;\r\n    env: Record<string, string | undefined>;\r\n    clientVersion: string;\r\n}): string;\r\n\r\nexport declare type Result<T, A, F extends Operation> = T extends {\r\n    [K: symbol]: {\r\n        types: {\r\n            payload: any;\r\n        };\r\n    };\r\n} ? GetResult<T[symbol]['types']['payload'], A, F> : GetResult<{\r\n    composites: {};\r\n    objects: {};\r\n    scalars: {};\r\n    name: '';\r\n}, {}, F>;\r\n\r\nexport declare type Result_2<T, A, F extends Operation> = Result<T, A, F>;\r\n\r\ndeclare namespace Result_3 {\r\n    export {\r\n        Count,\r\n        GetFindResult,\r\n        SelectablePayloadFields,\r\n        SelectField,\r\n        DefaultSelection,\r\n        UnwrapPayload,\r\n        ApplyOmit,\r\n        OmitValue,\r\n        GetCountResult,\r\n        Aggregate,\r\n        GetAggregateResult,\r\n        GetBatchResult,\r\n        GetGroupByResult,\r\n        GetResult,\r\n        ExtractGlobalOmit\r\n    }\r\n}\r\n\r\ndeclare type Result_4<T> = {\r\n    map<U>(fn: (value: T) => U): Result_4<U>;\r\n    flatMap<U>(fn: (value: T) => Result_4<U>): Result_4<U>;\r\n} & ({\r\n    readonly ok: true;\r\n    readonly value: T;\r\n} | {\r\n    readonly ok: false;\r\n    readonly error: Error_2;\r\n});\r\n\r\nexport declare type ResultArg = {\r\n    [FieldName in string]: ResultFieldDefinition;\r\n};\r\n\r\nexport declare type ResultArgs = {\r\n    result: {\r\n        [ModelName in string]: ResultArg;\r\n    };\r\n};\r\n\r\nexport declare type ResultArgsFieldCompute = (model: any) => unknown;\r\n\r\nexport declare type ResultFieldDefinition = {\r\n    needs?: {\r\n        [FieldName in string]: boolean;\r\n    };\r\n    compute: ResultArgsFieldCompute;\r\n};\r\n\r\ndeclare type ResultNode = {\r\n    type: 'affectedRows';\r\n} | {\r\n    type: 'object';\r\n    fields: Record<string, ResultNode>;\r\n    serializedName: string | null;\r\n    skipNulls: boolean;\r\n} | {\r\n    type: 'field';\r\n    dbName: string;\r\n    fieldType: FieldType;\r\n};\r\n\r\nexport declare type Return<T> = T extends (...args: any[]) => infer R ? R : T;\r\n\r\nexport declare type RuntimeDataModel = {\r\n    readonly models: Record<string, RuntimeModel>;\r\n    readonly enums: Record<string, RuntimeEnum>;\r\n    readonly types: Record<string, RuntimeModel>;\r\n};\r\n\r\ndeclare type RuntimeEnum = Omit<DMMF_2.DatamodelEnum, 'name'>;\r\n\r\ndeclare type RuntimeModel = Omit<DMMF_2.Model, 'name'>;\r\n\r\ndeclare type RuntimeName = 'workerd' | 'deno' | 'netlify' | 'node' | 'bun' | 'edge-light' | '';\r\n\r\ndeclare type Schema = ReadonlyDeep_2<{\r\n    rootQueryType?: string;\r\n    rootMutationType?: string;\r\n    inputObjectTypes: {\r\n        model?: InputType[];\r\n        prisma?: InputType[];\r\n    };\r\n    outputObjectTypes: {\r\n        model: OutputType[];\r\n        prisma: OutputType[];\r\n    };\r\n    enumTypes: {\r\n        model?: SchemaEnum[];\r\n        prisma: SchemaEnum[];\r\n    };\r\n    fieldRefTypes: {\r\n        prisma?: FieldRefType[];\r\n    };\r\n}>;\r\n\r\ndeclare type SchemaArg = ReadonlyDeep_2<{\r\n    name: string;\r\n    comment?: string;\r\n    isNullable: boolean;\r\n    isRequired: boolean;\r\n    inputTypes: InputTypeRef[];\r\n    requiresOtherFields?: string[];\r\n    deprecation?: Deprecation;\r\n}>;\r\n\r\ndeclare type SchemaEnum = ReadonlyDeep_2<{\r\n    name: string;\r\n    values: string[];\r\n}>;\r\n\r\ndeclare type SchemaField = ReadonlyDeep_2<{\r\n    name: string;\r\n    isNullable?: boolean;\r\n    outputType: OutputTypeRef;\r\n    args: SchemaArg[];\r\n    deprecation?: Deprecation;\r\n    documentation?: string;\r\n}>;\r\n\r\nexport declare type Select<T, U> = T extends U ? T : never;\r\n\r\nexport declare type SelectablePayloadFields<K extends PropertyKey, O> = {\r\n    objects: {\r\n        [k in K]: O;\r\n    };\r\n} | {\r\n    composites: {\r\n        [k in K]: O;\r\n    };\r\n};\r\n\r\nexport declare type SelectField<P extends SelectablePayloadFields<any, any>, K extends PropertyKey> = P extends {\r\n    objects: Record<K, any>;\r\n} ? P['objects'][K] : P extends {\r\n    composites: Record<K, any>;\r\n} ? P['composites'][K] : never;\r\n\r\ndeclare type Selection_2 = Record<string, boolean | Skip | JsArgs>;\r\nexport { Selection_2 as Selection }\r\n\r\nexport declare function serializeJsonQuery({ modelName, action, args, runtimeDataModel, extensions, callsite, clientMethod, errorFormat, clientVersion, previewFeatures, globalOmit, }: SerializeParams): JsonQuery;\r\n\r\ndeclare type SerializeParams = {\r\n    runtimeDataModel: RuntimeDataModel;\r\n    modelName?: string;\r\n    action: Action;\r\n    args?: JsArgs;\r\n    extensions?: MergedExtensionsList;\r\n    callsite?: CallSite;\r\n    clientMethod: string;\r\n    clientVersion: string;\r\n    errorFormat: ErrorFormat;\r\n    previewFeatures: string[];\r\n    globalOmit?: GlobalOmitOptions;\r\n};\r\n\r\ndeclare class Skip {\r\n    constructor(param?: symbol);\r\n    ifUndefined<T>(value: T | undefined): T | Skip;\r\n}\r\n\r\nexport declare const skip: Skip;\r\n\r\ndeclare type SortOrder = 'asc' | 'desc';\r\n\r\n/**\r\n * An interface that represents a span. A span represents a single operation\r\n * within a trace. Examples of span might include remote procedure calls or a\r\n * in-process function calls to sub-components. A Trace has a single, top-level\r\n * \"root\" Span that in turn may have zero or more child Spans, which in turn\r\n * may have children.\r\n *\r\n * Spans are created by the {@link Tracer.startSpan} method.\r\n */\r\ndeclare interface Span {\r\n    /**\r\n     * Returns the {@link SpanContext} object associated with this Span.\r\n     *\r\n     * Get an immutable, serializable identifier for this span that can be used\r\n     * to create new child spans. Returned SpanContext is usable even after the\r\n     * span ends.\r\n     *\r\n     * @returns the SpanContext object associated with this Span.\r\n     */\r\n    spanContext(): SpanContext;\r\n    /**\r\n     * Sets an attribute to the span.\r\n     *\r\n     * Sets a single Attribute with the key and value passed as arguments.\r\n     *\r\n     * @param key the key for this attribute.\r\n     * @param value the value for this attribute. Setting a value null or\r\n     *              undefined is invalid and will result in undefined behavior.\r\n     */\r\n    setAttribute(key: string, value: SpanAttributeValue): this;\r\n    /**\r\n     * Sets attributes to the span.\r\n     *\r\n     * @param attributes the attributes that will be added.\r\n     *                   null or undefined attribute values\r\n     *                   are invalid and will result in undefined behavior.\r\n     */\r\n    setAttributes(attributes: SpanAttributes): this;\r\n    /**\r\n     * Adds an event to the Span.\r\n     *\r\n     * @param name the name of the event.\r\n     * @param [attributesOrStartTime] the attributes that will be added; these are\r\n     *     associated with this event. Can be also a start time\r\n     *     if type is {@type TimeInput} and 3rd param is undefined\r\n     * @param [startTime] start time of the event.\r\n     */\r\n    addEvent(name: string, attributesOrStartTime?: SpanAttributes | TimeInput, startTime?: TimeInput): this;\r\n    /**\r\n     * Adds a single link to the span.\r\n     *\r\n     * Links added after the creation will not affect the sampling decision.\r\n     * It is preferred span links be added at span creation.\r\n     *\r\n     * @param link the link to add.\r\n     */\r\n    addLink(link: Link): this;\r\n    /**\r\n     * Adds multiple links to the span.\r\n     *\r\n     * Links added after the creation will not affect the sampling decision.\r\n     * It is preferred span links be added at span creation.\r\n     *\r\n     * @param links the links to add.\r\n     */\r\n    addLinks(links: Link[]): this;\r\n    /**\r\n     * Sets a status to the span. If used, this will override the default Span\r\n     * status. Default is {@link SpanStatusCode.UNSET}. SetStatus overrides the value\r\n     * of previous calls to SetStatus on the Span.\r\n     *\r\n     * @param status the SpanStatus to set.\r\n     */\r\n    setStatus(status: SpanStatus): this;\r\n    /**\r\n     * Updates the Span name.\r\n     *\r\n     * This will override the name provided via {@link Tracer.startSpan}.\r\n     *\r\n     * Upon this update, any sampling behavior based on Span name will depend on\r\n     * the implementation.\r\n     *\r\n     * @param name the Span name.\r\n     */\r\n    updateName(name: string): this;\r\n    /**\r\n     * Marks the end of Span execution.\r\n     *\r\n     * Call to End of a Span MUST not have any effects on child spans. Those may\r\n     * still be running and can be ended later.\r\n     *\r\n     * Do not return `this`. The Span generally should not be used after it\r\n     * is ended so chaining is not desired in this context.\r\n     *\r\n     * @param [endTime] the time to set as Span's end time. If not provided,\r\n     *     use the current time as the span's end time.\r\n     */\r\n    end(endTime?: TimeInput): void;\r\n    /**\r\n     * Returns the flag whether this span will be recorded.\r\n     *\r\n     * @returns true if this Span is active and recording information like events\r\n     *     with the `AddEvent` operation and attributes using `setAttributes`.\r\n     */\r\n    isRecording(): boolean;\r\n    /**\r\n     * Sets exception as a span event\r\n     * @param exception the exception the only accepted values are string or Error\r\n     * @param [time] the time to set as Span's event time. If not provided,\r\n     *     use the current time.\r\n     */\r\n    recordException(exception: Exception, time?: TimeInput): void;\r\n}\r\n\r\n/**\r\n * @deprecated please use {@link Attributes}\r\n */\r\ndeclare type SpanAttributes = Attributes;\r\n\r\n/**\r\n * @deprecated please use {@link AttributeValue}\r\n */\r\ndeclare type SpanAttributeValue = AttributeValue;\r\n\r\ndeclare type SpanCallback<R> = (span?: Span, context?: Context) => R;\r\n\r\n/**\r\n * A SpanContext represents the portion of a {@link Span} which must be\r\n * serialized and propagated along side of a {@link Baggage}.\r\n */\r\ndeclare interface SpanContext {\r\n    /**\r\n     * The ID of the trace that this span belongs to. It is worldwide unique\r\n     * with practically sufficient probability by being made as 16 randomly\r\n     * generated bytes, encoded as a 32 lowercase hex characters corresponding to\r\n     * 128 bits.\r\n     */\r\n    traceId: string;\r\n    /**\r\n     * The ID of the Span. It is globally unique with practically sufficient\r\n     * probability by being made as 8 randomly generated bytes, encoded as a 16\r\n     * lowercase hex characters corresponding to 64 bits.\r\n     */\r\n    spanId: string;\r\n    /**\r\n     * Only true if the SpanContext was propagated from a remote parent.\r\n     */\r\n    isRemote?: boolean;\r\n    /**\r\n     * Trace flags to propagate.\r\n     *\r\n     * It is represented as 1 byte (bitmap). Bit to represent whether trace is\r\n     * sampled or not. When set, the least significant bit documents that the\r\n     * caller may have recorded trace data. A caller who does not record trace\r\n     * data out-of-band leaves this flag unset.\r\n     *\r\n     * see {@link TraceFlags} for valid flag values.\r\n     */\r\n    traceFlags: number;\r\n    /**\r\n     * Tracing-system-specific info to propagate.\r\n     *\r\n     * The tracestate field value is a `list` as defined below. The `list` is a\r\n     * series of `list-members` separated by commas `,`, and a list-member is a\r\n     * key/value pair separated by an equals sign `=`. Spaces and horizontal tabs\r\n     * surrounding `list-members` are ignored. There can be a maximum of 32\r\n     * `list-members` in a `list`.\r\n     * More Info: https://www.w3.org/TR/trace-context/#tracestate-field\r\n     *\r\n     * Examples:\r\n     *     Single tracing system (generic format):\r\n     *         tracestate: rojo=00f067aa0ba902b7\r\n     *     Multiple tracing systems (with different formatting):\r\n     *         tracestate: rojo=00f067aa0ba902b7,congo=t61rcWkgMzE\r\n     */\r\n    traceState?: TraceState;\r\n}\r\n\r\ndeclare enum SpanKind {\r\n    /** Default value. Indicates that the span is used internally. */\r\n    INTERNAL = 0,\r\n    /**\r\n     * Indicates that the span covers server-side handling of an RPC or other\r\n     * remote request.\r\n     */\r\n    SERVER = 1,\r\n    /**\r\n     * Indicates that the span covers the client-side wrapper around an RPC or\r\n     * other remote request.\r\n     */\r\n    CLIENT = 2,\r\n    /**\r\n     * Indicates that the span describes producer sending a message to a\r\n     * broker. Unlike client and server, there is no direct critical path latency\r\n     * relationship between producer and consumer spans.\r\n     */\r\n    PRODUCER = 3,\r\n    /**\r\n     * Indicates that the span describes consumer receiving a message from a\r\n     * broker. Unlike client and server, there is no direct critical path latency\r\n     * relationship between producer and consumer spans.\r\n     */\r\n    CONSUMER = 4\r\n}\r\n\r\n/**\r\n * Options needed for span creation\r\n */\r\ndeclare interface SpanOptions {\r\n    /**\r\n     * The SpanKind of a span\r\n     * @default {@link SpanKind.INTERNAL}\r\n     */\r\n    kind?: SpanKind;\r\n    /** A span's attributes */\r\n    attributes?: SpanAttributes;\r\n    /** {@link Link}s span to other spans */\r\n    links?: Link[];\r\n    /** A manually specified start time for the created `Span` object. */\r\n    startTime?: TimeInput;\r\n    /** The new span should be a root span. (Ignore parent from context). */\r\n    root?: boolean;\r\n}\r\n\r\ndeclare interface SpanStatus {\r\n    /** The status code of this message. */\r\n    code: SpanStatusCode;\r\n    /** A developer-facing error message. */\r\n    message?: string;\r\n}\r\n\r\n/**\r\n * An enumeration of status codes.\r\n */\r\ndeclare enum SpanStatusCode {\r\n    /**\r\n     * The default status.\r\n     */\r\n    UNSET = 0,\r\n    /**\r\n     * The operation has been validated by an Application developer or\r\n     * Operator to have completed successfully.\r\n     */\r\n    OK = 1,\r\n    /**\r\n     * The operation contains an error.\r\n     */\r\n    ERROR = 2\r\n}\r\n\r\n/**\r\n * A SQL instance can be nested within each other to build SQL strings.\r\n */\r\nexport declare class Sql {\r\n    readonly values: Value[];\r\n    readonly strings: string[];\r\n    constructor(rawStrings: readonly string[], rawValues: readonly RawValue[]);\r\n    get sql(): string;\r\n    get statement(): string;\r\n    get text(): string;\r\n    inspect(): {\r\n        sql: string;\r\n        statement: string;\r\n        text: string;\r\n        values: unknown[];\r\n    };\r\n}\r\n\r\ndeclare interface SqlDriverAdapter extends SqlQueryable {\r\n    /**\r\n     * Execute multiple SQL statements separated by semicolon.\r\n     */\r\n    executeScript(script: string): Promise<void>;\r\n    /**\r\n     * Start new transaction.\r\n     */\r\n    startTransaction(isolationLevel?: IsolationLevel): Promise<Transaction>;\r\n    /**\r\n     * Optional method that returns extra connection info\r\n     */\r\n    getConnectionInfo?(): ConnectionInfo;\r\n    /**\r\n     * Dispose of the connection and release any resources.\r\n     */\r\n    dispose(): Promise<void>;\r\n}\r\n\r\nexport declare interface SqlDriverAdapterFactory extends DriverAdapterFactory<SqlQuery, SqlResultSet> {\r\n    connect(): Promise<SqlDriverAdapter>;\r\n}\r\n\r\ndeclare type SqlQuery = {\r\n    sql: string;\r\n    args: Array<unknown>;\r\n    argTypes: Array<ArgType>;\r\n};\r\n\r\ndeclare interface SqlQueryable extends Queryable<SqlQuery, SqlResultSet> {\r\n}\r\n\r\ndeclare interface SqlResultSet {\r\n    /**\r\n     * List of column types appearing in a database query, in the same order as `columnNames`.\r\n     * They are used within the Query Engine to convert values from JS to Quaint values.\r\n     */\r\n    columnTypes: Array<ColumnType>;\r\n    /**\r\n     * List of column names appearing in a database query, in the same order as `columnTypes`.\r\n     */\r\n    columnNames: Array<string>;\r\n    /**\r\n     * List of rows retrieved from a database query.\r\n     * Each row is a list of values, whose length matches `columnNames` and `columnTypes`.\r\n     */\r\n    rows: Array<Array<unknown>>;\r\n    /**\r\n     * The last ID of an `INSERT` statement, if any.\r\n     * This is required for `AUTO_INCREMENT` columns in databases based on MySQL and SQLite.\r\n     */\r\n    lastInsertId?: string;\r\n}\r\n\r\n/**\r\n * Create a SQL object from a template string.\r\n */\r\nexport declare function sqltag(strings: readonly string[], ...values: readonly RawValue[]): Sql;\r\n\r\n/**\r\n * Defines TimeInput.\r\n *\r\n * hrtime, epoch milliseconds, performance.now() or Date\r\n */\r\ndeclare type TimeInput = HrTime_2 | number | Date;\r\n\r\nexport declare type ToTuple<T> = T extends any[] ? T : [T];\r\n\r\ndeclare interface TraceState {\r\n    /**\r\n     * Create a new TraceState which inherits from this TraceState and has the\r\n     * given key set.\r\n     * The new entry will always be added in the front of the list of states.\r\n     *\r\n     * @param key key of the TraceState entry.\r\n     * @param value value of the TraceState entry.\r\n     */\r\n    set(key: string, value: string): TraceState;\r\n    /**\r\n     * Return a new TraceState which inherits from this TraceState but does not\r\n     * contain the given key.\r\n     *\r\n     * @param key the key for the TraceState entry to be removed.\r\n     */\r\n    unset(key: string): TraceState;\r\n    /**\r\n     * Returns the value to which the specified key is mapped, or `undefined` if\r\n     * this map contains no mapping for the key.\r\n     *\r\n     * @param key with which the specified value is to be associated.\r\n     * @returns the value to which the specified key is mapped, or `undefined` if\r\n     *     this map contains no mapping for the key.\r\n     */\r\n    get(key: string): string | undefined;\r\n    /**\r\n     * Serializes the TraceState to a `list` as defined below. The `list` is a\r\n     * series of `list-members` separated by commas `,`, and a list-member is a\r\n     * key/value pair separated by an equals sign `=`. Spaces and horizontal tabs\r\n     * surrounding `list-members` are ignored. There can be a maximum of 32\r\n     * `list-members` in a `list`.\r\n     *\r\n     * @returns the serialized string.\r\n     */\r\n    serialize(): string;\r\n}\r\n\r\ndeclare interface TracingHelper {\r\n    isEnabled(): boolean;\r\n    getTraceParent(context?: Context): string;\r\n    dispatchEngineSpans(spans: EngineSpan[]): void;\r\n    getActiveContext(): Context | undefined;\r\n    runInChildSpan<R>(nameOrOptions: string | ExtendedSpanOptions, callback: SpanCallback<R>): R;\r\n}\r\n\r\ndeclare interface Transaction extends AdapterInfo, SqlQueryable {\r\n    /**\r\n     * Transaction options.\r\n     */\r\n    readonly options: TransactionOptions;\r\n    /**\r\n     * Commit the transaction.\r\n     */\r\n    commit(): Promise<void>;\r\n    /**\r\n     * Roll back the transaction.\r\n     */\r\n    rollback(): Promise<void>;\r\n}\r\n\r\ndeclare namespace Transaction_2 {\r\n    export {\r\n        Options,\r\n        IsolationLevel_2 as IsolationLevel,\r\n        InteractiveTransactionInfo,\r\n        TransactionHeaders\r\n    }\r\n}\r\n\r\ndeclare type TransactionHeaders = {\r\n    traceparent?: string;\r\n};\r\n\r\ndeclare type TransactionOptions = {\r\n    usePhantomQuery: boolean;\r\n};\r\n\r\ndeclare type TransactionOptions_2<InteractiveTransactionPayload> = {\r\n    kind: 'itx';\r\n    options: InteractiveTransactionOptions<InteractiveTransactionPayload>;\r\n} | {\r\n    kind: 'batch';\r\n    options: BatchTransactionOptions;\r\n};\r\n\r\nexport declare class TypedSql<Values extends readonly unknown[], Result> {\r\n    [PrivateResultType]: Result;\r\n    constructor(sql: string, values: Values);\r\n    get sql(): string;\r\n    get values(): Values;\r\n}\r\n\r\nexport declare type TypeMapCbDef = Fn<{\r\n    extArgs: InternalArgs;\r\n}, TypeMapDef>;\r\n\r\n/** Shared */\r\nexport declare type TypeMapDef = Record<any, any>;\r\n\r\ndeclare type TypeRef<AllowedLocations extends FieldLocation> = {\r\n    isList: boolean;\r\n    type: string;\r\n    location: AllowedLocations;\r\n    namespace?: FieldNamespace;\r\n};\r\n\r\ndeclare namespace Types {\r\n    export {\r\n        Result_3 as Result,\r\n        Extensions_2 as Extensions,\r\n        Utils,\r\n        Public_2 as Public,\r\n        isSkip,\r\n        Skip,\r\n        skip,\r\n        UnknownTypedSql,\r\n        OperationPayload as Payload\r\n    }\r\n}\r\nexport { Types }\r\n\r\ndeclare type uniqueIndex = ReadonlyDeep_2<{\r\n    name: string;\r\n    fields: string[];\r\n}>;\r\n\r\ndeclare type UnknownErrorParams = {\r\n    clientVersion: string;\r\n    batchRequestIdx?: number;\r\n};\r\n\r\nexport declare type UnknownTypedSql = TypedSql<unknown[], unknown>;\r\n\r\ndeclare type Unpacker = (data: any) => any;\r\n\r\nexport declare type UnwrapPayload<P> = {} extends P ? unknown : {\r\n    [K in keyof P]: P[K] extends {\r\n        scalars: infer S;\r\n        composites: infer C;\r\n    }[] ? Array<S & UnwrapPayload<C>> : P[K] extends {\r\n        scalars: infer S;\r\n        composites: infer C;\r\n    } | null ? S & UnwrapPayload<C> | Select<P[K], null> : never;\r\n};\r\n\r\nexport declare type UnwrapPromise<P> = P extends Promise<infer R> ? R : P;\r\n\r\nexport declare type UnwrapTuple<Tuple extends readonly unknown[]> = {\r\n    [K in keyof Tuple]: K extends `${number}` ? Tuple[K] extends PrismaPromise<infer X> ? X : UnwrapPromise<Tuple[K]> : UnwrapPromise<Tuple[K]>;\r\n};\r\n\r\n/**\r\n * Input that flows from the user into the Client.\r\n */\r\ndeclare type UserArgs_2 = any;\r\n\r\ndeclare namespace Utils {\r\n    export {\r\n        EmptyToUnknown,\r\n        NeverToUnknown,\r\n        PatchFlat,\r\n        Omit_2 as Omit,\r\n        Pick_2 as Pick,\r\n        ComputeDeep,\r\n        Compute,\r\n        OptionalFlat,\r\n        ReadonlyDeep,\r\n        Narrowable,\r\n        Narrow,\r\n        Exact,\r\n        Cast,\r\n        Record_2 as Record,\r\n        UnwrapPromise,\r\n        UnwrapTuple,\r\n        Path,\r\n        Fn,\r\n        Call,\r\n        RequiredKeys,\r\n        OptionalKeys,\r\n        Optional,\r\n        Return,\r\n        ToTuple,\r\n        RenameAndNestPayloadKeys,\r\n        PayloadToResult,\r\n        Select,\r\n        Equals,\r\n        Or,\r\n        JsPromise\r\n    }\r\n}\r\n\r\ndeclare type ValidationError = {\r\n    error_identifier: 'RELATION_VIOLATION';\r\n    context: {\r\n        relation: string;\r\n        modelA: string;\r\n        modelB: string;\r\n    };\r\n} | {\r\n    error_identifier: 'MISSING_RELATED_RECORD';\r\n    context: {\r\n        model: string;\r\n        relation: string;\r\n        relationType: string;\r\n        operation: string;\r\n        neededFor?: string;\r\n    };\r\n} | {\r\n    error_identifier: 'MISSING_RECORD';\r\n    context: {\r\n        operation: string;\r\n    };\r\n} | {\r\n    error_identifier: 'INCOMPLETE_CONNECT_INPUT';\r\n    context: {\r\n        expectedRows: number;\r\n    };\r\n} | {\r\n    error_identifier: 'INCOMPLETE_CONNECT_OUTPUT';\r\n    context: {\r\n        expectedRows: number;\r\n        relation: string;\r\n        relationType: string;\r\n    };\r\n} | {\r\n    error_identifier: 'RECORDS_NOT_CONNECTED';\r\n    context: {\r\n        relation: string;\r\n        parent: string;\r\n        child: string;\r\n    };\r\n};\r\n\r\ndeclare function validator<V>(): <S>(select: Exact<S, V>) => S;\r\n\r\ndeclare function validator<C, M extends Exclude<keyof C, `$${string}`>, O extends keyof C[M] & Operation>(client: C, model: M, operation: O): <S>(select: Exact<S, Args<C[M], O>>) => S;\r\n\r\ndeclare function validator<C, M extends Exclude<keyof C, `$${string}`>, O extends keyof C[M] & Operation, P extends keyof Args<C[M], O>>(client: C, model: M, operation: O, prop: P): <S>(select: Exact<S, Args<C[M], O>[P]>) => S;\r\n\r\n/**\r\n * Values supported by SQL engine.\r\n */\r\nexport declare type Value = unknown;\r\n\r\nexport declare function warnEnvConflicts(envPaths: any): void;\r\n\r\nexport declare const warnOnce: (key: string, message: string, ...args: unknown[]) => void;\r\n\r\nexport { }\r\n","node_modules/.prisma/client/wasm.d.ts":"export * from \"./index\"","node_modules/@prisma/client/index.d.ts":"export * from '.prisma/client/default'"},"document":"# Prisma Markdown\n\n> Generated by [`prisma-markdown`](https://github.com/samchon/prisma-markdown)\n\n- [Systematic](#systematic)\n- [Actors](#actors)\n- [Crawling](#crawling)\n- [Storage](#storage)\n- [Processing](#processing)\n- [Popularity](#popularity)\n- [API](#api)\n- [Alerts](#alerts)\n\n## Systematic\n\n```mermaid\nerDiagram\n\"political_news_crawler_crawl_sources\" {\n  String id PK\n  String source_code UK\n  String(80000) source_url UK\n  Boolean is_active\n  String description \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_crawl_policies\" {\n  String id PK\n  String policy_name UK\n  Int max_crawl_frequency_minutes\n  Int max_retry_attempts\n  Float backoff_multiplier\n  Boolean ban_detection_enabled\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_crawl_schedules\" {\n  String id PK\n  String crawl_source_id FK\n  String crawl_policy_id FK\n  String schedule_expression\n  DateTime last_crawled_at \"nullable\"\n  DateTime next_crawl_at \"nullable\"\n  Boolean is_enabled\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_crawl_schedules\" }o--|| \"political_news_crawler_crawl_sources\" : crawlSource\n\"political_news_crawler_crawl_schedules\" }o--|| \"political_news_crawler_crawl_policies\" : crawlPolicy\n```\n\n### `political_news_crawler_crawl_sources`\n\nRepresents political news crawling sources configuration. Contains source\nURLs, status, and metadata for controlling crawl initiation and\nprocessing. Used to manage diverse data feed points for\npoliticalNewsCrawler.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `source_code`: Unique identifier code for the crawl source.\n- `source_url`: The base URL of the crawl source website or API.\n- `is_active`\n  > Flag indicating whether the crawl source is active and enabled for\n  > crawling.\n- `description`: Optional description of the crawl source.\n- `created_at`: Record creation timestamp.\n- `updated_at`: Record last update timestamp.\n- `deleted_at`: Soft delete timestamp, if record is deleted.\n\n### `political_news_crawler_crawl_policies`\n\nConfiguration for crawl policies governing crawling frequency, retry, and\nerror handling for political news sources. Ensures adaptive and\nrespectful crawling behavior according to source limits and bans.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `policy_name`: Unique name identifier for the crawl policy.\n- `max_crawl_frequency_minutes`: Maximum allowed crawl frequency in minutes.\n- `max_retry_attempts`: Maximum number of retry attempts after failures.\n- `backoff_multiplier`: Multiplier factor for exponential backoff on retries.\n- `ban_detection_enabled`: Flag to enable detection and handling of bans during crawling.\n- `created_at`: Record creation timestamp.\n- `updated_at`: Record last update timestamp.\n- `deleted_at`: Soft delete timestamp, if record is deleted.\n\n### `political_news_crawler_crawl_schedules`\n\nSchedules defining when and how often crawling runs for each political\nnews source. References the crawl source and policy to enable adaptive\nscheduling and coordination.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `crawl_source_id`\n  > Reference to Crawling Source. {@link\n  > political_news_crawler_crawl_sources.id}\n- `crawl_policy_id`\n  > Reference to Crawl Policy. {@link\n  > political_news_crawler_crawl_policies.id}\n- `schedule_expression`: Cron expression defining the crawl schedule timing.\n- `last_crawled_at`: Timestamp when the crawl last occurred.\n- `next_crawl_at`: Timestamp for the next scheduled crawl.\n- `is_enabled`: Flag indicating if this schedule is enabled.\n- `created_at`: Record creation timestamp.\n- `updated_at`: Record last update timestamp.\n- `deleted_at`: Soft delete timestamp, if record is deleted.\n\n## Actors\n\n```mermaid\nerDiagram\n\"political_news_crawler_guests\" {\n  String id PK\n  String ip_address\n  String user_agent \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n```\n\n### `political_news_crawler_guests`\n\nStores political news crawler guest user information representing\nunauthenticated users accessing APIs. Captures identification via IP and\nuser agent, includes timestamps for auditing and soft deletion support.\nGuests are limited to read-only access with no password or login\ncredentials.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `ip_address`: IP address of the guest user.\n- `user_agent`: User agent string presented by the guest.\n- `created_at`: Timestamp when the guest record was created.\n- `updated_at`: Timestamp when the guest record was last updated.\n- `deleted_at`: Timestamp of soft deletion for the guest record.\n\n## Crawling\n\n```mermaid\nerDiagram\n\"political_news_crawler_crawl_jobs\" {\n  String id PK\n  String crawl_source_id FK\n  String crawl_schedule_id FK\n  Boolean active\n  DateTime last_run_started_at \"nullable\"\n  DateTime last_run_completed_at \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_crawl_attempts\" {\n  String id PK\n  String crawl_job_id FK\n  String raw_data_storage_id FK \"nullable\"\n  DateTime started_at\n  DateTime completed_at \"nullable\"\n  Boolean success\n  String error_message \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_crawled_news\" {\n  String id PK\n  String crawl_attempt_id FK\n  String url UK\n  String title \"nullable\"\n  DateTime published_at \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_crawl_attempts\" }o--|| \"political_news_crawler_crawl_jobs\" : crawlJob\n\"political_news_crawler_crawled_news\" }o--|| \"political_news_crawler_crawl_attempts\" : crawlAttempt\n```\n\n### `political_news_crawler_crawl_jobs`\n\nRepresents scheduled crawling jobs assigned to specific crawl sources and\nschedules, managing operational parameters and state for recurring\npolitical news retrieval tasks.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `crawl_source_id`\n  > Referenced crawl source identifier. {@link\n  > political_news_crawler_crawl_sources.id}\n- `crawl_schedule_id`\n  > Referenced crawl schedule identifier. {@link\n  > political_news_crawler_crawl_schedules.id}\n- `active`: Flag indicating if this crawl job is active and scheduled to run.\n- `last_run_started_at`: Timestamp when the last run of the crawl job started, null if never run.\n- `last_run_completed_at`\n  > Timestamp when the last run of the crawl job completed, null if still\n  > running or never run.\n- `created_at`: Record creation timestamp.\n- `updated_at`: Record last update timestamp.\n- `deleted_at`: Soft deletion timestamp, if set the job is considered deleted and ignored.\n\n### `political_news_crawler_crawl_attempts`\n\nRecords individual execution attempts of crawl jobs, tracking start and\ncompletion times, success status, errors, and associated raw data\nreferences to enable detailed auditing and failure analysis.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `crawl_job_id`\n  > Associated crawl job identifier. {@link\n  > political_news_crawler_crawl_jobs.id}\n- `raw_data_storage_id`\n  > Reference to raw data storage entry for the crawl result. {@link\n  > political_news_crawler_raw_data_storage.id}\n- `started_at`: Timestamp when this crawl attempt started.\n- `completed_at`: Timestamp when this crawl attempt ended; null if still running.\n- `success`: Indicator whether this crawl attempt was successful.\n- `error_message`: Error message details if the crawl attempt failed.\n- `created_at`: Record creation timestamp.\n- `updated_at`: Record last update timestamp.\n\n### `political_news_crawler_crawled_news`\n\nContains metadata for crawled political news articles, linking to the\ncrawl attempt that obtained the raw content and providing key attributes\nfor management and filtering.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `crawl_attempt_id`\n  > Associated crawl attempt identifier. {@link\n  > political_news_crawler_crawl_attempts.id}\n- `url`: URL of the crawled news article.\n- `title`: Title of the news article, if available.\n- `published_at`: Publish timestamp of the news article, if known.\n- `created_at`: Record creation timestamp.\n- `updated_at`: Record last update timestamp.\n\n## Storage\n\n```mermaid\nerDiagram\n\"political_news_crawler_raw_data_storage\" {\n  String id PK\n  String crawl_source_id FK\n  String crawl_job_id FK \"nullable\"\n  String storage_key UK\n  String file_format\n  Int file_size_bytes\n  String checksum \"nullable\"\n  DateTime crawl_timestamp\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_local_cache_files\" {\n  String id PK\n  String raw_data_storage_id FK\n  String local_file_path UK\n  Int file_size_bytes\n  DateTime ttl_expiration_at\n  DateTime deleted_at \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_processed_content\" {\n  String id PK\n  String raw_data_storage_id FK\n  String llm_job_id FK \"nullable\"\n  String content_type\n  String content_body\n  DateTime generation_timestamp\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_local_cache_files\" }o--|| \"political_news_crawler_raw_data_storage\" : rawDataStorage\n\"political_news_crawler_processed_content\" }o--|| \"political_news_crawler_raw_data_storage\" : rawDataStorage\n```\n\n### `political_news_crawler_raw_data_storage`\n\nStores metadata and references for raw political news data collected from\nvarious crawling sources. Ensures durable and consistent storage links to\ncloud object storage. Tracks source information, crawl job association,\nand data integrity validations. Includes audit timestamps for\ntraceability.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `crawl_source_id`: Belonged crawl source's political_news_crawler_crawl_sources.id.\n- `crawl_job_id`: Optional crawl job reference to political_news_crawler_crawl_jobs.id.\n- `storage_key`\n  > Unique key or path identifying storage location in cloud object storage\n  > (e.g., GCP or AWS S3).\n- `file_format`\n  > Format of the raw data file such as JSON or XML for processing\n  > compatibility.\n- `file_size_bytes`: Size of the raw data file in bytes.\n- `checksum`: Checksum hash to verify file integrity.\n- `crawl_timestamp`\n  > Timestamp when the raw data was crawled, used for data freshness and\n  > scheduling.\n- `created_at`: Creation timestamp record.\n- `updated_at`: Last update timestamp record.\n\n### `political_news_crawler_local_cache_files`\n\nTracks local file cache copies of raw crawled political news data with\nTTL enforcement and deletion status. Enables fast retrieval during cloud\nstorage outages and manages file lifecycle with audit timestamps.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `raw_data_storage_id`\n  > Reference to related raw data storage record,\n  > political_news_crawler_raw_data_storage.id.\n- `local_file_path`: Filesystem path or identifier for the local cached file copy.\n- `file_size_bytes`: Size of the local cached file in bytes.\n- `ttl_expiration_at`\n  > Datetime when the cached file expires and is due for deletion under TTL\n  > policy.\n- `deleted_at`\n  > Soft delete timestamp indicating when the cached file was deleted, if\n  > applicable.\n- `created_at`: Creation timestamp record.\n- `updated_at`: Last update timestamp record.\n\n### `political_news_crawler_processed_content`\n\nStores processed political news content generated by LLM post-processing,\nincluding summaries, highlights, and analysis. Links content to raw data\nstorage and optionally to the LLM job that generated it. Contains content\ntype, full text body, generation timestamp, and audit timestamps.\nSupports text search through GIN index on content body.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `raw_data_storage_id`\n  > Foreign key to the raw data storage record,\n  > political_news_crawler_raw_data_storage.id.\n- `llm_job_id`: Foreign key to associated LLM job, political_news_crawler_llm_jobs.id.\n- `content_type`: Type of processed content, e.g., summary, highlight, or analysis.\n- `content_body`: Full textual content produced by LLM processing.\n- `generation_timestamp`: Timestamp when this content was generated.\n- `created_at`: Record creation timestamp, typically same or near generation time.\n- `updated_at`: Last update timestamp record.\n\n## Processing\n\n```mermaid\nerDiagram\n\"political_news_crawler_llm_jobs\" {\n  String id PK\n  String crawl_source_id FK\n  String status\n  String parameters\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_llm_results\" {\n  String id PK\n  String llm_job_id FK\n  String content_type\n  String content_text\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_processing_metadata\" {\n  String id PK\n  String llm_job_id FK\n  String metadata_key\n  String metadata_value\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_llm_results\" }o--|| \"political_news_crawler_llm_jobs\" : llmJob\n\"political_news_crawler_processing_metadata\" }o--|| \"political_news_crawler_llm_jobs\" : llmJob\n```\n\n### `political_news_crawler_llm_jobs`\n\nLLM jobs represent individual processing tasks queued or executed for\npolitical news data. They track the job status, parameters, and\nprocessing flags. This model supports the management and monitoring of\nasynchronous LLM post-processing tasks such as generating summaries and\nanalysis.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `crawl_source_id`\n  > The source channel from which the raw news data originated, referencing\n  > political_news_crawler_crawl_sources.id.\n- `status`\n  > Processing status of the job, e.g., 'pending', 'running', 'completed',\n  > 'failed'.\n- `parameters`: JSON string of parameters or prompts used for this LLM job.\n- `created_at`: Job creation timestamp.\n- `updated_at`: Job last update timestamp.\n- `deleted_at`: Soft delete timestamp, null if not deleted.\n\n### `political_news_crawler_llm_results`\n\nLLM results store the output content generated by LLM jobs, including\nsummaries, highlights, and analyses. This model links back to the\noriginating LLM job and preserves output details for retrieval and audit\npurposes.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `llm_job_id`: Associated LLM job's political_news_crawler_llm_jobs.id.\n- `content_type`: Type of generated content, e.g., 'summary', 'highlight', 'analysis'.\n- `content_text`: Generated content text by the LLM.\n- `created_at`: Timestamp when the output was created.\n- `updated_at`: Timestamp when the output was last updated.\n- `deleted_at`: Soft delete timestamp, null if not deleted.\n\n### `political_news_crawler_processing_metadata`\n\nMetadata entries for LLM processing capturing auxiliary information\nrelated to jobs or overall processing context. This table stores\nadditional attributes to support enhancements and auditability.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `llm_job_id`: Associated LLM job's political_news_crawler_llm_jobs.id.\n- `metadata_key`: Key name of the metadata attribute.\n- `metadata_value`: Value of the metadata attribute.\n- `created_at`: Metadata entry creation timestamp.\n- `updated_at`: Metadata entry last update timestamp.\n- `deleted_at`: Soft delete timestamp, null if not deleted.\n\n## Popularity\n\n```mermaid\nerDiagram\n\"political_news_crawler_popularity_scores\" {\n  String id PK\n  String political_news_crawler_popular_topic_id FK\n  Float score\n  Float decay_factor\n  DateTime snapshot_at\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_popular_topics\" {\n  String id PK\n  String topic_code UK\n  String title\n  String description \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_topic_mentions\" {\n  String id PK\n  String political_news_crawler_popular_topic_id FK\n  String political_news_crawler_crawled_news_id FK\n  String mention_context \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_popularity_scores\" }o--|| \"political_news_crawler_popular_topics\" : popularTopic\n\"political_news_crawler_topic_mentions\" }o--|| \"political_news_crawler_popular_topics\" : popularTopic\n```\n\n### `political_news_crawler_popularity_scores`\n\nSnapshot table capturing computed popularity scores for political topics\nat specific timestamps. Each record represents a historical state of a\npopularity calculation for auditing and trend analysis purposes.\nReferences the related popular topic. Includes score metrics and aging\nfields consistent with time-decayed ranking models.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `political_news_crawler_popular_topic_id`\n  > Referenced popular topic's {@link\n  > political_news_crawler_popular_topics.id}.\n- `score`: Calculated popularity score for the topic at this snapshot.\n- `decay_factor`: Decay factor applied to the score based on the age of the topic mention.\n- `snapshot_at`: Timestamp when this popularity score snapshot was taken.\n- `created_at`: Record creation timestamp.\n- `updated_at`: Record last update timestamp.\n- `deleted_at`: Soft deletion timestamp if applicable, otherwise null.\n\n### `political_news_crawler_popular_topics`\n\nPrimary table listing all current political news topics with computed\npopularity rankings. Maintains unique topic identifiers, titles, and\nmetadata for efficient querying and API response. Supports independent\nmanagement of topics and serves as the main entity for popularity-related\nqueries.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `topic_code`: Unique code identifier for the political topic.\n- `title`: Official title or name of the popular topic.\n- `description`: Optional detailed description or context about the popular topic.\n- `created_at`: Record creation timestamp.\n- `updated_at`: Record last update timestamp.\n- `deleted_at`: Soft deletion timestamp if applicable, otherwise null.\n\n### `political_news_crawler_topic_mentions`\n\nSubsidiary table recording mentions of political topics within news\narticles. Establishes many-to-one relationships with both topics and\ncrawled news records. Supports detailed traceability of topic references\nand feeds data for popularity calculations. Managed as supporting entity\nfor topic analytics.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `political_news_crawler_popular_topic_id`\n  > Referenced popular topic's {@link\n  > political_news_crawler_popular_topics.id}.\n- `political_news_crawler_crawled_news_id`\n  > Referenced crawled news item's {@link\n  > political_news_crawler_crawled_news.id}.\n- `mention_context`\n  > Optional text snippet or context where the topic is mentioned within the\n  > article.\n- `created_at`: Record creation timestamp.\n- `updated_at`: Record last update timestamp.\n- `deleted_at`: Soft deletion timestamp if applicable, otherwise null.\n\n## API\n\n```mermaid\nerDiagram\n\"political_news_crawler_api_access_logs\" {\n  String id PK\n  String http_method\n  String path\n  Int status_code\n  String client_ip\n  String user_agent\n  Int duration_ms\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_api_error_logs\" {\n  String id PK\n  String path\n  String error_code\n  String error_message\n  String client_ip\n  String user_agent\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_api_usage_metrics\" {\n  String id PK\n  String http_method\n  String path\n  DateTime period_start\n  DateTime period_end\n  Int total_calls\n  Int max_response_ms\n  Int avg_response_ms\n  DateTime created_at\n  DateTime updated_at\n}\n```\n\n### `political_news_crawler_api_access_logs`\n\nRecords detailed log entries for every API access to track client\nrequests, including request method, path, response status, client IP\naddress, user agent, request duration in milliseconds, and timestamp.\nSupports comprehensive API usage analytics and operational monitoring.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `http_method`: HTTP request method used in the API call, e.g., GET, POST, PUT.\n- `path`: API endpoint path being accessed, e.g., /api/v1/popular_topics.\n- `status_code`: HTTP response status code returned to the client.\n- `client_ip`: IP address of the client making the API request.\n- `user_agent`: User agent string of the client or application making the request.\n- `duration_ms`: Duration of the API request processing in milliseconds.\n- `created_at`: Timestamp when the log entry was created.\n- `updated_at`: Timestamp when the log entry was last updated.\n\n### `political_news_crawler_api_error_logs`\n\nCaptures detailed records of API errors, including the API path, error\ncode, error message, client IP, user agent, occurrence timestamp, and\nupdate timestamp. Enables error analysis and system troubleshooting for\nAPI endpoints.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `path`: API endpoint path where the error occurred.\n- `error_code`: Error code identifying the type of API error.\n- `error_message`: Descriptive error message to assist debugging.\n- `client_ip`: IP address of the client causing the error.\n- `user_agent`: User agent string of the client application.\n- `created_at`: Timestamp when the error log was created.\n- `updated_at`: Timestamp when the error log was last updated.\n\n### `political_news_crawler_api_usage_metrics`\n\nAggregated API usage metrics capturing total counts of API calls by\nmethod and path over specific time periods, including maximum response\ntimes and average durations. Supports performance monitoring and traffic\nanalysis for API endpoints.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `http_method`: HTTP method for which metrics are aggregated.\n- `path`: API endpoint path for which metrics are aggregated.\n- `period_start`: Start timestamp of the aggregation period.\n- `period_end`: End timestamp of the aggregation period.\n- `total_calls`: Total number of API calls observed in the aggregation period.\n- `max_response_ms`: Maximum response time in milliseconds recorded during the period.\n- `avg_response_ms`: Average response time in milliseconds over the period.\n- `created_at`: Timestamp when this aggregated record was created.\n- `updated_at`: Timestamp when this aggregated record was last updated.\n\n## Alerts\n\n```mermaid\nerDiagram\n\"political_news_crawler_crawl_alerts\" {\n  String id PK\n  String crawl_source_id FK\n  String alert_type\n  String message\n  String severity\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_processing_alerts\" {\n  String id PK\n  String alert_type\n  String message\n  String severity\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_api_alerts\" {\n  String id PK\n  String alert_type\n  String message\n  String severity\n  DateTime created_at\n  DateTime updated_at\n}\n```\n\n### `political_news_crawler_crawl_alerts`\n\nStores alert events related to crawling operations, capturing failures,\nbans, or throttle notifications from crawl sources. Links alerts to\nspecific crawl sources for traceability. Contains timestamp, severity\nlevel, and descriptive message for operational monitoring.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `crawl_source_id`\n  > Referenced crawl source's [political_news_crawler_crawl_sources.id](#political_news_crawler_crawl_sources)\n  > which triggered the alert.\n- `alert_type`\n  > Type of alert event indicating the category, e.g., 'ban_detected',\n  > 'network_error', 'throttle_warning'.\n- `message`\n  > Detailed description of the alert event and context for operational\n  > understanding.\n- `severity`: Severity level of the alert such as 'info', 'warning', 'critical'.\n- `created_at`: Timestamp when the alert was created.\n- `updated_at`: Timestamp when the alert was last updated.\n\n### `political_news_crawler_processing_alerts`\n\nCaptures alert events related to processing pipeline failures including\nLLM processing errors, queue backlogs, or retry escalations. Provides\ndetailed messages and timestamp info for system diagnostics and\nresolution procedures.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `alert_type`\n  > Category of processing alert such as 'llm_failure', 'queue_overflow',\n  > 'retry_limit_reached'.\n- `message`: Detailed description of the processing alert event for operational use.\n- `severity`: Severity level of the alert (e.g., 'info', 'warning', 'critical').\n- `created_at`: Timestamp when the alert was created.\n- `updated_at`: Timestamp for last update of the alert.\n\n### `political_news_crawler_api_alerts`\n\nContains alert records related to API subsystem errors including rate\nlimiting, endpoint failures, and error spikes. Supports operational\nmonitoring by storing detailed messages and timestamps of occurrence.\n\nProperties as follows:\n\n- `id`: Primary Key.\n- `alert_type`\n  > Type of API alert event such as 'rate_limit_exceeded', 'endpoint_error',\n  > 'error_spike'.\n- `message`: Detailed message describing the API alert context.\n- `severity`: Severity level of the alert such as 'info', 'warning', 'critical'.\n- `created_at`: Timestamp when the alert was created.\n- `updated_at`: Timestamp when the alert was last updated.\n","diagrams":{"Systematic":"```mermaid\nerDiagram\n\"political_news_crawler_crawl_sources\" {\n  String id PK\n  String source_code UK\n  String(80000) source_url UK\n  Boolean is_active\n  String description \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_crawl_policies\" {\n  String id PK\n  String policy_name UK\n  Int max_crawl_frequency_minutes\n  Int max_retry_attempts\n  Float backoff_multiplier\n  Boolean ban_detection_enabled\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_crawl_schedules\" {\n  String id PK\n  String crawl_source_id FK\n  String crawl_policy_id FK\n  String schedule_expression\n  DateTime last_crawled_at \"nullable\"\n  DateTime next_crawl_at \"nullable\"\n  Boolean is_enabled\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_crawl_schedules\" }o--|| \"political_news_crawler_crawl_sources\" : crawlSource\n\"political_news_crawler_crawl_schedules\" }o--|| \"political_news_crawler_crawl_policies\" : crawlPolicy\n```","Actors":"```mermaid\nerDiagram\n\"political_news_crawler_guests\" {\n  String id PK\n  String ip_address\n  String user_agent \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n```","Crawling":"```mermaid\nerDiagram\n\"political_news_crawler_crawl_jobs\" {\n  String id PK\n  String crawl_source_id FK\n  String crawl_schedule_id FK\n  Boolean active\n  DateTime last_run_started_at \"nullable\"\n  DateTime last_run_completed_at \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_crawl_attempts\" {\n  String id PK\n  String crawl_job_id FK\n  String raw_data_storage_id FK \"nullable\"\n  DateTime started_at\n  DateTime completed_at \"nullable\"\n  Boolean success\n  String error_message \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_crawled_news\" {\n  String id PK\n  String crawl_attempt_id FK\n  String url UK\n  String title \"nullable\"\n  DateTime published_at \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_crawl_attempts\" }o--|| \"political_news_crawler_crawl_jobs\" : crawlJob\n\"political_news_crawler_crawled_news\" }o--|| \"political_news_crawler_crawl_attempts\" : crawlAttempt\n```","Storage":"```mermaid\nerDiagram\n\"political_news_crawler_raw_data_storage\" {\n  String id PK\n  String crawl_source_id FK\n  String crawl_job_id FK \"nullable\"\n  String storage_key UK\n  String file_format\n  Int file_size_bytes\n  String checksum \"nullable\"\n  DateTime crawl_timestamp\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_local_cache_files\" {\n  String id PK\n  String raw_data_storage_id FK\n  String local_file_path UK\n  Int file_size_bytes\n  DateTime ttl_expiration_at\n  DateTime deleted_at \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_processed_content\" {\n  String id PK\n  String raw_data_storage_id FK\n  String llm_job_id FK \"nullable\"\n  String content_type\n  String content_body\n  DateTime generation_timestamp\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_local_cache_files\" }o--|| \"political_news_crawler_raw_data_storage\" : rawDataStorage\n\"political_news_crawler_processed_content\" }o--|| \"political_news_crawler_raw_data_storage\" : rawDataStorage\n```","Processing":"```mermaid\nerDiagram\n\"political_news_crawler_llm_jobs\" {\n  String id PK\n  String crawl_source_id FK\n  String status\n  String parameters\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_llm_results\" {\n  String id PK\n  String llm_job_id FK\n  String content_type\n  String content_text\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_processing_metadata\" {\n  String id PK\n  String llm_job_id FK\n  String metadata_key\n  String metadata_value\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_llm_results\" }o--|| \"political_news_crawler_llm_jobs\" : llmJob\n\"political_news_crawler_processing_metadata\" }o--|| \"political_news_crawler_llm_jobs\" : llmJob\n```","Popularity":"```mermaid\nerDiagram\n\"political_news_crawler_popularity_scores\" {\n  String id PK\n  String political_news_crawler_popular_topic_id FK\n  Float score\n  Float decay_factor\n  DateTime snapshot_at\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_popular_topics\" {\n  String id PK\n  String topic_code UK\n  String title\n  String description \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_topic_mentions\" {\n  String id PK\n  String political_news_crawler_popular_topic_id FK\n  String political_news_crawler_crawled_news_id FK\n  String mention_context \"nullable\"\n  DateTime created_at\n  DateTime updated_at\n  DateTime deleted_at \"nullable\"\n}\n\"political_news_crawler_popularity_scores\" }o--|| \"political_news_crawler_popular_topics\" : popularTopic\n\"political_news_crawler_topic_mentions\" }o--|| \"political_news_crawler_popular_topics\" : popularTopic\n```","API":"```mermaid\nerDiagram\n\"political_news_crawler_api_access_logs\" {\n  String id PK\n  String http_method\n  String path\n  Int status_code\n  String client_ip\n  String user_agent\n  Int duration_ms\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_api_error_logs\" {\n  String id PK\n  String path\n  String error_code\n  String error_message\n  String client_ip\n  String user_agent\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_api_usage_metrics\" {\n  String id PK\n  String http_method\n  String path\n  DateTime period_start\n  DateTime period_end\n  Int total_calls\n  Int max_response_ms\n  Int avg_response_ms\n  DateTime created_at\n  DateTime updated_at\n}\n```","Alerts":"```mermaid\nerDiagram\n\"political_news_crawler_crawl_alerts\" {\n  String id PK\n  String crawl_source_id FK\n  String alert_type\n  String message\n  String severity\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_processing_alerts\" {\n  String id PK\n  String alert_type\n  String message\n  String severity\n  DateTime created_at\n  DateTime updated_at\n}\n\"political_news_crawler_api_alerts\" {\n  String id PK\n  String alert_type\n  String message\n  String severity\n  DateTime created_at\n  DateTime updated_at\n}\n```"}},"created_at":"2025-09-14T06:36:12.266Z","completed_at":"2025-09-14T06:38:29.147Z","step":0},{"id":"019946f3-b123-7258-80bc-be151223e1c0","type":"userMessage","contents":[{"type":"text","text":"Create the API interface specification."}],"created_at":"2025-09-14T06:39:59.779Z"},{"type":"interface","id":"01994719-6a5d-717d-aa35-591cf47f66dd","reason":"Generate API interface specification for backend application that provides endpoints to serve real-time popular hot political topics, summaries, highlights, analysis, and support flexible query parameters without user authentication.","authorizations":[{"role":"guest","operations":[{"specification":"This set of API operations enables authentication and token management for the 'guest' role within the politicalNewsCrawler system. Guest users represent unauthenticated users who only have restricted access to public endpoints for retrieving news and popular topics without needing login credentials. These operations facilitate guest account creation (join) which assigns a temporary guest identity to users to track their session or basic metadata such as IP and user agent, and enable refreshing of access tokens via a refresh endpoint.\n\nThe join operation at /auth/guest/join allows creating a temporary guest account. It does not require login credentials since guests don't authenticate with passwords. This endpoint is public and serves to provide a guest entry point. Upon successful creation, a temporary JWT token is issued encapsulated in the response object IPoliticalNewsCrawlerGuest.IAuthorized which represents the authorized guest state.\n\nThe refresh operation at /auth/guest/refresh allows guests to refresh their issued temporary tokens using a valid refresh token. This supports session continuity without rejoining.\n\nSecurity considerations include restricting guest operations to temporary token issuance without password authentication. These endpoints ensure controlled issuance and refresh of JWT tokens while guests remain unauthenticated users with limited access.\n\nRelated operations with login and user credential validation are not applicable for the guest role since they have no persistent login credentials.\n\nThese operations reference the 'political_news_crawler_guests' Prisma schema table which records guest metadata such as IP address and user agent with auditing timestamps to track anonymous user sessions safely and compliantly.\n","authorizationType":"join","description":"Provides an endpoint for guest users (unauthenticated) to create a temporary guest account and receive JWT tokens to access public APIs. The join route allows automatically generating guest identifiers without passwords. The response type IPoliticalNewsCrawlerGuest.IAuthorized represents the token response containing temporary guest authentication details and metadata as per the political_news_crawler_guests schema.","summary":"Create a temporary guest account and issue JWT tokens. Maps to political_news_crawler_guests table for guest metadata tracking.","parameters":[],"requestBody":{"description":"Guest join request payload. For guests, this is typically empty or minimal since no credentials are needed.","typeName":"IPoliticalNewsCrawlerGuest.IRequest"},"responseBody":{"description":"Guest authorization token response containing JWT tokens and guest metadata.","typeName":"IPoliticalNewsCrawlerGuest.IAuthorized"},"authorizationRole":"guest","name":"join","path":"/auth/guest/join","method":"post"},{"specification":"Allows guest users holding temporary issued tokens to refresh their access credentials using the refresh token. This operation supports continued access for guest sessions without requiring rejoining or account recreation. Tokens are validated and renewed securely.\n\nThis operation does not require traditional login credentials. It accepts a refresh token and returns a new set of JWT tokens encapsulated in the response type IPoliticalNewsCrawlerGuest.IAuthorized.\n\nReferencing the political_news_crawler_guests table schema, the refresh process maintains guest session continuity while enforcing secure token management policies. Guests remain unauthenticated with limited permission scopes.\n\nThis operation is crucial to support guest user experiences where tokens have expiry but sessions persist beyond token lifetime.\n","authorizationType":"refresh","description":"Refresh temporary JWT tokens for a guest user session. Requires a valid refresh token and issues new tokens with updated expiry.","summary":"Refresh guest access tokens securely. Maps to political_news_crawler_guests table for session continuity without login.","parameters":[],"requestBody":{"description":"Payload containing a refresh token to renew guest JWT tokens securely.","typeName":"IPoliticalNewsCrawlerGuest.IRefresh"},"responseBody":{"description":"New authorized tokens response including JWT tokens and associated guest session metadata.","typeName":"IPoliticalNewsCrawlerGuest.IAuthorized"},"authorizationRole":"guest","name":"refresh","path":"/auth/guest/refresh","method":"post"}]}],"document":{"operations":[{"specification":"This set of API operations enables authentication and token management for the 'guest' role within the politicalNewsCrawler system. Guest users represent unauthenticated users who only have restricted access to public endpoints for retrieving news and popular topics without needing login credentials. These operations facilitate guest account creation (join) which assigns a temporary guest identity to users to track their session or basic metadata such as IP and user agent, and enable refreshing of access tokens via a refresh endpoint.\n\nThe join operation at /auth/guest/join allows creating a temporary guest account. It does not require login credentials since guests don't authenticate with passwords. This endpoint is public and serves to provide a guest entry point. Upon successful creation, a temporary JWT token is issued encapsulated in the response object IPoliticalNewsCrawlerGuest.IAuthorized which represents the authorized guest state.\n\nThe refresh operation at /auth/guest/refresh allows guests to refresh their issued temporary tokens using a valid refresh token. This supports session continuity without rejoining.\n\nSecurity considerations include restricting guest operations to temporary token issuance without password authentication. These endpoints ensure controlled issuance and refresh of JWT tokens while guests remain unauthenticated users with limited access.\n\nRelated operations with login and user credential validation are not applicable for the guest role since they have no persistent login credentials.\n\nThese operations reference the 'political_news_crawler_guests' Prisma schema table which records guest metadata such as IP address and user agent with auditing timestamps to track anonymous user sessions safely and compliantly.\n","authorizationType":"join","description":"Provides an endpoint for guest users (unauthenticated) to create a temporary guest account and receive JWT tokens to access public APIs. The join route allows automatically generating guest identifiers without passwords. The response type IPoliticalNewsCrawlerGuest.IAuthorized represents the token response containing temporary guest authentication details and metadata as per the political_news_crawler_guests schema.","summary":"Create a temporary guest account and issue JWT tokens. Maps to political_news_crawler_guests table for guest metadata tracking.","parameters":[],"requestBody":{"description":"Guest join request payload. For guests, this is typically empty or minimal since no credentials are needed.","typeName":"IPoliticalNewsCrawlerGuest.IRequest"},"responseBody":{"description":"Guest authorization token response containing JWT tokens and guest metadata.","typeName":"IPoliticalNewsCrawlerGuest.IAuthorized"},"authorizationRole":"guest","name":"join","path":"/auth/guest/join","method":"post"},{"specification":"Allows guest users holding temporary issued tokens to refresh their access credentials using the refresh token. This operation supports continued access for guest sessions without requiring rejoining or account recreation. Tokens are validated and renewed securely.\n\nThis operation does not require traditional login credentials. It accepts a refresh token and returns a new set of JWT tokens encapsulated in the response type IPoliticalNewsCrawlerGuest.IAuthorized.\n\nReferencing the political_news_crawler_guests table schema, the refresh process maintains guest session continuity while enforcing secure token management policies. Guests remain unauthenticated with limited permission scopes.\n\nThis operation is crucial to support guest user experiences where tokens have expiry but sessions persist beyond token lifetime.\n","authorizationType":"refresh","description":"Refresh temporary JWT tokens for a guest user session. Requires a valid refresh token and issues new tokens with updated expiry.","summary":"Refresh guest access tokens securely. Maps to political_news_crawler_guests table for session continuity without login.","parameters":[],"requestBody":{"description":"Payload containing a refresh token to renew guest JWT tokens securely.","typeName":"IPoliticalNewsCrawlerGuest.IRefresh"},"responseBody":{"description":"New authorized tokens response including JWT tokens and associated guest session metadata.","typeName":"IPoliticalNewsCrawlerGuest.IAuthorized"},"authorizationRole":"guest","name":"refresh","path":"/auth/guest/refresh","method":"post"},{"specification":"This operation retrieves a paginated and filterable list of all political news crawler crawl sources as stored in the political_news_crawler_crawl_sources table in the Prisma schema. The crawl sources consist of configurations for various external news sources including their URLs, description, and active status. This endpoint supports searching and sorting to allow consumers to find sources based on source code, URL, status, or creation date.","description":"Retrieve a filtered and paginated list of all political news crawler crawl sources. The crawl sources represent configurations for political news content retrieval from diverse external websites or APIs in the system.\n\nThis operation supports advanced searching and sorting capabilities, enabling clients to query sources by attributes such as source code, URL, and active status. It returns summarized information optimized for listing.\n\nSecurity considerations: This endpoint is publicly accessible with no authentication required as all source metadata is non-sensitive.\n\nThis operation relates directly to the political_news_crawler_crawl_sources table in the Prisma schema, which tracks source identifiers, URLs, activation status, and audit metadata. Response includes only relevant summary fields for efficient transmission.\n\nUsage with other endpoints: Use POST /politicalNewsCrawler/crawlSources for creation, GET /politicalNewsCrawler/crawlSources/{id} for details, and PUT /politicalNewsCrawler/crawlSources/{id} for updates as needed.","summary":"Search and retrieve a filtered, paginated list of political news crawler crawl sources","parameters":[],"requestBody":{"description":"Search criteria and pagination parameters for crawl source filtering","typeName":"IPoliticalNewsCrawlerCrawlSources.IRequest"},"responseBody":{"description":"Paginated list of crawl source summaries matching search criteria","typeName":"IPageIPoliticalNewsCrawlerCrawlSources.ISummary"},"authorizationType":null,"authorizationRole":null,"path":"/politicalNewsCrawler/politicalNewsCrawler/crawlSources","method":"patch","name":"index"},{"specification":"This operation retrieves detailed information of a single political news crawler crawl source identified by its primary key ID. It returns all metadata including source code, URL, status flags, and audit timestamps as defined in the political_news_crawler_crawl_sources table in the Prisma schema. This fetch by ID allows clients to obtain full details for a given source configuration.","description":"Retrieve details of a specific political news crawler crawl source by its unique ID. The crawl source is a configuration entity representing an external site or API source for political news crawling.\n\nThis endpoint returns the complete information for the crawl source record including the source code, URL, active flag, description, and creation/update timestamps.\n\nNo authentication is required since this information is not sensitive and is intended for public consumption.\n\nUse this endpoint to examine or verify configuration details of a specific crawl source. Combine with the crawl source listing endpoint PATCH /politicalNewsCrawler/crawlSources for full source management workflows.\n\nThe operation is closely tied to the political_news_crawler_crawl_sources Prisma table.","summary":"Retrieve a specific political news crawler crawl source by ID","parameters":[{"name":"id","description":"Unique identifier of the target crawl source","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"Full detailed crawl source information","typeName":"IPoliticalNewsCrawlerCrawlSources"},"authorizationType":null,"authorizationRole":null,"path":"/politicalNewsCrawler/politicalNewsCrawler/crawlSources/{id}","method":"get","name":"at"},{"specification":"This operation creates a new political news crawler crawl source in the system, adding a new external source configuration to enable crawling. It accepts the source parameters including source code, URL, whether the source is active, and optional description, as defined in the political_news_crawler_crawl_sources Prisma table fields. The system generates the ID and timestamps internally. This endpoint allows clients to register new crawl sources dynamically as needed.","description":"Create a new political news crawler crawl source with specified configuration data. The client provides source code, source URL, active flag, and optional description.\n\nUpon successful creation, the system returns the full detailed crawl source record including generated ID and timestamps.\n\nThis operation is intended for administrative or automated system use to register new crawl source endpoints.\n\nIt directly maps to the political_news_crawler_crawl_sources table in the Prisma schema.","summary":"Create a new political news crawler crawl source","parameters":[],"requestBody":{"description":"Creation info of the crawl source","typeName":"IPoliticalNewsCrawlerCrawlSources.ICreate"},"responseBody":{"description":"Newly created crawl source information","typeName":"IPoliticalNewsCrawlerCrawlSources"},"authorizationType":null,"authorizationRole":null,"path":"/politicalNewsCrawler/politicalNewsCrawler/crawlSources","method":"post","name":"create"},{"specification":"This operation updates an existing political news crawler crawl source identified by its ID, modifying its configuration fields such as source code, URL, active status, and description. It performs full update of the crawl source record as defined in the political_news_crawler_crawl_sources Prisma table. The system updates the timestamp accordingly. This allows administrative maintenance of crawl source configurations.","description":"Update an existing political news crawler crawl source by ID with given update data. The client can modify source code, source URL, is_active flag, and description.\n\nThe system returns the updated full crawl source record upon success.\n\nThis operation supports CRUD maintenance over crawl source configurations and ensures uniform data integrity with Prisma schema field enforcement.\n\nCorresponds to the political_news_crawler_crawl_sources Prisma table.","summary":"Update an existing political news crawler crawl source","parameters":[{"name":"id","description":"Unique identifier of the target crawl source","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Update info of the crawl source","typeName":"IPoliticalNewsCrawlerCrawlSources.IUpdate"},"responseBody":{"description":"Updated crawl source information","typeName":"IPoliticalNewsCrawlerCrawlSources"},"authorizationType":null,"authorizationRole":null,"path":"/politicalNewsCrawler/politicalNewsCrawler/crawlSources/{id}","method":"put","name":"update"},{"specification":"This operation deletes a specific crawl source from the political_news_crawler_crawl_sources table identified by its UUID. This delete operation is a hard delete whereby the record is permanently removed from the database. Admin role authorization is required to perform this operation, ensuring that only authorized users can remove crawl sources which may have dependencies such as schedules, jobs and raw data.","description":"Deletes a crawl source identified by its UUID from the system's database. This will permanently remove the crawl source and all of its associations including crawl schedules, crawl jobs, raw data, and related processing linked to this source.\n\nOnly users with the admin role are authorized to perform this destructive operation.\n\nErrors for non-existent or invalid UUIDs are handled with proper HTTP error codes.\n\nNo request body is required. No response content is returned on successful deletion.","summary":"Delete a crawl source by ID","parameters":[{"name":"id","description":"Unique identifier of the crawl source to delete","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":null,"authorizationRoles":["admin"],"path":"/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSources/{id}","method":"delete","name":"erase","authorizationRole":"admin","authorizationType":null},{"specification":"Retrieve a paginated list of crawl policies stored in the political_news_crawler_crawl_policies table. This operation supports filtering by policy attributes along with pagination and sorting, enabling administrators to search and manage crawl policies effectively.\n\nAccess is restricted to users with admin role to protect sensitive crawling configuration data.","description":"Retrieves a filtered, paginated list of crawl policies from the database. Supports advanced search parameters including max crawl frequency, retry attempts, and ban detection flags.\n\nThis operation returns crawl policy summaries optimized for list display in administrative interfaces.\n\nOnly admin users are authorized for this operation.\n\nThe response contains a pageable data set with key policy attributes.\n\nErrors such as invalid filters or pagination parameters will be returned as appropriate HTTP errors.\n\nThe request body specifies complex search and pagination criteria.","summary":"Search and list crawl policies","parameters":[],"requestBody":{"description":"Search criteria and pagination parameters for crawl policies filtering","typeName":"IPoliticalNewsCrawlerCrawlPolicy.IRequest"},"responseBody":{"description":"Paginated list of crawl policy summaries matching search criteria","typeName":"IPageIPoliticalNewsCrawlerCrawlPolicy.ISummary"},"authorizationRoles":["admin"],"path":"/politicalNewsCrawler/guest/politicalNewsCrawler/crawlPolicies","method":"patch","name":"index","authorizationRole":"admin","authorizationType":null},{"specification":"Retrieve detailed information for a single crawl policy by its UUID from the political_news_crawler_crawl_policies table.\n\nAccess is restricted to admin users since this exposes complete crawl policy configuration details.\n\nReturns full crawl policy entity including all parameters and timestamps.\n\nErrors for invalid or missing IDs yield appropriate HTTP error codes.","description":"Retrieves detailed crawl policy information identified by its UUID.\n\nThis operation supports administrative usage for managing crawl policies.\n\nOnly users with admin role are authorized.\n\nResponse returns full crawl policy entity.\n\nInvalid IDs return error responses.","summary":"Retrieve crawl policy details by ID","parameters":[{"name":"id","description":"Unique identifier of the crawl policy to retrieve","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"Detailed crawl policy entity","typeName":"IPoliticalNewsCrawlerCrawlPolicy"},"authorizationRoles":["admin"],"path":"/politicalNewsCrawler/guest/politicalNewsCrawler/crawlPolicies/{id}","method":"get","name":"at","authorizationRole":"admin","authorizationType":null},{"specification":"Creates a new crawl policy record in the political_news_crawler_crawl_policies table. The request body must provide the policy data following the ICreate schema including policy name, max crawl frequency, retry attempts, backoff multiplier and ban detection flag.\n\nAuthorization is limited to admin users due to the impact on system crawling behavior.\n\nOn success, returns the created crawl policy entity including its ID and timestamps.\n\nValidation errors, such as duplicate policy names or out-of-range parameters, trigger detailed error responses.","description":"Creates a new crawl policy with the provided details.\n\nThe request body must include fields such as policy_name, max crawl frequency (minutes), max retry attempts, backoff multiplier and ban detection enabled flag.\n\nOnly admin users are authorized to create new crawl policies.\n\nReturns the created crawl policy entity.\n\nErrors in input data validation return detailed messages.\n\nNo path parameters are required.","summary":"Create new crawl policy","parameters":[],"requestBody":{"description":"New crawl policy data","typeName":"IPoliticalNewsCrawlerCrawlPolicy.ICreate"},"responseBody":{"description":"Created crawl policy entity","typeName":"IPoliticalNewsCrawlerCrawlPolicy"},"authorizationRoles":["admin"],"path":"/politicalNewsCrawler/guest/politicalNewsCrawler/crawlPolicies","method":"post","name":"create","authorizationRole":"admin","authorizationType":null},{"specification":"This API operation updates an existing crawl policy in the politicalNewsCrawler backend system. It allows modifying the maximum crawling frequency in minutes, maximum retry attempts after failures, exponential backoff multiplier, and ban detection enforcement flag for crawl scheduling. The operation updates a specific record in the political_news_crawler_crawl_policies table identified by its UUID primary key. It expects the updated crawl policy data in a structured request body matching the IPoliticalNewsCrawlerCrawlPolicy.IUpdate DTO type, and returns the updated crawl policy entity upon success. This supports backend administrators in managing crawling frequency and retry behavior dynamically to maintain optimal crawling performance while respecting source limitations.","path":"/politicalNewsCrawler/guest/politicalNewsCrawler/crawlPolicies/{id}","method":"put","summary":"Update an existing crawl policy in politicalNewsCrawler","description":"This endpoint updates the details of an existing crawl policy used by the politicalNewsCrawler system to govern crawl scheduling and error handling. Updating crawl policies enables administrators to adjust parameters including:\n\n- Maximum crawl frequency in minutes to control how often crawls are scheduled.\n- Maximum retry attempts to specify how many times to retry failed crawling operations before aborting.\n- Backoff multiplier controlling the exponential delay applied between retries.\n- Ban detection enabled flag indicating whether the system should actively detect and handle bans.\n\nSecurity considerations: Only authorized backend administrators should have access to update crawl policies to prevent disruption of crawling behavior. The operation updates a single policy record identified by the provided UUID path parameter, ensuring precise targeting.\n\nThe operation interfaces with the underlying political_news_crawler_crawl_policies table, modifying fields according to the request payload. Proper validation is performed to ensure data integrity.\n\nIn case of errors (e.g., invalid ID or data), the system returns appropriate HTTP error status codes. Successful updates return the modified crawl policy entity reflecting the new parameters.","parameters":[{"name":"id","description":"Unique identifier of the crawl policy to update","schema":{"type":"string","format":"uuid"},"in":"path"}],"requestBody":{"description":"Updated crawl policy data for modification","typeName":"IPoliticalNewsCrawlerCrawlPolicy.IUpdate"},"responseBody":{"description":"The updated crawl policy entity","typeName":"IPoliticalNewsCrawlerCrawlPolicy"},"authorizationRoles":["guest"],"authorizationType":null,"authorizationRole":"guest","name":"updateCrawlPolicy"},{"specification":"This API operation deletes an existing crawl policy record permanently from politicalNewsCrawler backend. It removes the entry from the political_news_crawler_crawl_policies table identified by the UUID primary key. This operation is intended for administrators to manage crawl policies lifecycle by removing deprecated or invalid policies. This delete action permanently removes the record and cannot be undone; no soft deletion is indicated for this entity.","path":"/politicalNewsCrawler/guest/politicalNewsCrawler/crawlPolicies/{id}","method":"delete","summary":"Delete a crawl policy by ID permanently","description":"Deletes the specified crawl policy record from the politicalNewsCrawler system permanently. \n\nThis operation requires administrative privileges due to its impact on crawling behavior and system stability. Careful consideration is necessary before invoking the delete to avoid disruption.\n\nThe API removes the crawl policy identified by the UUID path parameter from the underlying database table political_news_crawler_crawl_policies.\n\nNo request body or response body is returned. Successful invocation results in a confirmation of deletion with no content. Failure cases return an appropriate error code.","parameters":[{"name":"id","description":"Unique identifier of the crawl policy to delete","schema":{"type":"string","format":"uuid"},"in":"path"}],"requestBody":null,"responseBody":null,"authorizationRoles":["guest"],"authorizationType":null,"authorizationRole":"guest","name":"eraseCrawlPolicy"},{"specification":"Retrieve a filtered and paginated list of crawl schedules used in politicalNewsCrawler backend to manage crawl execution timing for different sources. This operation supports filtering by source, policy, and enabled status, with pagination parameters to handle large data sets. The schedules are retrieved from the political_news_crawler_crawl_schedules table and provide details including cron expression, last and next crawl times, and enablement flag.","path":"/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules","method":"patch","summary":"Search and list crawl schedules with filtering and pagination","description":"This endpoint provides a paginated list of crawl schedules in the politicalNewsCrawler system. Crawl schedules define when and how often crawling occurs for each configured source, making this information critical for managing crawl frequency and timing.\n\nUsers can filter results by various criteria including source, policy, and whether the schedule is enabled. Extensive pagination support allows clients to manage large result sets efficiently.\n\nSecurity considerations: Access to crawl schedule listings might be restricted to authorized personnel to prevent information disclosure about crawling operations.\n\nThe operation interfaces with the underlying political_news_crawler_crawl_schedules table, projecting relevant fields for API clients including schedule expression, last and next crawl timestamps, and enablement status.\n\nResponse contains a paginated array of crawl schedule summary information for client consumption.","parameters":[],"requestBody":{"description":"Search and pagination filter criteria for crawl schedules","typeName":"IPoliticalNewsCrawlerCrawlSchedule.IRequest"},"responseBody":{"description":"Paginated list of crawl schedules","typeName":"IPageIPoliticalNewsCrawlerCrawlSchedule.ISummary"},"authorizationRoles":["guest"],"authorizationType":null,"authorizationRole":"guest","name":"searchCrawlSchedules"},{"specification":"Retrieve detailed crawl schedule information by its ID to provide complete scheduling and policy data. This operation fetches a single crawl schedule record from politicalNewsCrawler backend's political_news_crawler_crawl_schedules table and presents all fields including cron expression, last and next crawl times, enablement flag, and associated crawl source and policy details.","path":"/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules/{id}","method":"get","summary":"Retrieve detailed crawl schedule by ID","description":"This endpoint retrieves a detailed crawl schedule record identified by its unique UUID from the politicalNewsCrawler system. Crawl schedules configure how crawling jobs are scheduled for specific sources and policies.\n\nThe operation returns full details of the schedule including its cron expression, timestamps of last and next crawls, enablement state, creation and update times, and links to the associated crawl source and crawl policy.\n\nSecurity considerations: Access may be limited to administrative users due to operational sensitivity of crawl schedule data.\n\nSuccessful retrieval provides a comprehensive data structure representing the specific crawl schedule for backend monitoring or management use cases. Errors such as invalid IDs return appropriate HTTP status codes indicating not found or unauthorized access.","parameters":[{"name":"id","description":"Unique identifier of the crawl schedule to retrieve","schema":{"type":"string","format":"uuid"},"in":"path"}],"requestBody":null,"responseBody":{"description":"Detailed crawl schedule information","typeName":"IPoliticalNewsCrawlerCrawlSchedule"},"authorizationRoles":["guest"],"authorizationType":null,"authorizationRole":"guest","name":"getCrawlSchedule"},{"specification":"This operation creates a new crawling schedule in the political_news_crawler_crawl_schedules table. It enables backend administrators or automated systems to define when, how often, and under which policies a specific crawl source should be crawled. This includes specifying the cron schedule expression, enabling or disabling the schedule, and linking to the related crawl source and crawl policy for adaptive crawling behavior. It is essential for orchestrating crawling tasks and ensuring compliance with crawling rate limits and bans. The creation operation respects the database schema constraints and relationships, establishing foreign key references to the crawl source and crawl policy tables.","description":"Create a new crawling schedule for political news crawling sources.\n\nThis operation allows authorized systems or administrators to define when and how often a crawl source should be crawled. The crawl schedule includes a cron expression specifying the timing, links to the crawl source and crawl policy to control crawl frequency and backoff strategies, and flags to enable or disable the schedule.\n\nSecurity considerations restrict this operation to authorized roles managing crawling infrastructure.\n\nThe created schedule is registered in the political_news_crawler_crawl_schedules table, with all required validations for data integrity and foreign key constraints against crawl_sources and crawl_policies.\n\nExpected behavior includes returning the newly created schedule with all relevant metadata.\n\nErrors are raised for invalid references or conflicting schedules. The operation never supports soft-deletion here, and data is persistently stored.","summary":"Create a new political news crawler schedule","parameters":[],"requestBody":{"description":"Creation info of the crawl schedules","typeName":"IPoliticalNewsCrawlerCrawlSchedules.ICreate"},"responseBody":{"description":"Created crawl schedule information","typeName":"IPoliticalNewsCrawlerCrawlSchedules"},"authorizationType":null,"authorizationRole":"guest","method":"post","path":"/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules","name":"create"},{"specification":"This operation updates an existing crawling schedule record in the political_news_crawler_crawl_schedules table. It enables modification of schedule parameters such as the cron expression, enable flag, and references to crawl source and policy. This update allows maintaining crawl frequency and timing dynamically according to system needs or source behavior changes. Validations ensure foreign keys exist and the schedule record is identified correctly.\n\nThe operation corresponds to a standard update on a resource identified by its id, providing the ability to maintain crawling infrastructure consistently.\n\nThis update modifies the scheduling metadata while preserving the temporal consistency of crawl start and end timestamps not affected here.\n\nErrors are managed for invalid IDs or data violations.","description":"Update an existing crawling schedule identified by its ID.\n\nAllows modification of cron schedule expression, crawl source and policy references, and enabled status.\n\nOnly authorized roles can perform update operations.\n\nThe operation updates the record in the political_news_crawler_crawl_schedules table and returns the updated entity.\n\nRobust validation of the input is performed to prevent data inconsistencies.\n\nNo soft delete behavior is relevant.\n\nErrors include not found schedule or invalid foreign keys.","summary":"Update specified political news crawler schedule","parameters":[{"name":"id","description":"Target crawl schedule's ID","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Update info for crawl schedule","typeName":"IPoliticalNewsCrawlerCrawlSchedules.IUpdate"},"responseBody":{"description":"Updated crawl schedule information","typeName":"IPoliticalNewsCrawlerCrawlSchedules"},"authorizationType":null,"authorizationRole":"guest","method":"put","path":"/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules/{id}","name":"update"},{"specification":"This operation permanently removes a crawling schedule from the political_news_crawler_crawl_schedules table by its unique ID. Removal is a hard delete; there are no soft delete mechanisms for this entity's API. Deleting a schedule stops all future crawling tasks associated with it.\n\nIt requires appropriate administrative roles for authorization due to the impact on crawling operations. This endpoint does not take a request body and returns no data upon success.\n\nErrors are returned if the specified schedule ID does not exist.","description":"Delete a crawling schedule by its ID.\n\nThis operation permanently removes the schedule and disables associated crawl jobs.\n\nAuthorization is restricted to admin roles to ensure controlled operations.\n\nNo response body is returned. Errors occur if the ID does not exist.\n\nThis is a hard delete operation reflecting the physical removal of the schedule record in the database.","summary":"Delete specified political news crawler schedule","parameters":[{"name":"id","description":"Target crawl schedule's ID","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":null,"authorizationType":null,"authorizationRole":"guest","method":"delete","path":"/politicalNewsCrawler/guest/politicalNewsCrawler/crawlSchedules/{id}","name":"erase"},{"specification":"This operation performs complex filtering, searching, and paginated retrieval of guest users accessing the political news crawler API. Guests represent unauthenticated users identified by IP and user agent, tracked for analytics and monitoring. This search endpoint supports advanced query criteria and pagination controls for efficient data retrieval.\n\nThe guest data is stored in the political_news_crawler_guests table. Only read operations are permitted by guest users themselves, while admin roles can utilize this endpoint for monitoring and analysis.\n\nThe request body defines search filters and pagination parameters. Responses include paginated summary records of guests matching the criteria.\n\nThis endpoint requires admin authorization to ensure privacy and proper access control.","description":"Retrieve a filtered, sorted, and paginated list of political news crawler guest users.\n\nGuests are unauthenticated visitors recorded by IP, user-agent, and timestamps. This operation allows search filtering on these attributes and supports efficient pagination and sort ordering.\n\nSecurity restricts this to administrator-level access to protect user privacy.\n\nThe response contains a paginated list of guest summaries matching the filters.\n\nErrors may arise from invalid criteria or pagination parameters.\n\nNo modifications are made to guest records here, this is a read-only operation.","summary":"Search and retrieve filtered, paginated political news crawler guests","parameters":[],"requestBody":{"description":"Search criteria and pagination parameters for guests","typeName":"IPoliticalNewsCrawlerGuests.IRequest"},"responseBody":{"description":"Paginated list of guest user summary records","typeName":"IPageIPoliticalNewsCrawlerGuests.ISummary"},"authorizationType":null,"authorizationRole":"guest","method":"patch","path":"/politicalNewsCrawler/guest/guests","name":"search"},{"specification":"This operation retrieves detailed information about a specific guest user of the political news crawler system. It accesses the political_news_crawler_guests table which stores IP address and user agent data of unauthenticated guest users. The operation supports identification of guests by their unique UUID. It is read-only and accessible publicly without authentication as guests have no write permissions.","description":"Retrieve information about a specific guest user identified by guestId in the political_news_crawler_guests table.\n\nThis operation returns guest details including IP address and user agent string, as well as timestamps for creation and last update.\n\nSecurity considerations: this endpoint is public and provides read-only access to guest metadata only. No sensitive data or authentication details are exposed.\n\nRelated operations include listing all guest users and managing crawl jobs.\n\nErrors will be returned if guestId does not exist.","summary":"Retrieve a specific guest user by ID","parameters":[{"name":"guestId","description":"Unique identifier of the guest user","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"Detailed information of the specified guest user","typeName":"IPoliticalNewsCrawlerGuests"},"authorizationRoles":["guest"],"name":"at","path":"/politicalNewsCrawler/guest/guests/{guestId}","method":"get","authorizationRole":"guest","authorizationType":null},{"specification":"This operation retrieves a paginated list of crawl jobs. It operates on the political_news_crawler_crawl_jobs table which manages scheduled crawling tasks for political news sources. The operation supports complex search and filtering parameters to query crawl jobs efficiently.","description":"Retrieve a paginated and filtered list of crawl jobs managed by the political_news_crawler_crawl_jobs table.\n\nSupports search parameters including schedule ID and active status, allowing clients to find specific crawl jobs.\n\nSecurity: This endpoint is publicly accessible, providing read-only access to crawl job status information.\n\nRelated operations include querying specific crawl job details and creating new crawl jobs.\n\nErrors will be returned if search criteria are invalid.","summary":"Search and list crawl jobs","parameters":[],"requestBody":{"description":"Search criteria and pagination parameters for crawl job filtering","typeName":"IPoliticalNewsCrawlerCrawlJobsIRequest"},"responseBody":{"description":"Paginated list of crawl jobs matching criteria","typeName":"IPageIPoliticalNewsCrawlerCrawlJobs"},"authorizationRoles":["guest"],"name":"index","path":"/politicalNewsCrawler/guest/crawlJobs","method":"patch","authorizationRole":"guest","authorizationType":null},{"specification":"This operation retrieves detailed information of a specific crawl job identified by its ID. The crawl job represents a scheduled crawling operation for political news sources. It provides metadata about the job status, schedule, and activity.","description":"Retrieve detailed information about a crawl job specified by its unique ID.\n\nReturns complete crawl job information including schedule, activity status, and timestamps.\n\nSecurity: Requires user-level authorization.\n\nRelated operations include listing crawl jobs and creating new crawl jobs.\n\nErrors occur if the crawl job ID does not exist.","summary":"Retrieve a crawl job by ID","parameters":[{"name":"id","description":"Unique identifier of the crawl job","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"Detailed crawl job information","typeName":"IPoliticalNewsCrawlerCrawlJobs"},"authorizationRoles":["guest"],"name":"at","path":"/politicalNewsCrawler/guest/crawlJobs/{id}","method":"get","authorizationRole":"guest","authorizationType":null},{"specification":"This operation creates a new crawl job record that schedules crawling tasks for political news sources. The crawl job links to specific crawl sources and schedules, defines its active state, and initializes timing metadata. This enables dynamic control over crawl task execution.","description":"Create a new crawl job to schedule crawling operations for a political news source.\n\nRequires specifying the associated crawl source, crawl schedule, and active status.\n\nReturns the detailed crawl job record after creation.\n\nSecurity: Requires user role authorization.\n\nRelated operations include listing crawl jobs and retrieving crawl job details.\n\nErrors occur if required fields are missing or references invalid IDs.","summary":"Create a new crawl job","parameters":[],"requestBody":{"description":"Information to create a new crawl job","typeName":"IPoliticalNewsCrawlerCrawlJobsICreate"},"responseBody":{"description":"Created crawl job information","typeName":"IPoliticalNewsCrawlerCrawlJobs"},"authorizationRoles":["guest"],"name":"create","path":"/politicalNewsCrawler/guest/crawlJobs","method":"post","authorizationRole":"guest","authorizationType":null},{"specification":"This operation updates an existing crawling job resource in the political_news_crawler_crawl_jobs table in the Prisma DB schema. Users can modify the job's active status and metadata such as the last run start and completion timestamps. This update allows controlling the scheduling and execution state of a specific crawl job associated with a given crawl source and schedule.","description":"Update the details of an existing crawl job identified by its unique ID. This enables controlling whether the crawl job is active, and can adjust timing metadata such as last run start and completion times. The operation is crucial for administrators or backend systems managing crawl schedules and execution state for political news data retrieval.\n\nSecurity considerations: this endpoint requires guest role authorization as per system role configuration.\n\nThe operation corresponds to the political_news_crawler_crawl_jobs table and updates mutable fields while preserving relational integrity.\n\nBusiness logic includes validation of input timestamps and ensuring the referenced crawl source and schedule remain valid during the update process.\n\nRelated operations include endpoints for retrieving crawl job details and managing crawl attempts.\n\nExpected behavior includes returning the updated crawl job resource upon success or appropriate error messages on failure.","summary":"Update an existing crawl job by ID","parameters":[{"name":"id","in":"path","description":"Unique identifier of the crawl job to update","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Update data for crawl job","typeName":"IPoliticalNewsCrawlerCrawlJob.IUpdate"},"responseBody":{"description":"Updated crawl job information","typeName":"IPoliticalNewsCrawlerCrawlJob"},"authorizationType":null,"authorizationRole":"guest","name":"update","path":"/politicalNewsCrawler/guest/crawlJobs/{id}","method":"put"},{"specification":"This operation performs a permanent deletion (hard delete) of a crawl job identified by its ID from the political_news_crawler_crawl_jobs table. It removes the job record and all references from the system, disabling scheduled crawling tasks accordingly.","description":"Permanently remove a crawl job by its unique ID. This operation deletes the record from the database and disables further scheduled crawling for the associated crawl source and schedule. The deletion is irreversible.\n\nSecurity considerations: this endpoint requires guest role authorization as per system role configuration.\n\nRelated operations include updating crawl job details and managing crawl attempts.\n\nExpected behavior is the complete removal of the job and returning no response body upon success.","summary":"Erase a crawl job by ID","parameters":[{"name":"id","in":"path","description":"Unique identifier of the crawl job to remove","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":null,"authorizationType":null,"authorizationRole":"guest","name":"erase","path":"/politicalNewsCrawler/guest/crawlJobs/{id}","method":"delete"},{"specification":"This operation retrieves a paginated list of crawl attempts for a specific crawl job identified by crawlJobId. It supports search, filtering, and sorting of crawl attempts associated with the job.","description":"Retrieve a filtered and paginated list of crawl attempts performed under a specific crawl job. This enables monitoring and auditing of individual execution runs, including success status, run times, and error details.\n\nThe operation accepts the crawl job ID as a path parameter and supports complex search criteria in the request body.\n\nIt returns a paginated list of crawl attempt summaries with metadata.\n\nAccess to this operation requires guest role authorization as per system role configuration.\n\nRelated operations include retrieving individual crawl attempt details.\n\nExpected behavior is to supply crawl attempt data efficiently and support pagination for large datasets.","summary":"List crawl attempts for a specific crawl job","parameters":[{"name":"crawlJobId","in":"path","description":"Unique identifier of the crawl job whose attempts to retrieve","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Search parameters for crawl attempts","typeName":"IPoliticalNewsCrawlerCrawlAttempt.IRequest"},"responseBody":{"description":"Paginated list of crawl attempt summaries","typeName":"IPageIPoliticalNewsCrawlerCrawlAttempt.ISummary"},"authorizationType":null,"authorizationRole":"guest","name":"index","path":"/politicalNewsCrawler/guest/crawlJobs/{crawlJobId}/crawlAttempts","method":"patch"},{"specification":"This operation retrieves detailed information about a specific crawl attempt by its unique ID linked to a crawl job.","description":"Fetch detailed information for a crawl attempt identified by its unique ID, linked to a specific crawl job. This allows inspection of individual crawl execution details including timestamps, success status, and error messages.\n\nThe operation requires both the crawl job ID and the crawl attempt ID to locate the record.\n\nAccess to this operation requires guest role authorization as per system role configuration.\n\nRelated operations include listing crawl attempts for a crawl job.\n\nExpected behavior is to return the crawl attempt resource or an error if not found.","summary":"Get details of a crawl attempt by ID","parameters":[{"name":"crawlJobId","in":"path","description":"Unique identifier of the crawl job containing the attempt","schema":{"type":"string","format":"uuid"}},{"name":"id","in":"path","description":"Unique identifier of the crawl attempt to retrieve","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"Detailed crawl attempt information","typeName":"IPoliticalNewsCrawlerCrawlAttempt"},"authorizationType":null,"authorizationRole":"guest","name":"at","path":"/politicalNewsCrawler/guest/crawlJobs/{crawlJobId}/crawlAttempts/{id}","method":"get"},{"specification":"This operation creates a new crawl attempt for a given crawl job, allowing the system to initiate a crawling task for political news data collection. It operates on the political_news_crawler_crawl_attempts table, which tracks individual executions of crawl jobs including start and completion timestamps, success status, and associated raw data references. The create action requires a POST method to the /crawlJobs/{crawlJobId}/crawlAttempts path, where crawlJobId specifies the target crawl job. This operation supports recording the initiation of new crawl attempt activities by authenticated system components responsible for managing crawler executions.","description":"Create a new crawl attempt record associated with a specific crawl job. The operation logs the start of a crawl process for a political news source, enabling tracking of individual crawl executions.\n\nSecurity considerations: This operation is restricted to system components or users with a role capable of scheduling and managing crawling tasks. It requires ownership or management privileges for the referenced crawl job.\n\nThe API request must include details such as the crawl job ID and initial crawl attempt metadata like the start time. The response confirms creation with complete crawl attempt details.\n\nThis operation interacts directly with the political_news_crawler_crawl_attempts database table, ensuring each crawl attempt is logged accurately for audit and operational monitoring.\n\nValidation rules prevent creation with nonexistent crawl job IDs and ensure timestamp formats conform to ISO 8601 standards.\n\nThis API is typically called by backend scheduler services or crawling orchestrators to start crawl attempts.","summary":"Create a crawl attempt for a specified crawl job","parameters":[{"name":"crawlJobId","in":"path","schema":{"type":"string","format":"uuid"},"description":"Unique identifier of the crawl job"}],"requestBody":{"description":"Creation information for a new crawl attempt","typeName":"IPoliticalNewsCrawlerCrawlAttempt.ICreate"},"responseBody":{"description":"Information about the created crawl attempt","typeName":"IPoliticalNewsCrawlerCrawlAttempt"},"authorizationType":null,"authorizationRole":"guest","name":"createCrawlAttempt","path":"/politicalNewsCrawler/guest/crawlJobs/{crawlJobId}/crawlAttempts","method":"post"},{"specification":"This operation updates an existing crawl attempt, providing the ability to modify status, timestamps, and error messages after a crawling execution has started or completed. It operates on the political_news_crawler_crawl_attempts table, uniquely identified by the crawl attempt ID and crawl job ID in the URL path. The HTTP method is PUT, and the path is /crawlJobs/{crawlJobId}/crawlAttempts/{id}.\n\nThe API allows adjusting the details of a crawl attempt, including marking success or failure, updating completion times, and recording error messages for audit and debugging.\n\nSecurity considerations ensure only authorized system roles can update crawl attempt records, typically crawler orchestrators or administrators.\n\nThe data model requires timestamps in ISO 8601 format and validates existence of the referenced crawl job and attempt ID.\n\nThis capability is essential for managing and tracking crawling operations' lifecycle and health.","description":"Update details of an existing crawl attempt record associated with a specified crawl job. This operation enables modification of crawl attempt state, success indication, completion time, and error information.\n\nSecurity: Restricted to roles with permission to manage crawling tasks. This operation enforces validation of both crawl job and crawl attempt identifiers.\n\nThe operation interacts with the political_news_crawler_crawl_attempts database table, ensuring consistent updates to crawl execution logs.\n\nCompleted timestamps must be later than the started timestamp. Error message updates may be used for debugging failed attempts.\n\nThis API is typically called by crawler system components upon completion or error detection in crawling.","summary":"Update details of a crawl attempt by ID under a given crawl job","parameters":[{"name":"crawlJobId","in":"path","schema":{"type":"string","format":"uuid"},"description":"Unique identifier of the crawl job"},{"name":"id","in":"path","schema":{"type":"string","format":"uuid"},"description":"Unique identifier of the crawl attempt"}],"requestBody":{"description":"Updated crawl attempt information","typeName":"IPoliticalNewsCrawlerCrawlAttempt.IUpdate"},"responseBody":{"description":"Updated crawl attempt details","typeName":"IPoliticalNewsCrawlerCrawlAttempt"},"authorizationType":null,"authorizationRole":"guest","name":"updateCrawlAttempt","path":"/politicalNewsCrawler/guest/crawlJobs/{crawlJobId}/crawlAttempts/{id}","method":"put"},{"specification":"This operation deletes an existing crawl attempt identified by both crawl job ID and crawl attempt ID in the URL. It acts on the political_news_crawler_crawl_attempts table and performs a hard delete because the schema does not contain soft delete fields preventing deletion. This HTTP DELETE endpoint at /crawlJobs/{crawlJobId}/crawlAttempts/{id} removes the crawl attempt permanently from the database.\n\nThis delete operation requires precise matching of identifiers for safety. It is restricted to administrative or system components authorized to manage crawl operations.\n\nThis capability is used to clean up crawl attempt logs, typically for maintenance or removing invalid entries.\n\nNo request body is needed for this operation, and it returns no content upon success.\n\nValidation ensures both crawl job and crawl attempt exist before deletion.","description":"Permanently delete a crawl attempt record by specifying its crawl job ID and crawl attempt ID.\n\nThis is a hard delete operation with no support for soft deletion or recovery.\n\nAccess is restricted to users with administrative rights or system-level permissions.\n\nThe operation directly impacts the political_news_crawler_crawl_attempts table.\n\nNo response body is returned upon success.\n\nUse with caution due to permanent data removal.","summary":"Delete a crawl attempt record by crawl job ID and crawl attempt ID","parameters":[{"name":"crawlJobId","in":"path","schema":{"type":"string","format":"uuid"},"description":"Unique identifier of the crawl job"},{"name":"id","in":"path","schema":{"type":"string","format":"uuid"},"description":"Unique identifier of the crawl attempt"}],"requestBody":null,"responseBody":null,"authorizationType":null,"authorizationRole":"guest","name":"eraseCrawlAttempt","path":"/politicalNewsCrawler/guest/crawlJobs/{crawlJobId}/crawlAttempts/{id}","method":"delete"},{"specification":"Retrieves a paginated and filtered list of crawled news items associated with a specified crawl attempt. It operates on the political_news_crawler_crawled_news table, which contains metadata of individual news articles obtained from crawl attempts.\n\nThe PATCH method at /crawlAttempts/{crawlAttemptId}/crawledNews supports advanced query parameters in the request body for filtering, sorting, and pagination.\n\nThe response includes a paginated collection of summary crawled news matching the query.\n\nThis endpoint is publicly accessible with no authentication to support read-only access to harvested news data.\n\nIt enables clients to retrieve detailed news items tied to particular crawl executions for display, analysis, or monitoring.\n\nError handling includes returning empty results for queries with no matching data and clear messages for malformed queries.","description":"Retrieve a paginated, filtered list of crawled news linked to a specific crawl attempt identified by crawlAttemptId.\n\nSupports complex querying including search filters, sorting, and pagination controls via request body.\n\nThis publicly accessible endpoint requires no authentication, allowing open read access to crawl results.\n\nThe operation queries the political_news_crawler_crawled_news database table and returns data optimized for UI display and analysis.\n\nTypical usage includes news aggregation views, crawl session detail pages, and backend analytics.\n\nProper error handling returns empty pages if no data matches the query and validation errors on bad requests.","summary":"List crawled news filtered by crawl attempt ID","parameters":[{"name":"crawlAttemptId","in":"path","schema":{"type":"string","format":"uuid"},"description":"Unique identifier of the crawl attempt"}],"requestBody":{"description":"Search and pagination parameters for filtering crawled news","typeName":"IPoliticalNewsCrawlerCrawledNews.IRequest"},"responseBody":{"description":"Paginated crawled news summaries matching filters","typeName":"IPageIPoliticalNewsCrawlerCrawledNews.ISummary"},"authorizationType":null,"authorizationRole":null,"name":"indexCrawledNews","path":"/politicalNewsCrawler/crawlAttempts/{crawlAttemptId}/crawledNews","method":"patch"},{"specification":"This operation manages the detailed CRUD (Create, Read, Update, Delete) operations for the CrawledNews entity associated with specific CrawlAttempts within the politicalNewsCrawler backend system. The CrawledNews entity represents metadata about individual political news articles retrieved during crawling attempts, including essential attributes such as the article's URL, title, and publish date. This operation interfaces specifically with the political_news_crawler_crawled_news table in the Prisma schema, ensuring data integrity and referential integrity by requiring the associated crawlAttemptId parameter. It enables precise management of news article metadata linked to crawl executions, providing mechanisms for creating new articles, retrieving existing article details, updating article information, or permanently deleting articles if no longer relevant. Each method carefully validates the crawlAttemptId and id path parameters to ensure API operations target the correct hierarchical resource and maintain system consistency.","description":"This operation retrieves detailed metadata of a specific political news article within a given crawl attempt. It returns the article's unique identifier, URL, title, and publishing date.\n\nAccess to this operation requires no authentication, reflecting the system's public API design. The operation references the political_news_crawler_crawled_news table, enforcing relationship integrity by requiring the crawlAttemptId path parameter that links the article to its crawl attempt.\n\nThe API throws an error if the specified article or crawl attempt does not exist. It is designed to provide comprehensive data for client applications that need access to individual news items.\n\nThis operation works closely with create, update, and delete endpoints providing full lifecycle management of news articles within crawl attempts.","summary":"Retrieve a specific crawled news article by crawlAttemptId and article id","parameters":[{"name":"crawlAttemptId","in":"path","description":"Unique identifier of the crawl attempt containing the news article","schema":{"type":"string","format":"uuid"}},{"name":"id","in":"path","description":"Unique identifier of the crawled news article","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"Detailed information of the requested crawled news article","typeName":"IPoliticalNewsCrawlerCrawledNews"},"authorizationRoles":[],"name":"at","path":"/politicalNewsCrawler/crawlAttempts/{crawlAttemptId}/crawledNews/{id}","method":"get","authorizationRole":null,"authorizationType":null},{"specification":"This operation creates a new CrawledNews record within a specified CrawlAttempt. CrawledNews records represent metadata about political news articles retrieved during a crawl execution.\n\nThe endpoint accepts a creation DTO containing required properties such as URL, optional title, and optional publish timestamp.\n\nThe operation ensures the new article is correctly linked to the specified CrawlAttempt identified by crawlAttemptId to maintain referential integrity.\n\nSuccessful creation returns the newly created CrawledNews data.\n\nThis operation is intended for backend administration or workflow automation scenarios where new news articles may be added to a crawl attempt post-crawl.\n\nIt references the political_news_crawler_crawled_news table and enforces correct entity associations.","description":"Create a new crawled news article associated with the specified crawl attempt.\n\nThe request body must contain the minimum required information for the crawler news metadata, including a valid URL. Title and published date are optional but recommended for completeness.\n\nNo authentication is required for this operation. On success, the newly created news article's full details are returned.\n\nThis operation complements retrieval and management endpoints allowing clients to add new news entries for a crawl attempt.","summary":"Create a new crawled news article for a given crawlAttemptId","parameters":[{"name":"crawlAttemptId","in":"path","description":"Unique identifier of the crawl attempt to which the news article belongs","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Information needed to create a new crawled news article","typeName":"IPoliticalNewsCrawlerCrawledNews.ICreate"},"responseBody":{"description":"Full details of the created crawled news article","typeName":"IPoliticalNewsCrawlerCrawledNews"},"authorizationRoles":[],"name":"create","path":"/politicalNewsCrawler/crawlAttempts/{crawlAttemptId}/crawledNews","method":"post","authorizationRole":null,"authorizationType":null},{"specification":"This operation updates an existing CrawledNews entity associated with a specific CrawlAttempt. It requires the crawlAttemptId and the unique id of the CrawledNews record to ensure the correct resource is targeted.\n\nThe update payload accepts partial or full modifications to properties such as the URL, title, and published date.\n\nUpon successful update, the operation returns the modified CrawledNews record.\n\nThis operation references the political_news_crawler_crawled_news table and keeps strict referential consistency by requiring valid identifiers for both the crawl attempt and news article.\n\nIt supports backend and client scenarios where crawled news metadata needs amendments after creation.","description":"Update metadata of a crawled news article within the specified crawl attempt.\n\nOnly provided fields in the request body will be updated; others remain unchanged.\n\nThe operation validates the existence of the target article linked to the crawl attempt.\n\nNo authentication is required. Responses include the updated entity details.\n\nThis operation works in conjunction with create, retrieve, and delete endpoints to provide full management capabilities.","summary":"Update an existing crawled news article by crawlAttemptId and article id","parameters":[{"name":"crawlAttemptId","in":"path","description":"Unique identifier of the crawl attempt containing the news article","schema":{"type":"string","format":"uuid"}},{"name":"id","in":"path","description":"Unique identifier of the crawled news article","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Fields to update for the crawled news article","typeName":"IPoliticalNewsCrawlerCrawledNews.IUpdate"},"responseBody":{"description":"Updated details of the crawled news article","typeName":"IPoliticalNewsCrawlerCrawledNews"},"authorizationRoles":[],"name":"update","path":"/politicalNewsCrawler/crawlAttempts/{crawlAttemptId}/crawledNews/{id}","method":"put","authorizationRole":null,"authorizationType":null},{"specification":"This operation permanently removes a CrawledNews record identified by its ID and associated CrawlAttempt ID from the database.\n\nIt requires both crawlAttemptId and article ID path parameters to uniquely identify the resource.\n\nThis is a hard delete operation since the Prisma schema for political_news_crawler_crawled_news does not specify soft delete timestamp.\n\nUpon successful execution, the news article is completely removed and cannot be recovered.\n\nNo response body is returned, and no authentication is required.\n\nThis operation must be used carefully as it irreversibly deletes article metadata tied to crawling attempts.","description":"Permanently delete a specific crawled news article associated with the given crawl attempt.\n\nThis operation removes the record from the database permanently.\n\nIt requires valid and existing identifiers for both the crawl attempt and the article.\n\nNo authentication is required to perform this operation.\n\nThere is no response body upon success.\n\nDeletion is irreversible, so caution is advised.","summary":"Delete a crawled news article by crawlAttemptId and article id","parameters":[{"name":"crawlAttemptId","in":"path","description":"Unique identifier of the crawl attempt containing the news article","schema":{"type":"string","format":"uuid"}},{"name":"id","in":"path","description":"Unique identifier of the crawled news article to delete","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":null,"authorizationRoles":[],"name":"erase","path":"/politicalNewsCrawler/crawlAttempts/{crawlAttemptId}/crawledNews/{id}","method":"delete","authorizationRole":null,"authorizationType":null},{"specification":"This operation retrieves a paginated list of raw crawled political news data storage entries from the political_news_crawler_raw_data_storage table in the Prisma schema. It enables filtering, sorting, and pagination based on various criteria such as crawl source, crawl job, crawl timestamp, and file metadata. This operation supports efficient retrieval of raw data files metadata for further processing or audit purposes.","description":"Retrieve a filtered and paginated list of raw data storage metadata entries for political news crawling. The operation supports filtering by crawl source and crawl job identifiers, file format types, crawl timestamps, and file sizes. Sorting and pagination options enable efficient browsing through large datasets stored in cloud object storage.\n\nSecurity considerations include limited access to authenticated users with appropriate read privileges, as raw data files may contain sensitive or proprietary information. \n\nThis operation is tightly integrated with the political_news_crawler_raw_data_storage table defined in the Prisma schema, encompassing all relevant fields and relationships. The response returns simplified summary information suited for list displays.\n\nThere is no request body since this is a PATCH method designed for complex search and filtering inputs. The response contains paginated summary records that can be used to locate and verify raw data files before further processing or download.","summary":"Search and retrieve a filtered, paginated list of raw data storage entries","parameters":[],"requestBody":{"description":"Search criteria and pagination parameters for raw data storage filtering","typeName":"IPoliticalNewsCrawlerRawDataStorage.IRequest"},"responseBody":{"description":"Paginated list of raw data storage summary matching the search criteria","typeName":"IPageIPoliticalNewsCrawlerRawDataStorage.ISummary"},"authorizationType":null,"authorizationRole":"guest","name":"index","path":"/politicalNewsCrawler/guest/rawDataStorage","method":"patch"},{"specification":"This operation retrieves detailed information about a specific raw data storage entry using its unique identifier from the political_news_crawler_raw_data_storage table in the Prisma schema. It returns all details including storage key, file format, size, crawl timestamp, and associated crawl source and job.\n\nAccess control restricts this operation to authenticated users with appropriate permissions to view sensitive raw data metadata. \n\nThe response provides a full detailed entity representation allowing clients to inspect or validate a specific raw data item.","description":"Retrieve detailed information about a specific raw data storage entry identified by rawDataStorageId. This operation fetches all fields from political_news_crawler_raw_data_storage and related references to crawl source and crawl job.\n\nSecurity requires authenticated user access to prevent unauthorized raw data exposure.\n\nClients can use this operation to access raw data file details necessary for processing or manual inspection.","summary":"Retrieve detailed raw data storage entry by ID","parameters":[{"name":"rawDataStorageId","description":"Unique identifier of the target raw data storage entry","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"Detailed raw data storage entry information","typeName":"IPoliticalNewsCrawlerRawDataStorage"},"authorizationType":null,"authorizationRole":"guest","name":"at","path":"/politicalNewsCrawler/guest/rawDataStorage/{rawDataStorageId}","method":"get"},{"specification":"This operation creates a new raw data storage record in the political_news_crawler_raw_data_storage table in the Prisma schema. It accepts creation details such as crawl source ID, optional crawl job ID, storage key, file format, file size, checksum, and crawl timestamp.\n\nCreation operations require authenticated user roles to ensure data integrity and traceability. \n\nUpon successful creation, the response returns the full entity including assigned ID and timestamps.","description":"Create a new raw data storage record representing a raw crawled data file stored in cloud object storage. The request body must contain all required fields such as crawlSourceId, storageKey, fileFormat, fileSizeBytes, and crawlTimestamp, with optional fields for crawlJobId and checksum.\n\nSecurity requires authenticated access to prevent unauthorized data addition.\n\nThis operation enables the persistence of raw crawl data metadata critical for downstream processing and archival.","summary":"Create new raw data storage entry","parameters":[],"requestBody":{"description":"Creation information of the raw data storage entry","typeName":"IPoliticalNewsCrawlerRawDataStorage.ICreate"},"responseBody":{"description":"Created raw data storage entry information","typeName":"IPoliticalNewsCrawlerRawDataStorage"},"authorizationType":null,"authorizationRole":"guest","name":"create","path":"/politicalNewsCrawler/guest/rawDataStorage","method":"post"},{"specification":"This operation updates an existing raw data storage record identified by rawDataStorageId in the political_news_crawler_raw_data_storage table of the Prisma schema. It accepts update data such as crawl source reference, crawl job reference, storage key, file format, file size, checksum, and crawl timestamp.\n\nThe operation enforces authorization restricting updates to authenticated users only.\n\nUpon successful update, the full updated raw data storage entity is returned for client confirmation and further processing.","description":"Update an existing raw data storage record representing raw crawled political news data. The request body must contain updatable fields such as crawlSourceId, optional crawlJobId, storageKey, fileFormat, fileSizeBytes, checksum, and crawlTimestamp.\n\nThis operation requires authenticated user roles to ensure secure modification of raw data metadata.\n\nClients can use this endpoint to correct or enhance metadata related to raw data files post-crawling or during data reconciliation.","summary":"Update raw data storage entry by ID","parameters":[{"name":"rawDataStorageId","description":"Unique identifier of the target raw data storage entry","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Update information of the raw data storage entry","typeName":"IPoliticalNewsCrawlerRawDataStorage.IUpdate"},"responseBody":{"description":"Updated raw data storage entry information","typeName":"IPoliticalNewsCrawlerRawDataStorage"},"authorizationType":null,"authorizationRole":"guest","name":"update","path":"/politicalNewsCrawler/guest/rawDataStorage/{rawDataStorageId}","method":"put"},{"specification":"This operation permanently deletes a raw data storage record identified by its UUID from the political_news_crawler_raw_data_storage table. This table stores metadata and references for raw political news data collected from various crawling sources, including storage keys for cloud object storage locations, file formats, file sizes, checksums, and crawl timestamps. Deleting a record here removes the raw data metadata and all associated local cache files and processed content entries due to cascading. The delete operation is a hard delete as no explicit soft delete is handled via this endpoint. This is intended for backend administrative cleanup or data lifecycle management.","description":"This DELETE operation removes a specific raw data storage record by its unique identifier. The targeted record belongs to the political_news_crawler_raw_data_storage database entity, which contains critical metadata linking crawled news data to their storage locations.\n\nBy deleting this record, all associated local cache files and processed content linked through foreign keys will also be deleted as cascades are enabled, ensuring referential integrity.\n\nSecurity considerations mandate that only authorized administrative roles can execute this deletion due to the potential for data loss.\n\nUsage of this endpoint requires precise identification of the record to avoid unintended data removal. The API does not soft delete; the resource is permanently removed.\n\nErrors such as attempting to delete a non-existent ID should return a 404 Not Found response.\n\nThis operation does not require a request body and does not yield a response body upon success.","summary":"Delete a raw data storage record permanently by ID","parameters":[{"name":"rawDataStorageId","in":"path","description":"Unique identifier of the raw data storage record to delete","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":null,"authorizationRoles":["admin"],"name":"erase","path":"/politicalNewsCrawler/guest/rawDataStorage/{rawDataStorageId}","method":"delete","authorizationRole":"admin","authorizationType":null},{"specification":"This operation retrieves a paginated list of local cache files associated with a given raw data storage record from the political_news_crawler_local_cache_files table. This table holds metadata about local filesystem cache copies of raw crawled political news data, including file paths, file sizes, TTL expiration times, and deletion timestamps. Listing local cache files provides fast retrieval and backup verification for cached raw data. The API supports pagination and filtering by the associated raw data storage ID.\n\nSecurity considerations include ensuring only authorized administrators or backend services access these listings due to potential sensitive file path exposures.\n\nThis operation requires the raw data storage ID as a path parameter and supports optional search and pagination filters in the request body.","description":"Retrieve a paginated list of local cache file metadata records linked to a specific raw data storage record. Each local cache file entry includes details such as the filesystem path, file size, TTL expiration for automatic deletion, and deletion status.\n\nThe response supports pagination to handle potentially large numbers of cached files efficiently.\n\nThis operation is intended for backend management and is not publicly accessible.\n\nErrors in specifying a non-existent raw data storage ID should produce a 404 Not Found error.\n\nRequest body supports filtering and pagination parameters according to the IPoliticalNewsCrawlerRawDataStorageLocalCacheFile.IRequest definition.\n\nResponse includes a paginated collection of local cache file summaries.","summary":"List local cache files for a raw data storage record","parameters":[{"name":"rawDataStorageId","in":"path","description":"Unique identifier of the raw data storage record","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Filtering and pagination parameters for listing local cache files","typeName":"IPoliticalNewsCrawlerRawDataStorageLocalCacheFile.IRequest"},"responseBody":{"description":"Paginated list of local cache file summaries linked to the raw data storage","typeName":"IPageIPoliticalNewsCrawlerRawDataStorageLocalCacheFile.ISummary"},"authorizationRoles":["guest"],"name":"index","path":"/politicalNewsCrawler/guest/rawDataStorage/{rawDataStorageId}/localCacheFiles","method":"patch","authorizationRole":"guest","authorizationType":null},{"specification":"This operation retrieves a single local cache file metadata record by its unique identifier associated with a given raw data storage record. The local cache file entity represents a local filesystem cached copy of raw crawled political news data, including fields for file path, file size, TTL expiration, and deletion timestamp.\n\nAccessing individual local cache files supports management and auditing of cached copies for data recovery and integrity checks.\n\nThis API endpoint requires both the raw data storage ID and local cache file ID as path parameters to uniquely identify the cache file record.\n\nSecurity restrictions limit access to authorized administrative or backend roles.\n\nResponses return detailed information about the local cache file or 404 if no matching record is found.","description":"Retrieve a single local cache file metadata entry associated with a specific raw data storage record by its unique ID. The response includes all critical details of the cached file including local file path, size, TTL expiration, and deletion status.\n\nThis operation supports backend cache management tasks and data integrity verification.\n\nIf the specified IDs do not exist, a 404 response is expected.\n\nThis endpoint provides detailed, actionable metadata for local cached raw data file inspection.","summary":"Retrieve a specific local cache file record by ID","parameters":[{"name":"rawDataStorageId","in":"path","description":"Unique identifier of raw data storage record","schema":{"type":"string","format":"uuid"}},{"name":"localCacheFileId","in":"path","description":"Unique identifier of local cache file record","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"Detailed local cache file information","typeName":"IPoliticalNewsCrawlerRawDataStorageLocalCacheFile"},"authorizationRoles":["guest"],"name":"at","path":"/politicalNewsCrawler/guest/rawDataStorage/{rawDataStorageId}/localCacheFiles/{localCacheFileId}","method":"get","authorizationRole":"guest","authorizationType":null},{"specification":"This operation creates a new local cache file record representing a cached copy of raw crawled political news data stored locally. It requires specifying the raw data storage reference, local file path, file size in bytes, TTL expiration datetime for automated deletion, and creation/update timestamps.\n\nThis API enables backend systems to track and manage cached files alongside the authoritative cloud object storage records.\n\nSecurity considerations limit creation capability to administrative roles to prevent unauthorized cache entries.\n\nProper validation includes verifying the referenced raw data storage ID exists and the TTL expiration is a valid future datetime.\n\nThe response returns the created local cache file record including all specified fields plus generated identifiers.","description":"Create a new local cache file metadata record for a raw data storage entry. The record includes the local file path, file size, TTL expiration datetime, and timestamps.\n\nThis operation facilitates tracking of local cached copies supporting data redundancy and faster access.\n\nStrict access control limits use to admin roles.\n\nValidation ensures payload completeness and data integrity.\n\nErrors include 400 for invalid data and 404 if referenced raw data storage record is not found.\n\nReturns the newly created local cache file record with its unique identifier.","summary":"Create a new local cache file record","parameters":[{"name":"rawDataStorageId","in":"path","description":"Unique identifier of the associated raw data storage record","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Information needed to create a new local cache file record","typeName":"IPoliticalNewsCrawlerRawDataStorageLocalCacheFile.ICreate"},"responseBody":{"description":"The created local cache file record","typeName":"IPoliticalNewsCrawlerRawDataStorageLocalCacheFile"},"authorizationRoles":["admin"],"name":"create","path":"/politicalNewsCrawler/guest/rawDataStorage/{rawDataStorageId}/localCacheFiles","method":"post","authorizationRole":"admin","authorizationType":null},{"specification":"This operation updates an existing local cache file record that duplicates the raw crawled data for faster access and resiliency against cloud storage outages. It belongs to the political_news_crawler_local_cache_files table. Users of this API provide the new local file path, file size, TTL expiration timestamp to extend caching retention, and optionally the deletion timestamp to mark soft deletion. This enables management of local copies of raw data with a strict TTL policy of one month, ensuring timely cache expiration and clean-up as per business rules. The operation requires the rawDataStorageId and localCacheFileId path parameters matching the records to be updated.","path":"/politicalNewsCrawler/guest/rawDataStorage/{rawDataStorageId}/localCacheFiles/{localCacheFileId}","method":"put","summary":"Update a specific local cache file metadata for a raw data storage record","description":"This API endpoint allows updating the metadata of a specific local cache file associated with raw data storage. This endpoint supports modifying key properties such as the local file path (location of the cached file), file size in bytes for accurate storage accounting, the TTL expiration timestamp which determines when the local cache should be deleted, and an optional deleted_at timestamp which marks the record as soft deleted.\n\nUsers must supply valid path parameters identifying the raw data storage and the local cache file for targeting the update. The input body must conform to the properties defined in IPoliticalNewsCrawlerLocalCacheFiles.IUpdate.\n\nSoft deletion is handled by setting the deleted_at timestamp; if null, the cache file record is considered active. This operation enforces TTL policies to manage local cache lifecycle and assists in maintaining data consistency between cloud storage and local caches.\n\nOnly authorized roles (guest) can update these records, ensuring control and security over cache metadata management.\n\nErrors on invalid IDs or permission violations will result in appropriate HTTP error responses.","parameters":[{"name":"rawDataStorageId","description":"Unique identifier of the raw data storage record","schema":{"type":"string","format":"uuid"}},{"name":"localCacheFileId","description":"Unique identifier of the local cache file record to update","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Local cache file update payload","typeName":"IPoliticalNewsCrawlerLocalCacheFiles.IUpdate"},"responseBody":{"description":"Updated local cache file record","typeName":"IPoliticalNewsCrawlerLocalCacheFiles"},"authorizationType":null,"authorizationRole":"guest","name":"updateLocalCacheFile"},{"specification":"This operation deletes a specific local cache file record linked to raw data storage. It performs a soft delete by setting a deleted_at timestamp, consistent with the political_news_crawler_local_cache_files table design supporting soft deletion. Users must specify both rawDataStorageId and localCacheFileId path parameters to identify the record to delete. The operation does not require a request body and does not return response body content. The operation is protected by guest role authorization to prevent unauthorized cache record deletions.","path":"/politicalNewsCrawler/guest/rawDataStorage/{rawDataStorageId}/localCacheFiles/{localCacheFileId}","method":"delete","summary":"Soft delete a specific local cache file record linked to raw data storage","description":"This API endpoint soft deletes a local cache file record associated with raw crawled data by setting the deleted_at timestamp. This marks the record as logically deleted without physically removing the data from the database. Users need to provide the raw data storage identifier and the local cache file identifier in the path parameters to target the deletion.\n\nSoft deletion enables the system to keep historical cache data records for audit and recovery while excluding logically deleted entries from active queries. This helps enforce the TTL deletion policy and supports clean cache lifecycle management.\n\nThe endpoint is accessible only to users with guest privileges to ensure operational security. If the record does not exist or the user lacks permission, the system returns appropriate errors.\n\nNo request or response body is required for this operation.","parameters":[{"name":"rawDataStorageId","description":"Unique identifier of the raw data storage record","schema":{"type":"string","format":"uuid"}},{"name":"localCacheFileId","description":"Unique identifier of the local cache file record to delete","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":null,"authorizationType":null,"authorizationRole":"guest","name":"eraseLocalCacheFile"},{"specification":"This operation retrieves a list of processed content records associated with a specific raw data storage record. It supports filtering, pagination, and sorting via the request body of type IPoliticalNewsCrawlerProcessedContent.IRequest. The processed content represents LLM-generated data such as summaries, highlights, or analyses corresponding to raw political news. The API path includes rawDataStorageId as a path parameter to identify the target raw data record. The response returns a paginated list of processed content summaries for client consumption. Public access is allowed without authentication roles to ensure broad API availability for news clients.","path":"/politicalNewsCrawler/rawDataStorage/{rawDataStorageId}/processedContent","method":"patch","summary":"Retrieve filtered, paginated list of processed content for a raw data record","description":"This endpoint allows clients to search and retrieve processed LLM-generated content linked to a specific raw data storage record. The input request body includes filtering and pagination parameters to control the result set. Processed content types include summaries, highlights, and analysis results. Clients use this endpoint to obtain enriched news content derived from raw crawled data.\n\nThe response returns a paginated list of processed content summaries including essential metadata suitable for display purposes. This operation is publicly accessible requiring no authentication.\n\nPath parameter rawDataStorageId identifies the raw data record to which the processed content belongs. Filters in the request body allow clients to target specific content types, date ranges, and pagination preferences.\n\nErrors for invalid IDs or malformed requests will be returned appropriately.\n\nThis operation links directly to the political_news_crawler_processed_content table.","parameters":[{"name":"rawDataStorageId","description":"Unique identifier of the raw data storage record","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Search criteria and pagination for processed content filtering","typeName":"IPoliticalNewsCrawlerProcessedContent.IRequest"},"responseBody":{"description":"Paginated list of processed content summaries matching criteria","typeName":"IPageIPoliticalNewsCrawlerProcessedContent.ISummary"},"authorizationType":null,"authorizationRole":null,"name":"searchProcessedContent"},{"specification":"This operation retrieves detailed information for a specific processed content record linked to a raw data storage entry. It requires both rawDataStorageId and processedContentId path parameters identifying the exact processed content item. The response returns full entity details including the content body, generation timestamp, and related metadata. This detailed view supports client applications displaying extended processed news content. The operation is publicly accessible requiring no authorization roles, promoting open data consumption.","path":"/politicalNewsCrawler/rawDataStorage/{rawDataStorageId}/processedContent/{processedContentId}","method":"get","summary":"Retrieve detailed processed content information by raw data and content IDs","description":"This API endpoint fetches complete details of a specified processed content item associated with raw crawled data. It requires valid path parameters to identify the raw data record and the processed content record individually.\n\nThe response includes comprehensive information such as the full text of the processed content, content type (summary, highlight, analysis), generation timestamp, and audit timestamps. This detailed data supports rich client display and further data processing.\n\nThe endpoint is publicly accessible with no authentication requirements.\n\nErrors such as missing or invalid IDs are handled via standard HTTP error codes.","parameters":[{"name":"rawDataStorageId","description":"Unique identifier of the raw data storage record","schema":{"type":"string","format":"uuid"}},{"name":"processedContentId","description":"Unique identifier of the processed content record","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"Detailed processed content information","typeName":"IPoliticalNewsCrawlerProcessedContent"},"authorizationType":null,"authorizationRole":null,"name":"atProcessedContent"},{"specification":"This operation creates new processed content for a specific raw data storage record in the politicalNewsCrawler backend system. It accepts content type and the full content body generated by LLM post-processing and links the processed content to the raw data storage entity. This functionality enables the efficient addition of summaries, highlights, or analytical content associated with raw crawled political news data. The operation interfaces with the political_news_crawler_processed_content table in the Prisma schema to insert new records with appropriate metadata timestamps.","path":"/politicalNewsCrawler/guest/rawDataStorage/{rawDataStorageId}/processedContent","method":"post","summary":"Create processed content for a specific raw data storage record","description":"Create a new processed content entry linked to a specified raw data storage record. This endpoint allows clients to submit new LLM-generated content such as summaries, highlights, or analyses for political news data.\n\nThe operation requires the rawDataStorageId path parameter to identify the raw data record the content belongs to.\n\nUsers must provide the content_type to specify the nature of the content (e.g., summary, highlight, analysis) and the content_body containing the actual text content.\n\nUpon successful creation, the new processed content entity including its unique ID, timestamps, and linkage to the raw data storage is returned.\n\nSecurity considerations: This operation accepts public (guest) access as per the project's role definitions.\n\nThis operation is associated with the political_news_crawler_processed_content database table, which stores processed textual content generated by LLM models linked to raw crawl data.","parameters":[{"name":"rawDataStorageId","description":"Unique identifier of the raw data storage record to link processed content","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Processed content creation payload","typeName":"IPoliticalNewsCrawlerProcessedContent.ICreate"},"responseBody":{"description":"Created processed content record","typeName":"IPoliticalNewsCrawlerProcessedContent"},"authorizationType":null,"authorizationRole":"guest","name":"createProcessedContent"},{"specification":"This operation updates an existing processed content entry associated with a specific raw data storage record. It allows modification of content type and content body fields for political news post-processing results managed within the politicalNewsCrawler system. The operation accepts processed content ID and raw data storage record ID as path parameters to identify the target resource.","path":"/politicalNewsCrawler/guest/rawDataStorage/{rawDataStorageId}/processedContent/{processedContentId}","method":"put","summary":"Update processed content for a given raw data storage record","description":"Update details of a processed content entry for a specific raw data storage record. The endpoint requires both rawDataStorageId and processedContentId path parameters to precisely identify the record to be updated.\n\nClients can modify fields such as content_type and content_body to correct or enhance the processed textual contents derived from LLM processing.\n\nProper user authentication is not required for this operation as per project role definitions.\n\nThis operation accesses the political_news_crawler_processed_content table for persistent updates.","parameters":[{"name":"rawDataStorageId","description":"Unique identifier of the raw data storage record linked to the processed content","schema":{"type":"string","format":"uuid"}},{"name":"processedContentId","description":"Unique identifier of the processed content record to update","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Processed content update payload","typeName":"IPoliticalNewsCrawlerProcessedContent.IUpdate"},"responseBody":{"description":"Updated processed content record","typeName":"IPoliticalNewsCrawlerProcessedContent"},"authorizationType":null,"authorizationRole":"guest","name":"updateProcessedContent"},{"specification":"This operation deletes a processed content record linked to a specific raw data storage identifier. It permanently removes the processed content from the politicalNewsCrawler system database. The operation is performed via path parameters identifying the raw data storage and the processed content to remove.\n\nNo request body is required. The platform user initiating this deletion does not require authentication as per system role definitions.\n\nThis operation interacts with the political_news_crawler_processed_content table, permanently erasing the specified record.","path":"/politicalNewsCrawler/guest/rawDataStorage/{rawDataStorageId}/processedContent/{processedContentId}","method":"delete","summary":"Delete a processed content record permanently","description":"Delete (erase) a processed content record associated with a given raw data storage item identified by rawDataStorageId and processedContentId. This operation permanently removes the processed content data and cannot be undone.\n\nClients do not need authentication to delete processed content as per current system roles.\n\nThis action does not accept a request body and does not return a response body.\n\nIt directly removes the referenced record within the political_news_crawler_processed_content table.","parameters":[{"name":"rawDataStorageId","description":"Unique identifier of the raw data storage record linked to processed content","schema":{"type":"string","format":"uuid"}},{"name":"processedContentId","description":"Unique identifier of the processed content record to be deleted","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":null,"authorizationType":null,"authorizationRole":"guest","name":"eraseProcessedContent"},{"specification":"Retrieve a paginated list of LLM jobs related to the politicalNewsCrawler system. This operation offers filtering, sorting, and pagination capabilities. It is used to query the history and status of LLM post-processing jobs that generate textual content from raw political news data.\n\nThis operation is mapped to the political_news_crawler_llm_jobs Prisma table, which stores asynchronous processing jobs with statuses and parameters.","path":"/politicalNewsCrawler/llmJobs","method":"patch","summary":"List and search LLM post-processing jobs with filters and pagination","description":"Retrieve a filtered and paginated list of large language model (LLM) jobs in the politicalNewsCrawler backend. This endpoint supports query parameters for filtering jobs by status, creation date, and related crawl source.\n\nThe operation returns a pageable list of job summaries including job ID, status, parameters, and timestamps.\n\nThis is a read-only public endpoint that allows monitoring of LLM processing activities.\n\nNo authentication required for this endpoint.\n\nIt is primarily used for administrative or monitoring purposes to track asynchronous processing status and history.","parameters":[],"requestBody":{"description":"Filtering and pagination request for LLM jobs","typeName":"IPoliticalNewsCrawlerLlmJobs.IRequest"},"responseBody":{"description":"Paginated list of LLM job summaries","typeName":"IPageIPoliticalNewsCrawlerLlmJobs.ISummary"},"authorizationType":null,"authorizationRole":null,"name":"indexLlmJobs"},{"specification":"This operation retrieves the detailed information of a specific LLM (Large Language Model) job by its unique identifier. The LLM job entity represents individual processing tasks related to political news data, including status, parameters, creation, and update timestamps, and soft deletion state. This GET operation enables clients to obtain the current state and configuration of the specified LLM job from the political_news_crawler_llm_jobs table in the database.","description":"Retrieve detailed information about a specific LLM job identified by the given UUID. The LLM job entity tracks processing tasks for political news data, including job status such as 'pending', 'running', 'completed', or 'failed'. It also stores the JSON-formatted parameters or prompts used for the job.\n\nSecurity considerations: The endpoint is publicly accessible without role restrictions as per system design; no authentication or authorization is required.\n\nThis operation relates to the political_news_crawler_llm_jobs table in the Postgres database schema, ensuring full coverage of that core entity responsible for large language model processing tasks.\n\nValidation: The UUID parameter must strictly comply with the UUID format.\n\nUsage: This endpoint is typically used by clients or monitoring services to track the status and details of ongoing or completed LLM processing jobs.\n\nError Handling: Accessing a non-existent LLM job ID should return an appropriate error response indicating the resource was not found.","summary":"Retrieve specific LLM job information by ID","parameters":[{"name":"id","in":"path","schema":{"type":"string","format":"uuid"},"description":"Identifier of the LLM job"}],"requestBody":null,"responseBody":{"description":"Detailed information of the requested LLM job","typeName":"IPoliticalNewsCrawlerLlmJobs"},"authorizationType":null,"authorizationRole":null,"name":"at","path":"/politicalNewsCrawler/llmJobs/{id}","method":"get"},{"specification":"This operation creates a new LLM job record for processing political news data. The LLM job entity includes the crawl source reference, status, JSON parameters, and timestamps. The client must provide the creation information following the IPoliticalNewsCrawlerLlmJobs.ICreate schema, which includes the source ID, status, and parameter details.\n\nOnce created, the LLM job status will typically be 'pending' until processed.\n\nThis operation is exposed without authorization restrictions to allow system components or external clients to add processing jobs.\n\nThe operation corresponds to the political_news_crawler_llm_jobs table in the database, enabling insertion of new asynchronous LLM processing tasks.\n\nValidation and business logic ensure all mandatory fields are present and correctly formatted.","description":"Create a new LLM job record to enqueue political news data processing tasks for LLM post-processing. Input must include crawl source ID, job status, and parameters in JSON string format.\n\nSecurity considerations: The endpoint is publicly accessible without restrictions.\n\nThis operation affects the political_news_crawler_llm_jobs table and enables clients or system components to add new processing jobs.\n\nValidation: Input must conform to the IPoliticalNewsCrawlerLlmJobs.ICreate schema with UUID and status constraints.\n\nExpected Behavior: Upon successful creation, the new job record is returned with its assigned unique identifier.","summary":"Create a new LLM job","parameters":[],"requestBody":{"description":"Information needed to create the LLM job","typeName":"IPoliticalNewsCrawlerLlmJobs.ICreate"},"responseBody":{"description":"The created LLM job entity","typeName":"IPoliticalNewsCrawlerLlmJobs"},"authorizationType":null,"authorizationRole":null,"name":"create","path":"/politicalNewsCrawler/llmJobs","method":"post"},{"specification":"This operation updates an existing LLM job record identified by its unique ID. The LLM job entity allows updating of job status, parameters, and timestamps according to the IPoliticalNewsCrawlerLlmJobs.IUpdate schema.\n\nThis is a full update operation (PUT) replacing the entity's mutable fields.\n\nThe endpoint interacts with the political_news_crawler_llm_jobs table in the database.\n\nSecurity: No authorization roles are required; the endpoint is publicly accessible.\n\nValidation: The ID path parameter must be a valid UUID, and the request body must satisfy the IUpdate schema requirements.\n\nError scenario: Updating a non-existent ID should return an error indicating resource not found.","description":"Update an existing LLM job identified by its ID with new status, parameters, or other mutable information. The request body must conform to the IPoliticalNewsCrawlerLlmJobs.IUpdate schema.\n\nThis operation supports management and correction of LLM job records.\n\nIt relates directly to the political_news_crawler_llm_jobs table.\n\nSecurity considerations: No authentication or authorization required.\n\nValidation: Ensures UUID format for path parameter and schema compliance for request body.\n\nError handling: Non-existent resources result in not found errors.","summary":"Update an existing LLM job by ID","parameters":[{"name":"id","in":"path","schema":{"type":"string","format":"uuid"},"description":"ID of the LLM job to update"}],"requestBody":{"description":"Updated information for the LLM job","typeName":"IPoliticalNewsCrawlerLlmJobs.IUpdate"},"responseBody":{"description":"The updated LLM job entity","typeName":"IPoliticalNewsCrawlerLlmJobs"},"authorizationType":null,"authorizationRole":null,"name":"update","path":"/politicalNewsCrawler/llmJobs/{id}","method":"put"},{"specification":"This operation deletes an existing LLM job record permanently from the database by its ID. The political_news_crawler_llm_jobs table does not indicate soft delete capability for this entity, so this operation performs a hard delete.\n\nThis endpoint is publicly accessible without authorization requirements.\n\nValidation requires the ID path parameter to be a valid UUID.\n\nErrors for non-existent resource IDs should return not found status.\n\nUsage: This operation removes processing jobs that are no longer needed or were created in error.","description":"Delete an LLM job by its unique identifier. This operation permanently removes the LLM job record from the database.\n\nSecurity considerations: No authorization required.\n\nRelates to the political_news_crawler_llm_jobs table.\n\nValidation: Requires a UUID path parameter.\n\nError handling: Non-existent IDs result in appropriate not found responses.","summary":"Delete an LLM job by ID","parameters":[{"name":"id","in":"path","schema":{"type":"string","format":"uuid"},"description":"ID of the LLM job to delete"}],"requestBody":null,"responseBody":null,"authorizationType":null,"authorizationRole":null,"name":"erase","path":"/politicalNewsCrawler/llmJobs/{id}","method":"delete"},{"specification":"This operation retrieves a paginated list of LLM job results associated with a specific LLM job. It operates on the political_news_crawler_llm_results table in the Prisma schema. The results correspond to generated content such as summaries or analyses related to the specified LLM job, supporting pagination, filtering, and sorting capabilities for efficient content retrieval.","description":"Retrieve a filtered and paginated list of LLM results generated from the specified LLM job. This operation allows clients to query processed content outputs including summaries, highlights, and analysis produced by the large language model for political news data. The results are scoped to the LLM job identified by the llmJobId path parameter.\n\nThe operation respects user access constraints and returns results with essential content metadata, including content type and timestamps. Pagination and sorting options enable flexible client-side querying.\n\nThis endpoint interacts directly with the political_news_crawler_llm_results table, ensuring that only results belonging to the given LLM job are included. It is primarily a read-only operation supporting data browsing by authorized clients.\n\nClients should first retrieve the list using this endpoint before accessing details of specific results via the detailed get operation. Proper error handling should cover cases where the LLM job does not exist or has no associated results.","summary":"Fetch paginated list of LLM results for a given LLM job","parameters":[{"name":"llmJobId","in":"path","schema":{"type":"string","format":"uuid"},"description":"Unique identifier of the target LLM job"}],"requestBody":{"description":"Search criteria and pagination parameters for LLM results filtering","typeName":"IPoliticalNewsCrawlerLlmJobResult.IRequest"},"responseBody":{"description":"Paginated list of LLM results for the specified LLM job","typeName":"IPageIPoliticalNewsCrawlerLlmJobResult"},"authorizationType":null,"authorizationRole":"guest","name":"index","path":"/politicalNewsCrawler/guest/llmJobs/{llmJobId}/results","method":"patch"},{"specification":"This operation retrieves detailed information for a specific LLM job result by its unique identifier. It accesses the political_news_crawler_llm_results table in the Prisma schema to provide full content details including content type, generated content body, generation timestamp, and audit information.","description":"Retrieve detailed information of a specific LLM job result identified by its unique ID. This provides comprehensive insight into the processed content generated by large language model post-processing tasks for political news data. It includes content metadata, textual content, generation timestamp, and audit timestamps.\n\nThe path parameter llmJobId references the parent LLM job, ensuring context and scope. Authorization restricts access to authenticated users who have permissions to view this detailed processed content.\n\nThis endpoint is typically used after fetching a list of LLM results to obtain full details for display or further analysis.","summary":"Retrieve detailed information of a specific LLM job result","parameters":[{"name":"llmJobId","in":"path","schema":{"type":"string","format":"uuid"},"description":"Unique identifier of the target LLM job"},{"name":"id","in":"path","schema":{"type":"string","format":"uuid"},"description":"Unique identifier of the LLM job result"}],"requestBody":null,"responseBody":{"description":"Detailed LLM job result information","typeName":"IPoliticalNewsCrawlerLlmJobResult"},"authorizationType":null,"authorizationRole":"guest","name":"at","path":"/politicalNewsCrawler/guest/llmJobs/{llmJobId}/results/{id}","method":"get"},{"specification":"This operation creates a new LLM job result entry associated with a specified LLM job. It inserts processed content data such as summary, highlight, or analysis into the political_news_crawler_llm_results table. The operation accepts content type and content text for storage and links the result to the parent LLM job.","description":"Create a new LLM job result for the given LLM job. This operation stores processed textual content generated by the large language model, categorized by content type such as summaries, highlights, or analysis. It accepts the content payload along with metadata linking to the parent LLM job.\n\nPost-creation, clients typically retrieve the new result's details via the detailed get operation. The LLM job identified by llmJobId must exist before successful creation. Validation rules enforce content type adherence and text length constraints.\n\nAuthorization restricts this operation to authenticated users with permission to add processed content results.","summary":"Create a new LLM job result","parameters":[{"name":"llmJobId","in":"path","schema":{"type":"string","format":"uuid"},"description":"Unique identifier of the target LLM job"}],"requestBody":{"description":"Information required to create an LLM job result","typeName":"IPoliticalNewsCrawlerLlmJobResult.ICreate"},"responseBody":{"description":"Details of the newly created LLM job result","typeName":"IPoliticalNewsCrawlerLlmJobResult"},"authorizationType":null,"authorizationRole":"guest","name":"create","path":"/politicalNewsCrawler/guest/llmJobs/{llmJobId}/results","method":"post"},{"specification":"This operation updates an existing LLM job result identified by its unique ID under a specified LLM job. It modifies processed content such as summaries or analysis stored in the political_news_crawler_llm_results table. The operation allows updating of content type and content text fields, preserving links to the parent LLM job.","description":"Update an existing LLM job result specified by its ID for the given LLM job. This endpoint modifies textual processed content, which may include summaries, highlights, or political news analyses generated by LLM processing tasks.\n\nThe operation supports validation of input content type and ensures that the linked LLM job and result exist prior to update. Authorization check ensures only permitted users can modify these processed results.\n\nSuccessful updates return the updated full resource representation.","summary":"Update an existing LLM job result","parameters":[{"name":"llmJobId","in":"path","schema":{"type":"string","format":"uuid"},"description":"Unique identifier of the target LLM job"},{"name":"id","in":"path","schema":{"type":"string","format":"uuid"},"description":"Unique identifier of the LLM job result"}],"requestBody":{"description":"Information required to update an LLM job result","typeName":"IPoliticalNewsCrawlerLlmJobResult.IUpdate"},"responseBody":{"description":"Details of the updated LLM job result","typeName":"IPoliticalNewsCrawlerLlmJobResult"},"authorizationType":null,"authorizationRole":"guest","name":"update","path":"/politicalNewsCrawler/guest/llmJobs/{llmJobId}/results/{id}","method":"put"},{"specification":"This operation deletes a specific LLM result identified by its unique ID and associated with a particular LLM job, removing the record from the political_news_crawler_llm_results table. It is intended to support administrative or maintenance functionality to clean up or remove specific processed content generated by LLM jobs in the politicalNewsCrawler backend.","path":"/politicalNewsCrawler/guest/llmJobs/{llmJobId}/results/{id}","method":"delete","summary":"Delete a specific LLM result by LLM job ID and result ID","description":"This API endpoint allows authorized users to permanently delete a specific LLM generated result record associated with a given LLM job. The resource is identified by the path parameters llmJobId and id corresponding to the LLM job and the result respectively.\n\nThis deletion operation permanently removes the record from political_news_crawler_llm_results table and cannot be undone.\n\nOnly public access (guest role) is granted as per system design.\n\nNo request body is needed as parameters in the path fully specify the target resource.","parameters":[{"name":"llmJobId","in":"path","description":"ID of the associated LLM job","schema":{"type":"string"}},{"name":"id","in":"path","description":"ID of the LLM result to delete","schema":{"type":"string"}}],"requestBody":null,"responseBody":null,"authorizationRoles":["guest"],"authorizationRole":"guest","authorizationType":null,"name":"erase"},{"specification":"This operation retrieves the list of metadata entries associated with the specified LLM job from the political_news_crawler_processing_metadata table. Metadata entries describe auxiliary information about the processing job, such as parameters, execution context, or other relevant attributes.\n\nThis endpoint allows querying all metadata entries linked to a given LLM job ID.\n\nThe response contains an array of metadata objects. This endpoint is useful for debugging, job management, and understanding LLM processing parameters.\n\nDocumentation references:\n- political_news_crawler_llm_jobs\n- political_news_crawler_processing_metadata","path":"/politicalNewsCrawler/guest/llmJobs/{llmJobId}/metadata","method":"get","summary":"Retrieve metadata list for an LLM job","description":"Retrieve the list of metadata associated with a particular LLM job. This metadata includes key/value pairs that provide additional information about the LLM processing context and parameters used.\n\nOnly public access (guest role) as per system design.\n\nThe request uses no body but uses the LLM job ID as a path parameter.\n\nPagination or filtering may be implemented in the future.\n\nResponse contains an array of metadata entries with fields such as metadata_key and metadata_value.","parameters":[{"name":"llmJobId","in":"path","description":"ID of the target LLM job","schema":{"type":"string"}}],"requestBody":null,"responseBody":{"description":"List of processing metadata entries for the LLM job","typeName":"IPoliticalNewsCrawlerProcessingMetadataArray"},"authorizationRoles":["guest"],"authorizationRole":"guest","authorizationType":null,"name":"index"},{"specification":"Creates a new metadata entry associated with a specified LLM job in the political_news_crawler_processing_metadata table. This metadata captures key-value pairs representing auxiliary processing information related to the LLM job.\n\nThis endpoint allows adding a single metadata record by linking it to the LLM job identified by the llmJobId path parameter.\n\nIt requires a request body with metadata_key and metadata_value properties.\n\nThe newly created metadata record is returned in the response.\n\nReferences:\n- political_news_crawler_llm_jobs\n- political_news_crawler_processing_metadata","path":"/politicalNewsCrawler/guest/llmJobs/{llmJobId}/metadata","method":"post","summary":"Create new metadata record for LLM job","description":"Create a new processing metadata record associated with the specified LLM job. Metadata records consist of key-value pairs representing additional context or parameters for the LLM processing.\n\nThe LLM job ID is specified as a path parameter.\n\nThe request body must include metadata_key and metadata_value.\n\nUpon success, the full metadata record including creation timestamps is returned.\n\nThe API is publicly accessible (guest role) according to system design.","parameters":[{"name":"llmJobId","in":"path","description":"ID of the target LLM job","schema":{"type":"string"}}],"requestBody":{"description":"Metadata creation data","typeName":"IPoliticalNewsCrawlerProcessingMetadataICreate"},"responseBody":{"description":"Created metadata record","typeName":"IPoliticalNewsCrawlerProcessingMetadata"},"authorizationRoles":["guest"],"authorizationRole":"guest","authorizationType":null,"name":"create"},{"specification":"Update metadata entries related to a given LLM job. Typically used to modify multiple metadata attributes in batch for a specific LLM job.\n\nThis endpoint accepts a request body containing an array of metadata update entries. Each entry should include the ID of the metadata record and the new values for metadata_key and metadata_value.\n\nReturns a list of updated metadata records after processing.\n\nThis operation maintains data consistency and auditability for LLM processing metadata.\n\nReferences:\n- political_news_crawler_llm_jobs\n- political_news_crawler_processing_metadata","path":"/politicalNewsCrawler/guest/llmJobs/{llmJobId}/metadata","method":"patch","summary":"Update processing metadata records for an LLM job","description":"Update one or multiple processing metadata records associated with the specified LLM job. This operation supports partial or full updates and batch modifications.\n\nUses the LLM job ID as a path parameter.\n\nThe request body should contain an array of metadata entries with their IDs and updated key/value pairs.\n\nReturns the updated list of metadata records.\n\nThis API is accessible publicly under guest role as per system design.","parameters":[{"name":"llmJobId","in":"path","description":"ID of the target LLM job","schema":{"type":"string"}}],"requestBody":{"description":"Metadata update data","typeName":"IPoliticalNewsCrawlerProcessingMetadataIUpdateArray"},"responseBody":{"description":"Updated metadata records","typeName":"IPoliticalNewsCrawlerProcessingMetadataArray"},"authorizationRoles":["guest"],"authorizationRole":"guest","authorizationType":null,"name":"update"},{"specification":"This operation updates a metadata record for a specific LLM job in the political_news_crawler_processing_metadata table. It accepts the LLM job ID and metadata record ID as path parameters and a request body with the updated key-value pair. It returns the updated metadata record upon success.","path":"/politicalNewsCrawler/guest/llmJobs/{llmJobId}/metadata/{id}","method":"put","summary":"Update a specific LLM job metadata record","description":"This endpoint allows client to update the key-value metadata information for a particular LLM processing job. This operation requires authentication with the role 'guest'. Only the specified metadata record is updated with new key and value provided in the request body.\n\nThis metadata is crucial for enriching the LLM job processing context and supporting downstream analysis.\n\nThe metadata belongs to the political_news_crawler_processing_metadata model, ensuring key uniqueness for the associated LLM job.\n\nProper validation ensures keys and values are appropriately updated.","parameters":[{"name":"llmJobId","in":"path","description":"Target LLM job's ID","schema":{"type":"string","format":"uuid"}},{"name":"id","in":"path","description":"Metadata record ID to update","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Updated metadata key-value pair","typeName":"IPoliticalNewsCrawlerProcessingMetadata.IUpdate"},"responseBody":{"description":"Updated LLM job metadata record","typeName":"IPoliticalNewsCrawlerProcessingMetadata"},"authorizationType":null,"authorizationRole":"guest","name":"updateMetadata"},{"specification":"This operation deletes a metadata record identified by ID for a specific LLM job in the political_news_crawler_processing_metadata table. It requires the LLM job ID and metadata record ID as path parameters and does not require a request body or return a response body. The deletion is permanent.","path":"/politicalNewsCrawler/guest/llmJobs/{llmJobId}/metadata/{id}","method":"delete","summary":"Delete a specific LLM job metadata record","description":"This endpoint permanently removes a metadata record associated with a given LLM job. Authorization with the 'guest' role is required to perform this delete operation. The operation ensures that the specified metadata entry is erased from the system, cleaning up auxiliary processing information as necessary.\n\nThe operation directly affects the political_news_crawler_processing_metadata model and is critical for metadata lifecycle management.","parameters":[{"name":"llmJobId","in":"path","description":"Target LLM job's ID","schema":{"type":"string","format":"uuid"}},{"name":"id","in":"path","description":"Metadata record ID to delete","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":null,"authorizationType":null,"authorizationRole":"guest","name":"eraseMetadata"},{"specification":"This operation retrieves a paginated and filtered list of popular political topics from the political_news_crawler_popular_topics table. Supports filtering by title keyword and sorting by creation date or popularity score. This endpoint is publicly accessible without authorization.","path":"/politicalNewsCrawler/popularTopics","method":"patch","summary":"Retrieve a list of popular political topics with filters and pagination","description":"Retrieve a filtered and paginated list of popular political topics. Supports filtering parameters for title keywords and sorting by creation dates or popularity metrics.\n\nThis API endpoint is public and requires no authentication.\n\nData is sourced from the political_news_crawler_popular_topics model, ensuring relevance, currency, and accuracy.\n\nSupports efficient pagination and search to facilitate frontend consumption.","parameters":[],"requestBody":{"description":"Search and pagination parameters for popular topics","typeName":"IPoliticalNewsCrawlerPopularTopics.IRequest"},"responseBody":{"description":"Paginated popular topics matching search criteria","typeName":"IPageIPoliticalNewsCrawlerPopularTopics"},"authorizationType":null,"authorizationRole":null,"name":"searchPopularTopics"},{"specification":"This operation retrieves detailed information by ID for a popular political topic from the political_news_crawler_popular_topics table. This endpoint is publicly accessible with no authorization requirement.","path":"/politicalNewsCrawler/popularTopics/{id}","method":"get","summary":"Retrieve a specific popular political topic by ID","description":"Get detailed information for a single popular political topic by specifying its unique ID in the path parameter.\n\nThe response includes topic code, title, description, and timestamps.\n\nThis API endpoint is public and requires no authentication.\n\nSupports frontend client needs for detailed topic information display.","parameters":[{"name":"id","in":"path","description":"Unique identifier of the popular political topic","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"Detailed popular political topic information","typeName":"IPoliticalNewsCrawlerPopularTopics"},"authorizationType":null,"authorizationRole":null,"name":"atPopularTopic"},{"specification":"This operation creates a new popular topic record in the political_news_crawler_popular_topics table. It accepts the topic's unique code, title, and optional description. The table stores current political news topics with computed popularity rankings, ensuring each topic code is unique. This creation enables the topic to be tracked, scored, and referenced by related popularity score snapshots and topic mentions.","description":"Creates a new popular political topic within the system. Users can specify a unique topic code and title to identify trending or important political themes. An optional description provides further context or details about the topic. This operation inserts a new row into political_news_crawler_popular_topics which serves as the primary entity representing popular political topics.\n\nSecurity considerations require that only authorized parties (e.g., system administrators) perform this operation to prevent duplicates or invalid entries. Validation ensures topic_code uniqueness and title presence.\n\nThis operation integrates with related tables: popularity_scores and topic_mentions, which track dynamic scoring and article references respectively. Creating a topic is a prerequisite for recording its popularity and news mentions.\n\nExpected behavior includes returning the full created topic entity upon successful creation. Errors may arise from duplicate topic codes or validation failures.","summary":"Create new popular political topic","parameters":[],"requestBody":{"description":"Creation info of the popular topic","typeName":"IPoliticalNewsCrawlerPopularTopic.ICreate"},"responseBody":{"description":"Created popular topic information","typeName":"IPoliticalNewsCrawlerPopularTopic"},"authorizationType":null,"authorizationRole":"guest","path":"/politicalNewsCrawler/guest/popularTopics","method":"post","name":"create"},{"specification":"This operation updates an existing popular topic in the political_news_crawler_popular_topics table. It identifies the topic by its unique ID and provides updated values for topic_code, title, and description. This helps maintain accurate and current topic information within the system's popularity tracking framework.","description":"Updates an existing popular political topic by ID. Allows modification of the topic code, title, and optional description to reflect changes in political themes or corrections to entries.\n\nSecurity measures mandate authorized access to prevent unauthorized modifications. Validation includes ensuring continued uniqueness of topic_code if changed.\n\nThis operation affects the main popular_topics entity and indirectly impacts associated popularity scores and topic mentions. Successful updates return the updated topic entity. In case of invalid ID or concurrency issues, appropriate errors are returned.","summary":"Update popular political topic by ID","parameters":[{"name":"id","in":"path","description":"Unique identifier of the popular political topic to update","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Update info for the popular topic","typeName":"IPoliticalNewsCrawlerPopularTopic.IUpdate"},"responseBody":{"description":"Updated popular topic information","typeName":"IPoliticalNewsCrawlerPopularTopic"},"authorizationType":null,"authorizationRole":"guest","path":"/politicalNewsCrawler/guest/popularTopics/{id}","method":"put","name":"update"},{"specification":"This operation deletes an existing popular topic from the political_news_crawler_popular_topics table by its unique ID. Since the schema does not explicitly define soft delete columns for this entity, this operation performs a hard delete, permanently removing the record and all associations from the database.","description":"Deletes a popular political topic identified by ID. This performs a permanent removal of the topic record from the database, including removal of all associated popularity scores and topic mentions due to foreign key constraints.\n\nSecurity constraints require administrative privileges to avoid accidental data loss. This operation cannot be undone; use with caution.\n\nErrors are returned if the ID does not exist or foreign key constraints prevent deletion.\n\nThis operation allows system administrators to clean up outdated or invalid topics.","summary":"Delete popular political topic by ID (hard delete)","parameters":[{"name":"id","in":"path","description":"Unique identifier of the popular political topic to delete","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":null,"authorizationType":null,"authorizationRole":"guest","path":"/politicalNewsCrawler/guest/popularTopics/{id}","method":"delete","name":"erase"},{"specification":"This operation retrieves a paginated list of popularity score snapshots associated with a specific popular topic identified by popularTopicId. The political_news_crawler_popularity_scores table contains time-stamped snapshots of calculated popularity scores for topics, including decay factors for time-based ranking models. This endpoint facilitates analysis and trend tracking of the popularity evolution of a political topic over time.","description":"Retrieve a paginated list of popularity score snapshots for a given popular topic ID. Provides historical and current popularity scores with decay factors applied based on snapshot timestamps.\n\nSecurity considerations include read-only access for authenticated users, ensuring information is not exposed to unauthorized parties.\n\nThis operation links directly to the primary topic entity and supports UI features like time-trend charts or score evolution tracking. Results are paginated to manage potentially large histories.\n\nExpected behavior includes returning summary entries with score, decay, and snapshot time, ordered by snapshot_at descending.","summary":"List popularity score snapshots for a popular topic","parameters":[{"name":"popularTopicId","in":"path","description":"Identifier of the popular topic whose popularity scores are queried","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Request parameters for popularity scores list with filtering, sorting, and pagination","typeName":"IPoliticalNewsCrawlerPopularityScore.IRequest"},"responseBody":{"description":"Paginated list of popularity score snapshots","typeName":"IPageIPoliticalNewsCrawlerPopularityScore.ISummary"},"authorizationType":null,"authorizationRole":"guest","path":"/politicalNewsCrawler/guest/popularTopics/{popularTopicId}/popularityScores","method":"patch","name":"index"},{"specification":"Retrieve detailed information for a specific popularity score record tied to a specific popular political topic within the political_news_crawler_popularity_scores table. This endpoint operates on the popularity score snapshots associated with political topics, allowing any caller to get the score, decay factor, and timestamps for the specified score record by IDs. It includes full against the primary key (id) of the score and the foreign key reference to the popular topic. No authentication or user roles are required for access.","description":"This operation returns detailed information about a specific popularity score snapshot for a popular political topic. Users can retrieve the calculated popularity score and decay factor applied at a certain snapshot time, enabling insight into topic trend changes.\n\nSecurity and accessibility are unrestricted; this is a public endpoint allowing read-only access. The response returns all stored properties, including creation and update timestamps.\n\nUnderlying data is stored in political_news_crawler_popularity_scores referencing political_news_crawler_popular_topics, thus reflecting a one-to-many relationship (one topic to many scores).\n\nErrors include invalid ID formats or non-existing records, typically resulting in 404 not found responses.\n\nThis GET endpoint does not require a request body and uniquely identifies the score record by both popularTopicId and id path parameters.","summary":"Retrieve a specific popularity score snapshot for a popular political topic","parameters":[{"name":"popularTopicId","in":"path","schema":{"type":"string"},"description":"Target popular topic's ID"},{"name":"id","in":"path","schema":{"type":"string"},"description":"Specific popularity score record ID"}],"requestBody":null,"responseBody":{"description":"Detailed popularity score snapshot information for the specified popular topic","typeName":"IPoliticalNewsCrawlerPopularityScores"},"authorizationType":null,"authorizationRole":null,"name":"at","path":"/politicalNewsCrawler/popularTopics/{popularTopicId}/popularityScores/{id}","method":"get"},{"specification":"Search and retrieve a paginated list of topic mentions associated with a specific popular topic. Provides filtering, sorting, and pagination capabilities to effectively query mentions within political_news_crawler_topic_mentions. Operates under the popularTopicId foreign key reference.\n\nEnables clients to discover contexts where a popular topic was mentioned within various crawled news articles.\n\nSupports advanced search criteria in the request body (e.g., mention_context, created_at ranges).\n\nThis operation returns a paginated list of topic mention summary information with essential properties optimized for efficient data transfer.\n\nThis endpoint is publicly accessible, requiring no authentication roles.","description":"Retrieve a list of topic mentions related to a specific popular political topic. This operation accepts complex search criteria for filtering and pagination to manage potentially large sets of mentions.\n\nThis list enables clients to explore the contexts and individual news items where the topic was referenced.\n\nThe response includes summary information per mention, including mention context snippets when available.\n\nNo authentication or restriction is applied to this read-only endpoint.\n\nThis PATCH endpoint requires a request body specifying search criteria and returns a paginated list with essential summary data.","summary":"Search and retrieve topic mentions for a popular topic","parameters":[{"name":"popularTopicId","in":"path","schema":{"type":"string"},"description":"Target popular topic's ID"}],"requestBody":{"description":"Search criteria and pagination parameters for topic mentions filtering","typeName":"IPoliticalNewsCrawlerTopicMentions.IRequest"},"responseBody":{"description":"Paginated list of topic mention summaries matching search criteria","typeName":"IPageIPoliticalNewsCrawlerTopicMentions.ISummary"},"authorizationType":null,"authorizationRole":null,"name":"index","path":"/politicalNewsCrawler/popularTopics/{popularTopicId}/topicMentions","method":"patch"},{"specification":"Retrieve detailed information about a specific topic mention record related to a popular political topic. Operates on the political_news_crawler_topic_mentions table by unique mention ID and linked popular topic ID.\n\nThis functionality allows viewing the mention context and associated metadata.\n\nThe endpoint is publicly accessible with no required authentication.\n\nErrors include invalid IDs or missing records resulting in 404 status.\n\nThe GET method retrieves a single resource without request body, returning full entity details.","description":"Get detailed data on a particular topic mention for a popular political topic. Provides the mention context snippet and metadata for understanding the mention occurrence.\n\nThis is a read-only public operation without authentication.\n\nThe response returns all properties of the topic mention record, including creation and update timestamps.","summary":"Retrieve a single topic mention detail","parameters":[{"name":"popularTopicId","in":"path","schema":{"type":"string"},"description":"Target popular topic's ID"},{"name":"id","in":"path","schema":{"type":"string"},"description":"Target topic mention record ID"}],"requestBody":null,"responseBody":{"description":"Detailed topic mention data","typeName":"IPoliticalNewsCrawlerTopicMentions"},"authorizationType":null,"authorizationRole":null,"name":"at","path":"/politicalNewsCrawler/popularTopics/{popularTopicId}/topicMentions/{id}","method":"get"},{"specification":"Update the specified topic mention record tied to a popular political topic ID. Enables modifying fields such as mention_context to refine the textual snippet describing the mention instance.\n\nThis operation validates input fields according to the political_news_crawler_topic_mentions table structure.\n\nOperates as a PUT method to perform full update of the mention record.\n\nAccess is unrestricted, consistent with the public reading endpoints. All changes are saved and returned in the response.\n\nErrors include validation failures and non-existing record IDs returning error statuses.\n\nRequest body uses IPublicNewsCrawlerTopicMentions.IUpdate schema. Response returns the updated complete entity data.","description":"Update an existing topic mention record associated with a popular topic. Modifiable fields typically include mention context text.\n\nThis PUT endpoint requires a full update payload matching the entity update schema.\n\nNo authentication or role is required as the endpoints are publicly open read/write.\n\nUpon success, the updated entity is returned.","summary":"Update a topic mention record for a popular topic","parameters":[{"name":"popularTopicId","in":"path","schema":{"type":"string"},"description":"Target popular topic's ID"},{"name":"id","in":"path","schema":{"type":"string"},"description":"Target topic mention record ID"}],"requestBody":{"description":"Updated topic mention data","typeName":"IPoliticalNewsCrawlerTopicMentions.IUpdate"},"responseBody":{"description":"Updated topic mention data","typeName":"IPoliticalNewsCrawlerTopicMentions"},"authorizationType":null,"authorizationRole":null,"name":"update","path":"/politicalNewsCrawler/popularTopics/{popularTopicId}/topicMentions/{id}","method":"put"},{"specification":"This operation deletes a specific topic mention entity from the politicalNewsCrawlerPopularTopics entity related to the popular topics feature. It performs a soft delete by setting the deleted_at timestamp to mark the topic mention as deleted without physically removing the record from the database. The topic mention record is identified by the popularTopicId and id path parameters. This allows logical removal of topic mentions for moderation or data integrity while preserving historical references.\n\nThe operation targets the 'political_news_crawler_topic_mentions' table, which supports soft deletion with a nullable deleted_at field.\n\nNo authentication is required as the API is public, but operational environments may enforce authorization externally. Clients should handle errors gracefully if the mention is already deleted or does not exist.\n\nThis operation is part of the full lifecycle management of popular topic mentions in conjunction with other CRUD endpoints.","description":"This endpoint allows soft deletion of a specific topic mention under a specific popular topic by setting the deleted_at field.\n\nThe 'popularTopicId' identifies the parent popular topic while 'id' identifies the mention to logically remove.\n\nThis operation does not physically delete the record but marks it as deleted for audit and historical integrity.\n\nClients should consider this logical deletion in their data filtering and retrieval.\n\nThe operation complements other endpoints for managing popular topics and mentions, supporting moderation workflows.","summary":"Soft delete a specific topic mention from a popular topic by ID","parameters":[{"name":"popularTopicId","description":"Unique identifier of the popular topic","schema":{"type":"string","format":"uuid"}},{"name":"id","description":"Unique identifier of the topic mention to delete","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":null,"authorizationRoles":[],"name":"erase","path":"/politicalNewsCrawler/popularTopics/{popularTopicId}/topicMentions/{id}","method":"delete","authorizationRole":null,"authorizationType":null},{"specification":"This operation retrieves a paged list of API access log entries from the 'political_news_crawler_api_access_logs' table. The endpoint supports advanced filtering, sorting, and pagination through the requestBody with IPoliticalNewsCrawlerApiAccessLog.IRequest type. The returned result includes paginated data with summaries of access logs, optimized for analysis of API usage patterns and client monitoring. The endpoint is publicly accessible without authentication, allowing monitoring systems and clients to retrieve access data.\n\nThis operation helps administrators and developers track API usage dynamics, investigate performance issues, and audit request sources without needing full access control. It integrates with other analytics endpoints such as error logs and usage metrics for comprehensive API monitoring.\n\nFiltering supports date ranges, HTTP methods, endpoint paths filtering using search patterns, and client IP/agent constraints. Pagination and sorting provide efficient data access even with large volumes of log entries.","description":"Retrieve a paginated and filtered list of API access log entries.\n\nThis endpoint interacts with the 'political_news_crawler_api_access_logs' table which records detailed logs for every API call.\n\nClients can filter entries using advanced search and pagination parameters included in the request body.\n\nThe search allows narrowing results by HTTP method, path pattern, date range, and other criteria.\n\nThe response includes a paginated list of API access log summaries with metadata designed for analysis and auditing.\n\nThis operation is public and requires no authorization roles.\n\nClients should handle typical pagination and search results because the data volume can be large.","summary":"Search and retrieve a paginated list of API access log entries","parameters":[],"requestBody":{"description":"Search filters and pagination parameters for API access logs","typeName":"IPoliticalNewsCrawlerApiAccessLog.IRequest"},"responseBody":{"description":"Paginated list of API access log summaries matching search criteria","typeName":"IPageIPoliticalNewsCrawlerApiAccessLog.ISummary"},"authorizationRoles":[],"name":"index","path":"/politicalNewsCrawler/api/accessLogs","method":"patch","authorizationRole":null,"authorizationType":null},{"specification":"This operation retrieves a specific API access log entry by ID from the 'political_news_crawler_api_access_logs' table. Used for detailed examination of individual API call information including request method, path, status, client IP, user agent, and timing metrics.\n\nThe resource is publicly accessible without authentication, enabling debugging and support tools to retrieve access details quickly.\n\nThis operation complements the search index endpoint allowing targeted retrieval of single entries.\n\nPath parameters validate the uniqueness of the ID with UUID format.\n\nErrors indicate not found or malformed ID inputs.\n\nReturned data includes the complete access log record as the main entity type IPoliticalNewsCrawlerApiAccessLog.","description":"Retrieve detailed information of a specific API access log entry by its unique ID.\n\nThis endpoint targets individual records in the 'political_news_crawler_api_access_logs' table.\n\nAllows clients to view full details of an access log for diagnostic purposes.\n\nNo authentication or role check is required because this is a public API endpoint.\n\nClients should handle cases where the requested ID does not exist.\n\nThe response includes all fields relevant to the access log data, such as method, path, status code, IP, and user agent.","summary":"Retrieve a specific API access log entry by ID","parameters":[{"name":"id","description":"Unique identifier of the API access log entry","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"API access log entry detailed information","typeName":"IPoliticalNewsCrawlerApiAccessLog"},"authorizationRoles":[],"name":"at","path":"/politicalNewsCrawler/api/accessLogs/{id}","method":"get","authorizationRole":null,"authorizationType":null},{"specification":"This endpoint provides a paginated and filtered search over API error log entries stored in the 'political_news_crawler_api_error_logs' table. It supports query capabilities enabled through a request body of type IPoliticalNewsCrawlerApiErrorLog.IRequest to specify filters such as path patterns, error codes, date ranges, client IPs, and user agents.\n\nThe response includes paginated summaries of error logs optimized for auditing and operational monitoring.\n\nThis endpoint is publicly accessible without authentication, supporting API diagnostics and data analytics tools.\n\nClients must handle pagination and filtering correctly to access large datasets efficiently.\n\nThis operation complements other API monitoring endpoints such as access logs and API usage metrics for thorough system oversight.","description":"Retrieve a paginated and filtered list of API error log entries.\n\nThis endpoint interacts with the 'political_news_crawler_api_error_logs' table which records detailed error log data.\n\nClients use the request body to specify filters and pagination criteria.\n\nThe response includes paginated summaries that aid in identifying and analyzing API error patterns.\n\nPublic access is allowed without any role restrictions.\n\nError entries may highlight issues such as rate limiting, endpoint failures, or spikes in error occurrence.\n\nClients should handle large result sets with efficient paging.","summary":"Search and retrieve a paginated list of API error log entries","parameters":[],"requestBody":{"description":"Filters and pagination parameters for API error logs","typeName":"IPoliticalNewsCrawlerApiErrorLog.IRequest"},"responseBody":{"description":"Paginated list of API error log summaries matching search criteria","typeName":"IPageIPoliticalNewsCrawlerApiErrorLog.ISummary"},"authorizationRoles":[],"name":"index","path":"/politicalNewsCrawler/api/errorLogs","method":"patch","authorizationRole":null,"authorizationType":null},{"specification":"This operation retrieves a specific API error log entry by its unique identifier from the political_news_crawler_api_error_logs table. It allows clients to fetch detailed error information for troubleshooting and analysis of API failures. The operation requires the error log ID to be provided as a path parameter and returns the corresponding error log data with details including path, error code, message, client IP, and user agent.","description":"Retrieve a detailed API error log entry by its unique identifier.\n\nThis operation is designed to fetch detailed information for a single API error event, referenced by its unique ID. It allows administrators or monitoring systems to obtain specifics about a particular error occurrence, including the error code, message, client IP, and user agent.\n\nOnly read access is required, as this operation exposes error logs for diagnostics without modification rights.\n\nThe data corresponds directly to the political_news_crawler_api_error_logs table implementation in the Prisma schema, ensuring all relevant columns are included in the response.\n\nNo request body is needed, and the error log ID is passed as the path parameter. If the ID does not exist, a 404 response can be expected.\n\nThis operation complements other log retrieval functions such as listing all error logs or fetching usage metrics for analysis.","summary":"Retrieve specific API error log by ID","parameters":[{"name":"id","in":"path","description":"Unique identifier of the API error log entry","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"API error log entry details","typeName":"IPoliticalNewsCrawlerApiErrorLog"},"authorizationType":null,"authorizationRole":null,"name":"at","path":"/politicalNewsCrawler/api/errorLogs/{id}","method":"get"},{"specification":"This operation retrieves aggregate API usage metrics records from the political_news_crawler_api_usage_metrics table, supporting complex filtering, sorting, and pagination. The request body allows specifying search criteria including HTTP method, API path, and time ranges to filter aggregated metric data.\n\nThe operation returns a paginated list of usage metrics summarizing total calls, max and average response times over defined periods, providing insights into API performance and traffic patterns.\n\nThis endpoint is read-only and publicly accessible, facilitating monitoring and analytics for API consumption without authentication requirements.\n\nThe operation supports flexible and complex queries via the PATCH method to enable refined access to usage metrics data for performance monitoring and capacity planning.","description":"Retrieve a filtered and paginated list of API usage metrics with complex search capabilities.\n\nThis operation supports detailed querying of aggregated API usage data, including filtering by HTTP methods, API paths, and time periods. It accepts pagination and sorting parameters to efficiently manage large datasets.\n\nThe data originates from the political_news_crawler_api_usage_metrics table, which records total call counts, maximum, and average response durations over specified aggregation periods.\n\nSecurity and access control are minimal as the endpoint is expected to be publicly accessible for monitoring systems.\n\nThe response returns a paginated collection of summarized API usage metric records.","summary":"Search and retrieve paginated API usage metrics","parameters":[],"requestBody":{"description":"Search criteria and pagination parameters for API usage metrics filtering","typeName":"IPoliticalNewsCrawlerApiUsageMetricRequest"},"responseBody":{"description":"Paginated list of API usage metrics matching search criteria","typeName":"IPageIPoliticalNewsCrawlerApiUsageMetricSummary"},"authorizationType":null,"authorizationRole":null,"name":"index","path":"/politicalNewsCrawler/api/usageMetrics","method":"patch"},{"specification":"This operation retrieves a specific API usage metric record by its unique identifier from the political_news_crawler_api_usage_metrics table.\n\nThis allows detailed inspection of a particular aggregated metric including total calls, max response time, and average response time over the defined time window.\n\nThe request requires the usage metric ID as a path parameter and returns the full usage metric record details.\n\nThe endpoint is publicly accessible and read-only, supporting monitoring and diagnostics without authentication.\n\nThis operation complements the API usage metrics listing by providing detail on individual records.","description":"Retrieve a specific API usage metric record by ID.\n\nThe response includes total calls, max response time, and average response time recorded during the aggregation period.\n\nThis endpoint is public and requires no authentication.\n\nIf the ID is invalid or not found, a 404 error will be returned.\n\nThis operation supports auditing and detailed performance inspection for API usage.","summary":"Retrieve specific API usage metric by ID","parameters":[{"name":"id","in":"path","description":"Unique identifier of the API usage metric record","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"API usage metric record details","typeName":"IPoliticalNewsCrawlerApiUsageMetric"},"authorizationType":null,"authorizationRole":null,"name":"at","path":"/politicalNewsCrawler/api/usageMetrics/{id}","method":"get"},{"specification":"This operation retrieves crawl alert events from the political_news_crawler_crawl_alerts table, supporting filtering and pagination to monitor crawl failures, bans, or throttle warnings.\n\nThe request body accepts search parameters such as crawl source filters, alert types, severities, and time ranges.\n\nThe response provides paginated crawl alert records that include related crawl source information, alert types, messages, severities, and timestamps.\n\nThis publicly accessible read-only API supports operational monitoring and alerting dashboards to observe crawl health and issues in near real-time.","description":"Retrieve filtered and paginated crawl alert events generated by crawl sources.\n\nFacilitates monitoring of crawl operation health by reporting bans, errors, or warnings.\n\nAccepts search and pagination parameters to manage potentially large alert data volumes.\n\nData is sourced from the political_news_crawler_crawl_alerts table, including alert metadata and associated crawl source references.\n\nSecurity is open for public access, enabling transparent operational insight.\n\nClients can filter alerts by severity, type, and crawl source as needed.\n\nReturns a paginated collection of alert records matching criteria.","summary":"Search and retrieve paginated crawl alert events","parameters":[],"requestBody":{"description":"Search filters and pagination parameters for crawl alerts retrieval","typeName":"IPoliticalNewsCrawlerCrawlAlertRequest"},"responseBody":{"description":"Paginated list of crawl alert records matching filters","typeName":"IPageIPoliticalNewsCrawlerCrawlAlert"},"authorizationType":null,"authorizationRole":null,"name":"index","path":"/politicalNewsCrawler/crawlAlerts","method":"patch"},{"specification":"This operation retrieves a specific crawl alert record from the political_news_crawler_crawl_alerts table by its unique identifier (id). crawl_alerts store operational alert events related to crawling failures, bans, and throttling for political news sources, providing context and severity information essential for monitoring and troubleshooting the crawler subsystem.","description":"Retrieve detailed information about a specific crawl alert by its unique ID. The crawl alert entity logs critical events in the crawling process such as bans, network errors, or throttle warnings related to specific crawl sources. This data helps system operators monitor crawler health and perform diagnostics.\n\nAccess to this endpoint requires appropriate permissions reflecting user roles responsible for viewing operational alerts.\n\nThe response returns all available metadata for the alert including its type, descriptive message, severity level, and timestamps. If the alert has been soft deleted, it will still be retrievable for audit purposes.\n\nThis retrieval operation maps directly to the political_news_crawler_crawl_alerts database table, ensuring consistent data mapping and field representation.\n\nClients should handle not found errors appropriately if the specified alert ID does not exist or has been deleted permanently.","summary":"Retrieve a crawl alert detail by ID","parameters":[{"name":"id","description":"Unique identifier of the target crawl alert","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"Detailed crawl alert information","typeName":"IPoliticalNewsCrawlerCrawlAlerts"},"authorizationRoles":["guest"],"path":"/politicalNewsCrawler/guest/crawlAlerts/{id}","method":"get","name":"at","authorizationRole":"guest","authorizationType":null},{"specification":"This operation creates a new crawl alert in the political_news_crawler_crawl_alerts table, which logs events such as bans, network errors, or throttling issues encountered during crawling of political news sources. These alerts include important metadata such as alert type, descriptive message, severity, and timestamps.\n\nThe API enables administrative clients to report new subsystem alerts for monitoring and operational awareness.\n\nAll required fields including crawl_source_id, alert_type, message, and severity must be provided for the alert creation. The system automatically manages audit timestamps on creation.\n\nNo direct user input fields other than essential alert details should be accepted.\n\nSecurity restrictions apply to ensure only authorized administrative roles can create alerts.","description":"Create a new crawl alert entry to record important operational events affecting crawling. This is essential for tracking issues such as bans or errors from crawl sources.\n\nClients must provide the crawl source reference, alert type, descriptive message, and severity level.\n\nNo soft delete or update timestamps are required, as this is strictly for new event logging.\n\nSuccessful creation returns the created crawl alert data with generated IDs and timestamps.","summary":"Create a new crawl alert","parameters":[],"requestBody":{"description":"New crawl alert details for creation","typeName":"IPoliticalNewsCrawlerCrawlAlerts.ICreate"},"responseBody":{"description":"Created crawl alert information","typeName":"IPoliticalNewsCrawlerCrawlAlerts"},"authorizationRoles":["guest"],"path":"/politicalNewsCrawler/guest/crawlAlerts","method":"post","name":"create","authorizationRole":"guest","authorizationType":null},{"specification":"This operation updates an existing crawl alert in the political_news_crawler_crawl_alerts database table by its unique identifier (id). It allows modification of alert details such as alert type, descriptive message, and severity level, reflecting updated operational status or corrections.\n\nOnly non-audit fields can be updated. Audit timestamps such as created_at should remain immutable.\n\nThe operation supports partial updates of provided fields and enforces proper authorization controls.\n\nIf the crawl alert ID does not exist, clients should handle such errors gracefully.\n\nThis update operation is critical for maintaining accurate monitoring records and operational alert data integrity.","description":"Update an existing crawl alert identified by ID. This allows modification of operational alert details including alert type, message, and severity.\n\nAudit timestamps are immutable and managed internally.\n\nClients should ensure to provide only the fields that need to be updated.\n\nProper error handling is required for non-existent IDs.\n\nThis operation maps to the political_news_crawler_crawl_alerts table ensuring data consistency.","summary":"Update crawl alert information by ID","parameters":[{"name":"id","description":"Unique identifier of the target crawl alert","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Updated crawl alert data","typeName":"IPoliticalNewsCrawlerCrawlAlerts.IUpdate"},"responseBody":{"description":"Updated crawl alert detail","typeName":"IPoliticalNewsCrawlerCrawlAlerts"},"authorizationRoles":["guest"],"path":"/politicalNewsCrawler/guest/crawlAlerts/{id}","method":"put","name":"update","authorizationRole":"guest","authorizationType":null},{"specification":"This operation permanently removes a crawl alert record from the political_news_crawler_crawl_alerts database table by its unique identifier (id). This hard delete operation irreversibly deletes all associated data for compliance and housekeeping.\n\nClients must exercise caution as deleted records cannot be recovered.\n\nThe API enforces role-based access control to allow deletions only by authorized administrative users.\n\nThis corresponds directly to the underlying database entity removing the record in a hard delete semantics.\n\nClients should confirm existence and permission before invoking this operation.","description":"Permanently delete a crawl alert record by its ID. This operation irreversibly removes the alert and all associated data from the database.\n\nThis hard delete is definitive and cannot be undone.\n\nOnly authorized users with administrative roles may perform this operation.\n\nClients should confirm the record exists before requesting deletion.\n\nThis action maps to the political_news_crawler_crawl_alerts DB table deletion behavior.","summary":"Delete crawl alert by ID","parameters":[{"name":"id","description":"Unique identifier of the target crawl alert","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":null,"authorizationRoles":["guest"],"path":"/politicalNewsCrawler/guest/crawlAlerts/{id}","method":"delete","name":"erase","authorizationRole":"guest","authorizationType":null},{"specification":"This operation retrieves a filtered and paginated list of processing alerts related to the politicalNewsCrawler backend system. It returns various alert events such as LLM processing failures, queue overflows, and retry escalations. The data returned includes alert type, severity, and detailed descriptive messages. It enables operators to monitor and diagnose processing pipeline issues efficiently. The underlying database table is political_news_crawler_processing_alerts, which stores alert records with creation and update timestamps as well as soft deletion support.","description":"Retrieve a paginated list of processing alerts for the politicalNewsCrawler service.\n\nThis operation provides filtering capabilities to search alerts by type, severity, time ranges, and message content.\n\nSecurity considerations: this endpoint is publicly accessible without authentication, reflecting the service's open design.\n\nEach alert record originates from the political_news_crawler_processing_alerts table and includes fields such as alert_type, message, severity, created_at, and updated_at.\n\nThe endpoint supports pagination and sorting to efficiently manage potentially large alert data sets.\n\nError handling includes returning appropriate responses for invalid filter parameters or server issues.\n\nRelated operations include retrieving individual alerts by ID for detailed inspection.\n\nThis operation adheres to business rules that ensure alerts accurately reflect backend processing issues and provide operational visibility.","path":"/politicalNewsCrawler/processingAlerts","method":"patch","summary":"Retrieve list of processing alerts with filtering and pagination","parameters":[],"requestBody":{"description":"Filtering criteria and pagination parameters for processing alerts","typeName":"IPoliticalNewsCrawlerProcessingAlert.IRequest"},"responseBody":{"description":"Paginated list of processing alert records","typeName":"IPageIPoliticalNewsCrawlerProcessingAlert"},"authorizationRoles":[],"name":"index","authorizationRole":null,"authorizationType":null},{"specification":"This operation retrieves details of a single processing alert by its unique identifier from the political_news_crawler_processing_alerts table. It returns comprehensive alert information including alert type, message, severity, timestamps, and soft deletion status. This facilitates precise monitoring and troubleshooting of backend processing issues associated with the politicalNewsCrawler service.","description":"Retrieve detailed information for a specific processing alert identified by its unique ID.\n\nThis operation returns a single alert record from the political_news_crawler_processing_alerts table including all descriptive fields.\n\nSecurity considerations: this endpoint is publicly accessible without authentication.\n\nIt allows operators and support personnel to view complete details for diagnosing and responding to alert events.\n\nIf the specified alert ID does not exist, the operation returns a not found error.\n\nRelated operations include the listing endpoint that returns multiple alerts with filtering.\n\nThis operation supports business requirements for transparency and operational health monitoring.","path":"/politicalNewsCrawler/processingAlerts/{id}","method":"get","summary":"Retrieve detailed processing alert information by ID","parameters":[{"name":"id","description":"Unique identifier of the processing alert","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"Processing alert detailed information","typeName":"IPoliticalNewsCrawlerProcessingAlert"},"authorizationRoles":[],"name":"at","authorizationRole":null,"authorizationType":null},{"specification":"This operation creates a new processing alert entry in the political_news_crawler_processing_alerts table to record issues identified during backend LLM processing jobs. It accepts alert type, descriptive message, and severity level as input fields. This endpoint enables the system and support teams to log new incidents for timely operational handling.","description":"Create a new processing alert record to log backend processing issues such as LLM failures or queue problems.\n\nThis operation records alert details including alert_type, message, and severity level in the system.\n\nSecurity considerations: this endpoint is publicly exposed without authentication, but typically would be called internally by system components.\n\nValidation rules ensure required fields are provided with allowed severity values like 'info', 'warning', and 'critical'.\n\nThe newly created alert record is returned including timestamps and identifier.\n\nRelated operations include listing processing alerts and retrieving individual alert details.\n\nProper use of this endpoint ensures timely detection and notification of backend processing problems.","path":"/politicalNewsCrawler/processingAlerts","method":"post","summary":"Create a new processing alert record","parameters":[],"requestBody":{"description":"Data required to create a new processing alert","typeName":"IPoliticalNewsCrawlerProcessingAlert.ICreate"},"responseBody":{"description":"Newly created processing alert record","typeName":"IPoliticalNewsCrawlerProcessingAlert"},"authorizationRoles":[],"name":"create","authorizationRole":null,"authorizationType":null},{"specification":"This operation updates an existing processing alert record identified by its unique ID in the political_news_crawler_processing_alerts table. It allows modifying alert attributes such as alert type, message, and severity. This endpoint supports administrative correction or augmentation of alert information to maintain accurate operational data.","description":"Update an existing processing alert identified by its ID.\n\nThis operation accepts updated alert_type, message, and severity fields.\n\nSecurity considerations: publicly accessible with no authentication.\n\nIf the specified ID does not exist, the operation returns an error.\n\nRelated operations include creating new alerts and listing alerts with filters.\n\nUpdating alerts is necessary for accurate status tracking, corrections, or additional information inclusion.","path":"/politicalNewsCrawler/processingAlerts/{id}","method":"put","summary":"Update an existing processing alert record","parameters":[{"name":"id","description":"Unique identifier of the processing alert to update","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Data required to update processing alert information","typeName":"IPoliticalNewsCrawlerProcessingAlert.IUpdate"},"responseBody":{"description":"Updated processing alert record","typeName":"IPoliticalNewsCrawlerProcessingAlert"},"authorizationRoles":[],"name":"update","authorizationRole":null,"authorizationType":null},{"specification":"This operation deletes an existing processing alert record from the political_news_crawler_processing_alerts table within the database. It allows for permanent removal of the alert record identified by the UUID 'id' path parameter. Processing alerts encapsulate various error or condition logs such as LLM processing failures or queue backlogs. Typically, only users with the role \"guest\" are authorized to access this endpoint, reflecting a controlled permission scenario within the given user role definitions. The deletion here is a hard delete, permanently removing the record from the database without soft delete markings.","description":"This API endpoint provides the capability to erase a specified processing alert by accepting its unique identifier as a path parameter.\n\nThe processing alerts represent system notifications for issues encountered during the LLM post-processing pipeline, such as failures, retries, or other significant events requiring operational attention.\n\nProper authorization is required, typically limited to users with the \"guest\" role to prevent unauthorized data loss.\n\nThe operation deletes the processing alert permanently from the system, meaning the record cannot be recovered after deletion.\n\nUsers must ensure the 'id' corresponds to a valid existing alert record to avoid errors.","summary":"Delete a specific processing alert by ID","parameters":[{"name":"id","in":"path","description":"Unique identifier of the processing alert to delete","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":null,"authorizationType":null,"authorizationRole":"guest","path":"/politicalNewsCrawler/guest/processingAlerts/{id}","method":"delete","name":"eraseProcessingAlert"},{"specification":"This operation retrieves a paginated list of API alerts from the political_news_crawler_api_alerts table. API alerts record system notifications such as rate limiting, endpoint errors, and error spikes. The API supports filtering, sorting, and pagination via query parameters in the IRequest request body. Results help identify operational issues and trigger maintenance actions. Alerts include severity level, message, and type timestamped for tracking. Typically accessible by system monitoring users with the \"guest\" role to observe API health and incident trends.","description":"Retrieve a list of API alert records with flexible search and pagination.\n\nAPI alerts correspond to system event notifications for rate limiting, endpoint issues, and spike detection.\n\nThis operation allows monitoring users or admins to filter alerts based on severity, type, or date ranges.\n\nResults are paginated and sorted according to request criteria, enabling effective operational surveillance.\n\nProper authorization ensures only permitted roles can view sensitive alert data, commonly the \"guest\" user role in this context.\n\nAll users of the \"guest\" role are authorized.","summary":"Search and retrieve a filtered, paginated list of API alerts","parameters":[],"requestBody":{"description":"Search and pagination parameters for API alerts","typeName":"IPoliticalNewsCrawlerApiAlert.IRequest"},"responseBody":{"description":"Paginated search results of API alert summaries","typeName":"IPageIPoliticalNewsCrawlerApiAlert.ISummary"},"authorizationType":null,"authorizationRole":"guest","path":"/politicalNewsCrawler/guest/apiAlerts","method":"patch","name":"indexApiAlerts"},{"specification":"This operation retrieves a single API alert from the political_news_crawler_api_alerts table by its unique UUID identifier. It returns detailed information including alert type, message, severity, and timestamps. This is useful for viewing specific incident details in the system monitoring context. Access is granted to users with the \"guest\" role. The operation returns 404 if the specified alert ID does not exist.","description":"Retrieve detailed information about a specific API alert identified by its unique ID.\n\nThis endpoint is intended for use by users with the \"guest\" role or monitoring tools requiring deep insights into particular alert events.\n\nAPI alert data includes event type, severity level, descriptive message, and timestamps.\n\nAttempting to retrieve a non-existent alert will result in an error response indicating not found.","summary":"Get detailed information of a specific API alert by ID","parameters":[{"name":"id","in":"path","description":"Unique identifier of the API alert to retrieve","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":{"description":"Detailed API alert information","typeName":"IPoliticalNewsCrawlerApiAlert"},"authorizationType":null,"authorizationRole":"guest","path":"/politicalNewsCrawler/guest/apiAlerts/{id}","method":"get","name":"atApiAlert"},{"specification":"This operation creates a new API alert record in the political_news_crawler_api_alerts table. API alerts capture system events regarding API subsystem errors such as rate limiting, endpoint failures, and error spikes. The request body includes alert type, severity, message, and timestamps. Creation of alerts is typically automated by the backend monitoring system, but can be manually invoked for testing or exceptional cases by authorized users with the \"guest\" role. The operation validates input data and returns the created alert entity with assigned UUID.","description":"Create a new API alert entry to record system-level API issues or notifications.\n\nThis endpoint is generally used by automated monitoring or system components, but manual creation is supported for maintenance purposes.\n\nThe alert includes type, severity, message, and the time it was generated.\n\nOnly users with the \"guest\" role can create API alerts to maintain system integrity.\n\nThe API returns the newly created alert including its unique identifier.","summary":"Create a new API alert record","parameters":[],"requestBody":{"description":"Information required for creating an API alert","typeName":"IPoliticalNewsCrawlerApiAlert.ICreate"},"responseBody":{"description":"Created API alert information","typeName":"IPoliticalNewsCrawlerApiAlert"},"authorizationType":null,"authorizationRole":"guest","path":"/politicalNewsCrawler/guest/apiAlerts","method":"post","name":"createApiAlert"},{"specification":"This operation updates a specific API alert record identified by its unique UUID. It acts on the political_news_crawler_api_alerts table in the Prisma schema which stores alert events related to API errors such as rate limiting and endpoint failures. The operation allows changing alert_type, message, and severity, and ensures monitoring alert accuracy. It requires the alert id as a path parameter and the update request body containing alert details according to IPoliticalNewsCrawlerApiAlert.IUpdate schema. The response returns the updated alert record. Authorized roles: guest.","path":"/politicalNewsCrawler/guest/apiAlerts/{id}","method":"put","summary":"Update a specific API alert by id","description":"Update an existing API alert identified by its unique UUID.\n\nThis operation modifies the alert_type, message, and severity attributes of the API alert stored in the political_news_crawler_api_alerts table. This ensures that monitoring systems maintain correct and timely alert data for API subsystem errors.\n\nThe path parameter id uniquely identifies the API alert record to be updated.\n\nOnly users with 'guest' role authorization can execute this operation as the alert management is publicly accessible read/write controlled.\n\nThe operation will return the updated API alert record upon successful update.\n\nIf the specified id does not exist or payload validation fails, appropriate error responses will be generated.\n\nThis operation is a key part of the alert management subsystem that helps in tracking API error conditions and notifying stakeholders.","parameters":[{"name":"id","in":"path","description":"Unique identifier of the API alert to update","schema":{"type":"string","format":"uuid"}}],"requestBody":{"description":"Update data for the API alert","typeName":"IPoliticalNewsCrawlerApiAlert.IUpdate"},"responseBody":{"description":"Updated API alert record","typeName":"IPoliticalNewsCrawlerApiAlert"},"authorizationRoles":["guest"],"authorizationRole":"guest","authorizationType":null,"name":"update"},{"specification":"This operation permanently deletes a specified API alert identified by its unique UUID. It operates on the political_news_crawler_api_alerts table which contains API subsystem error alerts. The deletion is a hard delete without soft deletion semantics and does not return a response body. The API alert id must be supplied as a path parameter. Only users with 'guest' authorization role may invoke this endpoint, reflecting public access without authentication. This operation supports managing alert records and cleaning obsolete entries to maintain system hygiene and reduce storage load.","path":"/politicalNewsCrawler/guest/apiAlerts/{id}","method":"delete","summary":"Delete a specific API alert by id","description":"Delete an existing API alert permanently by its unique UUID.\n\nThis operation removes the alert record from the political_news_crawler_api_alerts table irreversibly.\n\nThe path parameter id specifies the alert to remove.\n\nOnly users with 'guest' role authorization can perform this action.\n\nNo response body is returned upon successful deletion.\n\nThis is a hard delete operation; the record is fully removed with no soft delete functionality.\n\nUse this operation cautiously as deleted alert records cannot be recovered.\n\nThis endpoint helps maintain system health by allowing removal of outdated or resolved alerts.","parameters":[{"name":"id","in":"path","description":"Unique identifier of the API alert to delete","schema":{"type":"string","format":"uuid"}}],"requestBody":null,"responseBody":null,"authorizationRoles":["guest"],"authorizationRole":"guest","authorizationType":null,"name":"erase"}],"components":{"authorization":[{"name":"guest","description":"Unauthenticated users who can access public endpoints to retrieve news and popular topics.","kind":"guest"}],"schemas":{"IPage.IPagination":{"type":"object","properties":{"current":{"type":"integer","minimum":0,"description":"Current page number."},"limit":{"type":"integer","minimum":0,"description":"Limitation of records per a page."},"records":{"type":"integer","minimum":0,"description":"Total records in the database."},"pages":{"type":"integer","minimum":0,"description":"Total pages.\n\nEqual to {@link records} / {@link limit} with ceiling."}},"required":["current","limit","records","pages"],"description":"Page information."},"IAuthorizationToken":{"type":"object","properties":{"access":{"type":"string","description":"JWT access token for authenticated requests.\n\nThis token should be included in the Authorization header for subsequent\nauthenticated API requests as `Bearer {token}`."},"refresh":{"type":"string","description":"Refresh token for obtaining new access tokens.\n\nThis token can be used to request new access tokens when the current access\ntoken expires, extending the user's session."},"expired_at":{"type":"string","format":"date-time","description":"Access token expiration timestamp.\n\nISO 8601 date-time string indicating when the access token will expire and\ncan no longer be used for authentication."},"refreshable_until":{"type":"string","format":"date-time","description":"Refresh token expiration timestamp.\n\nISO 8601 date-time string indicating the latest time until which the\nrefresh token can be used to obtain new access tokens."}},"required":["access","refresh","expired_at","refreshable_until"],"description":"Authorization token response structure.\n\nThis interface defines the structure of the authorization token response\nreturned after successful user authentication. It contains both access and\nrefresh tokens along with their expiration information.\n\nThis token structure is automatically included in API schemas when the system\ndetects authorization roles in the requirements analysis phase. It provides a\nstandard format for JWT-based authentication across the generated backend\napplications."},"IPageIPoliticalNewsCrawlerCrawlSources.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerCrawlSources.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerCrawlPolicy.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerCrawlPolicy.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerCrawlSchedule.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerCrawlSchedule.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerGuests.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerGuests.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerCrawlJobs":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerCrawlJobs"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerCrawlAttempt.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerCrawlAttempt.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerCrawledNews.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerCrawledNews.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerRawDataStorage.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerRawDataStorage.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerRawDataStorageLocalCacheFile.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerRawDataStorageLocalCacheFile.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerProcessedContent.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerProcessedContent.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerLlmJobs.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerLlmJobs.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerLlmJobResult":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerLlmJobResult"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerPopularTopics":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerPopularTopics"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerPopularityScore.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerPopularityScore.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerTopicMentions.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerTopicMentions.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerApiAccessLog.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerApiAccessLog.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerApiErrorLog.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerApiErrorLog.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerApiUsageMetricSummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerApiUsageMetricSummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerCrawlAlert":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerCrawlAlert"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerProcessingAlert":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerProcessingAlert"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPageIPoliticalNewsCrawlerApiAlert.ISummary":{"type":"object","properties":{"pagination":{"$ref":"#/components/schemas/IPage.IPagination","description":"Page information."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerApiAlert.ISummary"},"description":"List of records."}},"required":["pagination","data"],"description":"A page.\n\nCollection of records with pagination information."},"IPoliticalNewsCrawlerGuest.IRequest":{"description":"Guest join request payload. For guests, this is typically empty or minimal since no credentials are needed.","type":"object","properties":{},"required":[]},"IPoliticalNewsCrawlerGuest.IAuthorized":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Unique identifier of the authenticated guest"},"token":{"$ref":"#/components/schemas/IAuthorizationToken","description":"JWT token information for authentication"},"ip_address":{"type":"string","description":"IP address of the guest user"},"user_agent":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"User agent string presented by the guest"},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the guest record was created"},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when the guest record was last updated"}},"required":["id","token","ip_address","created_at","updated_at"],"description":"Authorization response containing JWT token.\n\nThis response is returned after successful guest authentication or token refresh operations. It contains guest metadata and token expiry information to support authenticated guest sessions."},"IPoliticalNewsCrawlerGuest.IRefresh":{"description":"Payload containing a refresh token to renew guest JWT tokens securely.","type":"object","properties":{"refresh_token":{"type":"string","description":"The refresh token used to obtain new JWT tokens."}},"required":["refresh_token"]},"IPoliticalNewsCrawlerCrawlSources.IRequest":{"type":"object","properties":{"search_keyword":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional search keyword to filter source code or URL."},"is_active":{"oneOf":[{"type":"boolean"},{"type":"null"}],"description":"Filter active sources only if true, inactive if false, or both if null."},"page":{"oneOf":[{"type":"integer","minimum":1},{"type":"null"}],"description":"Pagination page number, starting at 1."},"limit":{"oneOf":[{"type":"integer","minimum":1},{"type":"null"}],"description":"Records per page limit."},"order_by":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Sort by field name, e.g., \"source_code\" or \"created_at\"."},"direction":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Sort order direction: \"asc\" or \"desc\"."}},"required":[],"description":"Request interface for crawl sources listing with filtering and pagination.\nSupports criteria to search and paginate crawl sources."},"IPoliticalNewsCrawlerCrawlSources":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key.\n\nUnique identifier of the crawl source."},"source_code":{"type":"string","description":"Unique identifier code for the crawl source.\n\nThis code uniquely identifies each crawl source within the system."},"source_url":{"type":"string","description":"The base URL of the crawl source website or API.\n\nThe URL serves as the source location for crawling news data."},"is_active":{"type":"boolean","description":"Flag indicating whether the crawl source is active and enabled for crawling.\n\nWhen true, crawling operations are allowed for this source."},"description":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional description of the crawl source.\n\nProvides additional contextual information about the source."},"created_at":{"type":"string","format":"date-time","description":"Record creation timestamp.\n\nTimestamp when this crawl source record was created."},"updated_at":{"type":"string","format":"date-time","description":"Record last update timestamp.\n\nTimestamp when this record was last modified."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp, if record is deleted.\n\nNullable field indicating if the record was deleted."}},"required":["id","source_code","source_url","is_active","created_at","updated_at"],"description":"Political News Crawler Crawl Sources entity stores the configuration of each news source that the system can crawl. This includes the source's unique code, URL, active status, optional description, and audit timestamps.\n\nThis entity is fundamental for managing the variety of external sites and APIs from which political news is retrieved. Managing these sources centrally allows the crawler to operate on diverse data feeds efficiently and safely.\n\nSecurity note: This entity does not contain sensitive details and is generally exposed publicly.\n\nBusiness logic includes ensuring uniqueness of source_code and source_url and that inactive sources are excluded from crawling cycles."},"IPoliticalNewsCrawlerCrawlSources.ICreate":{"type":"object","properties":{"source_code":{"type":"string","description":"Unique identifier code for the crawl source.\n\nRequired during creation to uniquely identify the source."},"source_url":{"type":"string","description":"The base URL of the crawl source website or API.\n\nThis field is mandatory for crawl source creation."},"is_active":{"type":"boolean","description":"Flag indicating whether the crawl source is active and enabled for crawling.\n\nDefaults to true when creating a new source."},"description":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional description of the crawl source.\n\nCan be null if no description is provided."}},"required":["source_code","source_url","is_active"],"description":"Input type for creating a new political news crawler crawl source."},"IPoliticalNewsCrawlerCrawlSources.IUpdate":{"type":"object","properties":{"source_code":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Unique identifier code for the crawl source.\n\nUpdatable field for renaming or correcting source code."},"source_url":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"The base URL of the crawl source website or API.\n\nCan be updated to change the crawl target."},"is_active":{"type":"boolean","description":"Flag indicating whether the crawl source is active and enabled for crawling.\n\nAllows enabling or disabling crawling for this source."},"description":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional description of the crawl source.\n\nCan be updated or cleared by setting null explicitly."}},"required":[],"description":"Input type for updating an existing political news crawler crawl source."},"IPoliticalNewsCrawlerCrawlPolicy.IRequest":{"type":"object","properties":{"page":{"oneOf":[{"type":"integer","minimum":0,"description":"Pagination page number.\n\nThe page to retrieve for paginated results."},{"type":"null"}],"description":"Pagination page number.\n\nThe page to retrieve for paginated results."},"limit":{"oneOf":[{"type":"integer","minimum":0,"description":"Pagination page size limit.\n\nThe maximum number of items per page."},{"type":"null"}],"description":"Pagination page size limit.\n\nThe maximum number of items per page."},"policy_name":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Filter for policy name matching.\n\nCan be used to search for policies by name."},"max_crawl_frequency_minutes":{"oneOf":[{"type":"integer"},{"type":"null"}],"description":"Filter for maximum crawl frequency.\n\nLimits results to policies with max frequency below this value."},"ban_detection_enabled":{"oneOf":[{"type":"boolean"},{"type":"null"}],"description":"Filter for enabling ban detection.\n\nIf true, only policies with ban detection enabled are returned."}},"required":[],"description":"Request type for searching crawl policies, supports filtering and pagination."},"IPoliticalNewsCrawlerCrawlPolicy":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"policy_name":{"type":"string","description":"Unique name identifier for the crawl policy."},"max_crawl_frequency_minutes":{"type":"integer","format":"int32","description":"Maximum allowed crawl frequency in minutes."},"max_retry_attempts":{"type":"integer","format":"int32","description":"Maximum number of retry attempts after failures."},"backoff_multiplier":{"type":"number","description":"Multiplier factor for exponential backoff on retries."},"ban_detection_enabled":{"type":"boolean","description":"Flag to enable detection and handling of bans during crawling."},"created_at":{"type":"string","format":"date-time","description":"Record creation timestamp."},"updated_at":{"type":"string","format":"date-time","description":"Record last update timestamp."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp, if record is deleted."}},"required":["id","policy_name","max_crawl_frequency_minutes","max_retry_attempts","backoff_multiplier","ban_detection_enabled","created_at","updated_at"],"description":"Configuration for crawl policies governing crawling frequency, retry, and error handling for political news sources. Ensures adaptive and respectful crawling behavior according to source limits and bans."},"IPoliticalNewsCrawlerCrawlPolicy.ICreate":{"type":"object","properties":{"policy_name":{"type":"string","description":"Unique name identifier for the crawl policy."},"max_crawl_frequency_minutes":{"type":"integer","format":"int32","description":"Maximum allowed crawl frequency in minutes."},"max_retry_attempts":{"type":"integer","format":"int32","description":"Maximum number of retry attempts after failures."},"backoff_multiplier":{"type":"number","description":"Multiplier factor for exponential backoff on retries."},"ban_detection_enabled":{"type":"boolean","description":"Flag to enable detection and handling of bans during crawling."}},"required":["policy_name","max_crawl_frequency_minutes","max_retry_attempts","backoff_multiplier","ban_detection_enabled"],"description":"Create info for crawl policy."},"IPoliticalNewsCrawlerCrawlPolicy.IUpdate":{"type":"object","properties":{"policy_name":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Unique name identifier for the crawl policy."},"max_crawl_frequency_minutes":{"oneOf":[{"type":"integer","format":"int32"},{"type":"null"}],"description":"Maximum allowed crawl frequency in minutes."},"max_retry_attempts":{"oneOf":[{"type":"integer","format":"int32"},{"type":"null"}],"description":"Maximum number of retry attempts after failures."},"backoff_multiplier":{"oneOf":[{"type":"number"},{"type":"null"}],"description":"Multiplier factor for exponential backoff on retries."},"ban_detection_enabled":{"oneOf":[{"type":"boolean"},{"type":"null"}],"description":"Flag to enable detection and handling of bans during crawling."}},"required":[],"description":"Update info for crawl policy."},"IPoliticalNewsCrawlerCrawlSchedule.IRequest":{"type":"object","properties":{"page":{"oneOf":[{"type":"integer","format":"uint32"},{"type":"null"}],"description":"Page number."},"limit":{"oneOf":[{"type":"integer","format":"uint32"},{"type":"null"}],"description":"Limitation of records per a page."},"sort":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Sorting expression with 'propertyName asc' or 'propertyName desc'.\n\nExample: \"created_at desc\""},"crawl_source_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Filter by crawl source ID (foreign key to political_news_crawler_crawl_sources)."},"crawl_policy_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Filter by crawl policy ID (foreign key to political_news_crawler_crawl_policies)."},"is_enabled":{"oneOf":[{"type":"boolean"},{"type":"null"}],"description":"Filter by enabled flag."},"last_crawled_after":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Filter records last crawled after this timestamp."},"last_crawled_before":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Filter records last crawled before this timestamp."},"next_crawl_after":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Filter records next crawl after this timestamp."},"next_crawl_before":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Filter records next crawl before this timestamp."}},"required":[],"description":"Search data and pagination filter criteria for crawl schedules.","default":{}},"IPoliticalNewsCrawlerCrawlSchedule":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key.\n\nUnique identifier for the crawl schedule record.\n\nFormat: UUID string."},"crawl_source_id":{"type":"string","format":"uuid","description":"Reference to Crawling Source.\n\nForeign key to the political_news_crawler_crawl_sources entity."},"crawl_policy_id":{"type":"string","format":"uuid","description":"Reference to Crawl Policy.\n\nForeign key to the political_news_crawler_crawl_policies entity."},"schedule_expression":{"type":"string","description":"Cron expression defining the crawl schedule timing.\n\nFormat is a standard cron string defining when the crawl runs."},"last_crawled_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp when the crawl last occurred.\n\nOptional ISO 8601 date-time string."},"next_crawl_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp for the next scheduled crawl.\n\nOptional ISO 8601 date-time string."},"is_enabled":{"type":"boolean","description":"Flag indicating if this schedule is enabled.\n\nTrue if schedule is active."},"created_at":{"type":"string","format":"date-time","description":"Record creation timestamp.\n\nISO 8601 date-time string."},"updated_at":{"type":"string","format":"date-time","description":"Record last update timestamp.\n\nISO 8601 date-time string."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp, if record is deleted.\n\nOptional ISO 8601 date-time string."}},"required":["id","crawl_source_id","crawl_policy_id","schedule_expression","is_enabled","created_at","updated_at"],"description":"Defines when and how often crawling runs for each political news source. References the crawl source and policy to enable adaptive scheduling and coordination."},"IPoliticalNewsCrawlerCrawlSchedules.ICreate":{"type":"object","properties":{"crawl_source_id":{"type":"string","format":"uuid","description":"Reference to Crawling Source.\n\nRequired foreign key UUID string."},"crawl_policy_id":{"type":"string","format":"uuid","description":"Reference to Crawl Policy.\n\nRequired foreign key UUID string."},"schedule_expression":{"type":"string","description":"Cron expression defining the crawl schedule timing.\n\nRequired string with cron format."},"is_enabled":{"type":"boolean","description":"Flag indicating if this schedule is enabled.\n\nRequired boolean."}},"required":["crawl_source_id","crawl_policy_id","schedule_expression","is_enabled"],"description":"Creation info of the crawl schedules"},"IPoliticalNewsCrawlerCrawlSchedules":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key identifier of the crawl schedule."},"data":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerCrawlSchedule"},"description":"List of crawl schedule records."},"pagination":{"type":"object","properties":{"current":{"type":"integer","minimum":1,"description":"Current page number."},"limit":{"type":"integer","minimum":1,"description":"Number of records per page."},"records":{"type":"integer","minimum":0,"description":"Total number of records matching the criteria."},"pages":{"type":"integer","minimum":1,"description":"Total number of pages available."}},"required":["current","limit","records","pages"],"description":"Pagination information for the result set."}},"required":["id","data","pagination"],"description":"Response structure for paginated crawl schedules."},"IPoliticalNewsCrawlerCrawlSchedules.IUpdate":{"type":"object","properties":{"crawl_source_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Reference to Crawling Source.\n\nOptional foreign key UUID string."},"crawl_policy_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Reference to Crawl Policy.\n\nOptional foreign key UUID string."},"schedule_expression":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Cron expression defining the crawl schedule timing.\n\nOptional string with cron format."},"last_crawled_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp when the crawl last occurred.\n\nOptional ISO 8601 date-time string."},"next_crawl_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp for the next scheduled crawl.\n\nOptional ISO 8601 date-time string."},"is_enabled":{"type":"boolean","description":"Flag indicating if this schedule is enabled.\n\nOptional boolean."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp, if record is deleted.\n\nOptional ISO 8601 date-time string."}},"required":[],"description":"Update info of the crawl schedules"},"IPoliticalNewsCrawlerGuests.IRequest":{"type":"object","properties":{"ip_address":{"type":"string","description":"Optional string filter for IP address.\n\nSupports exact or partial search."},"user_agent":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional string filter for user agent.\n\nSupports exact or partial search."},"page":{"oneOf":[{"type":"number"},{"type":"null"}],"description":"Pagination: page number.\n\nOptional unsigned 32-bit integer."},"limit":{"oneOf":[{"type":"number"},{"type":"null"}],"description":"Pagination: number of records per page.\n\nOptional unsigned 32-bit integer.\n\nDefault is typically 100."},"sort":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional sort order specification.\n\nCould be a string indicating sorting field and direction."},"search":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional search string for fuzzy matching or full-text search."}},"description":"Request body schema for searching political news crawler guests with filtering and pagination.","required":[]},"IPoliticalNewsCrawlerGuests":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"ip_address":{"type":"string","description":"IP address of the guest user."},"user_agent":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"User agent string presented by the guest."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the guest record was created."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when the guest record was last updated."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp of soft deletion for the guest record."}},"required":["id","ip_address","created_at","updated_at"],"description":"Stores political news crawler guest user information representing unauthenticated users accessing APIs. Captures identification via IP and user agent, includes timestamps for auditing and soft deletion support.\n\nGuests are limited to read-only access with no password or login credentials."},"IPoliticalNewsCrawlerCrawlJobsIRequest":{"type":"object","properties":{"crawl_schedule_id":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional filter for crawl schedule ID.\n\nIdentifies the schedule to which the job belongs."},"active":{"oneOf":[{"type":"boolean"},{"type":"null"}],"description":"Optional filter for job active status.\n\nBoolean to filter active or inactive jobs."},"page":{"oneOf":[{"type":"number"},{"type":"null"}],"description":"Pagination: current page number.\n\nOptional unsigned 32-bit integer."},"limit":{"oneOf":[{"type":"number"},{"type":"null"}],"description":"Pagination: limit of records per page.\n\nOptional unsigned 32-bit integer.\n\nDefault value is usually 100."},"sort":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional sort instructions.\n\nSpecifies how results should be ordered."},"search":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional search keyword.\n\nUsed for filtering jobs based on relevant text fields."}},"description":"Request body schema for searching crawl jobs with filtering and pagination.","required":[]},"IPoliticalNewsCrawlerCrawlJobs":{"type":"object","properties":{"id":{"type":"string","description":"Primary Key.\n\nUnique identifier for the crawl job.\n\nStored as UUID string."},"crawl_source_id":{"type":"string","description":"Referenced crawl source identifier.\n\nRelates to the source where crawling is performed.\n\nUUID string."},"crawl_schedule_id":{"type":"string","description":"Referenced crawl schedule identifier.\n\nSpecifies schedule associated with the crawl job.\n\nUUID string."},"active":{"type":"boolean","description":"Boolean flag indicating if the crawl job is active.\n\nTrue if scheduled to run, false otherwise."},"last_run_started_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Optional timestamp when the last run started.\n\nNullable ISO 8601 date-time string with timezone."},"last_run_completed_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Optional timestamp when the last run completed.\n\nNullable ISO 8601 date-time string with timezone."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the crawl job was created.\n\nISO 8601 date-time format."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when the crawl job was last updated.\n\nISO 8601 date-time format."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Optional soft deletion timestamp.\n\nNullable ISO 8601 date-time string with timezone."}},"required":["id","crawl_source_id","crawl_schedule_id","active","created_at","updated_at"],"description":"Entity representing a scheduled crawl job for a political news source."},"IPoliticalNewsCrawlerCrawlJobsICreate":{"type":"object","properties":{"crawl_source_id":{"type":"string","format":"uuid","description":"Reference to the crawl source identifier.\nFormat: UUID v4 string.\nIt identifies the source from which the crawl job originates."},"crawl_schedule_id":{"type":"string","format":"uuid","description":"Reference to the crawl schedule identifier.\nFormat: UUID v4 string.\nLinks the job to a predefined crawl schedule."},"active":{"type":"boolean","description":"Indicates whether the crawl job is active and scheduled to run.\ntrue means the job is currently active and enabled."},"last_run_started_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp when the last run of the crawl job started.\nOptional, nullable.\nFormat: ISO 8601 date-time string.\nRepresents the start time of the most recent execution."},"last_run_completed_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp when the last run of the crawl job completed.\nOptional, nullable.\nFormat: ISO 8601 date-time string.\nRepresents when the most recent execution finished."}},"required":["crawl_source_id","crawl_schedule_id","active"],"description":"Create request body schema for political_news_crawler_crawl_jobs table representing crawl job creation information."},"IPoliticalNewsCrawlerCrawlJob.IUpdate":{"type":"object","properties":{"crawl_source_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Reference to the crawl source identifier.\nFormat: UUID v4 string.\nIdentifies the source from which this crawl job originates.\nOptional in update, nullable."},"crawl_schedule_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Reference to the crawl schedule identifier.\nFormat: UUID v4 string.\nLinks the job to its crawl schedule.\nOptional in update, nullable."},"active":{"type":"boolean","description":"Boolean indicating if the crawl job is active.\nOptional in update."},"last_run_started_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp when the last run of the crawl job started.\nOptional in update, nullable.\nFormat: ISO 8601 date-time string."},"last_run_completed_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp when the last run of the crawl job completed.\nOptional in update, nullable.\nFormat: ISO 8601 date-time string."}},"required":[],"description":"Update request body schema for political_news_crawler_crawl_jobs table representing crawl job update information."},"IPoliticalNewsCrawlerCrawlJob":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Unique identifier of the crawl job."},"crawl_source_id":{"type":"string","format":"uuid","description":"Reference to the crawl source identifier.\nIdentifies the source of the crawl job."},"crawl_schedule_id":{"type":"string","format":"uuid","description":"Reference to the crawl schedule identifier.\nLinks to the crawl schedule dictating crawl timing."},"active":{"type":"boolean","description":"Boolean indicating if the crawl job is active."},"last_run_started_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp when the last run started. Optional, nullable."},"last_run_completed_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp when the last run completed. Optional, nullable."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the record was created."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when the record was last updated."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp when the record was soft deleted. Optional, nullable."}},"required":["id","crawl_source_id","crawl_schedule_id","active","created_at","updated_at"],"description":"Entity schema for political_news_crawler_crawl_jobs table representing a crawl job record."},"IPoliticalNewsCrawlerCrawlAttempt.IRequest":{"type":"object","properties":{"crawl_job_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Filters for crawl job ID to restrict crawl attempts to a specific job. Optional filter."},"success":{"oneOf":[{"type":"boolean"},{"type":"null"}],"description":"Filter for success status of the crawl attempt. Optional."},"started_after":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Start timestamp to filter crawl attempts that started after this time. Optional, nullable."},"started_before":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"End timestamp to filter crawl attempts that started before this time. Optional, nullable."},"page":{"oneOf":[{"type":"integer","minimum":1},{"type":"null"}],"description":"Pagination page number. Optional. Must be positive integer if provided."},"limit":{"oneOf":[{"type":"integer","minimum":1},{"type":"null"}],"description":"Pagination page size limit. Optional. Must be positive integer if provided."}},"required":[],"description":"Request schema for filtering and pagination of crawl attempts."},"IPoliticalNewsCrawlerCrawlAttempt":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"crawl_job_id":{"type":"string","format":"uuid","description":"Associated crawl job identifier."},"raw_data_storage_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Reference to raw data storage entry for the crawl result."},"started_at":{"type":"string","format":"date-time","description":"Timestamp when this crawl attempt started."},"completed_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp when this crawl attempt ended; null if still running."},"success":{"type":"boolean","description":"Indicator whether this crawl attempt was successful."},"error_message":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Error message details if the crawl attempt failed."},"created_at":{"type":"string","format":"date-time","description":"Record creation timestamp."},"updated_at":{"type":"string","format":"date-time","description":"Record last update timestamp."}},"required":["id","crawl_job_id","started_at","success","created_at","updated_at"],"description":"Records individual execution attempts of crawl jobs, tracking start and completion times, success status, errors, and associated raw data references to enable detailed auditing and failure analysis."},"IPoliticalNewsCrawlerCrawlAttempt.ICreate":{"type":"object","properties":{"crawl_job_id":{"type":"string","format":"uuid","description":"Associated crawl job identifier. {@link political_news_crawler_crawl_jobs.id}"},"raw_data_storage_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Optional reference to raw data storage entry for the crawl result. {@link political_news_crawler_raw_data_storage.id}"},"started_at":{"type":"string","format":"date-time","description":"Timestamp when this crawl attempt started."},"completed_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Optional timestamp when this crawl attempt ended; null if still running."},"success":{"type":"boolean","description":"Indicator whether this crawl attempt was successful."},"error_message":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional error message details if the crawl attempt failed."}},"required":["crawl_job_id","started_at","success"],"description":"Input data for creating a new crawl attempt record.\n\nIncludes crawl job association, start time, success indicator, and optionally raw data reference, completion time, and error message."},"IPoliticalNewsCrawlerCrawlAttempt.IUpdate":{"type":"object","properties":{"crawl_job_id":{"type":"string","format":"uuid","description":"Associated crawl job identifier. {@link political_news_crawler_crawl_jobs.id}"},"raw_data_storage_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Optional reference to raw data storage entry for the crawl result. {@link political_news_crawler_raw_data_storage.id}"},"started_at":{"type":"string","format":"date-time","description":"Timestamp when this crawl attempt started."},"completed_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Optional timestamp when this crawl attempt ended; null if still running."},"success":{"type":"boolean","description":"Indicator whether this crawl attempt was successful."},"error_message":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional error message details if the crawl attempt failed."}},"required":[],"description":"Partial update data for modifying an existing crawl attempt record.\n\nAllows updating any combination of crawl job ID, raw data storage reference, start and end timestamps, success flag, and error message."},"IPoliticalNewsCrawlerCrawledNews.IRequest":{"type":"object","properties":{"page":{"oneOf":[{"type":"integer"},{"type":"null"}],"description":"Page number for pagination."},"limit":{"oneOf":[{"type":"integer"},{"type":"null"}],"description":"Limitation of records per a page."},"search":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Search term to filter news."},"sort_by":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Sorting field and direction."},"crawl_attempt_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Filter to specific crawl attempt ID."}},"required":[],"description":"Request parameters for querying crawled news with filtering, sorting, and pagination."},"IPoliticalNewsCrawlerCrawledNews":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"crawl_attempt_id":{"type":"string","format":"uuid","description":"Associated crawl attempt identifier."},"url":{"type":"string","description":"URL of the crawled news article."},"title":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Title of the news article, if available."},"published_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Publish timestamp of the news article, if known."},"created_at":{"type":"string","format":"date-time","description":"Record creation timestamp."},"updated_at":{"type":"string","format":"date-time","description":"Record last update timestamp."}},"required":["id","crawl_attempt_id","url","created_at","updated_at"],"description":"Contains metadata for crawled political news articles, linking to the crawl attempt that obtained the raw content and providing key attributes for management and filtering."},"IPoliticalNewsCrawlerCrawledNews.ICreate":{"type":"object","properties":{"crawl_attempt_id":{"type":"string","format":"uuid","description":"Associated crawl attempt identifier. {@link\r\n  /// political_news_crawler_crawl_attempts.id}"},"url":{"type":"string","description":"URL of the crawled news article."},"title":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Title of the news article, if available."},"published_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Publish timestamp of the news article, if known."}},"required":["crawl_attempt_id","url"],"description":"Create a new crawled news article associated with the specified crawl attempt.\n\nThe request body must contain the minimum required information for the crawler news metadata, including a valid URL. Title and published date are optional but recommended for completeness.\n\nNo authentication is required for this operation. On success, the newly created news article's full details are returned.\n\nThis operation complements retrieval and management endpoints allowing clients to add new news entries for a crawl attempt."},"IPoliticalNewsCrawlerCrawledNews.IUpdate":{"type":"object","properties":{"crawl_attempt_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Associated crawl attempt identifier. {@link\r\n  /// political_news_crawler_crawl_attempts.id}"},"url":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"URL of the crawled news article."},"title":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Title of the news article, if available."},"published_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Publish timestamp of the news article, if known."},"created_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Record creation timestamp."},"updated_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Record last update timestamp."}},"required":[],"description":"Update metadata of a crawled news article within the specified crawl attempt.\n\nOnly provided fields in the request body will be updated; others remain unchanged.\n\nThe operation validates the existence of the target article linked to the crawl attempt.\n\nNo authentication is required. Responses include the updated entity details.\n\nThis operation works in conjunction with create, retrieve, and delete endpoints to provide full management capabilities."},"IPoliticalNewsCrawlerRawDataStorage.IRequest":{"type":"object","properties":{"crawl_source_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Belonged crawl source's political_news_crawler_crawl_sources.id."},"crawl_job_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Optional crawl job reference to political_news_crawler_crawl_jobs.id."},"storage_key":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Unique key or path identifying storage location in cloud object storage (e.g., GCP or AWS S3)."},"file_format":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Format of the raw data file such as JSON or XML for processing compatibility."},"file_size_bytes":{"oneOf":[{"type":"number"},{"type":"null"}],"description":"Size of the raw data file in bytes."},"checksum":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Checksum hash to verify file integrity."},"crawl_timestamp":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp when the raw data was crawled, used for data freshness and scheduling."},"created_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Creation timestamp record."},"updated_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Last update timestamp record."}},"required":[],"description":"Retrieve a filtered and paginated list of raw data storage metadata entries for political news crawling. The operation supports filtering by crawl source and crawl job identifiers, file format types, crawl timestamps, and file sizes. Sorting and pagination options enable efficient browsing through large datasets stored in cloud object storage.\n\nSecurity considerations include limited access to authenticated users with appropriate read privileges, as raw data files may contain sensitive or proprietary information. \n\nThis operation is tightly integrated with the political_news_crawler_raw_data_storage table defined in the Prisma schema, encompassing all relevant fields and relationships. The response returns simplified summary information suited for list displays.\n\nThere is no request body since this is a PATCH method designed for complex search and filtering inputs."},"IPoliticalNewsCrawlerRawDataStorage":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"crawl_source_id":{"type":"string","format":"uuid","description":"Belonged crawl source's political_news_crawler_crawl_sources.id."},"crawl_job_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Optional crawl job reference to political_news_crawler_crawl_jobs.id."},"storage_key":{"type":"string","description":"Unique key or path identifying storage location in cloud object storage (e.g., GCP or AWS S3)."},"file_format":{"type":"string","description":"Format of the raw data file such as JSON or XML for processing compatibility."},"file_size_bytes":{"type":"integer","format":"int32","description":"Size of the raw data file in bytes."},"checksum":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Checksum hash to verify file integrity."},"crawl_timestamp":{"type":"string","format":"date-time","description":"Timestamp when the raw data was crawled, used for data freshness and scheduling."},"created_at":{"type":"string","format":"date-time","description":"Creation timestamp record."},"updated_at":{"type":"string","format":"date-time","description":"Last update timestamp record."}},"required":["id","crawl_source_id","storage_key","file_format","file_size_bytes","crawl_timestamp","created_at","updated_at"],"description":"Stores metadata and references for raw political news data collected from various crawling sources. Ensures durable and consistent storage links to cloud object storage. Tracks source information, crawl job association, and data integrity validations. Includes audit timestamps for traceability."},"IPoliticalNewsCrawlerRawDataStorage.ICreate":{"type":"object","properties":{"crawl_source_id":{"type":"string","description":"Belonged crawl source's political_news_crawler_crawl_sources.id.\n\nIdentifier of the crawl source from which this raw data originated."},"crawl_job_id":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional crawl job reference to political_news_crawler_crawl_jobs.id.\n\nIdentifier of the crawl job associated with this raw data, if any."},"storage_key":{"type":"string","description":"Unique key or path identifying storage location in cloud object storage\n(e.g., GCP or AWS S3).\n\nStorage key that identifies the raw data file location within cloud storage."},"file_format":{"type":"string","description":"Format of the raw data file such as JSON or XML for processing\ncompatibility.\n\nString specifying the file format of the stored raw data."},"file_size_bytes":{"type":"integer","description":"Size of the raw data file in bytes.\n\nInteger representing the size of the raw data file in bytes."},"checksum":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Checksum hash to verify file integrity.\n\nOptional checksum string for data integrity verification."},"crawl_timestamp":{"type":"string","format":"date-time","description":"Timestamp when the raw data was crawled, used for data freshness and\nscheduling.\n\nDate-time when the raw data was obtained."}},"required":["crawl_source_id","storage_key","file_format","file_size_bytes","crawl_timestamp"],"description":"Creation info of the crawl source\n\n@author AutoBE - https://github.com/wrtnlabs/autobe"},"IPoliticalNewsCrawlerRawDataStorage.IUpdate":{"type":"object","properties":{"crawl_source_id":{"type":"string","description":"Belonged crawl source's political_news_crawler_crawl_sources.id.\n\nIdentifier of the crawl source from which this raw data originated."},"crawl_job_id":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional crawl job reference to political_news_crawler_crawl_jobs.id.\n\nIdentifier of the crawl job associated with this raw data, if any."},"storage_key":{"type":"string","description":"Unique key or path identifying storage location in cloud object storage\n(e.g., GCP or AWS S3).\n\nStorage key that identifies the raw data file location within cloud storage."},"file_format":{"type":"string","description":"Format of the raw data file such as JSON or XML for processing\ncompatibility.\n\nString specifying the file format of the stored raw data."},"file_size_bytes":{"type":"integer","description":"Size of the raw data file in bytes.\n\nInteger representing the size of the raw data file in bytes."},"checksum":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Checksum hash to verify file integrity.\n\nOptional checksum string for data integrity verification."},"crawl_timestamp":{"type":"string","format":"date-time","description":"Timestamp when the raw data was crawled, used for data freshness and\nscheduling.\n\nDate-time when the raw data was obtained."}},"required":[],"description":"Update info of the crawl source\n\n@author AutoBE - https://github.com/wrtnlabs/autobe"},"IPoliticalNewsCrawlerRawDataStorageLocalCacheFile.IRequest":{"type":"object","properties":{"page":{"oneOf":[{"type":"integer"},{"type":"null"}],"description":"Page number.\n\nOptional page number for pagination (unsigned 32-bit integer)."},"limit":{"oneOf":[{"type":"integer"},{"type":"null"}],"description":"Limitation of records per a page.\n\nOptional limit to restrict the number of records per page (unsigned 32-bit integer)."},"ttl_expiration_at_from":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Filter records with ttl_expiration_at greater than or equal to this ISO datetime.\n\nOptional filter to include only cache files whose TTL expiration is after or equal to certain date-time."},"ttl_expiration_at_to":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Filter records with ttl_expiration_at less than or equal to this ISO datetime.\n\nOptional filter to include only cache files whose TTL expiration is before or equal to certain date-time."},"created_at_from":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Filter records created after or equal to this ISO datetime.\n\nOptional filter for records created on or after a specific date-time."},"created_at_to":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Filter records created before or equal to this ISO datetime.\n\nOptional filter for records created on or before a specific date-time."}},"required":[],"description":"Search and pagination filter criteria for crawl schedules\n\n@author AutoBE - https://github.com/wrtnlabs/autobe"},"IPoliticalNewsCrawlerRawDataStorageLocalCacheFile":{"type":"object","description":"Tracks local file cache copies of raw crawled political news data with TTL enforcement and deletion status. Enables fast retrieval during cloud storage outages and manages file lifecycle with audit timestamps.","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"raw_data_storage_id":{"type":"string","format":"uuid","description":"Reference to related raw data storage record, political_news_crawler_raw_data_storage.id."},"local_file_path":{"type":"string","description":"Filesystem path or identifier for the local cached file copy."},"file_size_bytes":{"type":"integer","description":"Size of the local cached file in bytes."},"ttl_expiration_at":{"type":"string","format":"date-time","description":"Datetime when the cached file expires and is due for deletion under TTL policy."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp indicating when the cached file was deleted, if applicable."},"created_at":{"type":"string","format":"date-time","description":"Creation timestamp record."},"updated_at":{"type":"string","format":"date-time","description":"Last update timestamp record."}},"required":["id","raw_data_storage_id","local_file_path","file_size_bytes","ttl_expiration_at","created_at","updated_at"]},"IPoliticalNewsCrawlerRawDataStorageLocalCacheFile.ICreate":{"type":"object","description":"Create a new local cache file metadata record for a raw data storage entry. The record includes the local file path, file size, TTL expiration datetime, and timestamps.","properties":{"raw_data_storage_id":{"type":"string","format":"uuid","description":"Reference to related raw data storage record, political_news_crawler_raw_data_storage.id."},"local_file_path":{"type":"string","description":"Filesystem path or identifier for the local cached file copy."},"file_size_bytes":{"type":"integer","description":"Size of the local cached file in bytes."},"ttl_expiration_at":{"type":"string","format":"date-time","description":"Datetime when the cached file expires and is due for deletion under TTL policy."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp indicating when the cached file was deleted, if applicable."}},"required":["raw_data_storage_id","local_file_path","file_size_bytes","ttl_expiration_at"]},"IPoliticalNewsCrawlerLocalCacheFiles.IUpdate":{"type":"object","description":"Update the metadata of a specific local cache file associated with raw data storage. Supports modifying path, size, TTL expiration, and deletion timestamp.","properties":{"raw_data_storage_id":{"type":"string","format":"uuid","description":"Reference to related raw data storage record, political_news_crawler_raw_data_storage.id."},"local_file_path":{"type":"string","description":"Filesystem path or identifier for the local cached file copy."},"file_size_bytes":{"type":"integer","description":"Size of the local cached file in bytes."},"ttl_expiration_at":{"type":"string","format":"date-time","description":"Datetime when the cached file expires and is due for deletion under TTL policy."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp indicating when the cached file was deleted, if applicable."}},"required":[]},"IPoliticalNewsCrawlerLocalCacheFiles":{"type":"object","description":"Tracks local file cache copies of raw crawled political news data with TTL enforcement and deletion status. Enables fast retrieval during cloud storage outages and manages file lifecycle with audit timestamps.","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"raw_data_storage_id":{"type":"string","format":"uuid","description":"Reference to related raw data storage record, political_news_crawler_raw_data_storage.id."},"local_file_path":{"type":"string","description":"Filesystem path or identifier for the local cached file copy."},"file_size_bytes":{"type":"integer","description":"Size of the local cached file in bytes."},"ttl_expiration_at":{"type":"string","format":"date-time","description":"Datetime when the cached file expires and is due for deletion under TTL policy."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp indicating when the cached file was deleted, if applicable."},"created_at":{"type":"string","format":"date-time","description":"Creation timestamp record."},"updated_at":{"type":"string","format":"date-time","description":"Last update timestamp record."}},"required":["id","raw_data_storage_id","local_file_path","file_size_bytes","ttl_expiration_at","created_at","updated_at"]},"IPoliticalNewsCrawlerProcessedContent":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"raw_data_storage_id":{"type":"string","format":"uuid","description":"Foreign key to the raw data storage record, political_news_crawler_raw_data_storage.id."},"llm_job_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Foreign key to associated LLM job, political_news_crawler_llm_jobs.id."},"content_type":{"type":"string","description":"Type of processed content, e.g., summary, highlight, or analysis."},"content_body":{"type":"string","description":"Full textual content produced by LLM processing."},"generation_timestamp":{"type":"string","format":"date-time","description":"Timestamp when this content was generated."},"created_at":{"type":"string","format":"date-time","description":"Record creation timestamp, typically same or near generation time."},"updated_at":{"type":"string","format":"date-time","description":"Last update timestamp record."}},"required":["id","raw_data_storage_id","content_type","content_body","generation_timestamp","created_at","updated_at"],"description":"Processed political news content generated by LLM post-processing, including summaries, highlights, and analysis. Links content to raw data storage and optionally to the LLM job that generated it. Contains content type, full text body, generation timestamp, and audit timestamps.\n\nSupports text search through GIN index on content body."},"IPoliticalNewsCrawlerProcessedContent.IRequest":{"type":"object","properties":{"raw_data_storage_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Filter by raw data storage id for processed content records"},"content_type":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Filter by content type, such as \"summary\", \"highlight\", or \"analysis\""},"page":{"oneOf":[{"type":"integer"},{"type":"null"}],"description":"Pagination current page number."},"limit":{"oneOf":[{"type":"integer"},{"type":"null"}],"description":"Pagination limit on number of records per page."},"generated_from":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Optional filter for date range start for generation timestamp."},"generated_to":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Optional filter for date range end for generation timestamp."}},"required":[],"description":"Request type for searching and paginating processed content records linked to raw data storage."},"IPoliticalNewsCrawlerProcessedContent.ICreate":{"type":"object","properties":{"raw_data_storage_id":{"type":"string","format":"uuid","description":"Foreign key to the raw data storage record, political_news_crawler_raw_data_storage.id."},"llm_job_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Foreign key to associated LLM job, political_news_crawler_llm_jobs.id."},"content_type":{"type":"string","description":"Type of processed content, e.g., summary, highlight, or analysis."},"content_body":{"type":"string","description":"Full textual content produced by LLM processing."},"generation_timestamp":{"type":"string","format":"date-time","description":"Timestamp when this content was generated."}},"required":["raw_data_storage_id","content_type","content_body","generation_timestamp"],"description":"Request type for creating processed content, including raw data reference and LLM job association."},"IPoliticalNewsCrawlerProcessedContent.IUpdate":{"type":"object","properties":{"raw_data_storage_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Foreign key to the raw data storage record, political_news_crawler_raw_data_storage.id."},"llm_job_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Foreign key to associated LLM job, political_news_crawler_llm_jobs.id."},"content_type":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Type of processed content, e.g., summary, highlight, or analysis."},"content_body":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Full textual content produced by LLM processing."},"generation_timestamp":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp when this content was generated."}},"required":[],"description":"Request type for updating processed content with optional fields for patch-like modification."},"IPoliticalNewsCrawlerLlmJobs.IRequest":{"type":"object","properties":{"crawl_source_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Filter by crawl source UUID. Optional."},"status":{"oneOf":[{"const":"pending"},{"const":"running"},{"const":"completed"},{"const":"failed"},{"type":"null"}],"description":"Filter by exact status: 'pending', 'running', 'completed', 'failed'. Optional."},"page":{"oneOf":[{"type":"integer","minimum":1,"format":"uint32"},{"type":"null"}],"description":"Pagination: page number >= 1. Optional. Provides the page number for paginated results."},"limit":{"oneOf":[{"type":"integer","minimum":1,"format":"uint32"},{"type":"null"}],"description":"Pagination: limit per page >= 1. Optional, default can be 100."},"orderBy":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Sort key, e.g., 'created_at' or 'updated_at'. Optional."}},"description":"Request parameters for searching and pagination of LLM jobs.","required":[]},"IPoliticalNewsCrawlerLlmJobs":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Unique identifier of the LLM job."},"crawl_source_id":{"type":"string","format":"uuid","description":"The source channel from which the raw news data originated."},"status":{"oneOf":[{"const":"pending","description":"Processing status of the job."},{"const":"running","description":"Processing status of the job."},{"const":"completed","description":"Processing status of the job."},{"const":"failed","description":"Processing status of the job."}],"description":"Processing status of the job."},"parameters":{"type":"string","description":"JSON string of parameters or prompts used for this LLM job."},"created_at":{"type":"string","format":"date-time","description":"Job creation timestamp."},"updated_at":{"type":"string","format":"date-time","description":"Job last update timestamp."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp, if record is deleted; nullable."}},"required":["id","crawl_source_id","status","parameters","created_at","updated_at"],"description":"Represents a Large Language Model (LLM) processing job entity managing asynchronous processing tasks for political news data."},"IPoliticalNewsCrawlerLlmJobs.ICreate":{"type":"object","properties":{"crawl_source_id":{"type":"string","format":"uuid","description":"The source channel from which the raw news data originated."},"status":{"oneOf":[{"const":"pending","description":"Processing status of the job."},{"const":"running","description":"Processing status of the job."},{"const":"completed","description":"Processing status of the job."},{"const":"failed","description":"Processing status of the job."}],"description":"Processing status of the job."},"parameters":{"type":"string","description":"JSON string of parameters or prompts used for this LLM job."}},"required":["crawl_source_id","status","parameters"],"description":"Request body for creating a new LLM processing job."},"IPoliticalNewsCrawlerLlmJobs.IUpdate":{"type":"object","properties":{"crawl_source_id":{"type":"string","format":"uuid","description":"The source channel from which the raw news data originated."},"status":{"oneOf":[{"const":"pending","description":"Processing status of the job."},{"const":"running","description":"Processing status of the job."},{"const":"completed","description":"Processing status of the job."},{"const":"failed","description":"Processing status of the job."}],"description":"Processing status of the job."},"parameters":{"type":"string","description":"JSON string of parameters or prompts used for this LLM job."}},"description":"Request body for updating an existing LLM job.","required":[]},"IPoliticalNewsCrawlerLlmJobResult.IRequest":{"type":"object","properties":{"content_type":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Filter by content type for the results to return.\n\nOptional string filter."},"created_after":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Filter by creation date; results created after this timestamp are included.\n\nOptional ISO 8601 date-time string."},"created_before":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Filter by creation date; results created before this timestamp are included.\n\nOptional ISO 8601 date-time string."},"page":{"oneOf":[{"type":"number","minimum":1},{"type":"null"}],"description":"Pagination: current page number.\n\nDefault: 1"},"limit":{"oneOf":[{"type":"number","minimum":1},{"type":"null"}],"description":"Pagination: number of items per page.\n\nDefault: 20"}},"description":"Request type for searching LLM job results with filters and pagination.","required":[]},"IPoliticalNewsCrawlerLlmJobResult":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"llm_job_id":{"type":"string","format":"uuid","description":"Associated LLM job's political_news_crawler_llm_jobs.id.\n\nUUID format as per Prisma schema."},"content_type":{"type":"string","description":"Type of generated content, e.g., 'summary', 'highlight', 'analysis'.\n\nIndicates the nature of the processed content."},"content_text":{"type":"string","description":"Generated content text by the LLM.\n\nContains the full textual data of the processed content."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the output was created.\n\nDateTime in RFC 3339 / ISO 8601 format with timezone."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when the output was last updated.\n\nDateTime in RFC 3339 / ISO 8601 format with timezone."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp, null if not deleted.\n\nOptional timestamp indicating logical deletion."}},"required":["id","llm_job_id","content_type","content_text","created_at","updated_at"],"description":"LLM results store the output content generated by LLM jobs, including summaries, highlights, and analyses. This model links back to the originating LLM job and preserves output details for retrieval and audit purposes.\n\n @namespace Processing\n @author AutoBE - https://github.com/wrtnlabs/autobe"},"IPoliticalNewsCrawlerLlmJobResult.ICreate":{"type":"object","properties":{"llm_job_id":{"type":"string","format":"uuid","description":"Associated LLM job's political_news_crawler_llm_jobs.id.\n\nUUID format required."},"content_type":{"type":"string","description":"Type of generated content, e.g., 'summary', 'highlight', 'analysis'.\n\nMandatory content type string."},"content_text":{"type":"string","description":"Generated content text by the LLM.\n\nFull text content to store."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the content is generated.\n\nISO 8601 date-time string format."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when the content was last updated.\n\nISO 8601 date-time string format."}},"required":["llm_job_id","content_type","content_text","created_at","updated_at"],"description":"Create request schema for new LLM job result record."},"IPoliticalNewsCrawlerLlmJobResult.IUpdate":{"type":"object","properties":{"llm_job_id":{"type":"string","format":"uuid","description":"Associated LLM job's political_news_crawler_llm_jobs.id.\n\nUUID format, optional for update."},"content_type":{"type":"string","description":"Type of generated content.\n\nOptional string for update."},"content_text":{"type":"string","description":"Generated content text.\n\nOptional full text for update."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the content is generated.\n\nOptional ISO 8601 string."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when the content was last updated.\n\nOptional ISO 8601 string."}},"required":[],"description":"Update request schema for LLM job result record."},"IPoliticalNewsCrawlerProcessingMetadataArray":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerProcessingMetadata"},"description":"Array of processing metadata entries."},"IPoliticalNewsCrawlerProcessingMetadataICreate":{"type":"object","properties":{"llm_job_id":{"type":"string","format":"uuid","description":"Associated LLM job's unique identifier (UUID)."},"metadata_key":{"type":"string","description":"Key name of the metadata attribute."},"metadata_value":{"type":"string","description":"Value associated with the metadata attribute."}},"required":["llm_job_id","metadata_key","metadata_value"],"description":"Creation object for a processing metadata entry representing key-value pairs linked to an LLM job."},"IPoliticalNewsCrawlerProcessingMetadata":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Unique identifier for the metadata entry."},"llm_job_id":{"type":"string","format":"uuid","description":"Associated LLM job's unique identifier (UUID)."},"metadata_key":{"type":"string","description":"Key name of the metadata attribute."},"metadata_value":{"type":"string","description":"Value associated with the metadata attribute."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the metadata entry was created."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when the metadata entry was last updated."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Timestamp when the metadata entry was soft deleted or null if active."}},"required":["id","llm_job_id","metadata_key","metadata_value","created_at","updated_at"],"description":"Processing metadata entry contains key-value pairs associated with an LLM job used to provide auxiliary contextual information for processing."},"IPoliticalNewsCrawlerProcessingMetadataIUpdateArray":{"type":"array","items":{"$ref":"#/components/schemas/IPoliticalNewsCrawlerProcessingMetadata"},"description":"Array of processing metadata entries for batch update."},"IPoliticalNewsCrawlerProcessingMetadata.IUpdate":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"The unique identifier of the metadata entry.\n\nThis ID is required to identify the record to update."},"metadata_key":{"type":"string","description":"Key name of the metadata attribute.\n\nDescribes the metadata context related to LLM processing."},"metadata_value":{"type":"string","description":"Value of the metadata attribute.\n\nContains the corresponding value for the key."},"created_at":{"type":"string","format":"date-time","description":"Creation timestamp of the metadata entry."},"updated_at":{"type":"string","format":"date-time","description":"Last update timestamp of the metadata entry."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp if applicable."}},"required":["id","metadata_key","metadata_value","created_at","updated_at"],"description":"Update container for processing metadata of LLM jobs.\n\nThis container represents the update DTO for processing metadata related to LLM jobs."},"IPoliticalNewsCrawlerPopularTopics.IRequest":{"type":"object","properties":{"page":{"oneOf":[{"type":"number"},{"type":"null"}],"description":"Pagination page number.\n\nOptional. If null, default pagination applies."},"limit":{"oneOf":[{"type":"number"},{"type":"null"}],"description":"Pagination limit per page.\n\nOptional. Default value is determined by server."},"search_term":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Search keyword for filtering topics by title.\n\nOptional."},"order_by":{"oneOf":[{"const":"createdAt"},{"const":"popularityScore"},{"type":"null"}],"description":"Sorting criterion for the list.\n\nPossible values: 'createdAt', 'popularityScore'\n\nOptional."},"order_direction":{"oneOf":[{"const":"asc"},{"const":"desc"},{"type":"null"}],"description":"Order direction.\n\nPossible values: 'asc' or 'desc'\n\nOptional."}},"description":"Request payload for searching popular political topics.","required":[]},"IPoliticalNewsCrawlerPopularTopic":{"type":"object","properties":{"id":{"type":"string","description":"Primary Key.\n\nUnique identifier of the popular political topic."},"topic_code":{"type":"string","description":"Unique code identifier for the political topic.\n\nCode uniquely identifying the political topic. Used for topic\ncategorization and mapping."},"title":{"type":"string","description":"Official title or name of the popular topic.\n\nHuman-readable title useful for displaying topic summaries and lists."},"description":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional detailed description or context about the popular topic.\n\nExtended description providing additional context or information\nabout the political topic."},"created_at":{"type":"string","format":"date-time","description":"Record creation timestamp.\n\nISO 8601 date-time string indicating when the record was created."},"updated_at":{"type":"string","format":"date-time","description":"Record last update timestamp.\n\nISO 8601 date-time string indicating when the record was last updated."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft deletion timestamp if applicable, otherwise null.\n\nISO 8601 date-time string marking when the record was deleted\n(soft delete). null means active."}},"required":["id","topic_code","title","created_at","updated_at"],"description":"Represents a popular political topic entity.\n\nThis entity contains unique identifiers, codes, titles, and optional descriptions to\ncategorize and track trending political topics.\n\nIt manages lifecycle metadata including creation, update, and optional soft deletion timestamps.\n"},"IPoliticalNewsCrawlerPopularTopic.ICreate":{"type":"object","properties":{"topic_code":{"type":"string","description":"Unique topic code identifier."},"title":{"type":"string","description":"Title of the topic."},"description":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional description providing additional context or details."}},"required":["topic_code","title"],"description":"Request payload for creating a new popular political topic."},"IPoliticalNewsCrawlerPopularTopics":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"A unique identifier for the popular political topic.\n\nThis ID uniquely distinguishes each popular political topic within the system and is used to reliably reference topics in relationships.\n\nFormat: UUID string."},"topic_code":{"type":"string","description":"Unique code for the political topic.\n\nThis code serves as an alternate unique identifier for the topic and must be unique across all topics. Used for indexing and quick lookups."},"title":{"type":"string","description":"The official title of the popular political topic.\n\nTitles should clearly identify the topic content and must be provided."},"description":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional description for the popular political topic.\n\nProvides additional context or detailed information about the topic.\n\nNullable to allow brief or minimal entries."},"created_at":{"type":"string","format":"date-time","description":"Timestamp marking when the topic record was created.\n\nRecords audit information about data creation times.\nFormat: ISO 8601 date-time string."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp marking when the topic record was last updated.\n\nTracks changes for concurrency and audit.\nFormat: ISO 8601 date-time string."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp. Null if not deleted.\n\nMarks logical removal status.\nFormat: ISO 8601 date-time string or null."}},"required":["id","topic_code","title","created_at","updated_at"],"description":"Representation of a popular political topic as recorded in the political_news_crawler_popular_topics table.\n\nThis entity includes unique identifiers such as UUID and topic code, descriptive title and optional description, and audit timestamps for creation, update, and optional soft deletion.\n\nPopular topics serve as reference points for aggregating popularity scores and news mentions relevant to South Korean political news.\n\nSoft delete capability allows logical removal while preserving historical correctness."},"IPoliticalNewsCrawlerPopularTopic.IUpdate":{"type":"object","properties":{"topic_code":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Unique code identifier for the political topic.\n\nCode uniquely identifying the political topic. Used for topic\ncategorization and mapping."},"title":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Official title or name of the popular topic.\n\nHuman-readable title useful for displaying topic summaries and lists."},"description":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional detailed description or context about the popular topic.\n\nExtended description providing additional context or information\nabout the political topic."}},"required":[],"description":"Update data for a popular political topic.\n\nAllows modification of code, title, and description fields.\n\nSoft-deletions or audit timestamps are managed separately, not here.\n"},"IPoliticalNewsCrawlerPopularityScore.IRequest":{"type":"object","properties":{"page":{"oneOf":[{"type":"number"},{"type":"null"}],"description":"Page number.\n\nOptional pagination parameter indicating the page to retrieve."},"limit":{"oneOf":[{"type":"number"},{"type":"null"}],"description":"Limitation of records per a page.\n\nOptional pagination parameter limiting items per page.\nDefault is 100 if omitted."},"scoreMin":{"oneOf":[{"type":"number"},{"type":"null"}],"description":"Filter by popularity score greater than or equal.\n\nOptional filter to retrieve popularity scores with scores above this value."},"scoreMax":{"oneOf":[{"type":"number"},{"type":"null"}],"description":"Filter by popularity score less than or equal.\n\nOptional filter to retrieve popularity scores with scores below this value."},"snapshotAtStart":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Filter by snapshot date - start.\n\nOptional timestamp to filter scores by snapshot start time."},"snapshotAtEnd":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Filter by snapshot date - end.\n\nOptional timestamp to filter scores by snapshot end time."}},"required":[],"description":"Request parameters for popularity scores list filtering, sorting, and pagination."},"IPoliticalNewsCrawlerPopularityScores":{"type":"object","properties":{"id":{"type":"string","description":"Primary Key.\n\nUnique identifier of the popularity score snapshot record."},"political_news_crawler_popular_topic_id":{"type":"string","description":"Referenced popular topic's ID.\n\nForeign key to the associated popular topic."},"score":{"type":"number","description":"Calculated popularity score for the topic at this snapshot."},"decay_factor":{"type":"number","description":"Decay factor applied to the score based on the age of the topic mention."},"snapshot_at":{"type":"string","format":"date-time","description":"Timestamp when this popularity score snapshot was taken."},"created_at":{"type":"string","format":"date-time","description":"Record creation timestamp."},"updated_at":{"type":"string","format":"date-time","description":"Record last update timestamp."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft deletion timestamp if applicable, otherwise null."}},"required":["id","political_news_crawler_popular_topic_id","score","decay_factor","snapshot_at","created_at","updated_at"],"description":"Snapshot record capturing popularity scores for political topics."},"IPoliticalNewsCrawlerTopicMentions.IRequest":{"type":"object","properties":{"limit":{"type":"integer","format":"int32","description":"Number of items to retrieve in the page."},"offset":{"type":"integer","format":"int32","description":"Pagination offset for items."},"search":{"type":"string","description":"Search string to filter mentions context."},"political_news_crawler_popular_topic_id":{"type":"string","format":"uuid","description":"Foreign key to the popular topic entity."},"political_news_crawler_crawled_news_id":{"type":"string","format":"uuid","description":"Foreign key to the crawled news entity."}},"required":[],"description":"Request parameters for querying topic mentions with filtering, searching, and pagination."},"IPoliticalNewsCrawlerTopicMentions":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"political_news_crawler_popular_topic_id":{"type":"string","format":"uuid","description":"Referenced popular topic's Identifier."},"political_news_crawler_crawled_news_id":{"type":"string","format":"uuid","description":"Referenced crawled news item's Identifier."},"mention_context":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional text snippet or context where the topic is mentioned within the article."},"created_at":{"type":"string","format":"date-time","description":"Record creation timestamp."},"updated_at":{"type":"string","format":"date-time","description":"Record last update timestamp."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft deletion timestamp if applicable, otherwise null."}},"required":["id","political_news_crawler_popular_topic_id","political_news_crawler_crawled_news_id","created_at","updated_at"],"description":"Subsidiary table recording mentions of political topics within news articles. Establishes many-to-one relationships with both topics and crawled news records. Supports detailed traceability of topic references and feeds data for popularity calculations. Managed as supporting entity for topic analytics."},"IPoliticalNewsCrawlerTopicMentions.IUpdate":{"type":"object","properties":{"mention_context":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Text snippet of the mention to update."}},"required":[],"description":"Used for updating a topic mention's content snippet. All fields are optional and nullable."},"IPoliticalNewsCrawlerApiAccessLog.IRequest":{"type":"object","properties":{"limit":{"type":"integer","format":"int32","description":"Number of log entries to retrieve per page."},"offset":{"type":"integer","format":"int32","description":"Pagination offset for log entries."},"search":{"type":"string","description":"Search keyword to filter API access logs by path or client info."},"http_method":{"type":"string","description":"Filter logs by HTTP method (e.g., GET, POST)."},"path":{"type":"string","description":"Filter logs by API endpoint path."},"status_code":{"type":"integer","format":"int32","description":"Filter logs by HTTP status code."},"client_ip":{"type":"string","description":"Filter logs by client's IP address."},"user_agent":{"type":"string","description":"Filter logs by client's user agent string."},"date_from":{"type":"string","format":"date-time","description":"Start date/time for logs filtering (ISO 8601)."},"date_to":{"type":"string","format":"date-time","description":"End date/time for logs filtering (ISO 8601)."}},"required":[],"description":"Request parameters for searching and paginating API access logs."},"IPoliticalNewsCrawlerApiAccessLog":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"http_method":{"type":"string","description":"HTTP request method used in the API call."},"path":{"type":"string","description":"API endpoint path being accessed."},"status_code":{"type":"integer","format":"int32","description":"HTTP response status code returned to the client."},"client_ip":{"type":"string","description":"IP address of the client making the API request."},"user_agent":{"type":"string","description":"User agent string of the client or application making the request."},"duration_ms":{"type":"integer","format":"int32","description":"Duration of the API request processing in milliseconds."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the log entry was created."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when the log entry was last updated."}},"required":["id","http_method","path","status_code","client_ip","user_agent","duration_ms","created_at","updated_at"],"description":"Records detailed log entries for every API access to track client requests, including request method, path, response status, client IP address, user agent, request duration in milliseconds, and timestamp. Supports comprehensive API usage analytics and operational monitoring."},"IPoliticalNewsCrawlerApiErrorLog.IRequest":{"type":"object","description":"Request type for filtering and paginating API error logs.","properties":{"path":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Filter by API path pattern for the error logs."},"error_code":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Filter errors by error code."},"start_date":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Filter logs within this start time (inclusive)."},"end_date":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Filter logs within this end time (inclusive)."},"page":{"oneOf":[{"type":"integer","minimum":0},{"type":"null"}],"description":"Pagination page number."},"limit":{"oneOf":[{"type":"integer","minimum":0},{"type":"null"}],"description":"Number of items per page."},"sort_order":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Sort order for returned items."}},"required":[]},"IPoliticalNewsCrawlerApiErrorLog":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"path":{"type":"string","description":"API endpoint path where the error occurred."},"error_code":{"type":"string","description":"Error code identifying the type of API error."},"error_message":{"type":"string","description":"Descriptive error message to assist debugging."},"client_ip":{"type":"string","description":"IP address of the client causing the error."},"user_agent":{"type":"string","description":"User agent string of the client application."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the error log was created."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when the error log was last updated."}},"required":["id","path","error_code","error_message","client_ip","user_agent","created_at","updated_at"],"description":"Captures detailed records of API errors, including the API path, error code, error message, client IP, user agent, occurrence timestamp, and update timestamp. Enables error analysis and system troubleshooting for API endpoints."},"IPoliticalNewsCrawlerApiUsageMetricRequest":{"type":"object","description":"Request type for filtering API usage metrics with pagination and sort options.","properties":{"http_method":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"HTTP method to filter usage metrics."},"path":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"API path to filter usage metrics."},"period_start":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Start datetime for the metric aggregation period."},"period_end":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"End datetime for the metric aggregation period."},"page":{"oneOf":[{"type":"integer","minimum":0},{"type":"null"}],"description":"Page number for pagination."},"limit":{"oneOf":[{"type":"integer","minimum":0},{"type":"null"}],"description":"Number of items per page."},"sort_order":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Sort order direction."}},"required":[]},"IPoliticalNewsCrawlerApiUsageMetric":{"type":"object","properties":{"id":{"type":"string","description":"Unique identifier.\n\nThis ID defines each unique metric record in the API usage metrics."},"http_method":{"type":"string","description":"HTTP method for the API call aggregation.\n\nDefines the request method such as GET, POST, etc."},"path":{"type":"string","description":"Path of the API endpoint.\n\nThe endpoint path being aggregated."},"period_start":{"type":"string","format":"date-time","description":"Start time of the aggregation period.\n\nISO 8601 date-time representation marking aggregation window start."},"period_end":{"type":"string","format":"date-time","description":"End time of the aggregation period.\n\nISO 8601 date-time representation marking aggregation window end."},"total_calls":{"type":"integer","description":"Total number of API calls within the aggregation period."},"max_response_ms":{"type":"integer","description":"Maximum response time in milliseconds.\n\nThe longest duration for a single API call."},"avg_response_ms":{"type":"integer","description":"Average response time in milliseconds.\n\nRepresents the mean duration of API calls."},"created_at":{"type":"string","format":"date-time","description":"Creation timestamp of this record.\n\nISO 8601 date-time of record insertion."},"updated_at":{"type":"string","format":"date-time","description":"Last update timestamp of this record.\n\nISO 8601 date-time of last modification."}},"required":["id","http_method","path","period_start","period_end","total_calls","max_response_ms","avg_response_ms","created_at","updated_at"],"description":"Represents aggregated usage metrics of API calls over defined periods.\n\nEach record includes total calls, maximum and average response times,\nassociated HTTP method, path, and timestamps for aggregation."},"IPoliticalNewsCrawlerCrawlAlertRequest":{"type":"object","properties":{"crawl_source_id":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional filter for crawl source IDs."},"alert_type":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional filter for alert types, e.g., 'ban_detected'.\n\nAllows filtering alerts by their event classification."},"severity":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional filter for severity levels such as 'info', 'warning', 'critical'."},"page":{"oneOf":[{"type":"integer","minimum":0},{"type":"null"}],"description":"Pagination - current page number."},"limit":{"oneOf":[{"type":"integer","minimum":1},{"type":"null"}],"description":"Pagination - number of records per page."}},"required":[],"description":"Represents filtering and pagination parameters for retrieving crawl alerts.\n\nIncludes optional fields for crawl source identification, alert type, severity level, and paging controls."},"IPoliticalNewsCrawlerCrawlAlerts":{"type":"object","properties":{"id":{"type":"string","description":"Unique identifier."},"crawl_source_id":{"type":"string","description":"Crawl source identifier that generated this alert."},"alert_type":{"type":"string","description":"Type of alert event.\n\nExamples include 'ban_detected', 'network_error', 'throttle_warning'."},"message":{"type":"string","description":"Human-readable message describing the alert.\n\nProvides operational context and details."},"severity":{"type":"string","description":"Severity level of the alert.\n\nValues include 'info', 'warning', 'critical'."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when alert was created."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when alert was last updated."}},"required":["id","crawl_source_id","alert_type","message","severity","created_at","updated_at"],"description":"Represents an alert event related to crawling.\n\nThis contains details about the alert type, message, severity level, and\nassociated crawl source provenance."},"IPoliticalNewsCrawlerCrawlAlerts.ICreate":{"type":"object","properties":{"crawl_source_id":{"type":"string","description":"Crawl source identifier.\n\nRequired to link alert to source."},"alert_type":{"type":"string","description":"Alert event type.\n\nExamples include 'ban_detected', 'network_error', 'throttle_warning'."},"message":{"type":"string","description":"Alert message.\n\nDetailed description of the alert event."},"severity":{"oneOf":[{"const":"info","description":"Alert severity level.\n\nMust be one of 'info', 'warning', or 'critical'."},{"const":"warning","description":"Alert severity level.\n\nMust be one of 'info', 'warning', or 'critical'."},{"const":"critical","description":"Alert severity level.\n\nMust be one of 'info', 'warning', or 'critical'."}],"description":"Alert severity level.\n\nMust be one of 'info', 'warning', or 'critical'."}},"required":["crawl_source_id","alert_type","message","severity"],"description":"Information needed to create a crawl alert event.\n\nIncludes required identifiers and metadata about the alert type,\nmessage content, and severity level."},"IPoliticalNewsCrawlerCrawlAlerts.IUpdate":{"type":"object","properties":{"alert_type":{"type":"string","description":"Type of alert event indicating the category, e.g., 'ban_detected', 'network_error', 'throttle_warning'."},"message":{"type":"string","description":"Detailed description of the alert event and context for operational understanding."},"severity":{"oneOf":[{"const":"info","description":"Severity level of the alert such as 'info', 'warning', 'critical'."},{"const":"warning","description":"Severity level of the alert such as 'info', 'warning', 'critical'."},{"const":"critical","description":"Severity level of the alert such as 'info', 'warning', 'critical'."}],"description":"Severity level of the alert such as 'info', 'warning', 'critical'."}},"required":["alert_type","message","severity"],"description":"Request schema for updating political news crawler crawl alert. Defines alert type, message, and severity level."},"IPoliticalNewsCrawlerProcessingAlert.IRequest":{"type":"object","properties":{"alert_type":{"oneOf":[{"type":"string","description":"Filter alerts by type (e.g., 'llm_failure') to limit results."},{"type":"null"}],"description":"Filter alerts by type (e.g., 'llm_failure') to limit results."},"severity":{"oneOf":[{"const":"info","description":"Filter alerts by severity level, including 'info', 'warning', and 'critical'."},{"const":"warning","description":"Filter alerts by severity level, including 'info', 'warning', and 'critical'."},{"const":"critical","description":"Filter alerts by severity level, including 'info', 'warning', and 'critical'."},{"type":"null"}],"description":"Filter alerts by severity level, including 'info', 'warning', and 'critical'."},"message":{"oneOf":[{"type":"string","description":"Filter by partial or full alert message text content."},{"type":"null"}],"description":"Filter by partial or full alert message text content."},"page":{"oneOf":[{"type":"integer","minimum":0,"description":"Page number for pagination, defaults to 0 (first page)."},{"type":"null"}],"description":"Page number for pagination, defaults to 0 (first page)."},"limit":{"oneOf":[{"type":"integer","minimum":1,"description":"Number of records per page, defaults to 100."},{"type":"null"}],"description":"Number of records per page, defaults to 100."}},"required":[],"description":"Request schema for listing and filtering political news crawler processing alerts."},"IPoliticalNewsCrawlerProcessingAlert.ICreate":{"type":"object","properties":{"alert_type":{"type":"string","description":"Type of processing alert such as 'llm_failure', 'queue_overflow', 'retry_limit_reached'."},"message":{"type":"string","description":"Detailed description of the processing alert event for operational use."},"severity":{"oneOf":[{"const":"info","description":"Severity level of the alert (e.g., 'info', 'warning', 'critical')."},{"const":"warning","description":"Severity level of the alert (e.g., 'info', 'warning', 'critical')."},{"const":"critical","description":"Severity level of the alert (e.g., 'info', 'warning', 'critical')."}],"description":"Severity level of the alert (e.g., 'info', 'warning', 'critical')."}},"required":["alert_type","message","severity"],"description":"Request schema for creating political news crawler processing alert events."},"IPoliticalNewsCrawlerProcessingAlert":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Unique identifier for the processing alert."},"alert_type":{"type":"string","description":"Category of processing alert such as 'llm_failure', 'queue_overflow', 'retry_limit_reached'."},"message":{"type":"string","description":"Detailed description of the processing alert event for operational use."},"severity":{"oneOf":[{"const":"info","description":"Severity level of the alert (e.g., 'info', 'warning', 'critical')."},{"const":"warning","description":"Severity level of the alert (e.g., 'info', 'warning', 'critical')."},{"const":"critical","description":"Severity level of the alert (e.g., 'info', 'warning', 'critical')."}],"description":"Severity level of the alert (e.g., 'info', 'warning', 'critical')."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the alert was created."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp for last update of the alert."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp, null if not deleted."}},"required":["id","alert_type","message","severity","created_at","updated_at"],"description":"Represents a processing alert event record for the political news crawler backend system."},"IPoliticalNewsCrawlerProcessingAlert.IUpdate":{"type":"object","properties":{"alert_type":{"type":"string","description":"Category of processing alert such as 'llm_failure', 'queue_overflow', 'retry_limit_reached'."},"message":{"type":"string","description":"Detailed description of the processing alert event for operational use."},"severity":{"type":"string","description":"Severity level of the alert (e.g., 'info', 'warning', 'critical')."},"id":{"type":"string","format":"uuid","description":"Primary Key."},"created_at":{"type":"string","format":"date-time","description":"Metadata entry creation timestamp."},"updated_at":{"type":"string","format":"date-time","description":"Metadata entry last update timestamp."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp, null if not deleted."}},"required":[],"description":"Update data schema for editing existing processing alert. All fields are optional and nullable."},"IPoliticalNewsCrawlerApiAlert.IRequest":{"type":"object","properties":{"alert_type":{"type":"string","description":"Type of API alert event such as 'rate_limit_exceeded', 'endpoint_error', or 'error_spike'."},"message":{"type":"string","description":"Detailed message describing the API alert context."},"severity":{"type":"string","description":"Severity level of the alert such as 'info', 'warning', 'critical'."},"created_at_lt":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Query filter for alerts created before specified date."},"created_at_gt":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Query filter for alerts created after specified date."},"updated_at_lt":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Query filter for alerts updated before specified date."},"updated_at_gt":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Query filter for alerts updated after specified date."},"page":{"oneOf":[{"type":"integer"},{"type":"null"}],"description":"Page number for pagination."},"limit":{"oneOf":[{"type":"integer"},{"type":"null"}],"description":"Limit number of records per page."},"orderBy":{"type":"string","description":"Ordering field and direction, e.g., 'created_at desc'."}},"required":[],"description":"Request schema for paginated and filtered query of API alert records."},"IPoliticalNewsCrawlerApiAlert.ICreate":{"type":"object","properties":{"alert_type":{"type":"string","description":"Type of API alert event such as 'rate_limit_exceeded', 'endpoint_error', or 'error_spike'."},"message":{"type":"string","description":"Detailed message describing the API alert context."},"severity":{"type":"string","description":"Severity level of the alert such as 'info', 'warning', 'critical'."}},"required":["alert_type","message","severity"],"description":"Creation schema for a new API alert entry."},"IPoliticalNewsCrawlerApiAlert":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"alert_type":{"type":"string","description":"Type of API alert event such as 'rate_limit_exceeded', 'endpoint_error', or 'error_spike'."},"message":{"type":"string","description":"Detailed message describing the API alert context."},"severity":{"type":"string","description":"Severity level of the alert such as 'info', 'warning', 'critical'."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the alert was created."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when the alert was last updated."}},"required":["id","alert_type","message","severity","created_at","updated_at"],"description":"API alert entity storing system error notifications and status messages.\n\nThis entity records detailed information about operational events related to API subsystem errors.\n\nIt captures fields including alert type to identify the nature of the error, a descriptive message for context, severity level to prioritize alerts, and timestamps for creation and last update.\n\nThis structured data facilitates real-time monitoring and analysis of API performance and stability within the politicalNewsCrawler backend system."},"IPoliticalNewsCrawlerApiAlert.IUpdate":{"type":"object","properties":{"alert_type":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Type of API alert event.\n\n@example \"rate_limit_exceeded\""},"id":{"type":"string","format":"uuid","description":"Unique identifier of the API alert to update."},"message":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Detailed message describing the API alert.\n\n@example \"Exceeded rate limit of 1000 per minute\""},"severity":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Severity level such as 'info', 'warning', 'critical'.\n\n@example \"critical\""}},"required":["id"],"description":"Update data for ApiAlert that allows modification of alert_type, message and severity without changing the unique id."},"IPoliticalNewsCrawlerCrawlSources.ISummary":{"type":"object","properties":{"created_at":{"type":"string","format":"date-time","description":"Record creation timestamp."},"id":{"type":"string","format":"uuid","description":"Primary Key."},"is_active":{"type":"boolean","description":"Flag indicating whether the crawl source is active and enabled for crawling."},"source_code":{"type":"string","description":"Unique identifier code for the crawl source."},"source_url":{"type":"string","description":"The base URL of the crawl source website or API."}},"required":["id","source_code","source_url","is_active","created_at"],"description":"Summary view of the politicalNewsCrawler crawl source for listing purposes."},"IPoliticalNewsCrawlerCrawlPolicy.ISummary":{"type":"object","properties":{"ban_detection_enabled":{"type":"boolean","description":"Flag to enable detection and handling of bans during crawling."},"created_at":{"type":"string","format":"date-time","description":"Record creation timestamp."},"id":{"type":"string","format":"uuid","description":"Primary Key."},"max_crawl_frequency_minutes":{"type":"integer","description":"Maximum allowed crawl frequency in minutes."},"policy_name":{"type":"string","description":"Unique name identifier for the crawl policy."}},"required":["id","policy_name","max_crawl_frequency_minutes","ban_detection_enabled","created_at"],"description":"Summary view of the politicalNewsCrawler crawl policy optimized for list display."},"IPoliticalNewsCrawlerCrawlSchedule.ISummary":{"type":"object","properties":{"crawl_policy_id":{"type":"string","format":"uuid","description":"Reference to Crawl Policy. Reference id."},"crawl_source_id":{"type":"string","format":"uuid","description":"Reference to Crawling Source. Reference id."},"created_at":{"type":"string","format":"date-time","description":"Record creation timestamp."},"id":{"type":"string","format":"uuid","description":"Primary Key."},"is_enabled":{"type":"boolean","description":"Flag indicating if this schedule is enabled."},"schedule_expression":{"type":"string","description":"Cron expression defining the crawl schedule timing."}},"required":["id","crawl_source_id","crawl_policy_id","schedule_expression","is_enabled","created_at"],"description":"Summary view of the politicalNewsCrawler crawl schedule optimized for listing."},"IPoliticalNewsCrawlerGuests.ISummary":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"ip_address":{"type":"string","description":"IP address of the guest user."},"user_agent":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"User agent string presented by the guest."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the guest record was created."}},"required":["id","ip_address","created_at"],"description":"Summary records of political news crawler guest users with essential identification and creation timestamps."},"IPoliticalNewsCrawlerCrawlAttempt.ISummary":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"crawl_job_id":{"type":"string","format":"uuid","description":"Associated crawl job identifier."},"started_at":{"type":"string","format":"date-time","description":"Timestamp when this crawl attempt started."},"success":{"type":"boolean","description":"Indicator whether this crawl attempt was successful."}},"required":["id","crawl_job_id","started_at","success"],"description":"Summary records of crawl attempts containing essential identifiers and status."},"IPoliticalNewsCrawlerCrawledNews.ISummary":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"url":{"type":"string","description":"URL of the crawled news article."},"title":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Title of the news article, if available."},"published_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Publish timestamp of the news article, if known."}},"required":["id","url"],"description":"Summary records of crawled news articles including minimal metadata for display and identification."},"IPoliticalNewsCrawlerRawDataStorage.ISummary":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"storage_key":{"type":"string","description":"Unique key or path identifying storage location in cloud object storage (e.g., GCP or AWS S3)."},"file_format":{"type":"string","description":"Format of the raw data file such as JSON or XML for processing compatibility."},"file_size_bytes":{"type":"integer","format":"int32","description":"Size of the raw data file in bytes."},"crawl_timestamp":{"type":"string","format":"date-time","description":"Timestamp when the raw data was crawled, used for data freshness and scheduling."}},"required":["id","storage_key","file_format","file_size_bytes","crawl_timestamp"],"description":"Summary records summarizing raw data storage entities with key file attributes for efficient identification and listing."},"IPoliticalNewsCrawlerRawDataStorageLocalCacheFile.ISummary":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary key identifying the local cache file record."},"raw_data_storage_id":{"type":"string","format":"uuid","description":"Reference ID to the related raw data storage record."},"local_file_path":{"type":"string","description":"Filesystem path or identifier for the local cached file copy."},"file_size_bytes":{"type":"integer","description":"Size of the local cached file in bytes."},"ttl_expiration_at":{"type":"string","format":"date-time","description":"Datetime when the cached file expires and is due for deletion under TTL policy."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft delete timestamp indicating when the cached file was deleted, if applicable."},"created_at":{"type":"string","format":"date-time","description":"Creation timestamp record."},"updated_at":{"type":"string","format":"date-time","description":"Last update timestamp record."}},"required":["id","raw_data_storage_id","local_file_path","file_size_bytes","ttl_expiration_at","created_at","updated_at"],"description":"Summary information about a local cache file related to raw crawled data. Provides essential identifiers and metadata for quick access and management."},"IPoliticalNewsCrawlerProcessedContent.ISummary":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary key identifying the processed content record."},"raw_data_storage_id":{"type":"string","format":"uuid","description":"Foreign key linking to raw data storage."},"llm_job_id":{"oneOf":[{"type":"string","format":"uuid"},{"type":"null"}],"description":"Foreign key to associated LLM job, can be null if not linked."},"content_type":{"type":"string","description":"Type of processed content, e.g., summary, highlight, or analysis."},"generation_timestamp":{"type":"string","format":"date-time","description":"Timestamp when this content was generated."}},"required":["id","raw_data_storage_id","content_type","generation_timestamp"],"description":"Summary of processed content records including basic identification, type and generation time."},"IPoliticalNewsCrawlerLlmJobs.ISummary":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Unique identifier for the LLM job."},"crawl_source_id":{"type":"string","format":"uuid","description":"Source channel ID the raw news came from."},"status":{"type":"string","description":"Status string, e.g., pending, running, completed, failed."},"created_at":{"type":"string","format":"date-time","description":"Timestamp job was created."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp of last job update."}},"required":["id","crawl_source_id","status","created_at","updated_at"],"description":"Summary information of LLM job including identification and status timestamps."},"IPoliticalNewsCrawlerPopularityScore.ISummary":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary key identifying the popularity score snapshot."},"political_news_crawler_popular_topic_id":{"type":"string","format":"uuid","description":"Reference to the popular topic ID."},"score":{"type":"number","format":"double","description":"Computed score indicating popularity."},"decay_factor":{"type":"number","format":"double","description":"Decay factor applied to score for time decay."},"snapshot_at":{"type":"string","format":"date-time","description":"Timestamp of the popularity score snapshot."}},"required":["id","political_news_crawler_popular_topic_id","score","decay_factor","snapshot_at"],"description":"Summary data for a popularity score snapshot related to a specific popular topic."},"IPoliticalNewsCrawlerTopicMentions.ISummary":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"mention_context":{"oneOf":[{"type":"string"},{"type":"null"}],"description":"Optional text snippet or context where the topic is mentioned within the article."}},"required":["id"],"description":"A summary type for topic mentions containing minimal identification and context."},"IPoliticalNewsCrawlerApiAccessLog.ISummary":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"http_method":{"type":"string","description":"HTTP request method used in the API call."},"path":{"type":"string","description":"API endpoint path being accessed."},"status_code":{"type":"integer","format":"int32","description":"HTTP response status code returned to the client."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the log entry was created."}},"required":["id","http_method","path","status_code","created_at"],"description":"A summary type containing essential API access log information for listing and overview."},"IPoliticalNewsCrawlerApiErrorLog.ISummary":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"path":{"type":"string","description":"API endpoint path where the error occurred."},"error_code":{"type":"string","description":"Error code identifying the type of API error."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when the error log was created."}},"required":["id","path","error_code","created_at"],"description":"A summary type providing brief error log info for listing and monitoring."},"IPoliticalNewsCrawlerApiUsageMetricSummary":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key."},"http_method":{"type":"string","description":"HTTP method for which metrics are aggregated."},"path":{"type":"string","description":"API endpoint path for which metrics are aggregated."},"period_start":{"type":"string","format":"date-time","description":"Start timestamp of the aggregation period."},"period_end":{"type":"string","format":"date-time","description":"End timestamp of the aggregation period."},"total_calls":{"type":"integer","format":"int32","description":"Total number of API calls observed in the aggregation period."},"max_response_ms":{"type":"integer","format":"int32","description":"Maximum response time in milliseconds recorded during the period."},"avg_response_ms":{"type":"integer","format":"int32","description":"Average response time in milliseconds over the period."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when this aggregated record was created."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when this aggregated record was last updated."}},"required":["id","http_method","path","period_start","period_end","total_calls","max_response_ms","avg_response_ms","created_at","updated_at"],"description":"Aggregated API usage metrics capturing total counts of API calls by method and path over specific time periods, including maximum response times and average durations. Supports performance monitoring and traffic analysis for API endpoints."},"IPoliticalNewsCrawlerCrawlAlert":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Primary Key.\n\nUnique identifier of this crawl alert.\n\nFormat: UUID string."},"crawl_source_id":{"type":"string","format":"uuid","description":"Referenced crawl source's ID which triggered the alert.\n\nFormat: UUID string."},"alert_type":{"type":"string","description":"Type of alert event indicating category, e.g., 'ban_detected', 'network_error', 'throttle_warning'."},"message":{"type":"string","description":"Detailed description of the alert event providing operational context."},"severity":{"type":"string","description":"Severity level such as 'info', 'warning', or 'critical' indicating urgency."},"created_at":{"type":"string","format":"date-time","description":"Timestamp when alert record was created."},"updated_at":{"type":"string","format":"date-time","description":"Timestamp when alert record was last updated."},"deleted_at":{"oneOf":[{"type":"string","format":"date-time"},{"type":"null"}],"description":"Soft deletion timestamp if the record is deleted.\n\nNullable."}},"required":["id","crawl_source_id","alert_type","message","severity","created_at","updated_at"],"description":"A crawl alert record represents events such as bans or errors detected during crawling. It captures detailed context to support operational monitoring and troubleshooting.\n\nThis entity is associated with a crawl source and indicates the type and severity of the alert with timestamps.\n\nProperties include declarative alert type, descriptive text message, urgency level, and audit information.\n\nSoft deletion is supported."},"IPoliticalNewsCrawlerCrawlAlert.ICreate":{"type":"object","properties":{"crawl_source_id":{"type":"string","format":"uuid","description":"Referenced crawl source ID which triggered the alert.\nRequired during creation."},"alert_type":{"type":"string","description":"Type of alert event.\nRequired during creation."},"message":{"type":"string","description":"Detailed message describing alert.\nRequired during creation."},"severity":{"type":"string","description":"Severity level (\"info\", \"warning\", \"critical\").\nRequired during creation."}},"required":["crawl_source_id","alert_type","message","severity"],"description":"Properties required to create a new crawl alert. All fields are required without timestamps since they are auto-generated."},"IPoliticalNewsCrawlerCrawlAlert.IUpdate":{"type":"object","properties":{"alert_type":{"type":"string","description":"Type of alert event.\nOptional."},"message":{"type":"string","description":"Detailed message describing alert.\nOptional."},"severity":{"type":"string","description":"Severity level (\"info\", \"warning\", \"critical\").\nOptional."}},"required":[],"description":"Properties used to update an existing crawl alert record. All fields are optional."},"IPoliticalNewsCrawlerCrawlAlert.ISummary":{"type":"object","properties":{"id":{"type":"string","format":"uuid","description":"Unique identifier of the alert."},"alert_type":{"type":"string","description":"Type of alert event."},"message":{"type":"string","description":"Detailed message content."},"severity":{"type":"string","description":"Severity level."},"created_at":{"type":"string","format":"date-time","description":"Creation timestamp."}},"required":["id","alert_type","message","severity","created_at"],"description":"Summary version of crawl alert record with essential identification and status fields for list views."},"IPoliticalNewsCrawlerApiAlert.ISummary":{"type":"object","properties":{"id":{"type":"string","description":"Unique identifier of the API alert."},"alert_type":{"type":"string","description":"API alert event type such as 'rate_limit_exceeded', 'endpoint_error', 'error_spike'."},"message":{"type":"string","description":"Short message describing the API alert."},"severity":{"type":"string","description":"Severity of the alert ('info', 'warning', 'critical')."},"created_at":{"type":"string","format":"date-time","description":"Timestamp of alert creation."}},"required":["id","alert_type","message","severity","created_at"],"description":"Summary version of API alert record including unique id, event type, message, severity level, and creation time."}}}},"created_at":"2025-09-14T06:40:00.815Z","completed_at":"2025-09-14T07:21:12.029Z","step":0}]